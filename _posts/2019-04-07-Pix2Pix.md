---
layout: post
title: Pix2Pix(Image-to-Image Translation with Conditional Adversarial Networks)
author: YouWon
categories: [Generative Model]
tags: [GAN, Machine Learning, CNN, Generative Model, Paper_Review]
---

---

이 글에서는 Pix2Pix(Image-to-Image Translation with Conditional Adversarial Networks)을 알아보도록 한다.  
Pix2Pix는 Berkeley AI Research(BAIR) Lab 소속 Phillip Isola 등의 연국자가 2016 최초 발표(2018년까지 업데이트됨)한 논문이다.

<center><img src="/public/img/2019-04-07-Pix2Pix/01.png" width="100%"></center>

Pix2Pix는 Image to Image Translation을 다루는 논문이다. 이러한 변환은 Colorization(black & white $\rightarrow$ color image) 등을 포함하는데, Pix2Pix에서는 이미지 변환 문제를 colorization처럼 한 분야에만 국한되지 않고 좀 더 일반화한 문제를 풀고자 했다. 그리고 그 수단으로써 Conditional adversarial nets를 사용했다.



논문을 적절히 번역 및 요약하는 것으로 시작한다. 많은 부분을 생략할 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.

---

# Pix2Pix(Image-to-Image Translation with Conditional Adversarial Networks)

논문 링크: **[Pix2Pix(Image-to-Image Translation with Conditional Adversarial Networks)](https://arxiv.org/abs/1611.07004)**

## 초록(Abstract)



---

## 서론(Introduction)



---

## 관련 연구(Related Works)



---

## 방법(Method)



### 목적함수(Objective)



### 네트워크 구조(Network architectures)

#### Generator with skips

#### Markovian discriminator(PatchGAN)

### 최적화 및 추론(Optimization and inference)

---

## 실험(Experiments)



---

## 결론(Conclusion)




---

## 참고문헌(References)

논문 참조!

--- 

# 보충 설명

##

---

# 이후 연구들

흠

---
