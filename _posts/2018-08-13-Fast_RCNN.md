---
layout: post
title: Fast R-CNN
author: Youyoung
categories: Paper_Review
tags: [Keras, Detection, CNN, Paper_Review]
---

### Fast RCNN  
> 이 포스트는 Ross Girshick의 Fast R-CNN 논문을 리뷰하는 것을 목적으로 한다.  

#### Background  
이 알고리즘의 핵심은 R-CNN의 여러 단점들을 상당 부분 해소했다는 점이다.  
R-CNN의 단점은 아래와 같았다.
> 1. **Training is a multi-stage pipeline**  
> CNN과 SVM, 그리고 Bounding Box Regressor까지 다 따로 따로 학습되었기 때문에,  
> 효율적이지 못한 학습 과정을 지니고 있었다.  
>   
> 2. **Training is expensive**  
> 각각의 object proposal에 대해서 feature가 추출되기 때문에 이 많은 feature를  
> 저장하는 데에는 많은 비용이 수반되었다.  
> 3. **Object detection is slow**  
> 모든 ROI는 하나 씩 CNN을 통과해야 했기 때문에 굉장히 느렸다.  
> 즉, sharing computation이 없었다는 뜻이다.  

#### 전체 파이프라인 구조  

<center><img src="/public/img/Deep_Learning/2018_08_13_Fast_RCNN/01.PNG" width="100%"></center>  
논문에 있는 위 그림을 조금 더 자세히 표현해 보자면 아래와 같다.  
<center><img src="/public/img/Deep_Learning/2018_08_13_Fast_RCNN/02.PNG" width="100%"></center>  

마지막 부분을 먼저 보면,  
각각의 ROI feature vector는 여러 개의 FC layers에 들어간 후, 2개의 output으로 분화된다. 첫 번째는 K+1의 길이를 가진 class 분류 벡터에 softmax 활성화 함수를 적용하여 class를 예측하고, (K = 총 class의 개수, background까지 추가하여 K+1이 됨) 두 번재는 각각의 class에 대해 4개의 bbox 값을 output으로 반환한다.  

**ROI pooling layer**는 각기 다른 비율과 크기를 지닌 이미지를 그 비율을 유지한 상태로 이미지를 축소시키는 기능을 갖고 있을 뿐만 아니라, 수많은 ROI를 동시에 feature map에 투사하여 fixed size의 small feature map들을 반환하게 된다.  

위 그림처럼 ROI pooling은 원하는 크기에 맞추어 (예: 7X7) 이미지를 축소시키는데, 
여기서는 max pooling을 사용하여 각 ROI에 맞는 이미지의 핵심 정보를 추출하였다.  
Pooling 작업은 각각의 feature map channel에 대해 독립적으로 수행된다.  

참고로 Deep CNN에서는 VGG16을 사용하였는데, include_top = FALSE 옵션을 주어, 
아래 FC layer들을 모두 제거하고 이를 통해 feature map을 반환하며, 마지막 max pooling 대신 ROI pooling layer를 배치하게 된다.  

#### Training  
Fast RCNN에서는 더욱 효과적인 training method가 제안되었는데, 이는 feature sharing이라는 큰 특징을 지닌다.  
SGD 미니배치들이 계층적으로 추출(sampling)되는데 그 순서는 이미지 -> ROI이다. 
먼저 N개의 이미지가 하나의 미니배치로써 추출되고 나면, R/N개의 ROI가 각 이미지로부터 추출된다. 즉, 결과적으로 N개의 이미지와 R개의 ROI가 추출되는 셈이다.  
같은 이미지에 대응하는 ROI는 forward & backward pass에서 computation과 memeory를 공유하기 때문에, training 속도가 매우 빠르다. 이론 상으로는 이러한 ROI가 correlated 되어 있기 때문에 training convergence를 느리게 만들 수 있는데, 실제로 N=2, R=128로 학습을 해본 결과 큰 문제가 없는 것으로 판명되었다.  

#### Multi-task loss  
본 논문에서는 classification loss와 localization loss를 형식 상 합쳐서 (concatenate) 동시에 학습이 진행되도록 설계하였다. 전체 Loss Function은 아래와 같은데,  
K+1 category에 대해,  
$p = (p_0, p_1, ... , p_K)$  
$u$ = ground-truth class (정답 레이블)  
$v$ = grund-truth bounding box regression target (bbox 좌표 정답))  
$t^u = (t_x^k, t_y^k, t_w^k, t_h^k)$ - bounding box regression offset  

$$L(p, u, t^u, v) = L_{classification}(p, u) + \lambda[u \geq 1] * L_{localization}(t^u, v)$$  

당연히 위 식은 다시 2개로 쪼개서 설명해야 한다.  
$$L_{classification} = -log(p, u)$$  
위 식은 true class u에 대한 log loss function이다.  

$x = t_i^u - v_i$ 일 때,
$L_{localizaion} = \sum_{i\in{x,y,w,h}} 0.5 x^2$ if $|x| < 1$
$L_{localizaion} = \sum_{i\in{x,y,w,h}}|x| - 0.5$ otherwise
  
인데, 위 함수를 $smooth_{L_i}$라고 한다.  
위 함수는 그림으로 그려보면 아래와 같이 생겼는데,  
<center><img src="/public/img/Deep_Learning/2018_08_13_Fast_RCNN/03.PNG" width="60%"></center>  
outlier에 상당히 robust하기 때문에 learning rate 튜닝 과정 속에서 gradient가 explode하는 위험성을 줄여준다.  
  

The Iversion bracket Indicator Function이라고 불리는 $[u\geq1]$은 background class일 때 0이 되고 u가 1보다 클 때(실제 object가 있을 때) 1을 반환하는 함수이다. 즉, 배경으로 판별되었을 경우 이를 0으로 만들어 굳이 weight를 학습시키지 않는다는 의미이다.  

$\lambda$의 경우 2개의 loss 사이의 balance를 조절하는 하이퍼파라미터인데, 여기서는 1을 사용하였다.  
