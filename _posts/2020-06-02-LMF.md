---
layout: post
title: Logistic Matrix Factorization 설명
author: Youyoung
categories: Machine_Learning
tags: [Machine_Learning, Recommendation System, Paper_Review]
---

본 글에서는 2014년에 Spotify에서 소개한 알고리즘인 **Logistic Matrix Factorization**에 대해 설명할 것이다. 먼저 논문 리뷰를 진행한 후, **Implicit** 라이브러리를 통해 학습하는 과정을 소개할 것이다.

---
## 1. Logistic Matrix Factorization for Implicit Feedback Data 논문 리뷰  
웹 상에서 얻을 수 있는 데이터는 대부분 암시적 피드백의 형태이기 때문에, 협업 필터링(Collaborative Filtering) 방법론에서도 이러한 암시적인 경우에 대응할 수 있는 알고리즘의 필요성이 대두되었다. 본 모델은 암시적 피드백에 적합한 새로운 확률론적 행렬 분해 기법인 **LMF**를 소개한다.  

<center>(전략)</center>

### 1.1. Problem Setup and Notation  
암시적 피드백은 클릭, 페이지 뷰, 미디어 스트리밍 수 등을 예로 들 수 있는데, 모든 피드백은 non-negative의 값을 가지게 된다. 기본 기호는 아래와 같다.  

$U = (u_1, ..., u_n)$: n명의 User  
$I = (i_1, ..., i_n)$: m개의 Item  
$R = (r_{ui})_{n \times m}$: User-Item 관측값 행렬  
$r_{ui}$: User $u$가 Item $i$와 몇 번 상호작용 했는지(예: 구매횟수)  

<center>(중략)</center>

### 1.2. Logistic MF  
$f$를 잠재 벡터의 차원이라고 할 때, 관측값 행렬 $R$은 $X_{n \times f}, Y_{m \times f}$라는 2개의 행렬로 분해될 수 있다. 이 때 $X$의 행은 User의 잠재 벡터를 의미하고, $Y$의 행은 Item의 잠재 벡터를 의미한다. 이전의 방법에서는 weighted RMSE를 최소화하는 방법으로 행렬 분해를 진행했는데, 본 논문에서는 확률론적인 접근법을 시도하였다.  

$l_{u, i}$를 User $u$가 Item $i$와 상호작용하기로 결정한 사건이라고 하자. 이 때 우리는 이러한 사건이 일어날 조건부 확률의 분포가 User와 Item의 잠재 벡터와 그에 상응하는 bias의 내적의 합이 parameter의 역할을 하는 **Logistic Function**에 따라서 결정되는 것으로 생각할 수 있다.  

$$p(l_{ui} | x_u, y_i, \beta_i, \beta_j) = \frac{exp(x_u y^T_i + \beta_u + \beta_i)}{1 + exp(x_u y^T_i + \beta_u + \beta_i)}$$  

$\beta$항은 물론 bias를 나타내며, User와 Item 각각의 행동 분산을 의미하게 된다. $r_{ui}$가 0이 아닐 때 이를 positive feedback으로, 0일 때를 negative feedback으로 간주하자. 이 때 우리는 **Confidence**를 정의할 수 있는데, 이를 $c = \alpha r_{ur}$로 표현할 수 있다. 이 때 $\alpha$는 Hyperparameter이다. $\alpha$를 크게하면 할수록, Positive Feedback에 더욱 큰 가중치를 부여하게 된다. $c$는 Log를 활용하여 다음과 같이 표현할 수도 있다.  

$$ c = 1 + \alpha log(1 + r_{ui}/\epsilon) $$  

$R$의 모든 원소가 서로 독립적이라는 가정하게 Parameter인 $X, Y, \beta$가 주어졌을 때 관측값 행렬 $R$의 우도는 아래와 같이 표현할 수 있다.  

$$ \mathcal{L}(R|X,Y,\beta) = \prod_{u,i} p(l_{ui} | x_u, y_i, \beta_u, \beta_i)^{\alpha r_{ui}} ( 1 - p(l_{ui} | x_u, y_i, \beta_u, \beta_i)) $$

추가적으로, 우리는 학습 과정 상의 과적합을 막기 위해 User와 Item의 잠재 벡터에 0이 평균인 **spherical Gaussian Prior**를 부여한다.  

$$ p(X|\sigma^2) = \prod_u N(x_u | 0, \sigma^2_uI) $$  
$$ p(Y|\sigma^2) = \prod_i N(y_i | 0, \sigma^2_iI) $$  

이제, **Posterior**에 Log를 취하고 상수항을 scaling parameter인 **$\lambda$**로 대체해주면 아래와 같은 식을 얻을 수 있다.  

$$ log p(R|X,Y,\beta) = \sigma_{u,i} \alpha r_{ui}(x_u y^T_i + \beta_u + \beta_i) - (1 + \alpha r_{ui}) log(1 + exp(x_u y^T_i + \beta_u + \beta_i)) - \frac{\lambda}{2} \Vert{x_u}\Vert^2 - \frac{\lambda}{2} \Vert{y_i}\Vert^2 $$  

잠재벡터에 대한 0이 평균인 **spherical Gaussian Prior**는 단지 User와 Item 벡터에 대한 $l2$ 정규화를 의미한다. 이제 우리의 목표는 **Log Posterior**를 최대화하는 $X, Y, \beta$를 찾는 것이다.  

$$ \argmax_{X,Y,\beta} log p (X,Y,\beta|R) $$  

위에서 제시된 목적 함수의 Local Maximum은 **Alternating Gradient Ascent** 과정을 거치면 찾을 수 있다. 각 Iteration에서 한 번은 User 벡터와 bias를 고정하고 Item 벡터에 대한 gradient를 업데이트하고, 그 다음에는 반대로 업데이트를 수행한다. User 벡터와 Bias의 편미분은 아래와 같다.  

<center><img src="/public/img/Machine_Learning/2020-06-02-LMF/01.JPG" width="70%"></center>  

각 Iteration은 User와 Item의 수에 선형적인데, 만약 선형적 계산이 불가능한 상황이라면, 적은 수의 Negative Sample($r_{ui} = 0$)를 샘플링하고 이에 따라 $\alpha$를 감소시키는 방법을 쓸 수 있다.  

이는 계산 시간을 굉장히 줄이면서도 충분히 최적점에 근접할 수 있는 장점을 지닌다. 또한 **Adagrad** 알고리즘을 활용할 경우 학습 시간을 획기적으로 줄이면서도 빠르게 수렴 지점에 도달할 수 있다. $x_u^t$를 $t$ Iteration에서의 $x_u$의 값으로, $g_{x_u}^t$를 Iteration $t$에서의 $x_u$의 Gradient라고 할 때, $x_u$에 대하여 Iteration $t$에서 우리는 아래와 같이 **Adagrad** 알고리즘을 수행할 수 있다.  

$$ x_u^t = x_u^{t-1} + \frac{\gamma g_u^{t-1}}{\sqrt{\sum_{t`=1}^{t-1} g_u^{t^{`2}} }} $$  

### 1.3. Scaling Up  



---
## 2. Implicit 라이브러리를 활용한 학습
### 2.1.Data Preparation  


### 2.2. Hyper Parameter Optimization with HyperOpt  


### 2.3. 결과 확인  
---
## Reference  
