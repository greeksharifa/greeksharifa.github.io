---
layout: post
title: DCGAN(Deep Convolutional GAN)
author: YouWon
categories: Paper_Review
tags: [GAN, Machine Learning]
---

---

이 글에서는 DCGAN(Deep Convolutional GAN)을 알아보도록 한다.  
DCGAN은 Alee Radford와 Luke Metz가 2015년(2016년 최종 수정) 제안한 GAN의 개선 모델이다.

DCGAN이 GAN과 다른 점은 다음과 같다.
- **$D$**
    - Strided Convolution을 사용한다.
    - Batch Normalization을 사용한다. 입력 레이어(첫 번째)에는 사용하지 않는다.
    - activation function으로 Leaky ReLU를 사용한다.
- **$G$**
    - Fractional Strided Convolution(Transposed Convolution)을 사용한다.
    - Batch Normalization을 사용한다. 출력 레이어(마지막)에는 사용하지 않는다.
    - activation function으로 ReLU를 사용하고 마지막 레이어에는 tanh를 사용한다.

*참고*: 논문에서 deconvolution이라 되어 있는 것은 Transposed 또는 fractional strided convolution을 의미한다. 이 연산은 엄밀히 말해 convolution의 역연산이 아니기 때문에(그 비슷한 것을 의도하긴 했지만) deconvolution은 사실 틀린 표현이다.

그래서 나아진 점, 혹은 알아낸 것은?

- (흔히 생각하는 FHD를 넘는 고해상도랑은 거리가 멀지만) 고해상도 이미지를 생성할 수 있게 되었다.
- 거의 대부분의 상황에서 안정적인 학습이 가능하다.
- 단순히 이미지를 기억(overfitting)하는 것이 아님을 보였다.
- convolution의 각 filter는 의미 있는 부분에 대한 정보를 갖고 있다. 논문에서는 침실 데이터를 사용하였는데, 어떤 필터는 창문에 대한 정보를 갖고 있는 식이다. 논문에서는 이를 시각화하여 보여주었다.
- input인 랜덤 벡터($z$)가 별 의미 없는 값이 아니라, 이것이 생성될 이미지의 특징을 결정하는 벡터이다. 논문에서는,
    - 웃는 여자를 생성한 입력 벡터 $z_1$
    - 무표정 여자를 생성한 입력 벡터 $z_2$
    - 무표정 남자를 생성한 입력 벡터 $z_3$
    - $z_4 :=$ $z_1$ - $z_2$ + $z_3$이라 할 때
    - $z_4$를 입력 벡터로 쓰면 웃는 남자를 생성해낸다.
- 또 왼쪽을 보는 사람과 오른쪽을 보는 사람을 생성한 두 벡터를 interpolating하면 마치 얼굴을 회전시킨 듯한 중간 결과들이 얻어진다.


논문을 적절히 번역 및 요약하는 것으로 시작한다. 많은 부분을 생략할 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.

---

# 논문(DCGAN)

논문 링크: **[Deep Convolutional GAN](https://arxiv.org/abs/1511.06434)**

## 초록(Abstract)

이 논문에서는 

---

## 서론(Introduction)



---

## 관련 연구(Related Works)

궁금하면 읽어보자.


---

## 적대적 망(Adversarial nets)

기호 | 설명
-------- | --------
$x$ | 데이터

<center><img src="/public/img/N/01.PNG" width="100%"></center>



---

## 이론적 결과(Theoretical Results)


---

## 실험(Experiments)


---

---

## 결론 및 추후 연구(Conclusions and future work)

1. conditional generative model로 발전시킬 수 있다(CGAN).
2. Learned approximate inference는 $x$가 주어졌을 때 $z$를 예측하는 보조 네트워크를 학습함으로써 수행될 수 있다. 
3. parameters를 공유하는 조건부 모델을 학습함으로써 다른 조건부 모델을 대략 모델링 할 수 있다. 특히, deterministic MP-DBM의 stochastic extension의 구현에 대부분의 네트워크를 쓸 수 있다.
4. Semi-supervised learning에도 활용 가능하다. classifier의 성능 향상을 꾀할 수 있다.
5. 효율성 개선: G와 D를 조정하는 더 나은 방법이나 학습하는 동안 sample $z$에 대한 더 나은 distributions을 결정하는 등의 방법으로 속도를 높일 수 있다.

--- 

# 학습 방법

GAN은 서로 경쟁하는 두 가지 모델을 학습시킨다. GAN을 쓰려면 다음 방법을 따른다.

1. 우선 다음을 정의한다.
    1. R(Real): 실제 데이터. 논문에선 $x$로 표시
    2. I(Input 또는 Imaginary): G가 가짜 데이터를 생성할 source. 논문에선 $z$로 표시. 
        - $G(z)$는 $G$가 $z$를 입력으로 받아 생성한 가짜 데이터이다.
    3. $G$(generator): 생성자, 위조범
    4. $D$(Distriminator): 감별자 또는 식별자, 경찰
2. 다음 전체 과정을 `num_epochs` 동안 반복한다: 
    1. D를 training하는 과정(`d_steps`만큼 반복): **D와 G를 모두 사용은 하지만 D의 parameter만 업데이트한다.**
        1. $D$에 실제 데이터($x$)와 정답(1)을 입력으로 주고 loss를 계산한다.
        2. $D$에 가짜 데이터($G(z)$)와 정답(0)을 입력으로 주고 loss를 계산한다.
        3. 두 loss를 합친 후 $D$의 parameter를 업데이트한다.
    2. G를 training하는 과정(`g_steps`만큼 반복): **D와 G를 모두 사용은 하지만 G의 parameter만 업데이트한다.**
        1. $D$에 가짜 데이터($G(z)$)와 정답(1)을 입력으로 주고 loss를 계산한다.
        2. 계산한 loss를 이용하여 $G$의 parameter를 업데이트한다.

---

# 튜토리얼

## MNIST 튜토리얼

GAN의 핵심 부분을 제외한 부분은 [여기](https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/)를 참고하면 된다.

---

# 이후 연구들

GAN 이후로 수많은 발전된 GAN이 연구되어 발표되었다. 가장 중요한 것 두 개는 GAN의 학습 불안정성을 많이 개선시킨 DCGAN(Deep Convolutional GAN), 단순 생성이 목적이 아닌 원하는 형태의 이미지를 생성시킬 수 있게 하는 CGAN(Conditional GAN)일 듯 하다.

많은 GAN들(DCGAN, LSGAN, WGAN, WGAN_GP, DRAGAN, CGAN, infoGAN, ACGAN, EBGAN, BEGAN 등)에 대한 설명은 [다음 글]()에서 진행하도록 하겠다.

---
