---
layout: post
title: 2019 ICML Papers
author: YouWon
categories: Paper_Review
tags: [PyTorch]
---

이 글에서는 2019년 ICML(International Conference on Machine Learning)에서 어떤 논문들이 accept되어 발표되었는지를 알아볼 것이다. 3424개의 논문이 접수되어 774개의 논문만이 구두 및 포스터 발표로 진행되었다.

논문 리스트는 목차와 같다. 774개를 다 살펴볼 수는 없으므로 몇 개만 추려서 최근 동향을 살펴보도록 하자.

---

## Training Neural Networks with Local Error Signals


&nbsp; &nbsp; &nbsp; 개요 &nbsp; &nbsp; &nbsp; | 내용
:--------: | -------- 
저자     | *Francesco Locatello et al*. Google Research
논문 링크 | <https://arxiv.org/abs/1811.12359>
소스코드  | <>
블로그  | <https://ai.googleblog.com/2019/04/evaluating-unsupervised-learning-of.html>
제출일 | Submitted on 29 Nov 2018 (v1), last revised 18 Jun 2019 (this version, v4)

이 논문은 표현(representation)에 대한 것인데, 논문에 쓰인 표현들이 참 어렵다.

초록을 대략 번역하자면, 

풀린 표현(*disentangled* representation)의 무감독 학습(*unsupervised* learning)의 핵심 아이디어는 '실제 세계의 데이터는 무감독 학습 알고리즘에 의해 복구될 수 있는 몇 가지 설명요인에 의해 생성된다'는 것이다.  

이 논문에서, 풀린 표현의 무감독 학습은 모델과 데이터 모두에 대해 귀납적 편향(inductive biases) 없이는 본질적으로 불가능하다는 것을 이론적으로 보일 것이다. 또한 6개의 최신 무감독 풀림 학습(unsupervised disentangled learning) 방법과 풀림 측정방식(disentangled measures)을 구현하여 이를 여러 데이터셋에 대해 12000개 이상의 모델을 학습시킬 것이다.  

이로써 

- 여러 방법들이 '대응되는 loss에 의한' 성질들을 강제함에도 불구하고 감독 없이는 잘 풀린(well-disentangled) 모델은 식별될 수 없다는 사실과(*역자 주: 모델이 식별될 수 없다는 것은 이를테면 두 가지 모델이 생성한 각각의 결과가 있을 때, 그 결과만 보고 원래 모델이 무엇이었을지를 알 수 없다는 뜻이다*), 
- '풀린 정도가 증가한(increased disentanglement)' 것도 downstream task의 학습의 샘플 복잡도의 감소로 이어지지는 않는다는 것

을 알아내었다.  

이같은 결과는 앞으로 풀린 학습에 대한 연구는 

- 명백히 귀납적 편향과 감독에 의해야 하며, 
- 학습된 표현의 풀림을 강제하는 것의 구체적인 이점을 조사하며, 
- 여러 데이터셋을 다룰 수 있는 재현 가능한 실험 설정을 고려해보아야 한다

는 것을 말해준다.


실제 논문 서론에서 주장하는 contribution은,

- 풀린 표현의 무감독 학습은 '학습방법과 데이터셋 모두에 대한 귀납적 편향' 없이는 본질적으로 불가능함을 이론적으로 보인 것
- 현재의 여러 무감독 풀림 학습 방법들을 조사 및 구현하여 이를 여러 데이터셋과 모델을 학습시킨 것
- 풀린 표현을 학습하고 평가하는 *disentanglement_lib*라는 새로운 라이브러리를 공개한 것
- 상당한 계산량을 필요로 하는 1만 개 이상의 사전 학습된(pre-trained) 모델을 공개한 것
- 무감독 풀림 학습에 대한 여러 생각들을 검증해보았다:
    - 고려된 모든 방법들이 샘플링된 posterior들의 차원(dimensions)의 독립성을 보장한다고 해도, 표현의 차원을 상관관계가 있다.
    - random seed와 hyperparameter이라는 무감독 조건 하에서 고려된 모델들이 풀린 표현을 더 잘 학습한다는 증거가 없다.
    - (데이터셋을 통한 훌륭한(학습이 잘 되는) hyperparameter들을 주는 것을 허용한다 할지라도) 'ground-truth 레이블에 접근할 수 없는' 잘 학습된 모델은 식별될 수 없다.
    - 고려된 모델과 데이터셋에 대해, 학습의 샘플 복잡도의 감소와 같은 downstream task에 풀림이 유용하지 않다.
- 실험 결과에 의해, 향후 연구에 대한 세 가지 중요한 부분을 제안하였다: 이는 초록 부분과 같다.

---

## Rates of Convergence for Sparse Variational Gaussian Process Regression

&nbsp; &nbsp; &nbsp; 개요 &nbsp; &nbsp; &nbsp; | 내용
:--------: | -------- 
저자     | *David R. Burt, et al*. University of Cambridge and PROWLER. io
논문 링크 | <https://arxiv.org/abs/1903.03571>
소스코드  | <>
제출일 | Submitted on 8 Mar 2019 (v1), last revised 3 Jul 2019 (this version, v2)

---

## Training Neural Networks with Local Error Signals


&nbsp; &nbsp; &nbsp; 개요 &nbsp; &nbsp; &nbsp; | 내용
:--------: | -------- 
저자     | *Arild Nøkland, Lars Hiller Eidnes*
논문 링크 | <https://arxiv.org/abs/1901.06656>
소스코드  | <https://github.com/anokland/local-loss>
제출일 | Submitted on 20 Jan 2019 (v1), last revised 7 May 2019 (this version, v2)


최근 분류(classification)를 위한 신경망의 감독학습(supervised learning)은 보통 global loss function을 사용하여 이루어졌다. 즉, 모델을 학습시키는 데 있어서 하나의 loss function만을 설정해 두고, prediction 단계에서 계산한 loss로 backward pass 동안 gradient를 계산하며 weights를 업데이트하는 역전파(back-propagation) 과정을 거쳐왔다.  

그러나 이 논문에서는 하나의 loss function을 모델의 모든 레이어에 걸쳐 global하게 사용하는 대신 각 레이어별로 loss function을 설정하여 실험하였고, 이 방법은 생물학적으로 그럴듯하고(biologically plausible) 그러면서도 여전히 state-of-the-art 결과를 얻을 수 있음을 보여주었다.

Global loss function의 사용은 다음과 같은 문제를 갖는다.

1. **Backward locking problem:** hidden layer의 weights들은 forward & backward pass가 끝날 때까지 업데이트되지 않는다. 따라서 weights update의 병렬화가 어렵다.
2. **Preventing reuse of the memory:** hidden layer의 activation들을 backward pass가 끝날 때까지 메모리에 상주시켜야 하기 때문에 메모리 사용량이 늘어난다.
3. **Biologically implausible:** global loss의 역전파는 신경망이라는 관점에서 생물학적으로 별로 타당하지 않다.

이 논문에서, backward locking problem은 지역적으로(각 레이어별로) 측정된 error에 의해 각각 학습시킴으로써 해결될 수 있음을 보인다. Local loss function은 global error에 의존하지 않고, gradient는 해당 레이어를 제외한 그 이전 레이어에 전파되지 않으며, hidden layer는 forward pass 중간에도 업데이트될 수 있다.  
추론(inference) 단계에서 네트워크는 global 역전파를 쓰는 것과 같이 움직인다. 그러나 hidden layer가 업데이트될 때, gradient와 activation은 더 이상 메모리에 남아 있을 필요가 없다.  
따라서 모든 레이어를 동시에 학습시킴에도, 지역적으로 측정된 error는 각 레이어를 학습시키며 이것을 메모리 사용량과 학습 시간을 줄여줄 수 있게 된다.

관련 연구는 **Local Loss Functions, Similarity Measures in Neuroscience/Machine Learning** 등이 있다(논문 참조).

표준 **convolutional & fully connected** 네트워크 구조를 사용하여, global loss 대신 각 레이어별로 (이전 레이어로 전파되지 않는) local learning signal을 설정했다. 이 signal은 2개의 single-layer sub-networks로 분리되어, 각각은 서로 다른 loss function을 갖는다. 하나는 표준 **cross-entropy loss**이고, 다른 하나는 **similarity matching loss**이다.

<center><img src="/public/img/2019-07-11-2019-ICML-Papers/01.png" width="100%" alt="activation and gradient flow"></center>


논문에서는 여러 loss를 정의하는데, 

- **sim loss:** mini-batch의 example들 간 pair-wise 유사도를 담고 있는 두 행렬간 L2 거리를 측정하는 similarity matching loss이다.
- **pred loss:** target과 local classifier의 prediction 간 cosss-entropy loss를 측정한다. 
- **sim-bpf loss & pred-bpf loss:** Backprop free version을 만들기 위해, global target이 각 hidden layer로 전파되는 것을 막는다. **sim loss**에서는 one-hot encoded target vector 대신 random transformation target vector를, **pred loss**에서는 binarized random transformation target vector를 사용한다. 
- **predsim & predsim-bpf loss:** sim과 pred를 조합해서 전체 loss를 만들었다.

$$ L_{predsim} = (1-\beta)L_{pred} + \beta L_{sim} $$

$$ L_{predsim-bpf} = (1-\beta)L_{pred-bpf} + \beta L_{sim-bpf} $$

실험은 MNIST, Fashion-MNIST, Kuzushiji-MNIST, CIFAR-10, CIFAR-100, STL_10, SVHN에 대해서 각각 진행하였다.

결과를 요약하자면 단지 local **pred** loss만으로도 global 역전파를 사용한 것과 거의 같은 성능을 보였고, **predsim**이나 **predsim-bpf**를 사용한 경우 state-of-the-art 결과를 얻을 수 있었다고 한다.

따라서 이 논문의 contribution은 loss function을 굳이 global하게 만들지 말고 각 레이어별로 local loss function을 만들어서 backward locking problem과 parallelization을 해결하는 것이 **학습속도, 생물학적 타당성, 분류 성능**을 다 잡을 수 있다는 가능성을 보여준 것이 되겠다.

---



--- 