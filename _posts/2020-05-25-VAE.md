---
layout: post
title: Variational AutoEncoder 설명
author: Youyoung
categories: [Generative Model]
tags: [Machine Learning, Paper_Review]
---

본 글의 주제는  2014년에 발표된 생성 모델인 Variational AutoEncoder에 대해 설명하고 이를 코드로 구현하는 내용을 담고 있다. **VAE**에 대해서 알기 위해서는 **Variational Inference** (변분 추론)에 대한 사전지식이 필요하다. 이에 대해 알고 싶다면 [이 글](https://greeksharifa.github.io/bayesian_statistics/2020/07/13/Variational-Inference/)을 참조하길 바란다.  

본 글은 크게 3가지 파트로 구성되어 있다. Chapter1에서는 VAE 논문을 리뷰할 것이다. Chapter2에서는 논문에서 언급되었던 몇 가지 개념에 대해 상세히 서술할 것이다. Chapter3에서는 Tensorflow를 통해 VAE를 구현할 것이다.  


## 1. Auto-Encoding Variational Bayes 논문 리뷰  
### 1.1. Introduction  
연속형 잠재 변수와 파라미터가 다루기 힘든 사후 분포를 갖는 방향성 확률 모델에 대해 효율적인 근사 추론 및 학습을 수행할 수 있는 방법이 없을까? **Variational Bayesian** 접근법은 다루기 힘든 사후 분포에 대한 근사의 최적화를 내포한다.  

불행히도, 일반적인 Mean-Field 접근법은 근사적 사후 분포에 대해 기댓값의 분석적 해결법을 요구하는데 이는 보통 굉장히 intractable한 방법이다. 본 논문은 **Variational Lower Bound**(ELBO)의 `Reparameterization`이 Lower Bound의 미분 가능한 불편향 estimator를 만드는 방법에 대해 보여줄 것이다. 이 **Stochastic Gradient Variational Bayes: SGVB estimator**는 연속형 잠재변수나 파라미터를 갖고 있는 대부분의 모델에 대해 효율적인 근사 사후 추론을 가능하게 하며, 표준 Stochastic Gradient Ascent 스킬을 사용하여 최적화하기에 굉장히 편리하다.  

iid 데이터셋이고, 데이터 포인트 별로 연속형 잠재변수를 갖고 있는 경우에 대해 본 논문은 `Auto-Encoding VB` 알고리즘을 제안한다. 이 알고리즘에서는 **Simple Ancestral Sampling**을 이용하여 근사 사후 추론을 하는 인식 모델을 최적화하기 위해 **SGVB estimator**를 사용하여 추론과 학습을 효율적으로 해낸다. 이 과정은 MCMC와 같이 데이터포인트 별로 반복적인 추론을 행하여 많은 연산량을 요구하지 않는 장점을 가진다.  

학습된 근사 사후 추론 모델은 recognition, denoising, representation, visualization의 목적으로 활용될 수 있다. 본 알고리즘이 인식(recognition) 모델에 사용될 때, 이를 `Variational Auto-Encoder`라고 부를 것이다.  

### 1.2. Method  
본 섹션에서는 연속형 잠재 변수를 내포하는 다양한 방향성 그래픽 모델(DIrected Graphical Model)에서 Stochastic 목적 함수인 **Lower Bound Estimator**를 끌어내는 과정을 설명할 것이다. 데이터포인트 별 잠재변수는 iid한 상황이라는 가정 하에 본 논문에서는 (전역) 파라미터에 대해 Maximum Likelihood와 Maximum A Posteriori 추론을 수행하고 잠재변수에 대해 `Variational Inference`를 수행할 것이다. 이러한 방법은 온라인 러닝에도 사용될 수 있지만 본 논문에서는 간단히 하기 위해 고정된 데이터셋을 사용할 것이다.  

#### 1.2.1. Problem Scenario  
N개의 Sample을 가진 $X$ 라는 데이터가 있다고 해보자. 본 논문은 이 데이터가 관측되지 않은 연속형 확률 변수 $z$ 를 내포하는 어떤 Random Process에 의해 형성되었다고 가정한다.  

이 과정은 2가지 단계로 구성된다.  

$$ z^{(i)} \sim Prior: p_{\theta^*}(z) $$  

$$ x^{(i)} \sim Conditional Dist: p_{\theta^*}(x|z) $$  

(여기서 $z$는 원인, $x$는 결과라고 보면 이해가 쉬울 것이다.)  

이 때 우리는 위 2개의 확률이 모두 아래 두 분포의 **Parametric Families of Distributions**에서 왔다고 가정한다.  

$$ p_{\theta}(z), p_{\theta}(x|z) $$  

이들의 확률밀도함수는 거의 모든 $\theta, z$에 대해 미분가능하다고 전제한다.  

불행히도, 이러한 과정의 많은 부분은 우리가 직접 확인하기 어렵다. True 파라미터인 $\theta^*$ 와 잠재 변수의 값 $z^{(i)}$ 는 우리에게 알려져 있지 않다.  

본 논문은 주변 확률이나 사후 확률에 대한 단순화를 위한 일반적인 가정을 취하지 않고, 아래에서 제시한 상황처럼 분포가 intractable하고 큰 데이터셋을 마주하였을 경우를 위한 효율적인 알고리즘에 대해 이야기하고자 한다.  

**1) Intractability**  

$$ \int p_{\theta}(x) p_{\theta}(x|z) dz $$  

(1) Marginal Likelihood $p_{\theta}(x)$ 의 적분은 위 식으로 표현되는데, 이 식이 intractable한 경우가 존재한다. 이 경우는 Evidence가 적분이 불가능한 경우를 의미한다.  

(2) True Posterior Density가 intractable한 경우 (EM알고리즘이 사용될 수 없음)  

True Posterior Density는 아래와 같다.  

$$ p_{\theta}(z|x) = p_{\theta}(x|z)p_{\theta}(z)/p_{\theta}(x) $$  


(3) 어떠한 합리적인 Mean-Field VB 알고리즘을 위한 적분이 불가능한 경우  

이러한 Intractability는 굉장히 흔하며, 복잡한 Likelihood 함수를 갖는 신경망 네트워크에서 발견할 수 있다.  

$$ Likelihood: p_{\theta}(x|z) $$  
  

**2) A Large Dataset**  

데이터가 너무 크면 배치 최적화는 연산량이 매우 많다. 우리는 작은 미니배치나 데이터포인트에 대해 파라미터 업데이트를 진행하고 싶은데, Monte Carlo EM과 같은 Sampling Based Solution은 데이터 포인트별로 Sampling Loop를 돌기 때문에 너무 느리다.  


위 시나리오에서 설명한 문제들에 대해 본 논문은 아래와 같은 해결책을 제시한다.  

첫 번째로, 파라미터 $\theta$ 에 대한 **효율적인 근사 ML/MAP 추정**을 제안한다. 이 파라미터들은 숨겨진 Random Process를 흉내내고 실제 데이터를 닮은 인공적인 데이터를 생성할 수 있게 해준다.  

두 번째로, 파라미터 $\theta$ 의 선택에 따라 관측값 $x$ 가 주어졌을 때 **잠재 변수 $z$ 에 대한 효율적인 근사 사후 추론**을 제안한다.  

세 번째로, 변수 $x$ **에 대한 효율적인 근사 Marginal Inference**를 제안한다. 이는 $x$ 에 대한 prior이 필요한 모든 추론 task를 수행할 수 있게 해준다.  

위 문제를 해결하기 위해 아래와 같은 **인식 모델**이 필요하다.  

$$ q_{\phi}(z|x) $$  

이 모델은 intractable한 True Posterior의 근사 버전이다.  

기억해야 할 것이, Mean-Field Variational Inference에서의 근사 Posterior와는 다르게 위 인식 모델은 꼭 계승적(factorial)일 필요도 없고, 파라미터 $\phi$ 가 닫힌 형식의 기댓값으로 계산될 필요도 없다.  

본 논문에서는 인식 모델 파라미터인 $\phi$ 와 생성 모델 파라미터인 $\theta$를 동시에 학습하는 방법에 대해 이야기할 것이다.  


|구분|기호|
|--------|--------|
|인식 모델 파라미터| $\phi$ |
|생성 모델 파라미터| $\theta$ |


코딩 이론의 관점에서 보면, 관측되지 않은 변수 $z$ 는 잠재 표현 또는 *code*라고 해석될 수 있다. 본 논문에서는 인식 모델을 **Encoder**라고 부를 것이다. 왜냐하면 데이터 포인트 $x$ 가 주어졌을 때 이 **Encoder**가 데이터 포인트 $x$ 가 발생할 수 code $z$의 가능한 값에 대한 분포를 생산하기 때문이다.  

비슷한 맥락에서 우리는 생성 모델을 **확률적 Decoder**라고 명명할 것인데, 왜냐하면 code $z$ 가 주어졌을 때 이 **Decoder**가 상응하는 가능한 $x$ 의 값에 대해 분포를 생성하기 때문이다.  

$$ Encoder: q_{\phi}(z|x) $$  

$$ Decoder: p_{\theta}(x|z) $$  


#### 1.2.2. The Variational Bound  
Marginal Likelihood는 각 데이터 포인트의 Marginal Likelihood의 합으로 구성된다. 이를 식으로 표현하면 아래와 같다.  

$$ log p_{\theta}(x^{(1)}, ..., x^{(N)}) = \sum_{i=1}^N log p_{\theta} (x^{(i)}) $$  

그런데 데이터 포인트 하나에 대한 Marginal Likelihood는 아래와 같이 재표현이 가능하다.  

$$ log p_{\theta} (x^{(i)}) = D_{KL} (q_{\phi}(z|x^{(i)}) || p_{\theta} (z|x^{(i)})) + L(\theta, \phi; x^{(i)}) $$  

우변의 첫 번째 항은 True Posterior의 근사 `KL Divergence`이다. 이 KL Divergence는 음수가 아니기 때문에, 두 번째 항인 $L(\theta, \phi; x^{(i)})$ 는 i번째 데이터 포인트의 Marginal Likelihood의 `Varitaional Lower Bound`라고 한다. 변분 추론 글을 읽어보고 왔다면 알겠지만, 이는 Evidence의 하한 값을 뜻하기도 하기 때문에 `ELBO`라고 부르기도 한다.  

부등식으로 나타내면 아래와 같다.  

$$ log p_{\theta} (x^{(i)}) \geq L(\theta, \phi; x^{(i)}) = E_{q_{\phi} (z|x)} [-logq_{\phi}(z|x) + log p_{\theta}(x, z)] $$  

이 식은 또 아래와 같이 표현할 수 있다.  

<center><img src="/public/img/Machine_Learning/2020-05-25-VAE/01.JPG" width="90%"></center>  

우리는 **Lower Bound** $L(\theta, \phi; x^{(i)})$ 를 Variational 파라미터와 생성 파라미터인 $\phi, \theta$ 에 대하여 미분하고 최적화하고 싶은데, 이 Lower Bound의 $\phi$ 에 대한 Gradient는 다소 복잡하다.  

이러한 문제에 대한 일반적인 `Monte Carlo Gradient Estimator`는 아래와 같다.  

<center><img src="/public/img/Machine_Learning/2020-05-25-VAE/02.JPG" width="100%"></center>  

$$ Where: z^{(l)} \sim q_{\phi} (z|x^{(i)}) $$  

그런데 이 Gradient Estimator는 굉장히 큰 분산을 갖고 있어서 우리의 목적에 적합하지 않다.  


#### 1.2.3. The SGVB estimator and AEVB algorithm  
이 섹션에서는 **Lower Bound**의 실용적인 추정량과 파라미터에 대한 그 추정량의 미분 값을 소개할 것이다. 

$$ q_{\phi} (z|x) $$  

일단 우리는 위와 같은 **근사 Posterior**를 가정한다. 다만 x에 대한 조건부를 가정하지 않은 케이스인 $q_{\phi}(z)$ 와 같은 경우에도 같은 테크닉을 적용할 수 있음에 유의하자. Posterior를 추론하는 **Fully Variational Bayesian** 방법론은 본 논문의 부록에 소개되어 있다.  

위에서 설정한 **근사 Posterior**에 대해 **1.2.4** 섹션에서 정한 certain mild conditions 하에 우리는 그 **근사 Posterior**를 따르는 확률 변수 $\tilde{z}$ 를 `Reparameterize` 할 수 있는데, 이는 Auxiliary Noise 변수 $\epsilon$ 의 **Diffrentiable Transformation**($g_{\phi} (\epsilon, x)$)를 통해 이루어진다.  

$$ \tilde{z} = q_{\phi} (z|x)  $$  

$$ \tilde{z} \sim g_{\phi} (\epsilon, x), \epsilon \sim p(\epsilon) $$  

다음 Chapter를 보면 적절한 $p(\epsilon)$ 분포와 $g_{\phi} (\epsilon, x)$ 함수를 선정하는 일반적인 방법에 대해 알 수 있다. 이제 이 Chapter 서두에서 언급한 **근사 Posterior**에 대해 어떤 함수 $f(z)$ 기댓값의 `Monte Carlo 추정량`을 다음과 같이 쓸 수 있다.  

$$ E_{q_{\phi} (z|x)} [f(z)] = E_{p(\epsilon)} [f(g_{\phi} (\epsilon, x^{(i)}))] \approx \frac{1}{L} \Sigma_{l=1}^L f(g_{\phi} (\epsilon^{(l)}, x^{(i)})) $$  

이는 실제로 계산하기 어려운 어떤 함수에 대해 $L$ 개의 Sample를 뽑아 이에 대한 근사치로 추정량을 구하는 방법이다.  

이제 이 테크닉을 **ELBO**에 대해 적용하면 **SGVB: Stochastic Gradient Variational Bayes** 추정량을 얻을 수 있다.  

$$ \tilde{\mathcal{L}}^A (\theta, \phi, x^{(i)}) \simeq \mathcal{L} (\theta, \phi, x^{(i)}) $$  

$$ \tilde{\mathcal{L}}^A (\theta, \phi, x^{(i)}) = \frac{1}{L} \Sigma_{l=1}^L log p_{\theta} (x^{(i)}, z^{(i, l)}) - logq_{\phi} (z^{(i, l)}|x^{(i)}) $$  

$$ g_{\phi} (\epsilon^{(i, l)}, x^{(i)}), \epsilon^{(l)} \sim p(\epsilon) $$  

잠시 아래 식에서 쿨백-라이블리 발산에 주목해보자.  

<center><img src="/public/img/Machine_Learning/2020-05-25-VAE/01.JPG" width="90%"></center>  

이 쿨백-라이블리 발산 값은 종종 analytic 하게 적분될 수 있는데 이렇게 되면 오직 `Expected Reconstruction Error`만이 샘플링에 의한 추정을 필요로하게 된다. `Expected Reconstruction Error` 항은 아래 식을 의미한다.  

$$ E_{q_{\phi} (z|x^{(i)})} [ logp_{\theta} (x^{(i)}|z) ] $$  

쿨백-라이블리 발산 항은 **근사 Posterior**를 **Prior** $p_{\theta}(z)$ 에 가깝게 만들어서 $\phi$ 를 규제하는 것으로 해석될 수 있다.  

$$ KL: p_{\theta} (z|x) \to p_{\theta}(z) $$

이러한 과정을 **SGVB** 추정량의 두 번째 버전으로 이어지는데, 이 추정량은 일반적인 추정량에 비해 작은 분산을 갖고 있다.  

$$ \tilde{\mathcal{L}}^B (\theta, \phi, x^{(i)}) = -D_{KL} (q_{\phi} (z|x^{(i)}) || p_{\theta} (z) ) + \frac{1}{L} \Sigma_{l=1}^L log p_{\theta} (x^{(i)}, z^{(i, l)}) $$  

이 때  

$$ z^{(i, l)} = g_{\phi} (\epsilon^{(i, l)}, x^{(i)}), \epsilon^{(l)} \sim p(\epsilon) $$  

$N$ 개의 데이터 포인트를 갖고 있는 데이터셋 $X$ 에서 복수의 데이터 포인트가 주어졌을 때 우리는 미니배치에 기반하여 전체 데이터셋에 대한 **Marginal Likelihood Lower Bound**의 추정량을 구성할 수 있다.  

$$ \mathcal{L} (\theta, \phi, X) \simeq \tilde{\mathcal{L}}^M (\theta, \phi, X^M) = \frac{N}{M} \Sigma_{i=1}^M \tilde{\mathcal{L}} (\theta, \phi, x^{(i)}) $$  

이 때  

$$ X^M = [x^{i}]_{i=1}^M $$  

미니배치 $X^M$ 은 전체 데이터셋 $X$ 에서 랜덤하게 뽑힌 샘플들을 의미한다. 본 논문의 실험에서, 미니 배치 사이즈 $M$ 이 (예를 들어 100) 충분히 크면 데이터 포인트 별 sample의 크기인 $L$ 이 1로 설정될 수 있다는 사실을 알아 냈다.  

$$ \triangledown_{\theta, \phi} \tilde{\mathcal{L}} (\theta; X^M) $$  

위와 같은 derivate가 도출될 수 있고, 이에 따른 Gradients는 **SGD**나 **Adagrad**와 같은 확률적 최적화 방법과 연결되어 사용될 수 있다.  

다음은 기본적인 Stochastic Gradients를 계산하는 방법에 대한 내용이다.  

<center><img src="/public/img/Machine_Learning/2020-05-25-VAE/03.JPG" width="80%"></center>  

아래 목적 함수를 보면 **Auto-Encoder**와의 연결성이 더욱 뚜렷해진다.  

$$ \tilde{\mathcal{L}}^B (\theta, \phi, x^{(i)}) = -D_{KL} (q_{\phi} (z|x^{(i)}) || p_{\theta} (z) ) + \frac{1}{L} \Sigma_{l=1}^L log p_{\theta} (x^{(i)}, z^{(i, l)}) $$  

**Prior**로부터 나온 **근사 Posterior**에 대한 쿨백-라이블리 발산 값인 첫 번째 항은 `Regularizer`의 역할을 하며, 두 번째 항은 `Expected Negative Reconstruction Error`의 역할을 하게 된다.  

$g_{\phi} (.)$ 라는 함수는 데이터 포인트 $x^{(i)}$ 와 Random Noise Vector $\epsilon^{(l)}$ 을 데이터 포인트 $z^{(i, l)}$ 을 위한 **근사 Posterior**로 부터 추출된 Sample로 매핑하는 역할을 수행한다.  

$$ \tilde{z} = q_{\phi} (z|x), \tilde{z} \sim g_{\phi} (\epsilon, x), \epsilon \sim p(\epsilon) $$  

그 후, 이 Sample $z^{(i, l)}$ 은 아래 함수의 Input이 된다.  

$$ log p_{\theta} (x^{(i)} | z^{(i, l)}) $$  

이 함수는 $z^{(i, l)}$ 이 주어졌을 때 생성 모델 하에서 데이터 포인트 $x^{(i)}$ 의 확률 밀도 함수와 동일하다. 이 항은 Auto-Encoder 용어에서 `Negative Reconstruction Error`에 해당한다.  


#### 1.2.4. The Reparamaterization Trick  
To be continued...



---
## 2. 이론에 대한 보충 설명  





---
## 3. Tensorflow로 VAE 구현  



---
## Reference  
1) https://ratsgo.github.io/generative%20model/2018/01/27/VAE/  
2) https://www.youtube.com/watch?v=SAfJz_uzaa8  
3) https://taeu.github.io/paper/deeplearning-paper-vae/
4) 
