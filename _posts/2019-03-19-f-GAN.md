---
layout: post
title: f-GAN
author: YouWon
categories: [Generative Model]
tags: [GAN, Machine Learning, CNN, Generative Model, Paper_Review]
---

---

이 글에서는 f-GAN을 알아보도록 한다.  
f-GAN은 Sebastian Nowozin 등 연구자들이 2016년 제안한 논문이다.

f-GAN은 특정한 구조를 제안했다기보다는 약간 divergence에 대한 일반적인 내용을 증명한 수학 논문에 가깝다.


논문을 적절히 번역 및 요약하는 것으로 시작한다. 많은 부분을 생략할 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.

*이 논문은 수학이 넘쳐흐르는 논문이다.*

---

# f-GAN

논문 링크: **[f-GAN](https://arxiv.org/abs/1606.00709)**

## 초록(Abstract)

2016년에 나온 논문임을 생각하라.

Generative neural sampler는 random input vector를 입력으로 받아 network weights에 정의된 확률분포로부터 sample을 만들어내는 확률적 모델이다. 이 모델들은 sample과 도함수 계산이 효율적이지만 우도(likelihood)나 주변화(marginalization)을 계산하진 못한다. 적대생성적 학습방법은 이런 모델이 추가 신경망을 통해 이를 학습할 수 있게 해준다.  
우리는 이 적대생성적 접근법이 더 일반적인 변화적 발산(variational divergence) 추정 접근의 특별한 경우임을 보일 것이다. 우리는 임의의 *f-divergence*가 Generative neural sampler에 쓰일 수 있음을 보일 것이다. 우리는 이렇게 다양한 divergence 함수를 쓸 수 있는 것이 학습 복잡도와 생성모델의 품질 면에서 이득임을 논할 것이다.

---

## 서론(Introduction)

확률적 생성모델은 주어진 domain $\chi$ 상의 확률분포를 서술한다. 예를 들면 자연언어 문장, 자연 이미지, 녹음된 파형 등의 분포가 있다.

가능한 모델 집합 $Q$에서 생성모델 Q가 주어졌을 때 우리는 일반적으로 다음에 관심이 있다:
- Sampling. Q로부터 sample을 생성한다. sample을 살펴보거나 어떤 함숫값을 계산해봄으로써 우리는 분포에 대한 통찰을 얻거나 결정문제를 풀 수 있다.
- Estimation. 알려지지 않은 진짜 분포 P로부터 iid sample $\{x_1, x_2, ..., x_n\}$이 주어졌을 때, 이 진짜 분포를 가장 잘 설명하는 Q $\in Q$를 찾는다.
- Point-wise 우도 측정. sample $x$가 주어지면, 우도 Q($x$)를 계산한다.

GAN은 정확한 sampling과 근사추정이 가능한 인상적인 모델이다. 여기서 사용된 모델은 균등분포 같은 random input vector를 받는 feedforward 신경망이다. 최종적으로 모델을 통과하여 나오는 것은 예를 들면 이미지이다. GAN에서 sampling하는 것은 딱 1개의 input이 신경망을 통과하면 정확히 하나의 sample이 나온다는 점에서 효율적이다.

이런 확률적 feedforward 신경망을 **generative neural samplers**라고 부를 것이다. GAN도 여기에 포함되며, 또한 variational autoencoder의 decoder 모델이기도 하다.

original GAN에서, neural sample를 [JSD](https://greeksharifa.github.io/generative%20model/2019/03/03/GAN/#%EB%AA%A9%EC%A0%81%ED%95%A8%EC%88%98-%EC%B5%9C%EC%A0%81%ED%99%94%EC%9D%98-%EC%9D%98%EB%AF%B8)의 근사적 최소화로 추정하는 것이 가능함이 증명되어 있다. 

$$ D_{JS}(P \| Q) = {1 \over 2} D_{KL}(P \| {1 \over 2}(P+Q)) + {1 \over 2} D_{KL}(Q \| {1 \over 2}(P+Q)) $$

$D_{KL}$은 [Kullback–Leibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)이다.

GAN 학습의 중요한 테크닉은 동시에 최적화된 **Discriminator** 신경망을 만든 것에 있다. 왜냐하면 $D_{JS}$는 진짜 분포 $P$는 충분한 학습을 통해 Q가 $P$에 충분히 가까워졌을 때 분포 간 divergence를 측정하는 적정한 방법이기 때문이다. 

우리는 이 논문에서 GAN 학습목적(training objectives)과 이를 임의의 *f-divergence*로 일반화하고자, GAN을 variational divergence 추정 framework로 확장할 것이다.

구체적으로, 이 논문에서 보여주는 state-of-the-art한 것은:

- GAN 학습목적을 모든 *f-divergence*에 대해 유도하고 여러 divergence 함수를 소개할 것이다: Kullback-Leibler와 Pearson Divergence를 포함한다.
- 우리는 GAN의 saddle-point 최적화를 단순화할 것이고 또 이론적으로 증명할 것이다.
- 자연 이미지에 대한 generative neural sampler을 측정하는 데 어느 divergence 함수가 적당한지 실험적 결과를 제시하겠다.

---

## 방법(Method)

먼저 divergence 추정 framework를 리뷰부터 하겠다. 이후 divergence 추정에서 model 추정으로 확장하겠다.

### The f-divergence Family

Kullback-Leibler divergence같이 잘 알려진 것은 두 확률분포 간 차이를 측정한다. 

두 분포 $P$와 $Q$가 있고, domain $\chi$에서 연속밀도함수 $p$와 $q$에 대해 *f-divergence*는  
$ f : \mathbb{R}_+ \rightarrow \mathbb{R} $이 $f(1)=0$인 convex하며 lower-semicontinuous한 함수 $f$에 대해
 
$$ D_f(P \Vert Q) = \int_{\chi} q(x) f \Bigl( {p(x) \over q(x)} \Bigr) dx $$

로 정의된다.


---

## 조건부 적대신경망(Conditional Adversarial Nets)

### GAN(Genearative Adversarial Nets)

최근 소개된 GAN은 다음 두 부분으로 이루어졌다. 둘 다 non-linear하게 매핑하는 함수일 수 있다.
- 데이터분포를 입력받아 실제에 가깝게 데이터를 생성하는 생성모델 G
- 입력받은 데이터가 진짜 데이터인지 G가 만들어낸 것인지를 판별하는 D

다음 식으로 표현되는 minimax 게임을 G와 D가 진행하게 된다:

$$ min_G max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[log D(x)] + \mathbb{E}_{x \sim p_{z}(z)}[log (1-D(G(z)))]  $$

수식에 대한 자세한 설명은 [GAN](https://greeksharifa.github.io/paper_review/2019/03/03/GAN/#%EC%A0%81%EB%8C%80%EC%A0%81-%EB%A7%9Dadversarial-nets)을 참고하라.

### CGAN(Conditional Adversarial Nets)

G와 D가 추가 정보 $y$라는 조건이 붙는다면 조건부 생성모델을 만들 수 있다. $y$는 어떤 보조 정보라도 될 수 있는데, class label이나 다른 modality의 데이터 등이다. 우리는 $y$를 G와 D의 input layer에 추가로 같이 집어넣음으로써 이를 수행할 수 있다.

G에서는 input noise $p_z(z)$와 $y$가 합쳐진 형태가 된다. 이 적대적 학습 framework는 이 hidden representation이 어떻게 생겼는지에 별 영향을 받지 않는다.  
D에서는 $x$와 $y$가 input으로써 들어가게 된다.

좀 전 수식을 conditional 버전으로 바꿔보면,

$$ min_G max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[log D(x|y)] + \mathbb{E}_{x \sim p_{z}(z)}[log (1-D(G(z|y)))]  $$

*참고*: D와 G에 들어가는 input이 단지 조건부로 바뀌었다. 실제 들어가는 형태는 합쳐진 형태이다.

<center><img src="/public/img/2019-03-19-CGAN/01.png" width="80%"></center>

---

## 실험 결과(Experimental Results)

이미 좋다는 게 알려진 논문의 경우에는 굳이 실험 조건 등을 자세히 볼 필요는 없다. 여기서는 결과만 소개한다.

### Unimodal

모델 구조는 다음과 갈다.
- G 
    - uniform distribution $z$. size=100
    - $z$와 $y$는 각각 size 200, 1000짜리 hidden layer(ReLU)로 매핑됨
    - 1200짜리 hidden layer로 합쳐짐(ReLU)
    - 마지막으로 784차원으로 변환됨(MNIST 이미지는 $28^2$이다)
- D
    - $x$는 240 unit과 5 piece짜리 maxout layer, $y$는 50 unit과 5 piece짜리 maxout layer로 매핑됨
    - 240 unit, 5 piece짜리 maxout layer로 합쳐진 후 Sigmoid


MNIST로 실험한 결과이다. Log-likelihood 값이 잘 나왔음을 확인할 수 있다.

Model | MNIST
-------- | --------
DBN | 138 $\pm $ 2
Stacked CAE | 121 $\pm $ 1.6
Deep GSN | 214 $\pm $ 1.1
Adversarial nets | 225 $\pm $ 2
Conditional adversarial nets | 132 $\pm $ 1.8

$y$ 데이터는 각 row별로 0~9까지 들어갔다. 아래는 CGAN을 통해 생성된 이미지이다.

<center><img src="/public/img/2019-03-19-CGAN/02.png" width="100%"></center>

주어지는 조건($y$)에 따라 class가 잘 나뉘는 것은 확인할 수 있다(이미지 품질은 original GAN과 비슷하다).

### Multimodal

여러 이미지들에 대해 사람이 직접 넣은 태그와 CGAN이 생성해낸 태그를 비교한 테이블을 가져왔다.

<center><img src="/public/img/2019-03-19-CGAN/03.png" width="100%"></center>

가장 오른쪽 열이 생성된 태그 중 제일 나은 것 10개를 나열한 것인데, 꽤 잘 된 것으로 보인다.

---

## 추후 연구(Future work)

이 논문에서 소개된 결과는 서론 정도의 내용이지만, 각각은 조건부 생성모델의 잠재력과 다른 많은 분야로의 응용에 대한 가능성을 보여 준다.

이번 실험에서는 태그를 독립적으로 사용했지만, 한번에 여러 태그를 사용한다면 더 나은 결과를 얻을 수 있을 것이다.

추후 연구의 또 다른 방향은 언어 모델을 배우는 학습계획을 구현하는 것이 있겠다.

### Acknowledgments

이 프로젝트는 Pylearn2 framework로 개발되었다.

## 참고문헌(References)

논문 참조!

---

# 튜토리얼

GAN의 핵심 부분을 제외한 부분은 [여기](https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/)를 참고하면 된다.

[여기](https://github.com/znxlwm/pytorch-generative-model-collections/blob/master/CGAN.py)에서 CGAN을 학습시켜볼 수 있다. 해당 repository에는 CGAN뿐 아니라 많은 종류의 GAN이 Pytorch로 구현되어 있으므로 참고하면 좋다.

---

# 이후 연구들

GAN 이후로 수많은 발전된 GAN이 연구되어 발표되었다. 

많은 GAN들(LSGAN, WGAN, WGAN_GP, DRAGAN, infoGAN, ACGAN, EBGAN, BEGAN 등)에 대한 설명은 [다음 글](https://greeksharifa.github.io/generative%20model/2019/03/20/advanced-GANs/)에서 진행하도록 하겠다.

---
