---
layout: post
title: Graph Fourier Transform 설명
author: Youyoung
categories: [Machine_Learning]
tags: [Machine_Learning]
---

본 글에서는 Graph Neural Networks 이론의 근간 중 하나라고 할 수 있는 **Graph Fourier Transform**에 대해 설명할 것이다. Notation의 경우 최대한 가장 자주 쓰이는 형태를 고려하여 작성하였고, 글로써 완전히 전달하는 것이 어렵기 때문에 여러 자료들을 함께 참고하길 바라며, 관련 강의를 들을 수 있다면 더욱 좋을 것이다.  

---
# Graph Laplacian  
<center><img src="/public/img/Machine_Learning/2021-08-14-GFT/graph.PNG" width="70%"></center>  

위와 같은 Graph $\mathcal{G}$ 가 존재한다고 할 때, 각 node $v$ 는 feature를 갖고 있다.  
각각의 node가 갖고 있는 feature를 그 node의 signal이라고 설정해 볼 때, node $v_1$ 의 signal은 $f_1$ 이라는 함수에 의해 정의된다.  

node의 집합 $\mathcal{V}=[v_1, v_2, v_3, v_4]$ 에 대한 node feature matrix는 $(4, d)$ 형태의 2차원 행렬일 것인데 이 행렬의 각 행이 한 node에 대한 signal이라고 생각해보면 아래와 같이 표현할 수 있다.  

$$
\mathcal{V} \rightarrow \left[\begin{matrix} f_1\\f_2\\f_3\\f_4\\ \end{matrix}
\right] = \mathbf{f}
$$

이 Graph의 인접 행렬(Adjacency Matrix)를 표현하면 아래와 같다.  

$$
A = \left[
    \begin{matrix}
    0 & 1 & 1 & 0 \\
    1 & 0 & 1 & 0 \\
    0 & 1 & 1 & 1 \\
    0 & 0 & 1 & 0 \\
    \end{matrix}
\right]
$$

그리고 Graph의 Degree Matrix는 $D$ 이며 이 두 행렬을 이용하여 `Laplacian Matrix`를 정의한다.  

$$ \mathbf{L} = \mathbf{D} - \mathbf{A} $$  

`Laplacian Matrix`를 difference operator로 활용해보자.  

<center><img src="/public/img/Machine_Learning/2021-08-14-GFT/01.jpg" width="80%"></center>  

위 식을 마치고 


---

**spectral**이란 단어는 Graph 인접 행렬의 eigenvalue와 eigenvector를 구한다는 뜻을 내포한다.  

