---
layout: post
title: Adversarial AutoEncoder (AAE) 설명
author: Youyoung
categories: [Generative Model]
tags: [Machine Learning, Paper_Review, Bayesian_Statistics]
---

본 글에서는 `VAE`와 `GAN`을 결합한 `Adversarial Autoencoder` (이하 `AAE`)에 대한 논문을 리뷰하면서 이론에 대해 설명하고 이를 Tensorflow로 구현하는 과정을 보여줄 것이다. 이 알고리즘을 이해하기 위해서는 앞서 언급한 2가지 알고리즘에 대해 숙지하고 있어야 하며, `VAE`에 대해 알고 싶다면 [이 글](https://greeksharifa.github.io/generative%20model/2020/07/31/Variational-AutoEncoder/)을, `GAN`에 대해 알고 싶다면 [이 글](https://greeksharifa.github.io/generative%20model/2019/03/03/GAN/)을 참조하길 바란다.  

---
# 1. Adversarial Autoencoders Paper Review  
## 1.1. Introduction  
오디오, 이미지, 영상 등과 같은 rich distribution을 포착하기 위해 Scalable한 생성 모델을 구성하는 것은 머신러닝에서도 굉장히 중요하고도 어려운 문제로 여겨진다. RBM, DBNs, DBM 등은 MCMC 기반의 알고리즘으로 학습되었다. 이러한 방법론들은 학습이 진행될수록 부정확하게 Log Likelihood의 Gradient를 포착하는 경향을 보였다. 왜냐하면 Markov Chain에서 온 Sample들은 여러 Mode를 빠르게 혼합하지 못하기 때문이다.  

최근에는 이 대신 **Direct Back-propagation**을 이용하여 이 같은 단점을 극복한 `VAE`, `GAN`과 같은 알고리즘이 제안되었다.  

본 논문에서는 autoencoder를 생성 모델로 변환하는 `AAE`라는 알고리즘을 제안할 것이다. 우리의 모델에서 이 autoencoder는 autoencoder의 Latent Representation의 **Aggregated Posterior**를 **Arbitrary Prior**에 연결하는 2개의 목적함수 (**Traditional Reconstruction Error Criterion**, **Adversarial Training Criterion**)로 학습을 진행할 것이다. 본 논문에서는 이러한 학습 방법이 `VAE`의 학습과 강력한 연관성을 보여준다는 것을 보여줄 것이다. Encoder가 데이터 분포를 **Prior** 분포로 변환하는 방법에 대해 학습하고 Decoder는 **Imposed Prior**를 데이터 분포에 매핑하는 Deep 생성 모델을 학습하게 된다.  

### 1.1.1. Generative Adversarial Networks  
**GAN**은 생성 모델 `G`와 판별 모델 `D`라는 2개의 신경망 사이의 Min-Max 적대적 게임을 구축하는 프레임워크이다. 판별 모델 $D(x)$ 는 데이터 공간의 포인트 $\mathbf{x}$ 가 실제 데이터 분포 (Positive Samples) 로 부터 추출되었는지를 계산하는 신경망이다. 생성자는 $G(\mathbf{z})$ 라는 함수를 사용하게 되는데, 이 함수는 Prior $p(\mathbf{z})$ 로부터 추출된 Sample $\mathbf{z}$ 를 데이터 공간에 연결시키는 역할을 한다. $G(\mathbf{z})$ 는 최대한 판별 모델로 하여금 Sample이 실제 데이터 분포로부터 추출되었다고 믿게 만드는, 속이는 역할을 하게 된다. 이 생성자는 x에 대하여 $D(x)$ 의 Gradient를 레버리지하여 학습된다. 그리고 이를 활용하여 파라미터를 조정한다. 이 게임의 해는 아래와 같이 표현할 수 있다.  

$$ \underset{G}{min} \underset{D}{max} E_{\mathbf{x} \sim p_{data}} [logD(\mathbf{x})] + E_{\mathbf{z} \sim p(\mathbf{z})} [log(1 - D(G(\mathbf{z})))] $$  

alternating SGD를 이용하여 2단계로 학습이 진행된다. 먼저 판별자가 생성자로부터 생성된 가짜 Sample로부터 진짜 Sample을 구별하는 방법을 학습하고, 생성자는 이후 생성된 Sample을 통해 판별자를 속이는 방법을 학습한다.  

## 1.2. Adversarial Autoencoders  
잠시 기호에 대해 살펴보자.  

$$ p(\mathbf{z}), q(\mathbf{z}|\mathbf{x}), p(\mathbf{x}|\mathbf{z}) $$  

위 기호는 차례대로 1) Code에 투사하고 싶은 **Prior** 분포, 2) Encoding 분포, 3) Decoding 분포를 의미한다.  

$$ p_d (\mathbf{x}), p(\mathbf{x}) $$  

위 기호는 차례대로 4) 실제 데이터 분포, 5) Model 분포를 의미한다. Encoding 함수는 autoencoder의 (잠재 표현) `Hidden Code 벡터`에 대한 **Aggregated Posterior** 분포를 아래와 같이 정의한다.  

$$ q(\mathbf{z}) = \int_{\mathbf{x}} q(\mathbf{z} | \mathbf{x}) p_d (\mathbf{x}) d\mathbf{x} $$  

`Adversarial Autoencoder`는 **Aggregated Posterior**인 $q(\mathbf{z})$ 를 **Arbitrary Prior**인 $p(\mathbf{z})$ 와 매칭시킴으로써 regualarized 된다. 그렇게 하기 위해서 이 적대적 네트워크는 아래 그림과 같이 autoencoder의 `Hidden Code 벡터`의 상위에 추가된다.  

<center><img src="/public/img/Machine_Learning/2020-08-23-AAE/01.JPG" width="100%"></center>  

autoencoder는 그동안 `Reconstruction Error`를 최소화한다. 적대적 네트워크의 생성자는 사실 autoencoder의 encoder이다.  

$$ q(\mathbf{z} | \mathbf{x}) $$  

Encoder는 Hidden Code인 $q(\mathbf{z})$ 가 실제 **Prior** 분포 $p(\mathbf{z})$ 로부터 왔다고 판별 모델을 착각하게 만들어 **Aggregated Posterior** 분포가 판별 모델을 속이도록 만든다.  

적대적 네트워크와 autoencoder 모두 2단계를 통해 **SGD**로 결합하여 학습된다. (Reconstruction 단계 Regularization 단계) Reconstruction 단계에서 autoencoder는 Encoder와 Decoder가 Input에 대한 `Reconstruction Error`를 최소화하도록 업데이트하게 된다. Regularization 단계에서 적대적 네트워크는 먼저 판별 모델이 진짜 Sample을 구별하도록 업데이트한 후, 생성자가 판별 네트워크를 속이도록 업데이트를 진행한다.  

이러한 학습과정이 끝나면, autoencoder의 Decoder는 투사된 **Prior**인 $p(\mathbf{z})$ 를 실제 데이터 분포에 매핑하는 생성 모델을 정의하게 된다.  

`AAE`의 Encoder를 정의하는 방법에는 다음과 같이 3가지가 존재한다.  

$$ Encoder: q(\mathbf{z}|\mathbf{x}) $$  

**1) Deterministic**  
Encoder가 $\mathbf{x}$ 의 deterministic 함수라고 가정해보자. 그렇다면 이 때의 Encoder는 가장 기본적인 형태의 autoencoder의 Encoder과 유사할 것이고 $q(\mathbf{z})$ 내부의 Stochasticity는 오직 실제 데이터 분포 $p_d (\mathbf{x})$ 에서만 찾을 수 있게 된다.  

**2) Gaussian Posterior**  
Encoder가 Encoder 네트워크에 의해 예측된 평균과 분산을 따르는 정규 분포라고 가정해보자.  

$$ z_i \sim \mathcal{N} (\mu_i(\mathbf{x}), \sigma_i(\mathbf{x})) $$  

이 때 $q(\mathbf{z})$ 의 Stochasticity는 실제 데이터 분포와 Encoder의 결과의 정규 분포의 Randomness 모두에서 나온다. `VAE`에서 보았듯이 Encoder 네트워크의 Back-propagation은 `Reparametrization Trick`을 통해 이루어진다.  

**3) Universal Approximator Posterior**  
`AAE`의 Encoder네트워크가 정규 분포와 같은 고정된 분포에서 추출한 **Random Noise** $\eta$ 와 Input $\mathbf{x}$ 의 함수 $f(\mathbf{x}, \eta)$ 라고 해보자. 우리는 여러 $\eta$ 를 Sampling 한 뒤 이에 따른 $f(\mathbf{x}, \eta)$ 를 평가하여 아래와 같은 (Encoder) 임의의 사후 분포를 추출할 수 있다.  

$$ q(\mathbf{z|x}) $$  

우리는 Aggregated Posterior인 $q(\mathbf{z})$ 를 아래와 같이 표현할 수 있을 것이다.  

$$  q(\mathbf{z|x}) = \int_{\eta} q(\mathbf{z|x}, \eta) p_{\eta} (\eta) d \eta $$  

$$ \rightarrow q(\mathbf{z}) = \int_{\mathbf{x}} \int_{\eta} q(\mathbf{z|x}, \eta) p_d(\mathbf{x}) p_{\eta} p_{\eta}(\eta) d\eta d\mathbf{x} $$  

$$ q(\mathbf{z|x}) $$  

이 때 위와 같은 **Posterior**는 더 이상 Gaussian일 필요가 없고, Encoder는 Input $\mathbf{x}$ 가 주어졌을 때 어떠한 임의의 사후 분포도 학습할 수 있다. **Aggregated Posterior** $q(\mathbf{z})$ 로부터 Sampling을 하는 효과적인 방법이 존재하기 때문에, 적대적 학습 과정은 Encoder 네트워크 $f(\mathbf{x}, \eta)$ 를 통한 직접적인 Back-propagation으로 $q(\mathbf{z})$ 를 $p(\mathbf{x})$ 에 연결할 수 있다.  

지금까지 확인한 것처럼, 위 **Posterior**를 여러 다른 종류로 선택하게 되면 이는 또 다른 학습 Dymamics를 가진 다른 종류의 모델로 귀결된다. 예를 들어 1) Deterministic Case에서 네트워크는 데이터 분포로부터 Stochasticity를 뽑아내서 $q(\mathbf{z})$ 를 $p(\mathbf{x})$ 와 매칭시켜야 한다. 그러나 데이터의 경험적 분포가 학습 데이터 셋에서 고정되어 있기 때문에 Mapping이 Deterministic하면 부드럽지 못한 $q(\mathbf{z})$ 를 만들지도 모른다.  

하지만 나머지 2개의 케이스에서는 네트워크가 Stochasticity의 추가적인 원천에 접근할 수 있기 때문에 이는 $q(\mathbf{z})$ 를 부드럽게 만들어 **Adversarial Regularization** 단계에서 개선이 이루어진다. 그럼에도 불구하고, 굉장히 광범위한 Hyper-parameter Search를 통해서 우리는 **Posterior**의 각 경우에 맞는 유사한 Test-Likelihood를 얻을 수 있었고 따라서 지금부터 본 논문에서는 **Posterior**의 Deterministic한 버전을 통해서 논의를 전개해 나가도록 할 것이다.  

### 1.2.1. Relationship to Variational Autoencoders  
`VAE`에서는 KL divergence 페널티를 사용하여 autoencoder의 `Hidden Code 벡터`에 **Prior** 분포를 투사하지만, Hidden Code의 **Aggregated Posterior**를 **Prior** 분포에 매칭시키는 적대적 학습 과정을 사용할 것이다. `VAE`는 아래와 같이 $\mathbf{x}$ 의 Negative Log-Likelihood에 대한 상한선을 최소화한다.  

$$ E_{\mathbf{x} \sim p_d(\mathbf{x})} [-logp(\mathbf{x})] < E_{\mathbf{x}} [-log(p(\mathbf{x|z}))] + E_{\mathbf{x}} [KL(q(\mathbf{z|x})||p(\mathbf{z}))] $$  

$$ = E_{\mathbf{x}} [-log(p(\mathbf{x|z}))] - E_{\mathbf{x}} [H(q(\mathbf{z|x}))] + E_{q(\mathbf{z})} [-logp(\mathbf{z})] $$  

$$ = E_{\mathbf{x}} [-log(p(\mathbf{x|z}))] - E_{\mathbf{x}}[\Sigma_i log \sigma_i (\mathbf{x})] + E_{q(\mathbf{z})} [-logp(\mathbf{z})] + Const $$  

$$ Reconstruction - Entropy + CrossEntropy(q(\mathbf{z}), p(\mathbf{z})) $$  

첫 번째 항은 `Reconstruction` 항으로, 나머지 항은 `Regularization` 항으로 생각할 수 있다. 만약 `Regularization` 항이 없다면 모델은 단순히 Input을 재현하는 기본적인 autoencoder의 형태를 취할 것이다. 두 번째 항이 사후 분포의 분산을 크게 만든다면, 세 번째 항은 **Aggregated Posterior** $q(\mathbf{z})$ 와 **Prior** $p(\mathbf{z})$ 사이의 Cross-Entropy를 최소화한다.  

위 목적함수에서 KL divergence 또는 Cross-Entropy 항은 $q(\mathbf{z})$ 가 $p(\mathbf{z})$ 의 Modes를 고르도록 만든다. `AAE`에서 우리는 두 번째 두 항을 $q(\mathbf{z})$ 가 $p(\mathbf{z})$ 의 전체 분포와 매칭되게 하는 적대적 학습 과정으로 대체하였다.  

본 섹션에서 우리는 구체적인 **Prior** 분포 $p(\mathbf{z})$ 를 Coding 분포에 투사하는 능력에 대해 `AAE`와 `VAE`를 비교해볼 것이다. 

<center><img src="/public/img/Machine_Learning/2020-08-23-AAE/02.JPG" width="100%"></center>  

위 그림은 



### 1.2.2. Relationship to GANs and GMMNs  

### 1.2.3. Incorporating Label Information in the Adversarial Regularization  


## 1.3. Likelihood Analysis of Adversarial Autoencoders  

## 1.4. Supervised Adversarial Autoencoders 

## 1.5. Semi-Supervised Adversarial Autoencoders  

## 1.6. Unsupervised Clustering with Adversarial Autoencoders  

## 1.7. Dimentionality Reduction with Adversarial Autoencoders  

## 1.8. Conclusion  



---
# 2. Tensorflow로 구현  





---
# Reference  
1) [논문 원본](https://arxiv.org/abs/1511.05644)  
2) s