---
layout: post
title: DAN(Dual Attention Networks for Multimodal Reasoning and Matching)
author: YouWon
categories: [Computer Vision]
tags: [Attention Mechanism, Paper_Review, VQA]
---

---

이 글에서는 네이버랩스(Naver Corp.)에서 2017년 발표한 논문인 Dual Attention Networks for Multimodal Reasoning and Matching에 대해 알아보고자 한다.  
네이버랩스는 인공지능 국제대회 'VQA Challenge 2016'에서 2위를 차지하였고, 해당 챌린지에서 DAN(Dual Attention Networks)라는 알고리즘을 개발하였다. 이어 이 알고리즘을 조금 더 일반화하여 2017년 발표한 논문이 이 논문이다.

간단히, DAN은 


논문을 적절히 번역 및 요약하는 것으로 시작한다. 많은 부분을 생략할 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.

---

# DAN(Dual Attention Networks for Multimodal Reasoning and Matching)

논문 링크: **[DAN(Dual Attention Networks for Multimodal Reasoning and Matching)](https://arxiv.org/abs/1611.00471)**

## 초록(Abstract)



---

## 서론(Introduction)


---

## 관련 연구(Related Works)

- **Structures losses for image modeling:** 


---

## 방법(Method)



---

## 실험(Experiments)




<center><img src="/public/img/2019-04-07-Pix2Pix/08.png" width="100%"></center>



---

## 결론(Conclusion)



### Acknowledgments

~~매우 많다 ㅎㅎ~~

---

## 참고문헌(References)

논문 참조!

--- 




---

## 부록



---