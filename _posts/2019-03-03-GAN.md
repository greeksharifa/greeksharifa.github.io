---
layout: post
title: GAN(Generative Adversarial Networks)
author: YouWon
categories: Paper_Review
tags: [GAN, Machine Learning]
---

**[논문 링크](https://arxiv.org/abs/1406.2661)**

이 글에서는 생성적 적대신경망(GAN, Generative Adversarial Network)을 알아보도록 한다.  
GAN은 Ian J. Goodfellow가 2014년 제안한 생성 모델이다.

간단히 GAN은 두 가지 모델을 동시에 학습시키는 구조이다. G(Generator, 생성자)라는 모델은 직접 볼 수 없는 진짜 데이터와 최대한 비슷하게 생긴 가짜 데이터를 만드려고 하고, D(Distriminator, 식별자 또는 감별자)라는 모델은 자신에게 주어진 데이터가 진짜 데이터인지 가짜 데이터인지 최대한 구분하려고 한다.  

논문에서는 설명을 위한 예시로 화폐 위조범(G)와 경찰(D)을 제시하였다. 다만 차이가 있다면,
- 위조범은 진짜를 볼 수 없다는 것(그래서 장님blind라 불린다)
- 경찰은 자신이 판별한 결과를 위조범에게 알려준다
는 것이 있다.

참고로 GAN은 특정한 모델 구조를 가진 것이 아니므로 코드가 특별히 정해진 것은 아니다.

논문을 적절히 번역 및 요약하는 것으로 시작한다. 많은 부분을 생략할 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.

---

## 초록(Abstract)

이 논문에서는 적대적으로 동작하는 두 생성 모델을 동시에 학습시키는 새 framework를 제안한다. 생성자 G는 원본 data distribution을 흉내내려 하고, D는 눈앞의 데이터가 G에게서 온 것인지를 판별한다. G의 목적은 D가 최대한 실수하게 만드는 것이고, D는 당연히 최대한 정확하게 진짜/가짜를 판별하는 것이다.  
이는 2인 minimax 게임과 비슷하다. 어떤 유일한 해가 존재하여 최종적으로 D는 실수할 확률이 0.5가 된다(즉 찍는 수준).  
G와 D가 multi-layer perceptron으로 구성되면 전체 시스템은 backpropagation으로 학습될 수 있다.  
GAN에는 어느 과정에서든 마르코프 체인이나 기타 다른 네트워크가 필요가 전혀 없다.

---

## 서론(Introduction)

***적대적***인 두 네트워크를 학습시킨다. D는 원본 data distribution인지 G에서 온 것인지를 판별하고, G는 D가 실수하도록 가짜 데이터를 잘 만들어내는 것이 목표이다.  
이 framework는 많은 특별한 학습 알고리즘과 optimizer를 사용할 수 있다. 앞서 말한 대로 multi-layer perception을 쓰면 다른 복잡한 네트워크는 필요 없이 오직 forward/backpropagation만으로 (이 논문에서는 dropout을 또 쓴다) 학습이 가능하다.

---

## 관련 연구(Related Works)

궁금하면 읽어보자.
- RBMs: restricted Boltzmann machines, 잠재 변수를 가진 유향 그래프 모델에 대한 대안으로, 무향 그래프 모델
- DBMs: deep Boltzmann machines, RBMs와 비슷함. 다양한 변형이 존재
- MCMC: Markov chain Monte Carlo methods, 위 모델의 측정 방법
- DBNs: Deep belief networks, 하나의 무향 레이어와 여러 유향 레이어의 hybrid 모델. 계삭적 문제가 있음
- NCE: noise-contrasive estimation, log-likelihood를 근사하거나 경계값을 구하지 않는 방법
- GSN: generative stochastic network, 확률분포를 명시적으로 정의하지 않고 분포 샘플을 생성하도록 학습시키는 방법을 사용
- **adversarial nets**: 적대적 망은 생성 중 feedback loop를 필요로 하지 않아 sampling에서 Markov chain이 필요가 없다. 이는 backpropagation 성능 향상으로 이어진다. 
- auto-encoding varitional Bayes와 stochastic backpropagation은 생성 머신을 학습시키는 방법들 중 하나이다.

---

## 적대적 망(Adversarial nets)

기호 | 설명
-------- | --------
$x$ | 데이터
$p_g$ | $x$에 대한 생성자의 분포
$p_z(z)$ | input noise 변수
$\theta_g$ | multilayer perceptrions의 parameters
$G$ | $\theta_g$에 의해 표현되는 미분가능한 함수
$G(z; \theta_g$) | data space에 대한 mapping
$D(x)$ | $x$가 $p_g$가 아니라 원본 데이터에서 나왔을 확률
$D(x; \theta_d)$ | 두 번째 multilayer perceptron

D의 목적은 데이터가 '원본'인지 'G가 생성한 데이터'인지 판별하는 것이므로 어떤 데이터에 대해 정확한 label('원본' 또는 'G로부터')을 붙이는 것이다. G의 목적은 D가 실수하게 만드는 것, 즉 어떤 데이터가 주어졌을 때 D가 '원본'이라고 판별할 확률과 'G로부터 나온 데이터'라고 판별할 확률을 모두 높이는 것(정확히는 같게)이다.  
즉 $log(1-D(G(z)))$를 최소화하도록 G를 훈련시킨다.

D와 G 모두에 대해 value function $V(G, D)$를 정의하면, 

$$ min_G max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[log D(x)] + \mathbb{E}_{x \sim p_{z}(z)}[log (1-D(G(z)))]  $$

위 식의 의미는,
- $min_G$: G는 V를 최소화하려고 한다.
- $max_D$: D는 V를 최대화하려고 한다. 2-player minimax 게임과 같으므로 당연하다.
- $\mathbb{E}$: 기댓값
- $x \sim p_{data}(x)$: $x$가 원본 데이터 분포에서 왔을 때


D가 *아주 똑똑한 경찰*이라면, $x$가 실제로 원본에서 온 것이라면 $D(x)=1$이 될 것이고, $G(z)$에서 온 것이라면 $D(G(z))=0$이 된다. 만약 G가 *완벽한 위조범*이 되었다면, $D(x) = {1 \over 2}$이다.  
따라서 D의 입장에서 V의 최댓값은 0이 되며, G의 입장에서 V의 최솟값은 $-\infty$임을 알 수 있다.

학습시킬 때, inner loop에서 D를 최적화하는 것은 매우 많은 계산을 필요로 하고 유한한 데이터셋에서는 overfitting을 초래하기 때문에, $k$ step만큼 D를 최적화하고 G는 1 step만 최적화하도록 한다.  
학습 초반에는 G가 형편없기 때문에 D는 진짜인지 G가 생성한 것인지를 아주 잘 구분해 낸다.  
또 G가 $log(1-D(G(z)))$를 최소화하도록 하는 것보다는 $log(D(G(z)))$를 최대화하도록 하는 것이 더 학습이 잘 된다. 이는 G가 형편없을 때는 $log(1-D(G(z)))$의 gradient를 계산했을 때 너무 작은 값이 나와 학습이 느리기 때문이라고 한다.

<center><img src="/public/img/2019-03-03-GAN/01.PNG" width="100%"></center>

파란 점선은 disctiminative distribution(D), 검정색은 원본 데이터($p_x$), 초록색은 생성된 분포$p_g$(G), $x$는 원본 데이터 분포를, 화살표는 $x=G(z)$ mapping을 나타낸다. (a) 초기 상태. (b) D 학습 후, (c) G 학습 후, 분포가 비슷해지는 것을 볼 수 있다. (d) 여러 번의 학습 끝에 G가 완전히 원본을 흉내낼 수 있는 경지에 도달함. 즉 $p_g = p_{data}$. D는 이제 진짜인지 가짜인지 구분할 수 없다. 즉 $D(x) = {1 \over 2}$.

---

## 이론적 결과(Theoretical Results)

수학을 좋아한다면 직접 읽어보자.
- Algorithm 1
    - for epochs do
        - for k steps do
            - noise prior $p_g(z)$로부터 $m$개의 noise sample $z^{(1)}, ..., z^{(m)}$을 뽑는다.
            - noise prior $p_{data}(x)$로부터 $m$개의 noise sample $x^{(1)}, ..., x^{(m)}$을 뽑는다.
            - D를 다음 stochastic gradient로 update한다. (ascending)
                - $ \nabla_{\theta_d} {1 \over m} \sum^m_{i=1} [log D(x^{(i)}) + log (1-D(G(z^{(i)})))] $
        - noise prior $p_g(z)$로부터 $m$개의 noise sample $z^{(1)}, ..., z^{(m)}$을 뽑는다.
        - G를 다음 stochastic gradient로 update한다. (descending)
            - $ \nabla_{\theta_d} {1 \over m} \sum^m_{i=1} [log (1-D(G(z^{(i)})))] $
- 이 minimax 게임은 $p_g = p_{data}$에 대한 global optimum을 가진다.
    - G를 고정했을 때, optimal한 D는 $ D^*_G(x) = {p_{data}(x) \over p_{data}(x) + p_g(x)} $
- Algorithm 1은 수렴한다.

---

## 실험(Experiments)

MNIST, Toronto Face Database(TFD), CIFAR-10에 대해 학습을 진행했다.

- G는 rectifier linear activations와 sigmoid를 사용했고, D는 maxout activations를 사용했다. 
- Dropout은 D를 학습시킬 때 사용했다. 
- noise는 G에서 가장 밑의 레이어에만 input으로 넣었다.

자세한 실험 조건은 직접 읽어보자.

<center><img src="/public/img/2019-03-03-GAN/02.PNG" width="100%"></center>

가장 오른쪽 열은 바로 옆에 있는 생성된 이미지와 가장 비슷한 학습 샘플이다. a) MNIST b) TFD c) CIFAR-10(fully connected model) d) CIFAR-10(convolutional D와 "deconvolutional" G)

<center><img src="/public/img/2019-03-03-GAN/03.PNG" width="100%"></center>

숫자 간 보간을 했을 때는 위와 같이 된다. 물론 GAN을 통해 생성한 것이다.

---

## 장단점(Advantages and disadvantages)

### 단점

- $p_g(x)$가 명시적으로 존재하지 않는다.
- D는 G와 균형을 잘 맞추어서 성능이 향상되어야 한다(G는 D가 발전하기 전 너무 발전하면 안 된다).

### 장점
- 마르코프 체인이 전혀 필요 없이 backprop만으로 학습이 된다.
- 특별히 어떤 추론(inference)도 필요 없다.
- 다양한 함수들이 모델에 접목될 수 있다.
- 마르코프 체인을 썼을 때에 비해 훨씬 선명한(sharp) 이미지를 결과로 얻을 수 있다.

---

## 결론 및 추후 연구(Conclusions and future work)

1. conditional generative model로 발전시킬 수 있다(CGAN).
2. Learned approximate inference는 $x$가 주어졌을 때 $z$를 예측하는 보조 네트워크를 학습함으로써 수행될 수 있다. 
3. parameters를 공유하는 조건부 모델을 학습함으로써 다른 조건부 모델을 대략 모델링 할 수 있다. 특히, deterministic MP-DBM의 stochastic extension의 구현에 대부분의 네트워크를 쓸 수 있다.
4. Semi-supervised learning에도 활용 가능하다. classifier의 성능 향상을 꾀할 수 있다.
5. 효율성 개선: G와 D를 조정하는 더 나은 방법이나 학습하는 동안 sample $z$에 대한 더 나은 distributions을 결정하는 등의 방법으로 속도를 높일 수 있다.

--- 
