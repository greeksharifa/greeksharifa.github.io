<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>YW & YY</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <link href="http://localhost:4000/"/>
 <updated>2020-05-29T22:23:23+09:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>YW & YY</name>
   <email></email>
 </author>

 
 <entry>
   <title>GitHub 사용법 - 09. Overall</title>
   <link href="http://localhost:4000/github-usage-09-overall/"/>
   <updated>2020-05-27T00:00:00+09:00</updated>
   <id>http://localhost:4000/github-usage-09-overall</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/08/19/github-usage-08-conflict/&quot;&gt;저번 글&lt;/a&gt;에서는 Conflict에 대해서 알아보았다.&lt;br /&gt;
이번 글에서는, 전체 Git 명령어들의 사용법을 살펴본다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;명령어에 일반적으로 적용되는 규칙:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;이 글에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;blabla&amp;gt;&lt;/code&gt;와 같은 token은 여러분이 알아서 적절한 텍스트로 대체하면 된다.&lt;/li&gt;
  &lt;li&gt;각 명령에는 여러 종류의 옵션이 있다. ex) &lt;code class=&quot;highlighter-rouge&quot;&gt;git log&lt;/code&gt;의 경우 &lt;code class=&quot;highlighter-rouge&quot;&gt;--oneline&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;-&amp;lt;number&amp;gt;&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;-p&lt;/code&gt; 등의 옵션이 있다.&lt;/li&gt;
  &lt;li&gt;각 옵션은 많은 경우 축약형이 존재한다. 일반형은 &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;가 2개 있으며, 축약형은 &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;가 1개이며 보통 첫 일반형의 첫 글자만 따온다. ex) &lt;code class=&quot;highlighter-rouge&quot;&gt;--patch&lt;/code&gt; = &lt;code class=&quot;highlighter-rouge&quot;&gt;-p&lt;/code&gt;. 축약형과 일반형은 효과가 같다.&lt;/li&gt;
  &lt;li&gt;각 옵션의 순서는 상관없다. 명령의 필수 인자와 옵션의 순서를 바꾸어도 상관없다.&lt;/li&gt;
  &lt;li&gt;각 명령에 대한 자세한 설명은 &lt;code class=&quot;highlighter-rouge&quot;&gt;git help &amp;lt;command-name&amp;gt;&lt;/code&gt;으로 확인할 수 있다.&lt;/li&gt;
  &lt;li&gt;ticket branch는 parent branch로부터 생성되어, 어떤 특정 기능을 추가하고자 만든 실험적 branch라 생각하면 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;working-tree작업트리-생성&quot;&gt;Working tree(작업트리) 생성&lt;/h2&gt;

&lt;h3 id=&quot;git-init&quot;&gt;git init&lt;/h3&gt;

&lt;p&gt;빈 디렉토리나, 기존의 프로젝트를 &lt;strong&gt;git 저장소&lt;/strong&gt;(=&lt;strong&gt;git repository&lt;/strong&gt;)로 변환하고 싶다면 이 문단을 보면 된다.&lt;/p&gt;

&lt;p&gt;일반적인 디렉토리(=git 저장소가 아닌 디렉토리)를 git working tree로 만드는 방법은 다음과 같다. &lt;strong&gt;명령창&lt;/strong&gt;(cmd / terminal)에서 다음을 입력한다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git init

# 결과 예시
Initialized &lt;span class=&quot;nb&quot;&gt;empty&lt;/span&gt; Git repository &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; blabla&lt;span class=&quot;sr&quot;&gt;/sample_directory/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;git/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그러면 해당 디렉토리에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;.git&lt;/code&gt; 이라는 이름의 숨김처리된 디렉토리가 생성된다. 이 디렉토리 안에 든 것은 수동으로 건드리지 않도록 한다.&lt;/p&gt;

&lt;p&gt;참고) &lt;code class=&quot;highlighter-rouge&quot;&gt;git init&lt;/code&gt; 명령만으로는 인터넷(=&lt;strong&gt;원격 저장소&lt;/strong&gt; = &lt;strong&gt;remote repository&lt;/strong&gt;)에 그 어떤 연결도 되어 있지 않다. &lt;a href=&quot;https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#git-repository-%EC%97%B0%EA%B2%B0&quot;&gt;여기&lt;/a&gt;를 참조한다.&lt;/p&gt;

&lt;h3 id=&quot;git-clone&quot;&gt;git clone&lt;/h3&gt;

&lt;p&gt;인터넷에서 이미 만들어져 있는 작업트리를 본인의 컴퓨터(=&lt;strong&gt;로컬&lt;/strong&gt;)로 가져오고 싶을 때에는 해당 git repository의 &lt;code class=&quot;highlighter-rouge&quot;&gt;https://github.com/blabla.git&lt;/code&gt; 주소를 복사한 뒤 다음과 같은 명령어를 입력한다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;git&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;address&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

# 명령어 예시 
git clone https&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;//&lt;/span&gt;github&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/greeksharifa/&lt;/span&gt;git_tutorial&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;git

# 결과 예시
Cloning into &lt;span class=&quot;s1&quot;&gt;'git_tutorial'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
remote&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; Enumerating objects&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;56&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; done&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
remote&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; Total &lt;span class=&quot;m&quot;&gt;56&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;delta &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; reused &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;delta &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; pack&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;reused &lt;span class=&quot;m&quot;&gt;56&lt;/span&gt;
Unpacking objects&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;% &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;56&lt;/span&gt;/&lt;span class=&quot;m&quot;&gt;56&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; done&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;그러면 현재 폴더에 해당 프로젝트 이름의 하위 디렉토리가 생성된다. 이 하위 디렉토리에는 인터넷에 올라와 있는 모든 내용물을 그대로 가져온다(&lt;code class=&quot;highlighter-rouge&quot;&gt;.git&lt;/code&gt; 디렉토리 포함).&lt;br /&gt;
단, 다른 branch의 내용물을 가져오지는 않는다. 다른 branch까지 가져오려면 &lt;a href=&quot;&quot;&gt;추가 작업&lt;/a&gt;이 필요하다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;git-repository-연결&quot;&gt;Git Repository 연결&lt;/h2&gt;

&lt;p&gt;이 과정은 &lt;code class=&quot;highlighter-rouge&quot;&gt;git clone&lt;/code&gt;으로 원격저장소의 로컬 사본을 생성한 경우에는 필요 없다.&lt;/p&gt;

&lt;p&gt;먼저 &lt;a href=&quot;https://github.com/&quot;&gt;github&lt;/a&gt; 등에서 원격 저장소(remote repository)를 생성한다.&lt;/p&gt;

&lt;p&gt;로컬 저장소를 원격저장소에 연결하는 방법은 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git remote &lt;span class=&quot;nb&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;remote&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;git address&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

# 명령어 예시
git remote &lt;span class=&quot;nb&quot;&gt;add&lt;/span&gt; origin https&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;//&lt;/span&gt;github&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/greeksharifa/&lt;/span&gt;git_tutorial&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;remote-name&amp;gt;&lt;/code&gt;은 원격 저장소에 대한 일종의 별명인데, 보통은 &lt;code class=&quot;highlighter-rouge&quot;&gt;origin&lt;/code&gt;을 쓴다. 큰 프로젝트라면 여러 개를 쓸 수도 있다.&lt;/p&gt;

&lt;p&gt;이것만으로는 완전히 연결되지는 않았다. &lt;a href=&quot;https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#upstream-%EC%97%B0%EA%B2%B0&quot;&gt;upstream 연결&lt;/a&gt;을 지정하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;git push -u&lt;/code&gt; 명령을 사용해야 수정사항이 원격 저장소에 반영된다.&lt;/p&gt;

&lt;h3 id=&quot;연결된-원격-저장소-확인&quot;&gt;연결된 원격 저장소 확인&lt;/h3&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git remote &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;verbose&lt;/span&gt;
git remote &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;v&lt;/span&gt;

# 결과 예시
origin  https&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;//&lt;/span&gt;github&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/greeksharifa/&lt;/span&gt;git_tutorial&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;git &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;fetch&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
origin  https&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;//&lt;/span&gt;github&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/greeksharifa/&lt;/span&gt;git_tutorial&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;git &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;push&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;git-준비-영역index에-파일-추가&quot;&gt;Git 준비 영역(index)에 파일 추가&lt;/h2&gt;

&lt;p&gt;로컬 저장소의 수정사항이 반영되는 과정은 총 3단계를 거쳐 이루어진다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt; 명령을 통해 준비 영역에 변경된 파일을 추가하는 과정(stage라 부른다)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git commit&lt;/code&gt; 명령을 통해 여러 변경점을 하나의 commit으로 묶는 과정&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git push&lt;/code&gt; 명령을 통해 로컬 commit 내용을 원격 저장소에 올려 변경사항을 반영하는 과정&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이 중 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt; 명령은 첫 단계인, &lt;strong&gt;준비 영역&lt;/strong&gt;에 파일을 추가하는 것이다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git &lt;span class=&quot;nb&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;filename1&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&amp;lt;&lt;/span&gt;filename2&lt;span class=&quot;p&quot;&gt;&amp;gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...]&lt;/span&gt;
git &lt;span class=&quot;nb&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;directory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
git &lt;span class=&quot;nb&quot;&gt;add&lt;/span&gt; *
git &lt;span class=&quot;nb&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;all&lt;/span&gt;
git &lt;span class=&quot;nb&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;

# 명령어 예시
git &lt;span class=&quot;nb&quot;&gt;add&lt;/span&gt; third&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt; fourth&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;
git &lt;span class=&quot;nb&quot;&gt;add&lt;/span&gt; temp_dir/*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;은 와일드카드로 그냥 쓰면 변경점이 있는 모든 파일을 준비 영역에 추가한다(&lt;code class=&quot;highlighter-rouge&quot;&gt;git add *&lt;/code&gt;). 특정 directory 뒤에 쓰면 해당 directory의 모든 파일을, &lt;code class=&quot;highlighter-rouge&quot;&gt;*.py&lt;/code&gt;와 같이 쓰면 확장자가 &lt;code class=&quot;highlighter-rouge&quot;&gt;.py&lt;/code&gt;인 모든 파일이 준비 영역에 올라가게 된다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;git add .&lt;/code&gt;을 현재 directory(&lt;code class=&quot;highlighter-rouge&quot;&gt;.&lt;/code&gt;)의 모든 파일을 추가하는 명령으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add --all&lt;/code&gt;과 효과가 같다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt; 명령을 실행하고 이미 준비 영역에 올라간 파일을 또 수정한 뒤 &lt;a href=&quot;https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#git-status&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git status&lt;/code&gt;&lt;/a&gt; 명령을 실행하면 같은 파일이 &lt;strong&gt;Changes to be committed&lt;/strong&gt; 분류와 &lt;strong&gt;Changes not staged for commit&lt;/strong&gt; 분류에 동시에 들어가 있을 수 있다. 딱히 오류는 아니고 해당 파일을 다음 commit에 반영할 계획이면 한번 더 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt;를 실행시켜주자.&lt;/p&gt;

&lt;h3 id=&quot;한-파일-내-수정사항의-일부만-준비-영역에-추가&quot;&gt;한 파일 내 수정사항의 일부만 준비 영역에 추가&lt;/h3&gt;

&lt;p&gt;예를 들어 &lt;code class=&quot;highlighter-rouge&quot;&gt;fourth.py&lt;/code&gt;를 다음과 같이 변경한다고 하자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 변경 전
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'hello'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bye'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#변경 후
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'hello'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'git'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bye'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'20000'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이 중 &lt;code class=&quot;highlighter-rouge&quot;&gt;print('bye'); print('20000')&lt;/code&gt;을 제외한 나머지 변경사항만을 준비 영역에 추가하고 싶다고 하자. 그러면 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add &amp;lt;filename&amp;gt;&lt;/code&gt; 명령에 다음과 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;--patch&lt;/code&gt; 옵션을 붙인다.&lt;/p&gt;

&lt;div class=&quot;language-diff highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;git add --patch fourth.py
git add fourth.py -p
&lt;/span&gt;
# 결과 예시
&lt;span class=&quot;gh&quot;&gt;diff --git a/fourth.py b/fourth.py
index 13cc618..4c8cfb6 100644
&lt;/span&gt;&lt;span class=&quot;gd&quot;&gt;--- a/fourth.py
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+++ b/fourth.py
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;@@ -1,5 +1,5 @@&lt;/span&gt;
 print('hello')
&lt;span class=&quot;gi&quot;&gt;+print('git')
&lt;/span&gt;
-print(1)
&lt;span class=&quot;gd&quot;&gt;-
-print('bye')
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt; No newline at end of file
&lt;span class=&quot;gi&quot;&gt;+print('bye')
+print('20000')
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;\&lt;/span&gt; No newline at end of file
&lt;span class=&quot;p&quot;&gt;stage this hunk [y,n,q,a,d,s,e,?]? 
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그러면 수정된 코드 덩이(hunk)마다 선택할지를 물어본다. 인접한 초록색(+) 덩이 또는 인접한 빨간색 덩이(-)가 하나의 코드 덩이가 된다.&lt;/p&gt;

&lt;p&gt;각 옵션에 대한 설명은 다음과 같다. &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt;를 입력해도 도움말을 볼 수 있다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Option&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;y&lt;/td&gt;
      &lt;td&gt;stage this hunk&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;n&lt;/td&gt;
      &lt;td&gt;do not stage this hunk&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;q&lt;/td&gt;
      &lt;td&gt;quit; do not stage this hunk or any of the remaining ones&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;a&lt;/td&gt;
      &lt;td&gt;stage this hunk and all later hunks in the file&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;d&lt;/td&gt;
      &lt;td&gt;do not stage this hunk or any of the later hunks in the file&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;s&lt;/td&gt;
      &lt;td&gt;split the current hunk into smaller hunks&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;e&lt;/td&gt;
      &lt;td&gt;manually edit the current hunk&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;?&lt;/td&gt;
      &lt;td&gt;print help&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;여기서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;y&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;y&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt;을 차례로 입력하면 원하는 대로 추가/추가하지 않을 수 있다. (영어 원문을 보면 알 수 있듯이 (stage) = (준비 영역에 추가하다)와 같은 의미라고 보면 된다.)&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-p&lt;/code&gt; 옵션으로는 인접한 추가/삭제 줄들이 전부 하나의 덩이로 묶이기 때문에, 이를 더 세부적으로 하고 싶다면 위 옵션에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;e&lt;/code&gt;를 선택하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git add -p&lt;/code&gt; 명령을 통해 준비 영역에 파일의 일부 변경사항만 추가하고 나면 같은 파일이 &lt;strong&gt;Changes to be committed&lt;/strong&gt; 분류와 &lt;strong&gt;Changes not staged for commit&lt;/strong&gt; 분류에 동시에 들어가게 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;commit하기&quot;&gt;Commit하기&lt;/h2&gt;

&lt;p&gt;준비 영역에 올라간 파일들의 변경사항을 하나로 묶는 작업이라 보면 된다. Git에서는 이 commit(커밋)이 변경사항 적용의 기본 단위가 된다.&lt;/p&gt;

&lt;h3 id=&quot;git-commit--m-message-amend&quot;&gt;git commit [-m “message”] [–amend]&lt;/h3&gt;

&lt;p&gt;기본적으로, commit은 다음 명령어로 수행할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git commit

# 결과 예시&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
All text &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;line&lt;/span&gt; will be showed at &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;oneline

Maximum length &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;50&lt;/span&gt; characters&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
Below&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; detailed message&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;

# Please enter the commit message &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; your &lt;span class=&quot;k&quot;&gt;changes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; Lines starting
# with &lt;span class=&quot;s1&quot;&gt;'#'&lt;/span&gt; will be ignored&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;and&lt;/span&gt; an &lt;span class=&quot;nb&quot;&gt;empty&lt;/span&gt; message aborts the commit&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
#
# On branch master
# Your branch &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;up&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; date with &lt;span class=&quot;s1&quot;&gt;'origin/master'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
#
# Changes &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; be committed&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
#       &lt;span class=&quot;nb&quot;&gt;modified&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;   &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;gitignore
#       &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;   third&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;
#
&lt;span class=&quot;p&quot;&gt;~&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;~&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git commit&lt;/code&gt;을 입력하면 vim 에디터가 열리면서 commit 메시지 편집을 할 수 있다. 방법은:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;i&lt;/code&gt;를 누른다. insert의 약자이다.&lt;/li&gt;
  &lt;li&gt;이후 메시지를 마음대로 수정할 수 있다. 이 때 규칙이 있는데,
    &lt;ul&gt;
      &lt;li&gt;첫 번째 줄은 log를 볼 때 &lt;code class=&quot;highlighter-rouge&quot;&gt;--oneline&lt;/code&gt; 옵션에서 나타나는 대표 commit 메시지이다. 기본값으로, 50자 이상은 무시된다.&lt;/li&gt;
      &lt;li&gt;그 아래 줄에 쓴 텍스트는 해당 commit의 자세한 메시지를 포함한다.&lt;/li&gt;
      &lt;li&gt;맨 앞에 &lt;code class=&quot;highlighter-rouge&quot;&gt;#&lt;/code&gt;이 있는 줄은 주석 처리되어 commit 메시지에 포함되지 않는다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;편집을 마쳤으면 다음을 순서대로 누른다. &lt;code class=&quot;highlighter-rouge&quot;&gt;ESC&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;:wq&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Enter&lt;/code&gt;.
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ESC&lt;/code&gt;는 vim 에디터에서 명령 모드로 들어가가, &lt;code class=&quot;highlighter-rouge&quot;&gt;:wq&lt;/code&gt;는 저장 및 종료 모드 입력을 뜻한다. 잘 모르겠으면 그냥 따라하라.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;맨 밑에 있는 물결 표시(&lt;code class=&quot;highlighter-rouge&quot;&gt;~&lt;/code&gt;)는 파일의 끝이라는 뜻이다. 빈 줄도 아니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;commit의 자세한 메시지를 작성하기 귀찮다면(&lt;em&gt;별로 좋은 습관은 아니다.&lt;/em&gt;), 간단한 메시지만 작성할 수 있다:&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git commit &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&amp;lt;message&amp;gt;&quot;&lt;/span&gt;

# 명령 예시&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
git commit &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;hotfix for typr error&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;물론 이미 작성한 commit 메시지를 변경할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git commit &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;amend
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그러면 vim 에디터에서 수정할 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;수정사항을-원격저장소에-반영하기-git-push&quot;&gt;수정사항을 원격저장소에 반영하기: git push&lt;/h2&gt;

&lt;h3 id=&quot;upstream-연결&quot;&gt;upstream 연결&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git remote add&lt;/code&gt; 명령으로 원격저장소를 연결했으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;git push &amp;lt;git-address&amp;gt;&lt;/code&gt; 명령으로 로컬 저장소의 commit을 원격 저장소에 반영할 수 있다. 즉, 최종 반영이 되는 것이다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git push &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;git&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;address&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
git push https&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;//&lt;/span&gt;github&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/greeksharifa/&lt;/span&gt;gitgitgit&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;git

# 결과 예시
Enumerating objects&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; done&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
Counting objects&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;% &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;/&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; done&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
Writing objects&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;% &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/3), 200 bytes | 200.00 KiB/&lt;/span&gt;s&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; done&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
Total &lt;span class=&quot;m&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;delta &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; reused &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;delta &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
To https&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;//&lt;/span&gt;github&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/greeksharifa/&lt;/span&gt;gitgitgit&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;git
 * &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; branch&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;      master &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그러나 매번 git address를 인자로 주어가며 변경사항을 저장하는 것은 매우 귀찮으니, 다음 명령을 통해 upstream 연결을 지정할 수 있다. 이는 &lt;code class=&quot;highlighter-rouge&quot;&gt;git remote add&lt;/code&gt; 명령을 통해 원격 저장소의 이름을 이미 지정한 경우의 얘기이다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git push &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;upstream &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;remote&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;branch&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
git push &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;remote&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;branch&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

# 명령어 예시
git push &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;upstream origin master
git push &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;u&lt;/span&gt; origin master

# 결과 예시
Everything &lt;span class=&quot;k&quot;&gt;up&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;date
Branch &lt;span class=&quot;s1&quot;&gt;'master'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;up&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; track remote branch &lt;span class=&quot;s1&quot;&gt;'master'&lt;/span&gt; from &lt;span class=&quot;s1&quot;&gt;'origin'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git push --set-upstream &amp;lt;remote-name&amp;gt; &amp;lt;branch-name&amp;gt;&lt;/code&gt; 명령은 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;branch-name&amp;gt;&lt;/code&gt; branch의 upstream을 원격 저장소 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;remote-name&amp;gt;&lt;/code&gt;로 지정하는 것으로, 앞으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;git push&lt;/code&gt;나 &lt;code class=&quot;highlighter-rouge&quot;&gt;git pull&lt;/code&gt; 명령 등을 수행할 때 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;branch name&amp;gt;&lt;/code&gt;과 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;remote name&amp;gt;&lt;/code&gt;을 지정할 필요가 없도록 지정하는 역할을 한다. 즉, 앞으로는 commit을 원격 저장소에 반영할 때 &lt;code class=&quot;highlighter-rouge&quot;&gt;git push&lt;/code&gt;만 입력하면 된다.&lt;/p&gt;

&lt;p&gt;위와 같은 방법으로 지정하지 않은 branch나 원격 저장소에 push하고자 하는 경우, &lt;code class=&quot;highlighter-rouge&quot;&gt;git push &amp;lt;remote-name&amp;gt; &amp;lt;branch-name&amp;gt;&lt;/code&gt;을 사용한다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 명령어 예시
git push origin ticket&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;upstream-삭제&quot;&gt;upstream 삭제&lt;/h3&gt;

&lt;p&gt;더 이상 필요 없는 원격 branch를 삭제할 때는 다음 명령을 사용한다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git push &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;delete&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;remote&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;remote&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

# 명령어 예시
git push &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;delete&lt;/span&gt; origin ticket&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch
git push &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;d&lt;/span&gt; origin ticket&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;git-directory-상태-확인&quot;&gt;Git Directory 상태 확인&lt;/h2&gt;

&lt;h3 id=&quot;git-status&quot;&gt;git status&lt;/h3&gt;

&lt;p&gt;현재 git 저장소의 상태를 확인하고 싶다면 다음 명령어를 입력한다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git status

# 결과 예시 &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
On branch master
Your branch &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;up&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; date with &lt;span class=&quot;s1&quot;&gt;'origin/master'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;

nothing &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; commit&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; working tree clean

# 결과 예시 &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

On branch master
Your branch &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;up&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; date with &lt;span class=&quot;s1&quot;&gt;'origin/master'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;

Changes &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; be committed&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;use &lt;span class=&quot;s2&quot;&gt;&quot;git reset HEAD &amp;lt;file&amp;gt;...&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; unstage&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;nb&quot;&gt;modified&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;   &lt;span class=&quot;k&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;

Changes not staged &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; commit&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;use &lt;span class=&quot;s2&quot;&gt;&quot;git add/rm &amp;lt;file&amp;gt;...&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;update&lt;/span&gt; what will be committed&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;use &lt;span class=&quot;s2&quot;&gt;&quot;git checkout -- &amp;lt;file&amp;gt;...&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; discard &lt;span class=&quot;k&quot;&gt;changes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; working &lt;span class=&quot;nb&quot;&gt;directory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;nb&quot;&gt;modified&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;   &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;gitignore
        deleted&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;    second&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;

Untracked &lt;span class=&quot;k&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;use &lt;span class=&quot;s2&quot;&gt;&quot;git add &amp;lt;file&amp;gt;...&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;include&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; what will be committed&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        third&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git status&lt;/code&gt;로는 로컬 git 저장소에 변경점이 생긴 파일을 크게 세 종류로 나누어 보여준다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Changes to be committed&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Tracking되는 파일이며, 준비 영역(stage)에 이름이 올라가 있는 파일들. 이 단계에 있는 파일들만이 commit 명령을 내릴 시 다음 commit에 포함된다. (그래서 to be commited이다)&lt;/li&gt;
      &lt;li&gt;마지막 commit 이후 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt; 명령으로 준비 영역에 추가가 된 파일들.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Changes not staged for commit:&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Tracking되는 파일이지만, 다음 commit을 위한 준비 영역에 이름이 올라가 있지 않은 파일들.&lt;/li&gt;
      &lt;li&gt;마지막 commit 이후 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt; 명령의 대상이 된 적 없는 파일들.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Untracked files:&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Tracking이 안 되는 파일들.&lt;/li&gt;
      &lt;li&gt;생성 이후 한 번도 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt; 명령의 대상이 된 적 없는 파일들.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위와 같이 준비 영역 또는 tracked 목록에 올라왔는지가 1차 분류이고, 2차 분류는 해당 파일이 처음 생성되었는지(ex. &lt;code class=&quot;highlighter-rouge&quot;&gt;third.py&lt;/code&gt;), 변경되었는지(modified), 삭제되었는지(deleted)로 나눈다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;특정-파일디렉토리-무시하기-gitignore&quot;&gt;특정 파일/디렉토리 무시하기: .gitignore&lt;/h2&gt;

&lt;p&gt;프로젝트의 최상위 디렉토리에 &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt;라는 이름을 갖는 파일을 생성한다. 윈도우에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;copy con .gitignore&lt;/code&gt;라 입력한 뒤, 내용을 다 입력하고, &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + C&lt;/code&gt;를 누르면 파일이 저장되면서 생성된다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일을 열었으면 안에 원하는 대로 파일명이나 디렉토리 이름 등을 입력한다. 그러면 앞으로 해당 프로젝트에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt; 명령으로 준비 영역에 해당 종류의 파일 등이 추가되지 않는다.&lt;/p&gt;

&lt;p&gt;예시는 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dum_file&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;             # `dum_file&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;`라는 이름의 파일을 무시한다&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
*&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;zip                   # 확장자가 `&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;zip`인 모든 파일을 무시한다&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
data&lt;span class=&quot;sr&quot;&gt;/                   # data/&lt;/span&gt; 디렉토리 전체를 무시한다&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;!&lt;/span&gt;data&lt;span class=&quot;sr&quot;&gt;/regression.csv    # data/&lt;/span&gt; 디렉토리는 무시되지만&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; data/regression&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;csv 파일은 무시되지 않는다&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; 
                        # 이 경우는 data/ 이전 라인에 작성하면 적용되지 않는다&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
**/*&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;json               # 모든 디렉토리의 *&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;json 파일을 무시한다&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일을 저장하고 나면 앞으로는 해당 파일들은 tracking되지 않는다. 즉, 준비 영역에 추가될 수 없다.&lt;br /&gt;
그러나 이미 tracking되고 있는 파일들은 영향을 받지 않는다. 따라서 &lt;a href=&quot;&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git rm --cached&lt;/code&gt;&lt;/a&gt; 명령을 통해 tracking 목록에서 제거해야 한다.&lt;/p&gt;

&lt;h3 id=&quot;전체-프로젝트에-gitignore-적용하기&quot;&gt;전체 프로젝트에 .gitignore 적용하기&lt;/h3&gt;

&lt;p&gt;특정 프로젝트가 아닌 모든 프로젝트 전체에 적용하고 싶으면 다음 명령을 입력한다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git config &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;global core&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;excludesfile &lt;span class=&quot;p&quot;&gt;&amp;lt;.&lt;/span&gt;gitignore&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

# 명령 예시
git config &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;global core&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;excludesfile &lt;span class=&quot;p&quot;&gt;~&lt;/span&gt;/&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;gitignore
git config &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;global core&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;excludesfile C&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;\&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;gitignore
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그러면 해당 위치에 &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일이 생성되고, 이는 모든 프로젝트에 적용된다. 일반적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;git config --global&lt;/code&gt; 명령을 통해 설정하는 것은 특정 프로젝트가 아닌 해당 로컬에서 작업하는 모든 프로젝트에 영향을 준다. &lt;a href=&quot;&quot;&gt;여기&lt;/a&gt;를 참고하라.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;history-검토&quot;&gt;History 검토&lt;/h2&gt;

&lt;h3 id=&quot;git-log-현재-존재하는-commit-검토&quot;&gt;git log: 현재 존재하는 commit 검토&lt;/h3&gt;

&lt;p&gt;저장소 commit 메시지의 모든 history를 역순으로 보여준다. 즉, 가장 마지막에 한 commit이 가장 먼저 보여진다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git &lt;span class=&quot;nb&quot;&gt;log&lt;/span&gt;

# 결과 예시
commit da446019230a010bf333db9d60529e30bfa3d4e3 &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;HEAD &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; master&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; origin&lt;span class=&quot;sr&quot;&gt;/master, origin/&lt;/span&gt;HEAD&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
Merge&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;a521c5 &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;eae048
Author&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; greeksharifa &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;greeksharifa@gmail&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
Date&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;   Sun Aug &lt;span class=&quot;m&quot;&gt;19&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;59&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;24&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2018&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0900&lt;/span&gt;

    Merge branch &lt;span class=&quot;s1&quot;&gt;'3rd-branch'&lt;/span&gt;

commit &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;eae048f725c1d843cad359d655c193d9fd632b4
Author&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; greeksharifa &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;greeksharifa@gmail&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
Date&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;   Sun Aug &lt;span class=&quot;m&quot;&gt;19&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;29&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;48&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2018&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0900&lt;/span&gt;

    Unwanted commit from &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;nd&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch

&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이때 commit의 수가 많으면 다음 명령을 기다리는 커서가 깜빡인다. 여기서 space bar를 누르면 다음 commit들을 계속해서 보여주고, 끝에 다다르면(저장소의 최초 commit에 도달하면) &lt;code class=&quot;highlighter-rouge&quot;&gt;(END)&lt;/code&gt;가 표시된다.&lt;br /&gt;
끝에 도달했거나 이전 commit들을 더 볼 필요가 없다면, &lt;code class=&quot;highlighter-rouge&quot;&gt;q&lt;/code&gt;를 누르면 log 보기를 중단한다(quit).&lt;/p&gt;

&lt;h4 id=&quot;git-log-옵션-patch-p-max-count-number-onelineprettyoneline&quot;&gt;git log 옵션: –patch(-p), –max-count(-&amp;lt;number&amp;gt;), –oneline(–pretty=oneline)&lt;/h4&gt;

&lt;p&gt;각 commit의 diff 결과(commit의 세부 변경사항, 변경된 파일의 변경된 부분들을 보여줌)를 보고 싶으면 다음을 입력한다.&lt;/p&gt;

&lt;div class=&quot;language-diff highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;git log --patch
&lt;/span&gt;
# 결과 예시
&lt;span class=&quot;p&quot;&gt;commit 2eae048f725c1d843cad359d655c193d9fd632b4
Author: greeksharifa &amp;lt;greeksharifa@gmail.com&amp;gt;
Date:   Sun Aug 19 20:29:48 2018 +0900
&lt;/span&gt;
    Unwanted commit from 2nd-branch

diff --git a/first.py b/first.py
&lt;span class=&quot;gh&quot;&gt;index 2d61b9f..c73f054 100644
&lt;/span&gt;&lt;span class=&quot;gd&quot;&gt;--- a/first.py
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+++ b/first.py
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;@@ -9,3 +9,5 @@&lt;/span&gt; print(&quot;This is the 1st sentence written in 3rd-branch.&quot;)
 print('2nd')

 print('test git add .')
&lt;span class=&quot;gi&quot;&gt;+
+print(&quot;Unwanted sentence in 2nd-branch&quot;)
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;가장 최근의 commit들 3개만 보고 싶다면 다음과 같이 입력한다.&lt;/p&gt;
&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git &lt;span class=&quot;nb&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;-3&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;commit의 대표 메시지와 같은 핵심 내용만 보고자 한다면 다음과 같이 입력한다.&lt;/p&gt;
&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git &lt;span class=&quot;nb&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;oneline

# 결과 예시
da44601 &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;HEAD &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; master&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; origin&lt;span class=&quot;sr&quot;&gt;/master, origin/&lt;/span&gt;HEAD&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; Merge branch &lt;span class=&quot;s1&quot;&gt;'3rd-branch'&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;eae048 Unwanted commit from &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;nd&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch
&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;a521c5 Desired commit from &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;nd&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고로, 다음과 같이 입력하면 commit의 고유 id의 전체가 출력된다.&lt;/p&gt;
&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git &lt;span class=&quot;nb&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;pretty&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;oneline

# 결과 예시
da446019230a010bf333db9d60529e30bfa3d4e3 &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;HEAD &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; master&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; origin&lt;span class=&quot;sr&quot;&gt;/master, origin/&lt;/span&gt;HEAD&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; Merge branch &lt;span class=&quot;s1&quot;&gt;'3rd-branch'&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;eae048f725c1d843cad359d655c193d9fd632b4 Unwanted commit from &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;nd&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch
&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;a521c56a6c2e50ffa379a7f2737b5e90e9e6df3 Desired commit from &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;nd&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;옵션들은 중복이 가능하다.&lt;/p&gt;
&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git &lt;span class=&quot;nb&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;oneline &lt;span class=&quot;m&quot;&gt;-5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;git-reflog-commit과-commit의-변화-과정-전체를-검토&quot;&gt;git reflog: commit과 commit의 변화 과정 전체를 검토&lt;/h3&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git reflog

# 결과 예시&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;87&lt;/span&gt;ab51e &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;HEAD &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; master&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; specific_tag&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; HEAD@&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}:&lt;/span&gt; commit&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; All text &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;line&lt;/span&gt; will be showed at &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;onel
ine
da44601 &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;origin&lt;span class=&quot;sr&quot;&gt;/master, origin/&lt;/span&gt;HEAD&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; HEAD@&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}:&lt;/span&gt; clone&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; from https&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;//&lt;/span&gt;github&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;/greeksharifa/&lt;/span&gt;git_tutorial&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위와 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;HEAD@{0}&lt;/code&gt;: commit과 &lt;code class=&quot;highlighter-rouge&quot;&gt;HEAD@{1}&lt;/code&gt;: clone 이라는 변화를 볼 수 있다. &lt;code class=&quot;highlighter-rouge&quot;&gt;git reflog&lt;/code&gt;는 commit 뿐 아니라 commit이 삭제되었는지, 재배치했는지, clone이나 rebase 같은 변화가 있었는지 등등 git에서 일어난 모든 변화를 기록한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;head-branch의-tip&quot;&gt;HEAD: branch의 tip&lt;/h2&gt;

&lt;p&gt;HEAD는 현 branch history의 가장 끝을 의미한다. 여기서 끝은 가장 최신 commit 쪽의 끝이다(시작점을 가리키지 않는다).&lt;br /&gt;
다른 의미로는 checkout된 commit, 또는 현재 작업중인 commit이다.&lt;/p&gt;

&lt;p&gt;예를 들어, &lt;code class=&quot;highlighter-rouge&quot;&gt;HEAD@{0}&lt;/code&gt;은 1번째 최신 commit(즉, 가장 최신 commit)을 의미한다. index는 많은 프로그래밍 언어가 그렇듯 0부터 시작한다. 비슷하게, &lt;code class=&quot;highlighter-rouge&quot;&gt;HEAD@{1}&lt;/code&gt;은 2번째 최신 commit을 의미한다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;HEAD^&lt;/code&gt;는 HEAD의 직전, 즉 가장 최신 commit을 가리킨다.&lt;/p&gt;

&lt;p&gt;범위를 나타낼 땐 &lt;code class=&quot;highlighter-rouge&quot;&gt;~&lt;/code&gt;를 사용한다. 예를 들어, &lt;code class=&quot;highlighter-rouge&quot;&gt;HEAD~3&lt;/code&gt;은 가장 최신 commit(1번째)부터 3번째 commit까지를 가리킨다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;HEAD~2^&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;HEAD^&lt;/code&gt;(가장 최신, 즉 1번째 commit)보다 2번 더 이전 commit까지 간 것이고, 범위(&lt;code class=&quot;highlighter-rouge&quot;&gt;~&lt;/code&gt;)를 나타내므로 1~3번째 commit을 가리킨다. 헷갈리니까 3개의 commit을 다루고 싶으면 그냥 &lt;code class=&quot;highlighter-rouge&quot;&gt;HEAD~3&lt;/code&gt;을 쓰자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;tag-붙이기&quot;&gt;Tag 붙이기&lt;/h2&gt;

&lt;p&gt;태그는 특정한 commit을 찾아내기 위해 사용된다. 즐겨찾기와 같은 개념이기 때문에, 여러 commit에 동일한 태그를 붙이지 않도록 한다.&lt;/p&gt;

&lt;p&gt;우선 태그를 붙이고 싶은 commit을 찾자.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 명령어 예시 &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
git &lt;span class=&quot;nb&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;oneline &lt;span class=&quot;m&quot;&gt;-3&lt;/span&gt;

# 결과 예시 &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;87&lt;/span&gt;ab51e &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;HEAD &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; master&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; All text &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;line&lt;/span&gt; will be showed at &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;oneline
da44601 &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;origin&lt;span class=&quot;sr&quot;&gt;/master, origin/&lt;/span&gt;HEAD&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; Merge branch &lt;span class=&quot;s1&quot;&gt;'3rd-branch'&lt;/span&gt;
&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;eae048 Unwanted commit from &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;nd&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch

# 명령어 예시 &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
git &lt;span class=&quot;nb&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;87&lt;/span&gt;ab51e &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
git show &lt;span class=&quot;m&quot;&gt;87&lt;/span&gt;ab51e

# 결과 예시 &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
commit &lt;span class=&quot;m&quot;&gt;87&lt;/span&gt;ab51eecef1a526cb504846ddcaed0459f685c8 &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;HEAD &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; master&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
Author&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; greeksharifa &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;greeksharifa@gmail&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
Date&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;   Thu May &lt;span class=&quot;m&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;49&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;13&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2020&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0900&lt;/span&gt;

    All text &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;line&lt;/span&gt; will be showed at &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;oneline

    Maximum length &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;50&lt;/span&gt; characters&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
    Below&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; detailed message&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;git-tag&quot;&gt;git tag&lt;/h3&gt;

&lt;p&gt;이제 태그를 commit에 붙여보자.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git &lt;span class=&quot;k&quot;&gt;tag&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;87&lt;/span&gt;ab51e

# 명령어 예시
git &lt;span class=&quot;k&quot;&gt;tag&lt;/span&gt; specific_tag &lt;span class=&quot;m&quot;&gt;87&lt;/span&gt;ab51e
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;지금까지 붙인 태그 목록을 보려면 다음 명령을 입력한다.&lt;/p&gt;
&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git &lt;span class=&quot;k&quot;&gt;tag&lt;/span&gt;

# 결과 예시
specific_tag
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;해당 태그가 추가된 commit을 보려면 &lt;a href=&quot;https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#git-show-tag-name&quot;&gt;여기&lt;/a&gt;를 참조한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;특정-commit-보기&quot;&gt;특정 commit 보기&lt;/h2&gt;

&lt;h3 id=&quot;git-show&quot;&gt;git show&lt;/h3&gt;

&lt;p&gt;commit id를 사용해서 특정 commit을 보고자 하면 다음과 같이 쓴다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git &lt;span class=&quot;nb&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;87&lt;/span&gt;ab51e &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
git show &lt;span class=&quot;m&quot;&gt;87&lt;/span&gt;ab51e

# 결과 예시
Author&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; greeksharifa &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;greeksharifa@gmail&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
Date&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;   Thu May &lt;span class=&quot;m&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;49&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;13&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2020&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0900&lt;/span&gt;

    All text &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;line&lt;/span&gt; will be showed at &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;oneline

    Maximum length &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;50&lt;/span&gt; characters&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
    Below&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; detailed message&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;git-show-tag-name&quot;&gt;git show &amp;lt;tag-name&amp;gt;&lt;/h4&gt;

&lt;div class=&quot;language-diff highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;git show &amp;lt;tag-name&amp;gt;
&lt;/span&gt;
# 명령어 예시
&lt;span class=&quot;p&quot;&gt;git show specific_tag
&lt;/span&gt;
# 결과 예시
&lt;span class=&quot;p&quot;&gt;commit 87ab51eecef1a526cb504846ddcaed0459f685c8 (HEAD -&amp;gt; master, tag: specific_tag)
Author: greeksharifa &amp;lt;greeksharifa@gmail.com&amp;gt;
Date:   Thu May 28 14:49:13 2020 +0900
&lt;/span&gt;
    All text in first line will be showed at --oneline

    Maximum length is 50 characters.
    Below, is for detailed message.

diff --git a/.gitignore b/.gitignore
&lt;span class=&quot;gh&quot;&gt;index 8d16a4b..6ec8ec8 100644
&lt;/span&gt;&lt;span class=&quot;gd&quot;&gt;--- a/.gitignore
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+++ b/.gitignore
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;@@ -1,3 +1,2 @@&lt;/span&gt;
&lt;span class=&quot;gd&quot;&gt;-third.py
&lt;/span&gt; .idea/
 *dummy*
&lt;span class=&quot;gh&quot;&gt;diff --git a/third.py b/third.py
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;new file mode 100644
&lt;/span&gt;&lt;span class=&quot;gh&quot;&gt;index 0000000..0360dad
&lt;/span&gt;&lt;span class=&quot;gd&quot;&gt;--- /dev/null
&lt;/span&gt;&lt;span class=&quot;gi&quot;&gt;+++ b/third.py
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;@@ -0,0 +1 @@&lt;/span&gt;
&lt;span class=&quot;gi&quot;&gt;+print('hello 3!')
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;git-branch&quot;&gt;Git Branch&lt;/h2&gt;

&lt;h3 id=&quot;branch-목록-보기&quot;&gt;branch 목록 보기&lt;/h3&gt;

&lt;p&gt;로컬 branch 목록을 보려면 다음을 입력한다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git branch
git branch &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;list&lt;/span&gt;
git branch &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;l&lt;/span&gt;

# 결과 예시
* master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;branch 목록을 보여주는 모든 명령에서, 현재 branch(작업 중인 branch)는 맨 앞에 asterisk(&lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;)가 붙는다.&lt;/p&gt;

&lt;p&gt;모든 branch 목록 보기:&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git branch &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;all&lt;/span&gt;
git branch &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;a&lt;/span&gt;

# 결과 예시
* master
  remotes&lt;span class=&quot;sr&quot;&gt;/origin/&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;nd&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch
  remotes&lt;span class=&quot;sr&quot;&gt;/origin/&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;rd&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch
  remotes&lt;span class=&quot;sr&quot;&gt;/origin/&lt;/span&gt;HEAD &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; origin/master
  remotes&lt;span class=&quot;sr&quot;&gt;/origin/&lt;/span&gt;master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;remotes/&lt;/code&gt;가 붙은 것은 원격 branch라는 뜻이며, branch의 이름에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;remotes/&lt;/code&gt;가 포함되지 않는다.&lt;/p&gt;

&lt;p&gt;원격 branch 목록 보기:&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git branch &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;remotes
git branch &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;r&lt;/span&gt;

# 결과 예시
  origin/&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;nd&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch
  origin/&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;rd&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch
  origin&lt;span class=&quot;sr&quot;&gt;/HEAD -&amp;gt; origin/&lt;/span&gt;master
  origin/master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;원격-branch-목록-업데이트&quot;&gt;원격 branch 목록 업데이트&lt;/h3&gt;

&lt;p&gt;로컬 저장소와 원격 저장소는 실시간 동기화가 이루어지는 것이 아니기 때문에(일부 git 명령을 내릴 때에만 통신이 이루어짐), 원격 branch 목록은 자동으로 최신으로 유지되지 않는다. 목록을 새로 확인하려면 다음을 입력한다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git fetch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;별다른 변경점이 없으면 아무 것도 표시되지 않는다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;branch-전환&quot;&gt;branch 전환&lt;/h3&gt;

&lt;p&gt;단순히 branch 간 전환을 하고 싶으면 다음 명령어를 입력한다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git checkout &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;branch&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

# 명령어 예시
git checkout master

# 결과 예시
Switched &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; branch &lt;span class=&quot;s1&quot;&gt;'master'&lt;/span&gt;
M       &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;gitignore
D       second&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;
Your branch &lt;span class=&quot;k&quot;&gt;is&lt;/span&gt; ahead of &lt;span class=&quot;s1&quot;&gt;'origin/master'&lt;/span&gt; by &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt; commit&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;use &lt;span class=&quot;s2&quot;&gt;&quot;git push&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; publish your local commits&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;전환을 수행하면,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;변경된 파일의 목록과&lt;/li&gt;
  &lt;li&gt;현재 로컬 브랜치가 연결되어 있는 원격 브랜치 사이에 얼마만큼의 commit 차이가 있는지&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;도 알려준다.&lt;/p&gt;

&lt;p&gt;로컬에 새 branch를 생성하되, 그 내용을 원격 저장소에 있는 어떤 branch의 내용으로 하고자 하면 다음 명령을 사용한다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git checkout &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;track &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;local&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;remote&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

# 명령어 예시
git checkout &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;track &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;nd&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch origin/&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;nd&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch

# 결과 예시
Switched &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; branch &lt;span class=&quot;s1&quot;&gt;'2nd-branch'&lt;/span&gt;
M       &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;gitignore
D       second&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;
Branch &lt;span class=&quot;s1&quot;&gt;'2nd-branch'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;up&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; track remote branch &lt;span class=&quot;s1&quot;&gt;'2nd-branch'&lt;/span&gt; from &lt;span class=&quot;s1&quot;&gt;'origin'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;출력에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;2nd-branch&lt;/code&gt;라는 이름의 새 branch로 전환하였고, 파일의 현재 수정 사항을 간략히 보여주며, 로컬 branch &lt;code class=&quot;highlighter-rouge&quot;&gt;2nd-branch&lt;/code&gt;가 &lt;code class=&quot;highlighter-rouge&quot;&gt;origin&lt;/code&gt;의 원격 branch &lt;code class=&quot;highlighter-rouge&quot;&gt;2nd-branch&lt;/code&gt;를 추적하게 되었음을 알려준다.&lt;br /&gt;
즉 원격 branch의 로컬 사본이 생성되었음을 알 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;새-branch-생성&quot;&gt;새 branch 생성&lt;/h3&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git branch &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

# 명령어 예시
git branch fourth&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위 명령은 branch를 생성만 한다. 생성한 브랜치에서 작업을 시작하려면 checkout 과정을 거쳐야 한다.&lt;/p&gt;

&lt;h3 id=&quot;branch-생성과-같이-checkout하기&quot;&gt;branch 생성과 같이 checkout하기&lt;/h3&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git checkout &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;parent&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

# 명령어 예시
git checkout &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;b&lt;/span&gt; fourth&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch master

# 결과 예시
Switched &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; branch &lt;span class=&quot;s1&quot;&gt;'fourth-branch'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;새로운 branch는 생성 시점에서 parent branch와 같은 history(commit 기록들)을 갖는다.&lt;/p&gt;

&lt;h3 id=&quot;branch-병합&quot;&gt;branch 병합&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git merge &amp;lt;branch-name&amp;gt;&lt;/code&gt;를 사용한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;branch-name&amp;gt;&lt;/code&gt; branch의 수정 사항들(commit)을 &lt;strong&gt;현재 branch&lt;/strong&gt;로 가져와 병합한다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git merge &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;branch&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

# 명령어 예시
git merge ticket&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch

# 결과 예시
Updating &lt;span class=&quot;m&quot;&gt;96&lt;/span&gt;c99dc&lt;span class=&quot;p&quot;&gt;..&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;94&lt;/span&gt;d511c
Fast&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;forward
 &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;gitignore &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;+-&lt;/span&gt;
 fourth&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;+++++&lt;/span&gt;
 second&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;9&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;---------&lt;/span&gt;
 third&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;   &lt;span class=&quot;p&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;
 &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;files&lt;/span&gt; changed&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;6&lt;/span&gt; insertions&lt;span class=&quot;p&quot;&gt;(+),&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10&lt;/span&gt; deletions&lt;span class=&quot;p&quot;&gt;(-)&lt;/span&gt;
 create &lt;span class=&quot;k&quot;&gt;mode&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100644&lt;/span&gt; fourth&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;delete&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;mode&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100644&lt;/span&gt; second&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;
 create &lt;span class=&quot;k&quot;&gt;mode&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100644&lt;/span&gt; third&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이와 같은 방법을 history fast-forward라 한다(히스토리 빨리 감기).&lt;/p&gt;

&lt;p&gt;병합할 때 ticket branch의 모든 commit들을 하나의 commit으로 합쳐서 parent branch에 병합하고자 할 때는 &lt;code class=&quot;highlighter-rouge&quot;&gt;--squash&lt;/code&gt; 옵션을 사용한다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 현재 branch가 parent branch일 때
git merge ticket&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;squash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--squash&lt;/code&gt; 옵션은 애초에 branch를 분리하지 말았어야 할 상황에서 쓰면 된다. 즉, 병합 후 parent branch 입장에서는 그냥 하나의 commit이 반영된 것과 같은 효과를 갖는다.&lt;/p&gt;

&lt;p&gt;위와 같이 처리했을 때는 ticket branch가 더 이상 필요 없으니 삭제하도록 하자.&lt;/p&gt;

&lt;h3 id=&quot;branch-삭제&quot;&gt;branch 삭제&lt;/h3&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git branch &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;delete&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;branch&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
git branch &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;branch&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

# 명령어 예시
git branch &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;delete&lt;/span&gt; ticket&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch

# 결과 예시
Deleted branch fourth&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;branch &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;was &lt;span class=&quot;m&quot;&gt;94&lt;/span&gt;d511c&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;branch 삭제는 해당 branch의 수정사항들이 다른 branch에 병합되어서, 더 이상 필요없음이 확실할 때에만 문제없이 실행된다.&lt;br /&gt;
아직 수정사항이 남아 있음에도 그냥 해당 branch 자체를 폐기처분하고 싶으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;--delete&lt;/code&gt; 대신 &lt;code class=&quot;highlighter-rouge&quot;&gt;-D&lt;/code&gt; 옵션을 사용한다.&lt;/p&gt;

&lt;p&gt;이미 원격 저장소에 올라간 branch를 삭제하려면 &lt;a href=&quot;https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#upstream-%EC%82%AD%EC%A0%9C&quot;&gt;여기&lt;/a&gt;를 참조한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;작업-취소하기&quot;&gt;작업 취소하기&lt;/h2&gt;

&lt;p&gt;먼저 가능한 작업 취소 명령들을 살펴보자.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;원하는 것&lt;/th&gt;
      &lt;th&gt;명령어&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;특정 파일의 수정사항 되돌리기&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git checkout -- &amp;lt;filename&amp;gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;모든 수정사항을 되돌리기&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git reset --hard&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;준비 영역의 모든 수정사항을 삭제&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git reset --hard &amp;lt;commit&amp;gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;여러 commit 통합&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git reset &amp;lt;commit&amp;gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이전 commit들을 수정 또는 통합, 혹은 분리&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git rebase --interactive &amp;lt;commit&amp;gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;untracked 파일을 포함해 모든 수정사항을 되돌리기&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git clean -fd&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이전 commit을 삭제하되 history는 그대로 두기&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git revert &amp;lt;commit&amp;gt;&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;아래는 &lt;a href=&quot;https://www.amazon.com/Git-Teams-User-Centered-Efficient-Workflows/dp/1491911182&quot;&gt;Git for Teams&lt;/a&gt;라는 책에서 가져온 flowchart이다. 뭔가 잘못되었을 때 사용해보도록 하자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2020-05-27-github-usage-09-overall/01.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;여러 명이 협업하는 프로젝트에서 이미 원격 저장소에 잘못된 수정사항이 올라갔을 때, 이를 강제로 되돌리는 것은 금물이다. ‘잘못된 수정사항을 삭제하는’ 새로운 commit을 만들어 반영시키는 쪽이 훨씬 낫다.&lt;/p&gt;

&lt;p&gt;물론 branch를 잘 만들고, pull request 시스템을 적극 활용해서 그러한 일이 일어나지 않도록 하는 것이 최선이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;특정-파일의-수정사항-되돌리기-checkout-reset&quot;&gt;특정 파일의 수정사항 되돌리기: checkout, reset&lt;/h3&gt;

&lt;p&gt;특정 파일을 지워 버렸거나 수정을 잘못했다고 하자. 이 때에는 다음 전제조건이 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;수정사항을 commit하지 않았을 때&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;commit하지 않았다면, 다음 두 가지 경우가 있다. &lt;code class=&quot;highlighter-rouge&quot;&gt;git status&lt;/code&gt;를 입력하면 친절히 알려준다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git status

#결과 예시
On branch master

Changes not staged &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; commit&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;use &lt;span class=&quot;s2&quot;&gt;&quot;git add &amp;lt;file&amp;gt;...&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;update&lt;/span&gt; what will be committed&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;use &lt;span class=&quot;s2&quot;&gt;&quot;git checkout -- &amp;lt;file&amp;gt;...&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; discard &lt;span class=&quot;k&quot;&gt;changes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; working &lt;span class=&quot;nb&quot;&gt;directory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;nb&quot;&gt;modified&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;   third&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;py&lt;/span&gt;

no &lt;span class=&quot;k&quot;&gt;changes&lt;/span&gt; added &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; commit &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;use &lt;span class=&quot;s2&quot;&gt;&quot;git add&quot;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;and&lt;/span&gt;/&lt;span class=&quot;nb&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;git commit -a&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;마지막 줄에서 아직 commit된 것이 없다는 것을 확인해야 한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;수정사항을 준비 영역에 올리지 않았을 때(&lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt;를 안 수행했을 때)
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git checkout -- &amp;lt;filename&amp;gt;&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;그러면 파일이 원래대로 복구된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;수정사항을 stage했을 때(&lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt;를 수행했을 때)
    &lt;ul&gt;
      &lt;li&gt;그러면 위 결과 예시처럼 &lt;code class=&quot;highlighter-rouge&quot;&gt;no changes added to commit ...&lt;/code&gt;이라는 메시지가 없다. 다음 두 명령을 입력한다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git reset HEAD &amp;lt;filename&amp;gt;&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git checkout -- &amp;lt;filename&amp;gt;&lt;/code&gt;
 을 입력한다.&lt;/li&gt;
      &lt;li&gt;그러면 가장 최신(HEAD) commit에 저장되어 있는 파일의 원래 상태가 복구된다. commit하지 않았을 때 사용할 수 있는 이유가 이것이다.&lt;/li&gt;
      &lt;li&gt;아니면 명령어 두 개를 합친 다음 명령을 써도 된다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git reset --hard HEAD -- &amp;lt;filename&amp;gt;&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git reset &amp;lt;filename&amp;gt;&lt;/code&gt;은 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add &amp;lt;filename&amp;gt;&lt;/code&gt;의 역방향이라고 보면 된다. 물론 &lt;code class=&quot;highlighter-rouge&quot;&gt;git reset &amp;lt;commit&amp;gt; &amp;lt;filename&amp;gt;&lt;/code&gt;은 파일을 여러 commit 이전으로 되돌릴 수 있기 때문에 상황에 따라서는 다른 작업일 수 있다.&lt;/p&gt;

&lt;p&gt;비슷하게, &lt;code class=&quot;highlighter-rouge&quot;&gt;git reset -p &amp;lt;filename&amp;gt;&lt;/code&gt;은 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add -p &amp;lt;filename&amp;gt;&lt;/code&gt;의 역 작업이다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git reset&lt;/code&gt;의 옵션은 여러 개가 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git reset [-q | -p] [--] &amp;lt;paths&amp;gt;&lt;/code&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;paths&amp;gt;&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;filename&amp;gt;&lt;/code&gt;을 포함한다. 즉, filename 뿐만 아니라 디렉토리 등도 가능하다. 이 명령의 효과는 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add [-p]&lt;/code&gt;의 역 작업이다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git reset [--soft | --mixed [-N] | --hard | --merge | --keep] -[q] [&amp;lt;commit&amp;gt;]&lt;/code&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--hard&lt;/code&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;commit&amp;gt;&lt;/code&gt; 이후 발생한 모든 수정사항과 준비 영역의 수정사항이 폐기된다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--soft&lt;/code&gt;는 파일의 수정사항이 남아 있으며, 수정된 파일들이 모두 &lt;strong&gt;Changes to be committed&lt;/strong&gt; 상태가 된다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--mixed&lt;/code&gt;는 파일의 수정사항은 남아 있으나 준비 영역의 수정사항은 폐기된다. mixed가 기본 옵션이다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--merge&lt;/code&gt;는 준비 영역의 수정사항은 폐기하고 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;commit&amp;gt;&lt;/code&gt;과 &lt;code class=&quot;highlighter-rouge&quot;&gt;HEAD&lt;/code&gt; 사이 수정된 파일들을 업데이트하지만 수정된 파일들은 stage되지 않는다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--keep&lt;/code&gt;은 &lt;code class=&quot;highlighter-rouge&quot;&gt;--merge&lt;/code&gt;와 비슷하나 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;commit&amp;gt;&lt;/code&gt;때와 &lt;code class=&quot;highlighter-rouge&quot;&gt;HEAD&lt;/code&gt; 때가 다른 파일에 일부 변화가 있는 경우에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;reset&lt;/code&gt; 과정이 중단된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;모든 파일의 수정사항 되돌리기:&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git reset &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;hard HEAD
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;branch-병합-취소하기&quot;&gt;branch 병합 취소하기&lt;/h3&gt;

&lt;p&gt;먼저 다음 &lt;a href=&quot;https://www.amazon.com/Git-Teams-User-Centered-Efficient-Workflows/dp/1491911182&quot;&gt;flowchart&lt;/a&gt;를 살펴보자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2020-05-27-github-usage-09-overall/02.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;바로 직전에 한 병합(merge)를 취소하려면 다음 명령어를 입력한다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git reset &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;merge ORIG_HEAD
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;병합 후 추가한 commit이 있으면 해당 지점의 commit을 지정해야 한다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git reset &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;commit&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;어디인지 잘 모르겠으면 &lt;a href=&quot;https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#git-reflog-commit%EA%B3%BC-commit%EC%9D%98-%EB%B3%80%ED%99%94-%EA%B3%BC%EC%A0%95-%EC%A0%84%EC%B2%B4%EB%A5%BC-%EA%B2%80%ED%86%A0&quot;&gt;reflog&lt;/a&gt;를 사용해보자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;커밋-합치기-git-reset-commit&quot;&gt;커밋 합치기: git reset &amp;lt;commit&amp;gt;&lt;/h3&gt;

&lt;p&gt;기본적으로, &lt;code class=&quot;highlighter-rouge&quot;&gt;git reset&lt;/code&gt;은 branch tip을 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;commit&amp;gt;&lt;/code&gt;으로 옮기는 과정이다. 그래서, &lt;code class=&quot;highlighter-rouge&quot;&gt;git reset &amp;lt;option&amp;gt; HEAD&lt;/code&gt;는 마지막 commit의 상태로 준비 영역 또는 파일 내용을 되돌리는(reset) 작업이다.&lt;br /&gt;
또한, 바로 위에서 살펴봤듯이, &lt;code class=&quot;highlighter-rouge&quot;&gt;git reset&lt;/code&gt;은 기본 옵션이 &lt;code class=&quot;highlighter-rouge&quot;&gt;--mixed&lt;/code&gt;이며, 이는 옵션을 따로 명시하지 않으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;git reset&lt;/code&gt;은 파일의 수정사항은 그대로 둔 채 준비 영역에는 추가된 수정사항이 없는 상태로 만든다.&lt;/p&gt;

&lt;p&gt;그래서 특정 이전 commit을 지정하여 &lt;code class=&quot;highlighter-rouge&quot;&gt;git reset &amp;lt;commit&amp;gt;&lt;/code&gt;을 수행하면 해당 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;commit&amp;gt;&lt;/code&gt;부터 &lt;code class=&quot;highlighter-rouge&quot;&gt;HEAD&lt;/code&gt;까지의 파일의 수정사항은 작업트리(=프로젝트 디렉토리 전체)에 그대로 남아 있지만, 준비 영역에는 아무런 변화도 기록되어 있지 않다.&lt;br /&gt;
먼저 어떤 커밋들을 합칠지 &lt;code class=&quot;highlighter-rouge&quot;&gt;git log --oneline&lt;/code&gt;으로 확인해보자.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 결과 예시
c8c731b (HEAD -&amp;gt; master, origin/master, origin/HEAD) doong commit
87ab51e (tag: specific_tag) All text in first line will be showed at --oneline
da44601 Merge branch '3rd-branch'
2eae048 Unwanted commit from 2nd-branch
4a521c5 Desired commit from 2nd-branch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 가장 최신 2개의 commit을 합치고 싶으면, 현재 branch의 HEAD를 &lt;code class=&quot;highlighter-rouge&quot;&gt;c8c731b&lt;/code&gt;에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;da44601&lt;/code&gt;로 옮기면 된다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git reset da44601
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;그러면 직전 2개의 commit의 수정사항이 파일에는 그대로 남아 있지만, 준비 영역이나 commit 내역에선 사라진다. 이제 stage, commit, push 3단계를 수행하면 최종적으로 commit 2개가 1개로 합쳐진다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;commit&amp;gt;&lt;/code&gt; id를 지정하는 것이 헷갈린다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;git reset HEAD~2&lt;/code&gt;로 실행하자. 이는 &lt;a href=&quot;https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#head-branch%EC%9D%98-tip&quot;&gt;여기&lt;/a&gt;에서 볼 수 있듯이 범위로 2개의 commit을 포함한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;git-rebase&quot;&gt;git rebase&lt;/h3&gt;

&lt;p&gt;rebase는 일반적으로 history rearrange의 역할을 한다. 즉, 여러 commit들의 순서를 재배치하는 작업이라 할 수 있다. 혹은 parent branch의 수정사항을 가져오면서 자신의 commit은 그 이후에 추가된 것처럼 하는, 마치 분기된 시점을 뒤로 미룬 듯한 작업을 수행할 수도 있다.&lt;/p&gt;

&lt;p&gt;그러나 rebase와 같은 기존 작업을 취소 또는 변경하는 명령은 일반적으로 충돌(conflict)이 일어나는 경우가 많다. 충돌이 발생하면 git은 작업을 일시 중지하고 사용자에게 충돌을 처리하라고 한다.&lt;/p&gt;

&lt;h4 id=&quot;master-branch의-commit을-topic-branch로-가져오기&quot;&gt;master branch의 commit을 topic branch로 가져오기&lt;/h4&gt;

&lt;p&gt;다음과 같은 상황을 가정하자. 각 알파벳은 하나의 commit이며, 각 이름은 branch의 이름을 나타낸다.&lt;br /&gt;
아래 각 예시는 &lt;code class=&quot;highlighter-rouge&quot;&gt;git help&lt;/code&gt;에 나오는 도움말을 이용하였다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;          A---B---C topic
         /
    D---E---F---G master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;commit F, G를 topic branch에 반영(포함)시키려 한다면,&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                  A'--B'--C' topic
                 /
    D---E---F---G master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;commit A’와 A는 프로젝트에 동일한 수정사항을 적용시키지만, 16진수로 된 commit의 고유 id(&lt;code class=&quot;highlighter-rouge&quot;&gt;da44601&lt;/code&gt; 같은)는 다르다. 즉, 엄밀히는 다른 commit이다.&lt;/p&gt;

&lt;p&gt;commit을 재배열하는 명령어는 다음과 같다. 현재 branch는 topic이라 가정한다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git rebase master
git rebase master topic
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;commit A, B, C가 F, G와 코드 상으로 동일한 파일 또는 다른 일부분을 수정하지 않았다면, 이 rebase 작업은 자동으로 완료된다.&lt;/p&gt;

&lt;p&gt;만약 topic branch에 이미 master branch로부터 가져온 commit이 일부 존재하면, 이 commit들은 새로 배치되지 않는다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;          A---B---C topic
         /
    D---E---A'---F master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;에서&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                   B'---C' topic
                  /
    D---E---A'---F master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;로 바뀐다.&lt;/p&gt;

&lt;h4 id=&quot;branch의-parent-바꾸기-onto&quot;&gt;branch의 parent 바꾸기: –onto&lt;/h4&gt;

&lt;p&gt;topic을 next가 아닌 master에서 분기된 것처럼 바꾸고자 한다. 즉,&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    o---A---B---o---C  master
         \
          D---o---o---o---E  next
                           \
                            o---o---o  topic
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이걸 아래와 같이 바꿔보자.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    o---A---B---o---C  master
        |            \
        |             o'--o'--o'  topic
         \
          D---o---o---o---E  next
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;topic branch의 history에는 이제 commit D~E 대신 commit A~B가 포함되어 있다.&lt;/p&gt;

&lt;p&gt;이는 다음과 같은 명령어로 수행할 수 있다:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git rebase --onto master next topic
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다른 예시는:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                            H---I---J topicB
                           /
                  E---F---G  topicA
                 /
    A---B---C---D  master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git rebase &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;onto master topicA topicB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;                 H'--I'--J'  topicB
                /
                | E---F---G  topicA
                |/
    A---B---C---D  master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;특정-범위의-commit들-제거하기&quot;&gt;특정 범위의 commit들 제거하기&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    E---F---G---H---I---J  topic
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;topic branch의 5번째 최신 commit부터, 3번째 최신 commit &lt;strong&gt;직전&lt;/strong&gt;까지 commit을 topic branch에서 폐기하고 싶다고 하자. 그러면 다음 명령어로 사용 가능하다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git rebase &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;onto &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;branch&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;~&amp;lt;&lt;/span&gt;start&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;branch&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;~&amp;lt;&lt;/span&gt;end&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;branch&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;name&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

# 명령어 예시
git rebase &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;onto topic&lt;span class=&quot;p&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt; topic&lt;span class=&quot;p&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt; topic
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    E---H'---I'---J'  topic
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여기서 5(번째 최신 commit, F)은 삭제되고, 3(번째 최신 commit, H)은 삭제되지 않음을 주의하라. rebase가 되기 때문에 commit의 고유 id는 바뀐다(H -&amp;gt; H’)&lt;/p&gt;

&lt;h4 id=&quot;충돌-시-해결법&quot;&gt;충돌 시 해결법&lt;/h4&gt;

&lt;p&gt;일반적으로 rebase에서 수정하는 2개 이상의 commit이 같은 파일을 수정하면 충돌이 발생한다.&lt;/p&gt;

&lt;p&gt;보통은 다음 과정을 거치면 해결된다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;충돌이 일어난 파일에 적절한 조취를 취한다. 파일을 남기거나/삭제하거나, 또는 파일 일부분에서 남길 부분을 찾는다. 코드 중 다음과 비슷해 보이는 부분이 있을 것이다. 적절히 지워서 해결하자.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ㅤ&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt; HEAD
ㅤ&amp;lt;current-code&amp;gt;
ㅤ========
ㅤ&amp;lt;incoming-code&amp;gt;
ㅤ&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; da446019230a010bf333db9d60529e30bfa3d4e3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git add &amp;lt;conflict-resolved-filename&amp;gt;&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git rebase --continue&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그냥 다 모르겠고(?) rebase 작업을 취소하고자 하면 다음을 입력한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git rebased --abort
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;rebase로-commit-합치거나-수정하기&quot;&gt;rebase로 commit 합치거나 수정하기&lt;/h4&gt;

&lt;p&gt;다음과 같은 history가 있다고 하자.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;c3eace0 &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;HEAD &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; master&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; origin&lt;span class=&quot;sr&quot;&gt;/master, origin/&lt;/span&gt;HEAD&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; git checkout&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; reset&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; rebase
f6c56ef what igt
bd80626 github hem
b7801a2 github overall
&lt;span class=&quot;m&quot;&gt;608&lt;/span&gt;a518 highlighter theme &lt;span class=&quot;k&quot;&gt;change&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여러 개의 commit들을 합치거나, commit message를 수정하거나 하는 작업은 모두 rebase로 가능하다.&lt;br /&gt;
실행하면, vim 에디터가 열릴 것이다(ubuntu의 경우 nano일 수 있다). vim을 쓰는 방법은 &lt;a href=&quot;https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#git-commit--m-message-amend&quot;&gt;여기&lt;/a&gt;를 참고한다.&lt;/p&gt;

&lt;p&gt;rebase하는 부분에서는 다른 git command들과는 달리 수정할 commit 중 가장 오래된 commit이 가장 위에 온다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git rebase &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;interactive &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;commit&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
git rebase &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;commit&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;

# 명령 예시
git rebase &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;interactive &lt;span class=&quot;m&quot;&gt;608&lt;/span&gt;a518
git rebase &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;i&lt;/span&gt; HEAD&lt;span class=&quot;p&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;

# 결과 예시

pick c3eace0 &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;HEAD &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; master&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; origin&lt;span class=&quot;sr&quot;&gt;/master, origin/&lt;/span&gt;HEAD&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; git checkout&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; reset&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; rebase
pick f6c56ef what igt
pick bd80626 github hem
pick b7801a2 github overall
# Rebase &lt;span class=&quot;m&quot;&gt;608&lt;/span&gt;a518&lt;span class=&quot;p&quot;&gt;..&lt;/span&gt;c3eace0 onto &lt;span class=&quot;m&quot;&gt;608&lt;/span&gt;a518
#
# Commands&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
# &lt;span class=&quot;k&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; pick &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; use commit
# &lt;span class=&quot;k&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; reword &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; use commit&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; but &lt;span class=&quot;k&quot;&gt;edit&lt;/span&gt; the commit message
# &lt;span class=&quot;k&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;edit&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; use commit&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; but &lt;span class=&quot;k&quot;&gt;stop&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; amending
# s&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; squash &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; use commit&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; but meld into &lt;span class=&quot;k&quot;&gt;previous&lt;/span&gt; commit
# &lt;span class=&quot;k&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; fixup &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; like &lt;span class=&quot;s2&quot;&gt;&quot;squash&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; but discard this commit's &lt;span class=&quot;nb&quot;&gt;log&lt;/span&gt; message
# &lt;span class=&quot;k&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; exec &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; run command &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;the rest of the &lt;span class=&quot;nb&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; using &lt;span class=&quot;k&quot;&gt;shell&lt;/span&gt;
#
# These &lt;span class=&quot;nb&quot;&gt;lines&lt;/span&gt; can be &lt;span class=&quot;nb&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;ordered; they are executed from &lt;span class=&quot;nb&quot;&gt;top&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; bottom&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
#
# If you &lt;span class=&quot;nb&quot;&gt;remove&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;line&lt;/span&gt; here THAT COMMIT WILL BE LOST&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
#
# However&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; you &lt;span class=&quot;nb&quot;&gt;remove&lt;/span&gt; everything&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; the rebase will be aborted&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
#
# Note that &lt;span class=&quot;nb&quot;&gt;empty&lt;/span&gt; commits are commented out
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;설명을 잘 살펴보면 다음을 알 수 있다:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pick&lt;/code&gt; = &lt;code class=&quot;highlighter-rouge&quot;&gt;p&lt;/code&gt;는 수정 사항과 commit을 그대로 둔다. 각 commit의 맨 앞에는 기본적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;pick&lt;/code&gt;으로 설정되어 있다. 이 상태에서 아무 것도 안 하고 나간다면 이번 &lt;code class=&quot;highlighter-rouge&quot;&gt;rebase&lt;/code&gt;는 아무 효과도 없다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;reword&lt;/code&gt; = &lt;code class=&quot;highlighter-rouge&quot;&gt;r&lt;/code&gt;은 &lt;code class=&quot;highlighter-rouge&quot;&gt;pick&lt;/code&gt;과 거의 같지만 commit message를 수정할 수 있다. commit message를 수정하고 앞의 &lt;code class=&quot;highlighter-rouge&quot;&gt;pick&lt;/code&gt;을 &lt;code class=&quot;highlighter-rouge&quot;&gt;reword&lt;/code&gt;나 &lt;code class=&quot;highlighter-rouge&quot;&gt;r&lt;/code&gt;로 바꾸면 commit의 메시지를 수정할 수 있다. 가장 최신의 commit에 &lt;code class=&quot;highlighter-rouge&quot;&gt;r&lt;/code&gt;을 붙였다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;git commit --amend&lt;/code&gt;와 효과가 같다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;edit&lt;/code&gt; = &lt;code class=&quot;highlighter-rouge&quot;&gt;e&lt;/code&gt;는 해당 commit을 수정할 수 있다. reset 등의 작업이 가능하다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;squash&lt;/code&gt; = &lt;code class=&quot;highlighter-rouge&quot;&gt;s&lt;/code&gt;는 해당 commit이 바로 이전 commit에 흡수되며, commit message 또한 합쳐져서 하나로 된다. 합친 메시지들이 존재하는 에디터가 다시 열린다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;fixup&lt;/code&gt; = &lt;code class=&quot;highlighter-rouge&quot;&gt;f&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;squash&lt;/code&gt;와 비슷하지만, 해당 commit의 message는 삭제된다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;exec&lt;/code&gt; = &lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt;는 commit들 아래 줄에 명령어를 추가하여 실행하게 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;수정한 예시는 다음과 같다. 약어를 써도 되고 안 써도 된다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pick c3eace0 &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;HEAD &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; master&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; origin&lt;span class=&quot;sr&quot;&gt;/master, origin/&lt;/span&gt;HEAD&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; git checkout&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; reset&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; rebase
&lt;span class=&quot;k&quot;&gt;f&lt;/span&gt; f6c56ef what igt
&lt;span class=&quot;k&quot;&gt;f&lt;/span&gt; bd80626 github hem
fixup b7801a2 github overall
&lt;span class=&quot;p&quot;&gt;...(&lt;/span&gt;아래 주석은 지워도 되고 안 지워도 된다&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; 어차피 commit에서는 무시되는 도움말이다&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;하나의-commit을-2개로-분리하기&quot;&gt;하나의 commit을 2개로 분리하기&lt;/h4&gt;

&lt;p&gt;가장 최신 commit이라면 &lt;code class=&quot;highlighter-rouge&quot;&gt;git reset HEAD~1&lt;/code&gt;을 사용하여 직전 commit 상태로 되돌린 뒤 stage-commit을 2번 수행하면 되고, 그 이전 commit이라면 rebase에서 해당 commit을 &lt;code class=&quot;highlighter-rouge&quot;&gt;edit&lt;/code&gt;으로 두고 같은 과정을 반복하면 된다.&lt;/p&gt;

&lt;div class=&quot;language-vim highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 명령어 예시
git rebase HEAD&lt;span class=&quot;p&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;
# pick &lt;span class=&quot;p&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;edit&lt;/span&gt;
git &lt;span class=&quot;nb&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;filename&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
git commit &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;commit&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;message&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
git &lt;span class=&quot;nb&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;filename1&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;&amp;lt;&lt;/span&gt;filename2&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
git commit &lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;m&lt;/span&gt; &quot;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;nd&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;commit&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;message&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
git rebase &lt;span class=&quot;p&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;git cherry-pick -x&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Variational AutoEncoder 설명</title>
   <link href="http://localhost:4000/VAE/"/>
   <updated>2020-05-25T00:00:00+09:00</updated>
   <id>http://localhost:4000/VAE</id>
   <content type="html">&lt;p&gt;본 글의 주제는  2014년에 발표된 생성 모델인 Variational AutoEncoder에 대해 설명하고 이를 코드로 구현하는 내용을 담고 있다.&lt;/p&gt;

&lt;h2 id=&quot;1-auto-encoding-variational-bayes-논문-리뷰&quot;&gt;1. Auto-Encoding Variational Bayes 논문 리뷰&lt;/h2&gt;
&lt;h3 id=&quot;11-introduction&quot;&gt;1.1. Introduction&lt;/h3&gt;
&lt;p&gt;연속형 잠재 변수와 파라미터가 다루기 힘든 사후 분포를 갖는 방향성 확률 모델에 대해 효율적인 근사 추론 및 학습을 수행할 수 있는 방법이 없을까? &lt;strong&gt;Variational Bayesian&lt;/strong&gt; 접근법은 다루기 힘든 사후 분포에 대한 근사의 최적화를 내포한다.&lt;/p&gt;

&lt;p&gt;불행히도, 일반적인 평균 필드(mean-field) 접근법은 근사적 사후 분포에 대해 기댓값의 분석적 해결법을 요구하는데 이는 보통 굉장히 다루기 어려운 방법이다. 본 논문은 Variational Lower Bound의 &lt;strong&gt;Reparameterization&lt;/strong&gt;이 Lower Bound의 미분 가능한 불편향 estimator를 만드는 방법에 대해 보여줄 것이다. 이 &lt;strong&gt;Stochastic Gradient Variational Bayes: SGVB estimator&lt;/strong&gt;는 연속형 잠재변수나 파라미터를 갖고 있는 대부분의 모델에 대해 효율적인 근사 사후 추론을 가능하게 하며, 표준 Stochastic Gradient Ascent 스킬을 사용하여 최적화하기에 굉장히 편리하다.&lt;/p&gt;

&lt;p&gt;IID 데이터셋이고, 데이터포인트 별로 연속형 잠재변수를 갖고 있는 경우에 대해 본 논문은 &lt;code class=&quot;highlighter-rouge&quot;&gt;Auto-Encoding VB&lt;/code&gt; 알고리즘을 제안한다. 이 알고리즘에서는 &lt;strong&gt;Simple Ancestral Sampling&lt;/strong&gt;을 이용하여 근사 사후 추론을 하는 인식 모델을 최적화하기 위해 SGVB estimator를 사용하여 추론과 학습을 효율적으로 해낸다. 이 과정은 MCMC와 같이 데이터포인트 별로 반복적인 추론을 행하여 많은 연산량을 요구하지 않는 장점을 가진다.&lt;/p&gt;

&lt;p&gt;학습된 근사 사후 추론 모델은 recognition, denoising, representation, visualization의 목적으로 활용될 수 있다. 본 알고리즘이 인식(recognition) 모델에 사용될 때, 이를 &lt;code class=&quot;highlighter-rouge&quot;&gt;Variational Auto-Encoder&lt;/code&gt;라고 부를 것이다.&lt;/p&gt;

&lt;h3 id=&quot;12-method&quot;&gt;1.2. Method&lt;/h3&gt;
&lt;p&gt;본 섹션에서는 연속형 잠재 변수를 내포하는 다양한 방향성 그래픽 모델에서 Stochastic 목적 함수인 &lt;strong&gt;Lower Bound Estimator&lt;/strong&gt;를 끌어내는 과정을 설명할 것이다. 데이터포인트 별 잠재변수는 iid한 상황이라는 가정 하에 본 논문에서는 파라미터에 대해 Maximul Likelihood와 Maximum Posteriori 추론을 수행하고 잠재변수에 대해 &lt;strong&gt;Variational Inference&lt;/strong&gt;를 수행할 것이다. 이러한 방법은 온라인 러닝에도 사용될 수 있지만 본 논문에서는 간단히 하기 위해 고정된 데이터셋을 사용할 것이다.&lt;/p&gt;

&lt;h4 id=&quot;121-problem-scenario&quot;&gt;1.2.1. Problem Scenario&lt;/h4&gt;
&lt;p&gt;N개의 Sample을 가진 $X$라는 데이터가 있다고 해보자. 본 논문은 이 데이터가 관측되지 않은 연속형 확률 변수 $z$를 내포하는 어떤 Random Process에 의해 형성되었다고 가정한다.&lt;/p&gt;

&lt;p&gt;이 과정은 2가지 단계로 구성된다.&lt;br /&gt;
1) $z^{i}$라는 값은 어떤 사전 분포 $p_{\theta ^&lt;em&gt;}(z)$에서 발생한다.&lt;br /&gt;
2) $x^{i}$라는 값은 어떤 조건부 분포 $p_{\theta ^&lt;/em&gt;}(x|z)$에서 발생한다.&lt;/p&gt;

&lt;p&gt;(여기서 $z$는 원인, $x$는 결과라고 보면 이해가 쉬울 것이다.)&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;우리는 사전확률 $p_{\theta &lt;em&gt;}(z)$와 Likelihood $p_{\theta ^&lt;/em&gt;}(x&lt;/td&gt;
      &lt;td&gt;z)$가 $p_{\theta}(z)$, $p_{\theta}(x&lt;/td&gt;
      &lt;td&gt;z)$의 parametric families of distributions에서 왔다고 가정하고, 이들의 확률밀도함수는 거의 모든 $\theta, z$에 대해 미분가능하다고 전제한다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;불행히도, 이러한 과정의 많은 부분은 우리가 직접 확인하기 어렵다. True 파라미터인 $\theta ^*$와 잠재 변수의 값 $z^{i}$은 우리에게 알려져 있지 않다.&lt;/p&gt;

&lt;p&gt;본 논문은 주변 확률이나 사후 확률에 대한 단순화를 위한 일반적인 가정을 취하지 않고 분포가 다루기 힘들고 큰 데이터셋을 마주하였을 경우를 위한 효율적인 알고리즘에 대해 이야기하고자 한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1) Intractability&lt;/strong&gt;(다루기 힘듦)&lt;br /&gt;
(1) marginal likelihood $p_{\theta}(x)$의 적분인 $\int p_{\theta}(x) p_{\theta}(x|z) dz $가 다루기 힘든 경우&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;(2) true posterior density $p_{\theta}(z&lt;/td&gt;
      &lt;td&gt;x) = p_{\theta}(x&lt;/td&gt;
      &lt;td&gt;z)p_{\theta}(z)/p_{\theta}(x)$가 다루기 힘들어 EM 알고리즘이 사용될 수 없는 경우&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;(3) 어떠한 합리적인 평균-필드 VB알고리즘을 위한 적분이 다루기 힘든 경우&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;이러한 Intractability는 굉장히 흔하며, 복잡한 우도(likelihood) 함수 $p_{\theta}(x&lt;/td&gt;
      &lt;td&gt;z)$를 갖는 신경망 네트워크에서 발견할 수 있다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;2) A Large Dataset&lt;/strong&gt;&lt;br /&gt;
데이터가 너무 크면 배치 최적화는 연산량이 매우 많다. MC-EM과 같은 Sampling Based Solution은 데이터 포인트별로 Sampling Loop를 돌기 때문에 너무 느리다.&lt;/p&gt;

&lt;p&gt;위 시나리오에서 설명한 문제들에 대해 본 논문은 아래와 같은 해결책을 제시한다.&lt;/p&gt;

&lt;p&gt;1) 파라미터 $\theta$에 대한 효율적인 근사 ML/MAP estimation. 이 파라미터들은 숨겨진 랜덤 과정을 흉내내고 실제 데이터를 닮은 인공적인 데이터를 생성할 수 있게 해준다.&lt;br /&gt;
2) 파라미터 $\theta$의 선택에 따라 관측값 $x$이 주어졌을 때 잠재 변수 $z$에 대한 효율적인 근사 사후 추론&lt;br /&gt;
3) 변수 $x$에 대해 효율적인 근사 주변 추론. 이는 $x$에 대한 prior이 필요한 모든 추론 task를 수행할 수 있게 해준다.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;위 문제를 해결하기 위해 인식 모델 $q_{\phi}(z&lt;/td&gt;
      &lt;td&gt;x)$이 필요하다. 이 모델은 다루기 힘든 True Posterior $p_{\theta}(z&lt;/td&gt;
      &lt;td&gt;x)$의 근사 버전이라고 할 수 있다. 본 논문에서는 인식 모델 파라미터인 $\phi$와 생성 모델 파라미터인 $\theta$를 동시에 학습하는 방법에 대해 이야기할 것이다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;코딩 이론의 관점에서 보면, 관측되지 않은 변수 $z$는 잠재 표현 또는 &lt;em&gt;code&lt;/em&gt;라고 해석될 수 있다. 본 논문에서는 따라서 인식 모델 $q_{\phi}(z&lt;/td&gt;
      &lt;td&gt;x)$를 &lt;strong&gt;encoder&lt;/strong&gt;라고 부를 것인데, 왜냐하면 데이터 포인트 $x$가 주어졌을 때 이 &lt;strong&gt;encoder&lt;/strong&gt;가 데이터 포인트 $x$가 발생할 수 code $z$의 가능한 값에 대한 분포를 생산하기 때문이다. 비슷한 맥락에서 우리는 $q_{\theta}(x&lt;/td&gt;
      &lt;td&gt;z)$를 &lt;strong&gt;확률적 decoder&lt;/strong&gt;라고 명명할 것인데, 왜냐하면 code $z$가 주어졌을 때 이 &lt;strong&gt;decoder&lt;/strong&gt;가 상응하는 가능한 $x$의 값에 대해 분포를 생산하기 때문이다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;22-the-variational-bound&quot;&gt;2.2. The Variational Bound&lt;/h3&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;2-이론에-대한-보충-설명&quot;&gt;2. 이론에 대한 보충 설명&lt;/h2&gt;
&lt;h3 id=&quot;21-용어-정리&quot;&gt;2.1. 용어 정리&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1) Variational Inference&lt;/strong&gt;&lt;br /&gt;
$q(x)$라는 쉬운 분포를 통해 target 분포 $p(x)$를 근사 추론하는 방법론이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q^* = argmin_{q \in Q} KL(q||p)&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;2) KL Divergence&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3) s&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;22&quot;&gt;2.2.&lt;/h3&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;p&gt;1) https://ratsgo.github.io/generative%20model/2018/01/27/VAE/&lt;br /&gt;
2) https://www.youtube.com/watch?v=SAfJz_uzaa8&lt;br /&gt;
3) https://taeu.github.io/paper/deeplearning-paper-vae/
4)&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>추천 시스템의 기본 - 06. AFM 논문 리뷰 및 Tensorflow 구현</title>
   <link href="http://localhost:4000/AFM/"/>
   <updated>2020-05-01T00:00:00+09:00</updated>
   <id>http://localhost:4000/AFM</id>
   <content type="html">&lt;p&gt;본 글의 전반부에서는 먼저 &lt;strong&gt;Attentional Factorization Machines: Learning theWeight of Feature Interactions via Attention Networks&lt;/strong&gt; 논문을 리뷰하면서 본 모델에 대해 설명할 것이다. 후반부에서는 Tensorflow를 이용하여 직접 코딩을 하고 학습하는 과정을 소개할 것이다. 논문의 전문은 &lt;a href=&quot;https://www.ijcai.org/Proceedings/2017/0435.pdf&quot;&gt;이곳&lt;/a&gt;에서 확인할 수 있다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;1-attentional-factorization-machines-learning-theweight-of-feature-interactions-via-attention-networks-논문-리뷰&quot;&gt;1. Attentional Factorization Machines: Learning theWeight of Feature Interactions via Attention Networks 논문 리뷰&lt;/h2&gt;

&lt;h3 id=&quot;10-absbract&quot;&gt;1.0. Absbract&lt;/h3&gt;
&lt;p&gt;FM은 2차원 피쳐 상호작용을 잘 통합하여 선형 회귀를 개선한 지도학습 알고리즘이다. 이 알고리즘은 효과적이긴 하지만, 모든 피쳐에 대해 같은 weight로 학습을 진행시킨다는 점에서 비효율적이다. 왜냐하면 종종 일부 피쳐는 학습에 있어 필수적이지 않은 경우가 있기 때문이다. 오히려 이러한 피쳐들의 존재는 모델의 성능을 떨어트릴 수 있다. 따라서 우리는 여러 피쳐 상호작용 속에서 중요한 피쳐들을 구분해내는 새로운 모델, &lt;strong&gt;Attentional Factorization Machine (AFM)&lt;/strong&gt;을 소개한다.&lt;/p&gt;

&lt;h3 id=&quot;11-introduction&quot;&gt;1.1. Introduction&lt;/h3&gt;
&lt;center&gt; (전략) &lt;/center&gt;

&lt;p&gt;FM은 피쳐 상호작용의 중요성을 구분하는 능력이 부족하기 때문에(피쳐의 중요성을 파악하는 능력) suboptimal 문제에 빠질 수 있다. &lt;strong&gt;AFM&lt;/strong&gt;은 이러한 문제를 해결하기 위해 도입한 모델이다.&lt;/p&gt;

&lt;h3 id=&quot;12-factorization-machines&quot;&gt;1.2. Factorization Machines&lt;/h3&gt;
&lt;p&gt;FM 모델에 대한 설명은 &lt;a href=&quot;2019-12-21-FM.md&quot;&gt;이곳&lt;/a&gt;을 참조하길 바란다. 기호에 대해서만 설명을 추가하면, $v_i$는 피쳐 $i$에 대한 임베딩 벡터이며, $k$는 임베딩 크기를 의미한다.&lt;/p&gt;

&lt;h3 id=&quot;13-attentioanl-factorization-machines&quot;&gt;1.3. Attentioanl Factorization Machines&lt;/h3&gt;
&lt;h4 id=&quot;131-model&quot;&gt;1.3.1. Model&lt;/h4&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-05-01-AFM/01.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 그림은 &lt;strong&gt;AFM&lt;/strong&gt;의 구조를 보여준다. 선명히 보여주기 위해 그림에서는 선형 회귀 부분을 생략하였다. Input Layer와 Embedding Layer의 경우 FM과 같은 구조를 지니는데, Input 피쳐들은 sparse하게 이루어져있고 이들은 dense vector로 임베딩된다. 지금부터는 본 모델의 핵심인 &lt;code class=&quot;highlighter-rouge&quot;&gt;pair-wise interaction layer&lt;/code&gt;과 &lt;code class=&quot;highlighter-rouge&quot;&gt;attention-based pooling layer&lt;/code&gt;를 설명할 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pair-wise Interaction Layer&lt;/strong&gt;&lt;br /&gt;
상호작용을 포착하기 위해 내적을 사용하는 FM을 참고하여, 본 논문에서는 신경망 모델링에서 새로운 &lt;code class=&quot;highlighter-rouge&quot;&gt;Pair-wise Interaction Layer&lt;/code&gt;를 제시한다. $m$개의 벡터를 $\frac{m(m-1)}{2}$개의 interacted 벡터로 만드는데, 이 때 각 interacted 벡터는 상호작용을 포착하기 위해 2개의 다른 벡터들의 원소곱으로 계산된다.&lt;/p&gt;

&lt;p&gt;정확히 말하면, 피쳐 벡터 $x$의 0이 아닌 피쳐의 집합을 $\chi$라고 하자. 그리고 &lt;code class=&quot;highlighter-rouge&quot;&gt;Embedding Layer&lt;/code&gt;의 결과물을 $\epsilon = {{v_i x_i}}_{i \in \chi} $라고 하자. 우리는 아래와 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;Pair-wise Interaction Layer&lt;/code&gt;의 결과물을 아래와 같은 벡터의 집합으로 표현할 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_{PI}(\epsilon) = \{ (v_i \odot v_j) x_i x_j \}_{(i, j \in R_x)}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;$\odot$ 기호: 원소곱&lt;/li&gt;
  &lt;li&gt;$ R_x = { (i, j) }_{i, j \in \chi, j&amp;gt;i} $&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 Layer를 정의하면서 우리는 FM을 신경망 구조로 표현할 있게 된다. 먼저 $f_{PI}(\epsilon)$를 &lt;strong&gt;sum pooling&lt;/strong&gt;으로 압축한다음, &lt;strong&gt;Fully Connected Layer&lt;/strong&gt;를 사용하여 prediction score에 투사(project)한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{y} = p^T \sum_{(i, j) \in R_x} (v_i \odot v_j) x_i x_j + b&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;$p \in R^k$&lt;/li&gt;
  &lt;li&gt;$b \in R$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위에서 등장한 &lt;strong&gt;p, b&lt;/strong&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Prediction Layer&lt;/code&gt;의 weight과 bias이다. 물론 p=1, b=0으로 값을 고정한다면 이는 FM과 동일한 형상을 취하게 될 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Attention-based Pooling Layer&lt;/strong&gt;&lt;br /&gt;
Attention의 기본 아이디어는, 여러 개의 부분이 압축 과정에 있어서 각각 다르게 기여하여 하나로 표현되게 만드는 것이다. interacted 벡터들의 가중 합을 수행하여 피쳐 상호작용에 대해 Attention 메커니즘을 적용하였다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_{Att}(f_{PI}(\epsilon)) = a_{i,j} \sum_{(i, j) \in R_x} (v_i \odot v_j) x_i x_j&lt;/script&gt;

&lt;p&gt;여기서 $a_{i, j}$는 피쳐 상호작용 $\hat{w}_{ij}$의 &lt;strong&gt;Attention Score&lt;/strong&gt;이다.&lt;/p&gt;

&lt;p&gt;Prediction Loss를 최소화하여 직접적으로 학습을 진행하여 $a_{i,j}$를 추정하는 것이 기술적으로는 맞게 느껴지지만, 학습 데이터에서 한 번도 동시에 등장한 적이 없는 피쳐들의 경우, 이들의 상호작용에 대한 &lt;strong&gt;Attention Score&lt;/strong&gt;는 추정될 수 없다.&lt;/p&gt;

&lt;p&gt;이러한 일반화 문제를 해결하기 위해 MLP를 통해 &lt;strong&gt;Attention Score&lt;/strong&gt;를 파라미터화 하는 &lt;strong&gt;Attention Network&lt;/strong&gt;를 추가하였다. 이 네트워크의 Input은 2개의 피쳐의 interacted 벡터인데, 이들의 상호작용 정보는 임베딩 공간에 인코딩된다.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;e_{ij} = h^T ReLU(W (v_i \odot v_j) x_i x_j + b)&lt;/script&gt;&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;a_{ij} = \frac {exp(e_{ij})} { \sum_{(i, j) \in R_x} exp(e_{ij}) }&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$W \in R^{t*k}, b \in R^t, h \in R^t$&lt;/li&gt;
  &lt;li&gt;$t$: Attention Network의 hidden layer의 크기(Attention Factor)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Attention Score&lt;/strong&gt;는 softmax 함수를 통해 정규화된다. 이 &lt;code class=&quot;highlighter-rouge&quot;&gt;Attention-based Pooling Layer&lt;/code&gt;의 결과물은 k 차원의 벡터로, 중요성을 구별하여 임베딩 공간에서의 모든 피쳐 상호작용을 압축한 것이다. 요약하자면, &lt;strong&gt;AFM&lt;/strong&gt; 모델의 최종 공식은 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{y}_{AFM}(x) = w_0 + \sum_{i=1}^n w_i x_i + p^T \sum_{i=1}^n \sum_{j=i+1}^n a_{ij} (v_i \odot v_j) x_i x_j&lt;/script&gt;

&lt;p&gt;모델 파라미터들은 $ w_0, w, v, p, W, b, h $이다.&lt;/p&gt;

&lt;h4 id=&quot;132-learning&quot;&gt;1.3.2. Learning&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;AFM&lt;/strong&gt;이 데이터 모델링의 관점에서 FM을 개선함에 따라 본 모델은 예측, 회귀, 분류, 랭킹 문제 등에 다양하게 적용될 수 있다. 목적 함수를 최적화하기 위해 SGD를 사용하였다. SGD 알고리즘 적용의 핵심은, 각 파라미터를 기준으로 예측 모델 &lt;strong&gt;AFM&lt;/strong&gt;의 derivative를 구하는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;과적합 문제&lt;/strong&gt;&lt;br /&gt;
FM보다 표현력이 뛰어난 &lt;strong&gt;AFM&lt;/strong&gt;이기에 더욱 과적합 문제에 민감할 수 있다. 따라서 본 모델에서는 dropout과 L2 Regularization 테크닉이 사용되었다.&lt;/p&gt;

&lt;p&gt;(후략)&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;2-tensorflow를-활용한-구현&quot;&gt;2. Tensorflow를 활용한 구현&lt;/h2&gt;
&lt;h3 id=&quot;21-데이터-준비&quot;&gt;2.1. 데이터 준비&lt;/h3&gt;
&lt;p&gt;본 모델의 경우 Dataset에 대한 Domain 지식이 필요하다고 볼 수는 없지만, 학습을 진행하기에 앞서 기본적으로 직접 전처리를 해주어야 하는 부분들이 있다. One-Hot 인코딩 외에도, 본 모델은 앞서 논문 리뷰에서도 확인하였듯이 0이 아닌 값에 대해서만 Lookup을 수행하여 실제 학습 데이터를 사용하기 때문에 이에 대한 정보를 저장해야할 필요가 있다. 아래 예시를 잠시 살펴보면,&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-05-01-AFM/02.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;만약 연속형 변수 중에 0.0이라는 값이 존재하더라도 사실 이 값은 중요한 특성을 나타낼 수도 있다. 그러나 논문의 기본 논조대로라면, 0인 값이기 때문에 학습에서 제외되게 된다. 이렇게 0이라고 해서 중요한 값이 학습에서 제외되는 현상을 막기 위해 본 구현에서는 One-Hot 인코딩 이후의 데이터에 대하여 중요한 정보의 위치를 저장하는 masking 작업을 진행하게 된다.&lt;/p&gt;

&lt;p&gt;데이터는 &lt;a href=&quot;2020-04-07-DeepFM.md&quot;&gt;DeepFM 구현글&lt;/a&gt;에서 사용한 것과 동일하다. 데이터 전처리는 연속형 변수에 대해서는 MinMaxScale, 범주형 변수에 대해서는 One-Hot 인코딩만을 진행하게 된다.&lt;/p&gt;

&lt;h3 id=&quot;22-layer-정의&quot;&gt;2.2. Layer 정의&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;AFM&lt;/strong&gt; 모델에서는 크게 3개의 Layer가 필요하다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Embedding Layer&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Pairwise Interaction Layer&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Attention Pooling Layer&lt;/code&gt;가 바로 그 3가지이다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Embedding Layer&lt;/code&gt; 부분은 이전 글(논문)들을 읽었다면, 굉장히 익숙하게 받아들여 질 것이다. 다만 이전 &lt;a href=&quot;2020-04-07-DeepFM.md&quot;&gt;DeepFM 구현글&lt;/a&gt;에서는 하나의 Field에 대해 하나의 Embedding Row가 학습되었다면, 본 글에서는 하나의 Feature에 대해 하나의 Embedding Row가 학습되도록 코드를 수정하였다.&lt;/p&gt;

&lt;p&gt;앞서 언급하였듯이 One-Hot 인코딩으로 생성된 0 값을 갖는 feature를 제외한 feature들만 실제 학습에 사용되는데(예를 들어 One-Hot 인코딩 이후에 0.2, 7.4, 0, 1, … 0, 1와 같은 데이터로 변환되었다면 실제 학습에 사용되는 데이터는 0.2, 7.4, 1, … 1이라는 뜻이다.)&lt;/p&gt;

&lt;p&gt;위와 같은 논리를 구현하는 방법에는 여러가지가 있을 수 있겠지만 본 구현에서는 다음과 같은 논리를 따랐다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1) 연속형 변수들은 모두 앞쪽에 배치한 후, 이들에게는 무조건 True Mask를 씌워 학습 데이터로 활용한다.  
2) 범주형 변수들에 대해서는 0이 아닌 값들에 대해서 True Mask를 씌워 학습 데이터로 활용한다.  
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;논리 자체는 간단하며, 아래 call 메서드에서 그 논리가 구현되어 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;config&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Embedding_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_cont&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Embedding_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# k: 임베딩 벡터의 차원(크기)
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;              &lt;span class=&quot;c1&quot;&gt;# m: 인코딩 이전 feature 수
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;          &lt;span class=&quot;c1&quot;&gt;# p: 인코딩 이후 feature 수, m &amp;lt;= p
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_cont&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_cont&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;# 연속형 field 수
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_cat&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_cont&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# 범주형 field 수
&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Parameters
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                                              &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stddev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'V'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# inputs: (None, p, k), embeds: (None, m, k)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 원핫인코딩으로 생성된 0을 제외한 값에 True를 부여한 mask(np.array): (None, m)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# indices: 그 mask의 indices
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;cont_mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;full&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_cont&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fill_value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cat_mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;not_equal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_cont&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:],&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concatenate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cont_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cat_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flatten_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flatten_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# embedding_matrix: (None, m, k)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;embedding_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_lookup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# masked_inputs: (None, m, 1)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;masked_inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boolean_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                                   &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;masked_inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# (None, m, k)
&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masked_inputs&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음은 &lt;code class=&quot;highlighter-rouge&quot;&gt;Pairwise Interaction Layer&lt;/code&gt;에 대한 설명이다. 만약 14개의 Row가 존재한다면 이에 대한 모든 조합을 구하여 91 = $14\choose2$ 개의 Row를 생성하는 Layer인데, 간단하게 생각해보면 아래와 같이 코드를 짜고 싶을 것이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;itertools&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combinations&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;comb_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;combinations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;comb_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pairwise_interactions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                                    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;하지만 위와 같이 loop를 돌리게 되면, 속도가 현저하게 느려져서 실 사용이 불가능하다. 따라서 이 때는 Trick이 필요한데, 그림으로 설명하면 아래와 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-05-01-AFM/03.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 그림에서 14는 &lt;code class=&quot;highlighter-rouge&quot;&gt;num_field&lt;/code&gt;의 예시이고, 5는 &lt;code class=&quot;highlighter-rouge&quot;&gt;embedding_size&lt;/code&gt;의 예시이다. 가장 왼쪽에 있는 그림은 &lt;code class=&quot;highlighter-rouge&quot;&gt;Embedding Layer&lt;/code&gt;를 통과한 Input 행렬을 그대로 &lt;code class=&quot;highlighter-rouge&quot;&gt;num_field&lt;/code&gt; 수 만큼 쌓은 형태이이고, 그 오른쪽 그림은 똑같은 행들을 &lt;code class=&quot;highlighter-rouge&quot;&gt;num_field&lt;/code&gt; 수만큼 쌓은 형태이다. 이렇게 쌓은 두 행렬 집단을 그대로 원소곱을 하게 되면 마치 조합을 구해서 곱을 한 것과 같은 형태가 나온다. 여기서 필요한 행들만 masking을 통해 취하면, 제일 오른쪽과 같은 결과물을 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;이를 코드를 구현한 것이 아래이다. &lt;strong&gt;tf.tile&lt;/strong&gt;, &lt;strong&gt;tf.expand_dims&lt;/strong&gt; 함수를 잘 이용하면 이 Trick을 코드로 구현할 수 있다. 직접 해보길 바란다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Pairwise_Interaction_Layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Pairwise_Interaction_Layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# k: 임베딩 벡터의 차원(크기)
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;              &lt;span class=&quot;c1&quot;&gt;# m: 인코딩 이전 feature 수
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;          &lt;span class=&quot;c1&quot;&gt;# p: 인코딩 이후 feature 수, m &amp;lt;= p
&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;masks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;convert_to_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MASKS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# (num_field**2)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;masks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;             &lt;span class=&quot;c1&quot;&gt;# (num_field**2, 1)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;masks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;# (num_field**2, embedding_size)
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;         &lt;span class=&quot;c1&quot;&gt;# (1, num_field**2, embedding_size)
&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# a, b shape: (batch_size, num_field^2, embedding_size)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# ab, mask_tensor: (batch_size, num_field^2, embedding_size)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;ab&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mask_tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# pairwise_interactions: (batch_size, num_field C 2, embedding_size)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;pairwise_interactions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boolean_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                                           &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pairwise_interactions&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;config.MASKS&lt;/code&gt;는 아래와 같이 구현되어 있다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;MASKS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NUM_FIELD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;MASKS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;MASKS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NUM_FIELD&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음으로는 마지막 &lt;code class=&quot;highlighter-rouge&quot;&gt;Attention Pooling Layer&lt;/code&gt;이다. 설명할 것이 많지 않은 간단한 구조이다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Attention_Pooling_Layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Attention_Pooling_Layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# k: 임베딩 벡터의 차원(크기)
&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Parameters
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                                              &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stddev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                                              &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stddev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'W_attention'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 조합 수 = combinations(num_feauture, 2)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# inputs: (None, 조합 수, embedding_size)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# --&amp;gt; (전치 후) (None, embedding_size, 조합 수)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# e: (None, 조합 수, 1)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Attention Score 산출
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;attention_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_score&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;23-model-build&quot;&gt;2.3. Model Build&lt;/h3&gt;
&lt;p&gt;위에서 설명한 모든 Layer들을 이어 붙이면 &lt;strong&gt;AFM&lt;/strong&gt; 모델이 완성된다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Model 정의
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_floatx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AFM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_cont&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AFM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# k: 임베딩 벡터의 차원(크기)
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;              &lt;span class=&quot;c1&quot;&gt;# m: 인코딩 이전 feature 수
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;          &lt;span class=&quot;c1&quot;&gt;# p: 인코딩 이후 feature 수, m &amp;lt;= p
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_cont&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_cont&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;# 연속형 field 수
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;          &lt;span class=&quot;c1&quot;&gt;# Attention Pooling Layer Hidden Unit 수
&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Embedding_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                               &lt;span class=&quot;n&quot;&gt;num_cont&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pairwise_interaction_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pairwise_Interaction_Layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention_pooling_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Attention_Pooling_Layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Parameters
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                                              &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stddev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DROPOUT_RATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__repr__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;AFM Model: embedding{}, hidden{}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 1) Linear Term: (None, )
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;linear_terms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 2) Interaction Term
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;masked_inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pairwise_interactions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pairwise_interaction_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;masked_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Dropout and Attention Score
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;pairwise_interactions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pairwise_interactions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;attention_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention_pooling_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pairwise_interactions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# (None, 조합 수, embedding_size)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;attention_interactions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pairwise_interactions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# (None, embedding_size)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;final_interactions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention_interactions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 3) Final: (None, )
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_terms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;final_interactions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;24-코드-전문&quot;&gt;2.4. 코드 전문&lt;/h3&gt;
&lt;p&gt;코드의 전문은 &lt;a href=&quot;https://github.com/ocasoyy/Recommendation-Algorithms&quot;&gt;깃헙&lt;/a&gt;에서 확인할 수 있다.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>추천 시스템의 기본 - 05. DeepFM 논문 리뷰 및 Tensorflow 구현</title>
   <link href="http://localhost:4000/DeepFM/"/>
   <updated>2020-04-07T00:00:00+09:00</updated>
   <id>http://localhost:4000/DeepFM</id>
   <content type="html">&lt;p&gt;본 글의 전반부에서는 먼저 &lt;strong&gt;DeepFM: A Factorization-Machine based Neural Network for CTR Prediction&lt;/strong&gt; 논문을 리뷰하면서 본 모델에 대해 설명할 것이다. 후반부에서는 Tensorflow를 이용하여 직접 코딩을 하고 학습하는 과정을 소개할 것이다. 논문의 전문은 &lt;a href=&quot;https://arxiv.org/pdf/1703.04247v1.pdf&quot;&gt;이곳&lt;/a&gt;에서 확인할 수 있다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;1-deepfm-a-factorization-machine-based-neural-network-for-ctr-prediction-논문-리뷰&quot;&gt;1. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction 논문 리뷰&lt;/h2&gt;
&lt;h3 id=&quot;10-abstract&quot;&gt;1.0. Abstract&lt;/h3&gt;
&lt;p&gt;추천 시스템에서 CTR을 최대화하는 것에 있어 사용자의 행동 속에 숨어있는 복잡한 feature interactions들을 학습하는 것은 매우 중요하다. 본 논문에서는 저차원 및 고차원 feature interactions를 모두 강조하면서 end-to-end 학습을 진행하는 모델에 대해 설명할 것이다. 이 &lt;strong&gt;DeepFM&lt;/strong&gt;이라는 모델은 FM과 딥러닝을 결합한 것이다. 최근(2017년 기준) 구글에서 발표한 &lt;strong&gt;Wide &amp;amp; Deep model&lt;/strong&gt;에 비해 피쳐 엔지니어링이 필요 없고, wide하고 deep한 부분에서 공통된 Input을 가진다는 점이 특징적이다.&lt;/p&gt;

&lt;h3 id=&quot;11-introduction&quot;&gt;1.1. Introduction&lt;/h3&gt;
&lt;p&gt;추천 시스템에서 CTR은 매우 중요하다. 많은 경우에 추천시스템의 목표는 이 클릭 수를 증대하는 것인데, 따라서 CTR 추정값에 근거하여 아이템을 정렬한 뒤 아이템(기사, 영화 등)을 사용자에게 제시할 수 있다. 온라인 광고에서는 수익을 증가시키는 것이 가장 중요하기에, 이 상황에서는 &lt;strong&gt;CTR * bid&lt;/strong&gt;라는 기준 아래 랭킹 전략을 세울 수 있을 것이다. 여기서 bid는 사용자가 아이템을 클릭할 경우 시스템이 수령하는 수입을 의미한다. 어떠한 케이스든, 이 CTR을 정확히 추정하는 것은 매우 중요할 것이다.&lt;/p&gt;

&lt;p&gt;CTR 예측에 있어 중요한 포인트는, 사용자의 클릭 행동 속에 숨어 있는 implicit feature interactions(암시적 피쳐 상호작용)를 학습할 줄 알아야 한다는 것이다.&lt;/p&gt;

&lt;p&gt;예를 들어 사람들이 식사 시간에 음식 배달을 위한 앱을 다운로드 받는다면, 이 때 앱 카테고리와 시간이라는 요소 사이의 2차 상호작용이 바로 &lt;strong&gt;클릭&lt;/strong&gt;에 대한 신호가 될 수 있다는 것이다. 10대 남자아이가 RPG게임을 좋아한다고 하자, 이 때는 앱 카테고리-사용자의 성별-사용자의 나이라는 3개 요소의 관계가 &lt;strong&gt;클릭&lt;/strong&gt;을 결정하는 요인이 될 수 있다. 즉, 사용자의 클릭 뒤에 숨어있는 이러한 상호작용들은 매우 복잡하여 저/고차원 &lt;strong&gt;모두&lt;/strong&gt; 잘 잡아내는 것이 매우 중요하다.&lt;/p&gt;

&lt;p&gt;(중략)&lt;/p&gt;

&lt;p&gt;feature representation을 학습하는 방법으로써 Deep Neural Network가 복잡한 feature interactions를 학습하는 잠재력을 갖고 있다고 판단된다. 다만 CNN-based 모델의 경우 이웃한 feature들 사이에 발생하는 상호작용에 의해 편향된 경향을 보이고, RNN-based 모델의 경우 sequential dependency를 갖고 있는 클릭 데이터에 상대적으로 적합한 모습을 보였다. 이후에 FNN, PNN, Wide &amp;amp; Deep 등 여러 모델들이 제안되었다. 본 논문에서는 이러한 모델들의 단점을 보완한 새로운 모델을 제시한다.&lt;/p&gt;

&lt;p&gt;1) &lt;strong&gt;DeepFM&lt;/strong&gt;은 피쳐 엔지니어링 없이 end-to-end 학습을 진행할 수 있다. 저차원의 interaction들은 FM 구조를 통해 모델화하고, 고차원의 interaction들은 DNN을 통해 모델화한다.&lt;br /&gt;
2) &lt;strong&gt;DeepFM&lt;/strong&gt;은 같은 Input과 Embedding 벡터를 공유하기 때문에 효과적으로 학습을 진행할 수 있다.&lt;br /&gt;
3) 본 논문에서 &lt;strong&gt;DeepFM&lt;/strong&gt;은 벤치마크 데이터와 상업용 데이터 모두에서 평가될 것이다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h3 id=&quot;12-our-approach&quot;&gt;1.2. Our Approach&lt;/h3&gt;
&lt;p&gt;$n$개의 instance를 가진 $(\chi, y)$ 학습 데이터셋이 있다고 하자. 이 때 $\chi$는 $m$개의 &lt;strong&gt;field&lt;/strong&gt;를 지니고 있고, $y$는 0과 1의 값을 가진다. (1 = 클릭함)&lt;/p&gt;

&lt;p&gt;$\chi$에는 범주형 변수가 있을 수도 있고, 연속형 변수가 있을 수도 있다. 범주형 변수의 경우 원핫인코딩된 벡터로 표현되며, 연속형 변수의 경우 그 값 자체로 표현되거나 이산화되어 원핫인코딩된 벡터로 표현될 수도 있다.&lt;/p&gt;

&lt;p&gt;그렇다면 이제 데이터는 $(x, y)$로 표현할 수 있을 것이다. 여기서 $x$는 $[x_{field_1}, x_{field_2}, …, x_{field_m}]$의 구조를 갖게 되며 각각의 $x_{field_j}$는 $\chi$에서의 j번째 field의 벡터 표현을 의미하게 된다. 일반적으로 $x$는 굉장히 고차원이고 희소하다. CTR의 목적은 context가 주어졌을 때 사용자가 특정 어플을 클릭할 확률을 정확히 추정하는 것이다.&lt;/p&gt;

&lt;h4 id=&quot;121-deepfm&quot;&gt;1.2.1. DeepFM&lt;/h4&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-07-DeepFM/01.JPG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 그림에서도 확인할 수 있다시피, &lt;strong&gt;DeepFM&lt;/strong&gt;은 2가지 요소로 구성되어 있다. 이 요소들은 같은 Input을 공유한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$i$번재 피쳐에 대해 스칼라 $w_i$: 1차원 importance를 측정함&lt;/li&gt;
  &lt;li&gt;latent vector $V_i$: 다른 피쳐들과의 interaction의 영향을 측정&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$V_i$의 경우 FM요소에서는 2차원 interaction을 모델화하며, Deep요소에서는 고차원 피쳐 interaction을 모델화한다. 모든 파라미터들은 통합 예측모델에서 함께 학습된다. 즉 모델을 아주 간단히 표현하자면 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{y} = sigmoid(y_{FM} + y_{DNN})&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;FM Component&lt;/strong&gt;&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-07-DeepFM/02.JPG&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;FM요소는 Factorization Machine이다. FM모델에 대한 설명은 &lt;a href=&quot;2019-12-21-FM.md&quot;&gt;이글&lt;/a&gt;에서 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Deep Component&lt;/strong&gt;&lt;br /&gt;
CTR 예측에 사용되는 Raw 데이터는 일반적으로 매우 희소하고, 고차원이며, 범주형/연속형 변수가 섞여 있고, 일종의 field(성별, 위치, 나이 등)로 그룹화되어 있다는 특징을 지닌다. 따라서 &lt;strong&gt;Embedding Layer&lt;/strong&gt;로 이러한 정보들을 압축하여 저차원의, dense한 실수 벡터를 만들어서 Input을 재가공할 필요가 있다.&lt;/p&gt;

&lt;p&gt;아래 그림은 &lt;strong&gt;Input Layer&lt;/strong&gt;에서 &lt;strong&gt;Embedding Layer&lt;/strong&gt;로 이어지는 보조 네트워크를 강조한 부분이다. 여기서 확인해야 할 부분은 2가지이다. 첫 번재는, Input으로 쓰이는 Input field 벡터가 각자 다른 길이를 갖고 있을 수 있기 때문에, 이들의 임베딩은 같은 크기(&lt;strong&gt;k&lt;/strong&gt;)여야 한다는 것이다. 두 번재는, FM 모델에서 latent 벡터로 기능했던 $V$는 본 요소에서는 Input field 벡터를 Embedding 벡터로 압축하기 위해 사용되고 학습되는 네트워크 weight가 된다는 것이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-07-DeepFM/06.JPG&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;strong&gt;Embedding Layer&lt;/strong&gt;의 Output은 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;a^0 = [e_1, e_2, ..., e_m]&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;$e_i$는 i번재 field의 Embedding&lt;/li&gt;
  &lt;li&gt;$m$은 field의 수&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$a^{(0)}$는 DNN에 투입되며 forward process는 다음과 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;a^{(l+1)} = \sigma{(W^{(l)}a^{(l)} + b^{(l)}})&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;$l$: layer의 깊이&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이렇게 Dense한 실수 피쳐 벡터가 생성되면 CTR prediction을 위해 최종적으로 sigmoid 함수에 투입되게 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_{DNN} = \sigma{(W^{|H|+1} a^{|H|} + b^{|H| + 1}})&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;$ㅣHㅣ$: hidden layer의 수&lt;/li&gt;
  &lt;li&gt;$ \vert H \vert $: hidden layer의 수&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt; (중략) &lt;/center&gt;

&lt;h4 id=&quot;15-conclusions&quot;&gt;1.5. Conclusions&lt;/h4&gt;
&lt;p&gt;DeepFM은 FM Component와 Deep Component를 함께 학습시킨다. 이러한 방식은 다음과 같은 장점을 지닌다.&lt;br /&gt;
1) pre-training이 필요 없다.&lt;br /&gt;
2) 저/고차원 feature를 모두 잘 학습한다.&lt;br /&gt;
3) feature embedding을 통해 피쳐 엔지니어링이 불필요하다.&lt;/p&gt;

&lt;p&gt;실험 결과를 확인하면, DeepFM이 최신 모델들을 압도하고 상당한 효율성을 지닌 것을 알 수 있다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;2-tensorflow-구현&quot;&gt;2. Tensorflow 구현&lt;/h2&gt;
&lt;h3 id=&quot;21-데이터-설명-및-데이터-변환&quot;&gt;2.1. 데이터 설명 및 데이터 변환&lt;/h3&gt;
&lt;p&gt;구현의 핵심은 Parameter인 $w$와 $V$의 shape과 활용 방법에 대해 이해하는 것이다. 사실 구현하는 사람의 입장에서는 논문이 썩 친절하다고 느끼지는 못할 것이다. 다소 애매모호한 표현으로 읽는 사람으로 하여금 혼란을 일으키게 하는 문구나 그림 등도 존재한다. 그럼에도 침착하게 잘 생각해보면, 모델을 구축할 수 있을 것이다.&lt;/p&gt;

&lt;p&gt;학습 데이터로는 연봉이 5만 달러를 상회하는지의 여부를 예측하는 데이터를 사용하였고, &lt;a href=&quot;https://archive.ics.uci.edu/ml/datasets/Adult&quot;&gt;여기&lt;/a&gt;에서 다운로드 받을 수 있다.&lt;/p&gt;

&lt;p&gt;데이터는 48,842개의 Instance로 구성되어 있고, 14개의 Feature를 갖고 있으며, 이 중 6개의 변수가 연속형 변수이다. 당연히 예측 과제는 &lt;strong&gt;Binary Classification&lt;/strong&gt;이다. 0은 연봉 5만 달러 이하를 의미하며, 전체 데이터의 25% 정도를 차지한다. 1은 연봉 5만 달러 초과를 의미한다.&lt;/p&gt;

&lt;p&gt;앞에서 설명한 데이터를 예로 들어 설명하도록 하겠다. 이 데이터에는 총 14개의 변수가 있다. 이 14개는 곧, field의 개수가 된다. 이 중 범주형 변수를 One-Hot 인코딩을 통해 변환시키면(물론 연속형 변수도 필요에 따라 구간화하여 범주형 변수화해도 된다.) 본 데이터는 총 108개의 칼럼을 갖게 된다. 이 108개는 곧, feature의 개수가 된다. 즉, One-Hot 인코딩을 통해 변환시킨 칼럼의 개수를 feature의 개수로, 인코딩 이전의 데이터의 칼럼의 개수를 field의 개수로 이해하면 쉽다. 논문에서는 임베딩 스킬을 이용하고 있는데, 여기서 Embedding Matrix인 $V$의 칼럼의 개수는 Hyperparameter이다.&lt;/p&gt;

&lt;p&gt;본 프로젝트 파일은 다음과 같이 5개의 py파일로 구성되어 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-07-DeepFM/07.JPG&quot; width=&quot;25%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;먼저 config파일을 보자. 이 파일에는 칼럼의 목록을 연속형/범주형을 구분하여 저장한 리스트와 Hyperparameter들이 저장되어 있다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# config.py
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ALL_FIELDS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'age'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'workclass'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'fnlwgt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'education'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'education-num'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;s&quot;&gt;'marital-status'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'occupation'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'relationship'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'race'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;s&quot;&gt;'sex'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'capital-gain'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'capital-loss'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'hours-per-week'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'country'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;CONT_FIELDS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'age'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'fnlwgt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'education-num'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;s&quot;&gt;'capital-gain'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'capital-loss'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'hours-per-week'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;CAT_FIELDS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ALL_FIELDS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;difference&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CONT_FIELDS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Hyper-parameters for Experiment
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NUM_BIN&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;BATCH_SIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;EMBEDDING_SIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 데이터를 가공할 시간이다. (데이터가 매우 커서 서버에서 데이터를 받아오는 상황이라면, 아래 코드를 pyspark로 짜면 좋을 것이다.) 지금부터 할 작업은 &lt;code class=&quot;highlighter-rouge&quot;&gt;field_index&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;field_dict&lt;/code&gt;를 만드는 것인데, 쉽게 말해서 아래와 같은 작업을 진행하는 것이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-07-DeepFM/05.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;인코딩 이후의 데이터에 대해 각 칼럼이 본래 인코딩 이전에 몇 번째 field에 속했었는지에 대한 정보를 저장한 것이 &lt;code class=&quot;highlighter-rouge&quot;&gt;field_index&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;field_dict&lt;/code&gt;이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Preprocess
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;config&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;itertools&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;repeat&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MinMaxScaler&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_modified_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;continuous_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;categorical_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;field_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X_modified&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;{} not included: Check your column list&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;continuous_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;scaler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MinMaxScaler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# 연속형 변수도 구간화 할 것인가?
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_bin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X_bin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scaler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NUM_BIN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X_bin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Series&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_bin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'str'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

                &lt;span class=&quot;n&quot;&gt;X_bin_col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_dummies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_bin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prefix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prefix_sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'-'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;field_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_bin_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;repeat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_bin_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X_modified&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_modified&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_bin_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X_cont_col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scaler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;field_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X_modified&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_modified&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_cont_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;categorical_fields&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;X_cat_col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_dummies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prefix&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prefix_sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'-'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;field_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_cat_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;repeat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_cat_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;X_modified&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_modified&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_cat_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Data Prepared...'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'X shape: {}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_modified&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'# of Feature: {}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'# of Field: {}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_modified&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;22-모델-빌드&quot;&gt;2.2. 모델 빌드&lt;/h3&gt;
&lt;p&gt;먼저 FM Component에 대해 살펴보자. &lt;strong&gt;call&lt;/strong&gt; 함수에서 y_fm을 어떤 shape으로 반환할 지는 그 task에 맞게 변환하면 된다. 아래 코드에서는 (None, 2)의 형태로 반환되어 최종적으로 Deep Component의 (None, 2)와 합쳐져 (None, 4)의 최종 Output을 반환하게 되는데, 이 수치는 성능 향상을 위해 변경이 가능하다.&lt;/p&gt;

&lt;p&gt;Parameter $w$의 길이는 &lt;code class=&quot;highlighter-rouge&quot;&gt;num_feature(108)&lt;/code&gt;이며, Parameter $V$의 shape은 &lt;code class=&quot;highlighter-rouge&quot;&gt;num_field(14), embedding_size(5)&lt;/code&gt;이다. 그런데 아래 &lt;strong&gt;call&lt;/strong&gt; 함수에서 보면 알 수 있듯이, 이 $V$행렬은 One-Hot 인코딩된 데이터에 곱해지는 구조이기 때문에 &lt;code class=&quot;highlighter-rouge&quot;&gt;tf.nn.embedding_lookup&lt;/code&gt;이라는 함수를 통해 행이 복제된다. 즉, 앞서 생성한 &lt;code class=&quot;highlighter-rouge&quot;&gt;field_index&lt;/code&gt;의 정보를 참조하여, 같은 field에서 나온 feature일 경우, 같은 Embedding Row($V$의 Row)를 공유하는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;new_inputs&lt;/strong&gt;는 Deep Component의 Input으로 쓰일 개체이다. 코드를 살펴보면, $V$라는 행렬이 FM Component에도 쓰이지만, &lt;strong&gt;new_inputs&lt;/strong&gt;를 만들어내면서 Deep Component에도 영향을 미치는 것을 알 수 있다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FM_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FM_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# k: 임베딩 벡터의 차원(크기)
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;          &lt;span class=&quot;c1&quot;&gt;# f: 원래 feature 개수
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;              &lt;span class=&quot;c1&quot;&gt;# m: grouped field 개수
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;          &lt;span class=&quot;c1&quot;&gt;# 인코딩된 X의 칼럼들이 본래 어디 소속이었는지
&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Parameters of FM Layer
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# w: capture 1st order interactions
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# V: capture 2nd order interactions
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                                              &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stddev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                                              &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stddev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'V'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Parameter V를 field_index에 맞게 복사하여 num_feature에 맞게 늘림
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;embeds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_lookup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Deep Component에서 쓸 Input
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# (batch_size, num_feature, embedding_size)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;new_inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# (batch_size, )
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;linear_terms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# (batch_size, )
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subtract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;square&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;square&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;linear_terms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear_terms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;y_fm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear_terms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_fm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_inputs&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아래는 메인 모델에 대한 코드이다. 성능 향상을 위해 Deep Component를 수정하는 것은 연구자의 자유이다. Task에 따라 가볍게 설계할 수도, 복잡하게 설계할 수도 있을 것이다. 본 코드에서는 Dropout만을 추가하여 다소 가볍게 설계하였다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FM_layer&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_floatx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DeepFM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DeepFM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# k: 임베딩 벡터의 차원(크기)
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;          &lt;span class=&quot;c1&quot;&gt;# f: 원래 feature 개수
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;              &lt;span class=&quot;c1&quot;&gt;# m: grouped field 개수
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;          &lt;span class=&quot;c1&quot;&gt;# 인코딩된 X의 칼럼들이 본래 어디 소속이었는지
&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fm_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FM_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sigmoid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__repr__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;DeepFM Model: #Field: {}, #Feature: {}, ES: {}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# 1) FM Component: (num_batch, 2)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;y_fm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fm_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# retrieve Dense Vectors: (num_batch, num_feature*embedding_size)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;new_inputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 2) Deep Component
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;y_deep&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_deep&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_deep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_deep&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_deep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_deep&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_deep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_deep&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_deep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Concatenation
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_fm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_deep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;final&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;23-학습&quot;&gt;2.3. 학습&lt;/h3&gt;
&lt;p&gt;학습 코드는 아래와 같다. 그리 무거운 모델은 아니므로 Autograph는 사용하지 않았다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;config&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;preprocess&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_modified_data&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;DeepFM&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DeepFM&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;perf_counter&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow.keras.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BinaryAccuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AUC&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/adult.data'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;' &amp;lt;=50K'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;' &amp;gt;50K'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ALL_FIELDS&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;field_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_modified&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; \
        &lt;span class=&quot;n&quot;&gt;get_modified_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ALL_FIELDS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CONT_FIELDS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CAT_FIELDS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_modified&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stratify&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;train_ds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_tensor_slices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; \
        &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BATCH_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;test_ds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_tensor_slices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; \
        &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BATCH_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# Batch 단위 학습
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_on_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;auc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GradientTape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binary_crossentropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_logits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sources&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainable_variables&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# apply_gradients()를 통해 processed gradients를 적용함
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply_gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainable_variables&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# accuracy &amp;amp; auc
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;auc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# 반복 학습 함수
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DeepFM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDDING_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_feature&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                   &lt;span class=&quot;n&quot;&gt;num_field&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;field_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Start Training: Batch Size: {}, Embedding Size: {}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BATCH_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDDING_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;perf_counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BinaryAccuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;auc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AUC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss_history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_on_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;auc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss_history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Epoch {:03d}: 누적 Loss: {:.4f}, Acc: {:.4f}, AUC: {:.4f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;auc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;test_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BinaryAccuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_auc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AUC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test_acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test_auc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;테스트 ACC: {:.4f}, AUC: {:.4f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_auc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Batch Size: {}, Embedding Size: {}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BATCH_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDDING_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;걸린 시간: {:.3f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perf_counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'weights/weights-epoch({})-batch({})-embedding({}).h5'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BATCH_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDDING_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'__main__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Embedding Size를 변환하면서 진행한 테스트 결과는 아래와 같다. (Epoch: 100)&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Embedding Size&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;누적 Loss&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Train ACC&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Train AUC&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Test ACC&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Test AUC&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;시간&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;10&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.3243&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;0.8485&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;0.9038&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;0.8464&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8991&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4분 0.78초&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;9&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.3386&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8382&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8954&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8402&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8975&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4분 3.64초&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;8&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.3704&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8240&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8729&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8260&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8745&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4분 2.79초&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;7&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.3248&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8471&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.9033&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8424&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.9013&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4분 0.84초&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;6&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.3305&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8433&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.9001&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8416&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;0.9041&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4분 1.28초&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.3945&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8169&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8512&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8190&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8576&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4분 8.10초&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;p&gt;https://github.com/ChenglongChen/tensorflow-DeepFM&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>추천 시스템의 기본 - 04. Field-aware Factorization Machines 설명 및 xlearn 실습</title>
   <link href="http://localhost:4000/FFM/"/>
   <updated>2020-04-05T00:00:00+09:00</updated>
   <id>http://localhost:4000/FFM</id>
   <content type="html">&lt;p&gt;본 글의 전반부에서는 먼저 &lt;strong&gt;Field-aware Factorization Machines for CTR prediction&lt;/strong&gt; 논문을 리뷰하면서 본 모델에 대해 설명할 것이다. 후반부에서는 간단한 xlearn코드 역시 소개할 예정이다. 논문의 전문은 &lt;a href=&quot;https://www.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf&quot;&gt;이곳&lt;/a&gt;에서 확인할 수 있다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;1-field-aware-factorization-machines-for-ctr-prediction-논문-리뷰&quot;&gt;1. Field-aware Factorization Machines for CTR prediction 논문 리뷰&lt;/h2&gt;
&lt;h3 id=&quot;10abstract&quot;&gt;1.0.Abstract&lt;/h3&gt;
&lt;p&gt;CTR 예측과 같은 크고 희소한 데이터셋에 대해 &lt;strong&gt;FFM&lt;/strong&gt;은 효과적인 방법이다. 본 논문에서는 우리는 &lt;strong&gt;FFM&lt;/strong&gt;을 학습시키는 효과적인 구현 방법을 제시할 것이다. 그리고 우리는 이 모델을 전체적으로 분석한 뒤 다른 경쟁 모델과 비교를 진행할 것이다. 실험에 따르면 &lt;strong&gt;FFM&lt;/strong&gt;이 특정 분류 모델에 있어서 굉장히 뛰어난 접근 방법이라는 것을 알려준다. 마지막으로, 우리는 &lt;strong&gt;FFM&lt;/strong&gt; 패키지를 공개한다.&lt;/p&gt;

&lt;h3 id=&quot;11-introduction&quot;&gt;1.1. Introduction&lt;/h3&gt;
&lt;p&gt;CTR 예측에 있어서 굉장히 중요한 것은, feature 간의 conjunction(결합, 연결)을 이해하는 것이다. Simple Logistic Regression과 같은 간단한 모델은 이러한 &lt;code class=&quot;highlighter-rouge&quot;&gt;결합&lt;/code&gt;을 잘 이해하지 못한다. FM 모델은 2개의 Latent Vector의 곱으로 factorize하여 feature conjunction을 이해하게 된다.&lt;/p&gt;

&lt;p&gt;개인화된 태그 추천을 위해 pairwise interaction tensor factorization (PITF)라는 FM의 변형 모델이 제안되었다. 이후 KDD Cup 2020에서, Team Opera Solutions라는 팀이 이 모델의 일반화된 버전을 제안하였다. 그러나 이 용어는 다소 일반적이고 혼동을 줄 수 있는 이름이므로, 본 논문에서는 이를 &lt;strong&gt;FFM&lt;/strong&gt;이라고 부르도록 하겠다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;FFM&lt;/strong&gt;의 중요 특징은 아래와 같다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;최적화 문제를 해결하기 위해 Stochastic Gradient를 사용한다. 과적합을 막기 위해 오직 1 epoch만 학습한다.&lt;/li&gt;
  &lt;li&gt;FFM은 위 팀에서 비교한 모델 6개 중 가장 뛰어난 성적을 보여주었다.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;
&lt;h3 id=&quot;12-poly2-and-fm&quot;&gt;1.2. POLY2 and FM&lt;/h3&gt;
&lt;p&gt;(중략)&lt;/p&gt;

&lt;hr /&gt;
&lt;h3 id=&quot;13-ffm&quot;&gt;1.3. FFM&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;FFM&lt;/strong&gt;의 중요한 아이디어는 PITF로 부터 파생되었는데, 이는 바로 개인화된 태그에 관한 것이다. PIFT에서 그들은 &lt;code class=&quot;highlighter-rouge&quot;&gt;User, Item, Tag&lt;/code&gt;를 포함한 3개의 가용 필드를 가정했고, 이를 분리된 latent space에서 (User, Item), (User, Tag), (Item,Tag)로 factorize하였다. 이러한 정의는 추천 시스템에 적합한 정의이고 CTR 예측에 있어서는 자세한 설명이 부족한 편이므로, 좀 더 포괄적인 논의를 진행해보도록 하겠다.&lt;/p&gt;

&lt;p&gt;아래와 같은 데이터 테이블이 있을 때, &lt;code class=&quot;highlighter-rouge&quot;&gt;features&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;fields&lt;/code&gt;로 그룹화할 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-05-FFM/01.JPG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;예를 들어, Espn, Vogue, NBC는 Publisher라는 field에 속할 수 있겠다. &lt;strong&gt;FFM&lt;/strong&gt;은 이러한 정보를 활용하는 FM의 변형된 버전이다. &lt;strong&gt;FFM&lt;/strong&gt;의 원리를 설명하기 위해, 다음 새로운 예시에 대해 생각해보자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-05-FFM/02.JPG&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;FM의 상호작용 항인 $\phi_{FM}(w, x)$는 아래와 같이 표현될 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-05-FFM/03.JPG&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;FM에서는 다른 feature들과의 latent effect를 학습하기 위해 모든 feature는 오직 하나의 latent vector를 가진다. Espn을 예로 들어보면, $w_{Espn}$은 Nike와 Male과의 latent effect를 학습하기 위해 이용되었다. 그러나 Nike와 Male은 다른 Field에 속하기 때문에 사실 (Espn, Nike)의 관계와 (Espn, Male)의 관계에서 사용되었던 $w_{Espn}$의 값은 다를 가능성이 높다. 즉, 하나의 벡터로 2개의 관계를 모두 표현하기에는 무리가 있다는 점이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;FFM&lt;/strong&gt;에서는 각각의 feature는 여러 latent vector를 갖게 된다. &lt;strong&gt;FFM&lt;/strong&gt;의 상호작용 항인 $\phi_{FFM}(w, x)$은 아래와 같이 표현된다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-05-FFM/04.JPG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;수학적으로 재표현하면 아래와 같이 표현할 수 있겠다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-05-FFM/05.JPG&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;여기서 $f_1$과 $f_2$는 $j_1$과 $j_2$의 field를 의미한다. $j$들은 Espn, Nike 등을 의미한다. $f$를 field의 개수라고 할 때, FFM의 변수의 개수는 $nfk$이며, FFM의 계산 복잡성은 $O(\overline{n}^2 k)$이다.&lt;/p&gt;

&lt;p&gt;여기서 &lt;strong&gt;n, f, k&lt;/strong&gt;는 각각 feature의 개수(often called p), field의 개수, latent 변수의 개수를 의미한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;FFM&lt;/strong&gt;의 경우 각각의 latent vector아 오직 특정 field와 관련한 효과에 대해서는 학습을 진행하기 때문에 잠재 변수의 수은 $k$는 FM의 경우보다 작은 경우가 많다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
k_{FFM} &lt; k_{FM} %]]&gt;&lt;/script&gt;

&lt;hr /&gt;
&lt;h4 id=&quot;131-solving-the-optimization-problem&quot;&gt;1.3.1. Solving the Optimization Problem&lt;/h4&gt;
&lt;p&gt;사실 FFM의 최적화 문제를 푸는 것은 Simple Logistic Regression의 최적화 문제를 푸는 식에서 $\phi_{LM}(w, x)$를 $\phi_{FFM}(w, x)$로 바꾸는 것을 제외하면 동일하다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-05-FFM/06.JPG&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;실험 결과에 그 이유가 나오지만, Stochastic Gradient 알고리즘으로 행렬 분해에 있어 효과적인 &lt;code class=&quot;highlighter-rouge&quot;&gt;AdaGrad&lt;/code&gt;를 적용하였다. 각 SG 스텝마다 data point $(y, x)$는 $\phi_{FFM}(w, x)$ 식에서 $w_{j1, f2}, w_{j2f1}$를 업데이트하기 위해 추출된다. CTR prediction과 같은 문제를 푸는 데에 있어 $x$는 굉장히 희소한 벡터임을 기억하자. 따라서 실제로는 0이 아닌 값들에 대해서만 업데이트가 진행될 것이다.&lt;/p&gt;

&lt;p&gt;sub-gradient는 아래와 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-05-FFM/07.JPG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;d=1…k에 대해 gradient의 제곱합은 아래와 같이 합산된다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-05-FFM/08.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;최종적으로 $(w_{j1, f2})&lt;em&gt;d$과 $(w&lt;/em&gt;{j2, f1})_d$ 는 아래와 같이 업데이트 된다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-05-FFM/09.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;여기서 $\eta$는 직접 정한 learning rate를 의미한다. $w$의 초깃값은 $[0, 1/\sqrt{k}]$ 사이의 Uniform Distribution 에서의 랜덤한 값으로 초기화된다. $G$는 $(G_{j1, f2})_d^{-\frac{1}{2}}$의 값이 매우 커지는 것을 막기 위해 모두 1로 세팅된다. 전체적인 과정은 아래와 같으며, 각 instance를 normalize해주는 것이 성능 향상에 도움이 되었다는 말을 남긴다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-05-FFM/10.JPG&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;
&lt;h4 id=&quot;132-parallelization-on-shared-memory-systems&quot;&gt;1.3.2. Parallelization on Shared-memory Systems&lt;/h4&gt;
&lt;p&gt;본 논문에서는 Hog-WILD!라는 병렬처리 기법을 사용하였다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h4 id=&quot;133-adding-field-information&quot;&gt;1.3.3. Adding Field Information&lt;/h4&gt;
&lt;p&gt;널리 사용되는 LIBSVM의 데이터 포맷은 다음과 같다.&lt;/p&gt;

&lt;p&gt;label feat1:val1 feat2:val2 …&lt;/p&gt;

&lt;p&gt;여기서 각 (feat, val) 쌍은 feature index와 value를 의미한다. &lt;strong&gt;FFM&lt;/strong&gt;을 위해 우리는 위 포맷을 아래와 같이 확장할 수 있다.&lt;/p&gt;

&lt;p&gt;label field1:feat1:val1 field2:feat2:val2 …&lt;/p&gt;

&lt;p&gt;이는 적합한 field를 각 feature 마다 지정해주어야 함을 의미한다. 특정 feature에 대해서는 이 지정 작업이 쉽지만, 나머지들에 대해서는 그렇지 않을 수도 있다. 이 부분에 대해서는 feature의 3가지 종류의 관점에서 논의해보도록 하자.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Categorical Features&lt;/strong&gt;&lt;br /&gt;
선형 모델에서 categorical feature는 여러 개의 binary feature로 변환하는 것이 일반적이다. 우리는 다음과 같이 데이터 instance를 변형할 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-05-FFM/11.JPG&quot; width=&quot;55%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;LIBSVM 포맷에서는 0의 값은 저장되지 않기 때문에 이렇게 모든 categorical feature들을 binary feature로 변형할 수 있는 것이다. 이제 위 데이터는 최종적으로 아래와 같은 형상을 갖게 된다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-05-FFM/12.JPG&quot; width=&quot;45%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;strong&gt;Numerical Features&lt;/strong&gt;&lt;br /&gt;
conference에서 논문이 통과될지에 대한 데이터가 있다고 하자. 칼럼의 의미는 아래와 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;AR: accept rate of the conference&lt;/li&gt;
  &lt;li&gt;Hidx: h-index of the author&lt;/li&gt;
  &lt;li&gt;Cite: # citations of the author&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;각 feature를 dummy field로 취급하여 아래와 같은 데이터 형상을 만들 수도 있지만, 이는 딱히 도움이 되지 않는 방법 같다.&lt;/p&gt;

&lt;p&gt;Yes AR:AR:45.73 Hidx:Hidx:2 Cite:Cite:3&lt;/p&gt;

&lt;p&gt;또 하나의 방법은, feature는 field에 넣고, 기존의 실수 값을 이산화하여 feature로 만든 후, binary하게 1과 0의 값을 넣어주는 방식이다.&lt;/p&gt;

&lt;p&gt;Yes AR:45:1 Hidx:2:1 Cite:3:1&lt;/p&gt;

&lt;p&gt;이산화 방법에 대해서는 여러가지 방식이 존재할 수 있다. 어떠한 방법이든 일정 수준의 정보 손실은 감수해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Single-field Features&lt;/strong&gt;&lt;br /&gt;
일부 데이터 셋에 대해서 모든 feature가 단일 field에 속하여 각 feature에 대해 field를 지정해주는 것이 무의미한 경우도 있다. 특히 NLP와 같은 분야에서는 이러한 현상이 두드러진다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2020-04-05-FFM/13.JPG&quot; width=&quot;55%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 경우에서 유일한 field는 “sentence”가 될 것이다. 일부 사람들은 numerical features의 경우처럼 dummy field를 만들면 어떨까 하고 의문을 가지지만, 사실 그렇게 되면 n(feature의 수)이 너무 커지기 때문에 굉장히 비효율적이다.&lt;/p&gt;

&lt;p&gt;(&lt;strong&gt;FFM&lt;/strong&gt;의 모델 크기가 $O(nfk)$임을 기억해보자. 이 경우에는 $f=n$이 될 것이다. (field의 수 = feature의 수))&lt;/p&gt;

&lt;hr /&gt;
&lt;h4 id=&quot;14-experiments&quot;&gt;1.4. Experiments&lt;/h4&gt;
&lt;p&gt;(후략)&lt;/p&gt;

&lt;hr /&gt;
&lt;h3 id=&quot;2-xlearn&quot;&gt;2. xlearn&lt;/h3&gt;
&lt;h4 id=&quot;21-설치&quot;&gt;2.1. 설치&lt;/h4&gt;
&lt;p&gt;여러 가지 방법으로 설치를 진행할 수 있지만, &lt;a href=&quot;https://github.com/aksnzhy/xlearn/releases&quot;&gt;여기&lt;/a&gt;에서 whl파일을 통해 설치하는 것이 가장 간단하다.&lt;/p&gt;

&lt;h4 id=&quot;22-코드&quot;&gt;2.2. 코드&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_convert_to_ffm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numerics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;categories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Flagging categorical and numerical fields
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'convert_to_ffm - START'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numerics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'catdict'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'UPDATING CATDICT: numeric field - &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'catdict'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;categories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'catdict'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'UPDATING CATDICT: categorical field - &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'catdict'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;nrows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;_ffm.txt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;w&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Looping over rows to convert each row to libffm format
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nrows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;datastring&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;datarow&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;datastring&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datarow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Set Target Variable here
&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# For numerical fields, we are creating a dummy field here
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'catdict'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()):&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'catdict'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                    &lt;span class=&quot;c1&quot;&gt;# Not adding numerical values that are nan
&lt;/span&gt;                    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isnan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datarow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;datastring&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datastring&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datarow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;

                    &lt;span class=&quot;c1&quot;&gt;# For a new field appearing in a training example
&lt;/span&gt;                    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'catcodes'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
                        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'UPDATING CATCODES: categorical field - &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'catcodes'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'currentcode'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
                        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'UPDATING CATCODES: categorical value for field &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; - &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datarow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'catcodes'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datarow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'currentcode'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# encoding the feature
&lt;/span&gt;
                    &lt;span class=&quot;c1&quot;&gt;# For already encoded fields
&lt;/span&gt;                    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datarow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'catcodes'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'currentcode'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
                        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f'UPDATING CATCODES: categorical value for field &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; - &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datarow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'catcodes'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datarow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'currentcode'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# encoding the feature
&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;code&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'catcodes'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datarow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;datastring&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datastring&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;:1&quot;&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;datastring&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;text_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datastring&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# print('Encoder Summary:')
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# print(json.dumps(encoder, indent=4))
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위와 같이 LIBSVM 데이터 포맷으로 데이터를 변경한 후에,&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;xlearn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xl&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;create_ffm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 학습/테스트 데이터 path 연결
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setTrain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;data/train_ffm.txt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setValidate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;data/test_ffm.txt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Early Stopping 불가
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;disableEarlyStop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# param 선언
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'task'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'binary'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'lr'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'lambda'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.00002&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;s&quot;&gt;'k'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'epoch'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'metric'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'auc'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'opt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'adagrad'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;s&quot;&gt;'num_threads'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 학습
# model.fit(param=param, model_path=&quot;model/model.out&quot;)
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Cross-Validation 학습
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Predict
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setTest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;data/test_ffm.txt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setSigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;model/model.out&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;output/predictions.txt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위와 같이 학습을 진행하면 된다. 간단하다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;p&gt;https://wngaw.github.io/field-aware-factorization-machines-with-xlearn/&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>DDQN 알고리즘 설명</title>
   <link href="http://localhost:4000/DDQN/"/>
   <updated>2020-03-15T00:00:00+09:00</updated>
   <id>http://localhost:4000/DDQN</id>
   <content type="html">&lt;h2 id=&quot;1-ddqn-논문-리뷰&quot;&gt;1. DDQN 논문 리뷰&lt;/h2&gt;
&lt;p&gt;Deep Reinforcement Learning with Double Q-learning
&lt;a href=&quot;https://arxiv.org/abs/1509.06461&quot;&gt;논문 원본 링크&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;11-abstract&quot;&gt;1.1. Abstract&lt;/h3&gt;
&lt;p&gt;Q-learning 알고리즘은 특정 조건 하에서 Action Value를 과대평가한다고 알려져있다. 본 논문에서는 먼저 DQN 알고리즘이 일부 게임 상황에서 중대한 과적합문제를 겪고 있다는 것을 밝힐 것이다. 이후 Double Q-learning이 large-scale function approximation에 적용될 수 있다는 것을 보여줄 것이다. 또한 이를 DQN에 적용하면, 과적합 문제를 해결할 수 있을 뿐만 아니라 몇몇 경우에 더 나은 퍼포먼스를 보여준다는 것을 보여줄 것이다.&lt;/p&gt;

&lt;p&gt;강화학습의 중요한 목표는 누적된 Future Reward Signal을 최적화하여 Sequential Decision Problems에 적합한 Policy를 학습하는 것이다. Q-learning은 이 문제에 적합한 알고리즘이지만, 추정된 Action Value 값에 대해 max step을 취함으로써 비정상적으로 높은 Action Value를 학습하여 과적합 문제를 야기한다.&lt;/p&gt;

&lt;p&gt;Overestimation이 Uniform한 분포를 띤다면 큰 문제가 되지 않겠지만, 일반적으로 Uniform하지 않으며 이는 알고리즘의 성능을 저해하는 요인이 된다. 본 논문에서는 &lt;strong&gt;Doulble DQN&lt;/strong&gt;이 이 문제를 해결하여 더욱 정확한 추정값을 반환하고 더 나은 성능을 보인다는 것을 증명하고자 한다.&lt;/p&gt;

&lt;h3 id=&quot;12-background&quot;&gt;1.2. Background&lt;/h3&gt;
&lt;p&gt;Q함수는 state s에서 policy $\pi$에 따른 action a의 True Value로 정의된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q_{\pi}(s, a) = E[R_1 + {\gamma}R_2 + ... | S_0 = s, A_0 = a, {\pi}]&lt;/script&gt;

&lt;p&gt;이 Q함수의 최적값은 아래와 같이 표현된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Q^*(s, a) = \max_{\pi} Q_{\pi}(s, a)&lt;/script&gt;

&lt;p&gt;이 최적 Policy는 각 state에서 가장 높은 값을 가지는 Action을 선택하여 derive할 수 있다. 수많은 state와 action 사이의 Q-value를 모두 학습하는 것은 불가능에 가깝기 때문에 우리는 &lt;strong&gt;Parameterized($\theta$) Value Function&lt;/strong&gt;을 학습할 것이다. 표준 Q-learning의 업데이트 방식과 Target Y(True Value)는 아래와 같이 정의된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_{t+1} = \theta_t + \alpha(TargetY - Q(S_t, A_t ; \theta_t)) \nabla_{\theta_t} Q(S_t, A_t ; \theta_t)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Target Y = Y^Q_t := R_{t+1} + \gamma \max_a Q(S_{t+1}, a; \theta_t)&lt;/script&gt;

&lt;p&gt;위 업데이트 과정은 Target Value $Y^Q_T$를 향해 현재의 추정값 $Q(S_t, A_t ; \Theta_t)$를 업데이트하게 되는데, 이는 Stocastic Gradient Descent와 닮아 있다.&lt;/p&gt;

&lt;h4 id=&quot;deep-q-networks&quot;&gt;Deep Q Networks&lt;/h4&gt;
&lt;p&gt;본 네트워크는 state space에서 action space로 연결하는 Mapping Function에 해당한다. 타겟 네트워크와 경험 리플레이라는 2가지 방식을 통해 효과적인 학습을 수행한다.&lt;/p&gt;

&lt;h4 id=&quot;double-q-learning&quot;&gt;Double Q-learning&lt;/h4&gt;
&lt;p&gt;Q-learning과 DQN의 &lt;strong&gt;Max Operator&lt;/strong&gt;는 action을 선택하고 평가할 때 동일한 값을 사용한다. 이는 과적합을 유발하게 된다. 이를 해결하기 위해 선택과 과정을 분리할 수 있는데, 이것이 Double Q-learning의 기본적인 아이디어이다.&lt;/p&gt;

&lt;p&gt;초기의 Double Q-learning 알고리즘에서는 2개의 Value Function(Weight Sets: $\theta$ , $\theta$`)은 둘 중 하나만 업데이트하기 위해 각 experience를 랜덤하게 할당하는 방식으로 학습되었다. 각 업데이트에서 한 개의 Weight Set는 Greedy Policy를 결정하기 위해 사용되고 나머지 하나는 그 값을 결정하기 위해 사용되었다. 선택/평가를 분리하여 표현한 Target Y는 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Y^Q_t = R_{t+1} + \gamma \max_a Q(S_{t+1}, \argmax_a Q(S_{t+1}, a ; \theta_t); \theta_t)&lt;/script&gt;

&lt;p&gt;Double Q-learning Error는 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Y^{DoubleQ}_t = R_{t+1} + \gamma \max_a Q(S_{t+1}, \argmax_a Q(S_{t+1}, a ; \theta_t); \theta_t^`)&lt;/script&gt;

&lt;p&gt;action을 선택하는 부분(argmax 부분) 에서는 여전히 online weight인 $\theta_t$에 근거한다. 이는 여전히 $\theta_t$에 의해 정의된 현재 값들에 의해 Greedy Policy의 값을 추정한다는 뜻이다.&lt;/p&gt;

&lt;p&gt;그러나 우리는 2번째 weight set인 $\theta_t^&lt;code class=&quot;highlighter-rouge&quot;&gt;$를 이용하여 Policy를 평가한다. 이 2번째 set에 대해서는 $\theta$와 $\theta&lt;/code&gt;$의 역할을 바꿔가면서 대칭적으로 업데이트가 진행된다.&lt;/p&gt;

&lt;h3 id=&quot;13-overoptimism-due-to-estimation-errors&quot;&gt;1.3. Overoptimism due to estimation errors&lt;/h3&gt;
&lt;p&gt;Q-learning의 Overestimation은 처음으로 Thrun과 Schwartz에 의해 연구되었는데, 그들은 action value가 [$-\epsilon$, $\epsilon$] 사이의 Uniform Distribution을 갖는 random error를 포함하면, 각 Target은 최대 $ \frac{m-1}{m+1} $ 까지 Overestimate된다고 밝혔다. (m=num of actions) 또한 이들은 이러한 overestimation이 &lt;strong&gt;sub-optimal policy&lt;/strong&gt;로 인도할 수 있다고 하였다.&lt;/p&gt;

&lt;p&gt;이후 2010년에 Hasselt가 environment의 noise가 overestimation을 일으킬 수 있다고 하였고, Double Q-learning을 해결책으로 내놓았다.&lt;/p&gt;

&lt;p&gt;본 섹션에서는 우리는 어떠한 종류의 estimation error든(이 error가 environmental noise에서 온 것이든, function approximation에서 온 것이든…) upward bias를 야기할 수 있다는 것을 증명하고자 한다. 이것은 굉장히 중요한 데, 왜냐하면 실제로 이 문제는 어떠한 방식으로든 학습과정에 있어 정확도를 낮출 것이기 때문이다.&lt;/p&gt;

&lt;p&gt;Thrun과 Schwartz는 Overestimation의 Upper/Lower Bound를 구하는 방법을 제시했다. (논문 참조) 본 방법에서 우리는 다른 action에 대한 estimatino error가 독립적이라는 가정을 할 필요는 없다. 이 이론은 value에 대한 추정이 평균적으로 맞다하더라도, 어떤 source로 부터 온 estimation error라도 추정치를 끌어올려 True Optimal Value로 부터 멀어지게 만들 수 있다는 것을 보여준다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/RL/2020-03-15-DDQN/01.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 그림을 보면 action의 수가 증가할 수록 Q-learning(빨간색)의 Overestimation은 증가하지만, Double Q-learning(파란색)은 Unbiased함을 알 수 있다.&lt;/p&gt;

&lt;p&gt;이제 Function Approximation으로 돌아와서 각 state 마다 10개의 이산적인 action을 행할 수 있는 연속적인 state space를 생각해보자. 간단히 말해서 이 예시에서 True Optimal action value는 오직 state에만 의존하기 때문에 각 state마다 모든 action은 같은 True Value를 갖게 된다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/RL/2020-03-15-DDQN/02.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 그림을 보면, &lt;strong&gt;보라색 그래프&lt;/strong&gt;가 위에서 말한 &lt;strong&gt;True Value&lt;/strong&gt;를 나타내며 $Q_&lt;em&gt;(s, a) = sin(s) $(가장 위), $Q_&lt;/em&gt;(s, a) = 2exp(-s^2)$(중간, 밑)과 같이 정의된다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;초록색 그래프&lt;/strong&gt;는 &lt;strong&gt;State에 대한 함수로서의 single action의 근사값&lt;/strong&gt;을 보여준다. 초록색 점으로 된 부분은 추정값이 기반이 되는 sample 값을 의미한다. 추정값은 sample state에서의 true value에 적합한 다항식으로 이루어지는데, 가장 아래 그래프는 9차, 나머지는 6차 방정식으로 구성된다. 각 sample state에서는 추정값이 정확히 True Value와 일치하기 때문에 이러한 sample state에서는 우리는 Ground Truth for action value를 갖고 있다고 판단한다.&lt;/p&gt;

&lt;p&gt;상대적으로 차수가 낮은 위와 중간 그래프를 보면 그래프가 충분히 유연하지 못하여 sampled state에서도 부정확한 것을 알 수 있고, 차수가 높은 가장 아래의 그래프는 sampled state에서는 정확도가 높지만 unsampled state에서는 오히려 부정확한 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;또한 sampled state들이 본 그래프에서는 더욱 서로 거리를 두고 있는 것을 확인할 수 있는데, 이러한 특성이 더욱 큰 Estimation Error를 발생시키게 되었다. 이렇게 특정 순간에 제한적인 데이터를 보유하게 되는 것은 실제 학습 상황에서 자주 발생하게 된다.&lt;/p&gt;

&lt;p&gt;Example을 살펴보면, Overestimation은 심지어 우리가 특정 state의 true action value에 대한 sample을 갖고 있더라도 발생할 수 있다. 비록 Uniformly Overestimating Value는 Policy의 학습을 방해하지는 않겠지만 실제로 Overesimation Error는 여러 state와 action에 따라 다르다.&lt;/p&gt;

&lt;h3 id=&quot;16-double-dqn&quot;&gt;1.6. Double DQN&lt;/h3&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;blockquote&gt;

&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>Explain Yourself! Leveraging Language Models for Commonsense Reasoning</title>
   <link href="http://localhost:4000/Explain-Yourself-Leveraging-Language-Models-for-Commonsense-Reasoning/"/>
   <updated>2020-02-08T00:00:00+09:00</updated>
   <id>http://localhost:4000/Explain Yourself - Leveraging Language Models for Commonsense Reasoning</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 2019년 6월 &lt;em&gt;Nazneen Fatema Fajani&lt;/em&gt; 등이 발표한 &lt;strong&gt;Explain Yourself! Leveraging Language Models for Commonsense Reasoning&lt;/strong&gt; 논문을 살펴보도록 한다.&lt;/p&gt;

&lt;p&gt;이 논문에서는 &lt;strong&gt;CoS-E&lt;/strong&gt;라는 상식 설명문(Common Sense Explanations)에 관한 데이터셋을 만들어 공개했다. &lt;a href=&quot;https://github.com/salesforce/cos-e&quot;&gt;여기&lt;/a&gt;에서 찾아볼 수 있다(논문의 링크로 들어가보면 저장 위치가 바뀌었다고 한다).&lt;/p&gt;

&lt;p&gt;중요한 부분만 적을 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;explain-yourself-leveraging-language-models-for-commonsense-reasoning&quot;&gt;Explain Yourself! Leveraging Language Models for Commonsense Reasoning&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1906.02361&quot;&gt;Explain Yourself! Leveraging Language Models for Commonsense Reasoning&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Dataset: &lt;strong&gt;&lt;a href=&quot;https://github.com/salesforce/cos-e&quot;&gt;CoS-E&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;초록abstract&quot;&gt;초록(Abstract)&lt;/h2&gt;

&lt;p&gt;딥러닝 모델들은 상식추론(Commonsense Reasoning)이 필요한 task에서는 낮은 성능을 보여, 입력에는 당장 나타나지 않는 어떤 정보에 대한 지식이나 추론이 필요하게 하였다. 우리(이 논문의 저자)는 &lt;strong&gt;CoS-E(Common Sense Explanations)&lt;/strong&gt;라 부르는, 1) 일련의 자연어와 2) 강조된 구문 두 가지 형태로 구성된 새로운 데이터셋을 수집했다. &lt;strong&gt;CAGE(Commonsense Auto-Generated Explanation)&lt;/strong&gt; Framework에서 학습 및 추론 단계에서 사용될 수 있는 설명문(explanations)을 자동으로 생성하도록 언어모델을 학습시켰다. CAGE는 상식질답(CommonsenseQA) task에서 10%만큼 State-of-the-art를 뛰어넘었다. 우리는 또한 out-of-domain으로의 전이학습을 포함하여 사람이 그리고 기계가 자동생성한 설명문을 전부 사용하여 DNN에서 상식추론 문제를 연구할 것이라 하였다. 실험결과는 상식추론에 관해 언어모델을 효과적으로 조정(Leverage)할 수 있음을 시사한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-서론introduction&quot;&gt;1. 서론(Introduction)&lt;/h2&gt;

&lt;p&gt;상식추론(Commonsense Reasoning)은 현대 기계학습 방법에서 도전적인 과제이다. 설명문(Explanations)은 모델이 학습하는 추론을 말로 표현하는 방법이다. 상식질답(Commonsense QA, CQA)는 상식추론 능력을 가진 자연어처리(NLP) 모델을 개발하기 위한 다지선다형 질답 데이터셋이다. 이와 관련해 많은 노력이 있었지만 뚜렷한 발전이 없었다.&lt;br /&gt;
이 논문의 저자들은 CQA에 더해 상식추론을 위한 사람의 설명문을 수집했고 이를 &lt;strong&gt;CoS-E&lt;/strong&gt;라 하였다. CoS-E는&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;자유형식의 일련의 자연어(보통 문장)&lt;/li&gt;
  &lt;li&gt;정답을 추론하는 데 중요하다고 사람이 판단한 문장의 일부를 강조한 부분&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;두 가지 형태로 존재한다. 아래 그림에서 Question과 Choicse(3개)는 CQA dataset의 일부이며, CoS-E는 1) CoS-E 부분의 문장과 2) Question에서 노란색으로 강조된 부분을 포함한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2020-02-08-Explain Yourself - Leveraging Language Models for Commonsense Reasoning/01.png&quot; width=&quot;80%&quot; alt=&quot;Examples&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/N19-1421/&quot;&gt;Talmor et al. (2019)&lt;/a&gt;에서는 Google search를 활용하여 각 질답 당 100개의 snippet으로부터 문맥정보를 추출해내는 것은 ELMo 표현에 self-attention layer를 쓴 모델이자 현재 SOTA(state-of-the-art) 모델인 BiDAF++를 사용해도 CQA에서 정답률을 향상시키지 못한다고 하였다.&lt;/p&gt;

&lt;p&gt;이에 반해, 우리는 상식추론에 유용한 설명문(explanations)을 생성하는 사전학습된 모델을 조정하였다. CQA를 위한 설명문을 생성하는 framework로 &lt;strong&gt;CAGE(Commonsense Auto-Generated Explanations)&lt;/strong&gt;를 제안한다. 우리는 상식추론 문제를 두 단계로 나누었다:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;CQA sample과 그에 맞는 CoS-E 설명문을 언어모델에 입력으로 준다. 언어모델은 CQA 질답에 기초하여 CoS-E 설명문을 생성하도록 학습된다.&lt;/li&gt;
  &lt;li&gt;언어모델은 CQA의 학습(training)과 검증(validation) 세트 안에 있는 각 sample에 대해 설명문을 생성하도록 한다. 이 CAGE 설명문은 원래의 질문, 선택지, 언어모델의 출력값에 이어붙여 두 번째 상식추론 모델의 입력으로 들어간다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이 2단계의 CAGE framework는 기존 최고의 baseline보다 10% 초과 달성한 결과를 얻었으며 그 예측값을 정당화(justify)하는 설명문을 생성하였다. 아래 그림은 이 접근법을 개략적으로 보여준다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2020-02-08-Explain Yourself - Leveraging Language Models for Commonsense Reasoning/02.png&quot; width=&quot;100%&quot; alt=&quot;Examples&quot; /&gt;&lt;/center&gt;

&lt;p&gt;요약하면, 이 논문은 상식추론을 위한 새로운 CoS-E 데이터셋을 소개하였고, CQA v1.0에서 65%의 정답률을 보인 ‘설명문을 자동 생성하는’ CAGE framework를 제안하였다.&lt;/p&gt;

&lt;p&gt;참고로, 이 논문이 제출되기 직전 CQA는 v1.11를 공개하였는데, 질문에 대한 선택지가 3개에서 5개로 늘어났다. 더 도전적인(challenging) 과제로 바뀌었다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-배경이론과-관련-연구background-and-related-work&quot;&gt;2. 배경이론과 관련 연구(Background and Related Work)&lt;/h2&gt;

&lt;p&gt;논문에 2.1. section이라 소개하진 않았지만 목차를 위해 넣었다.&lt;/p&gt;

&lt;h3 id=&quot;21-commonsense-reasoning&quot;&gt;2.1. Commonsense Reasoning&lt;/h3&gt;

&lt;p&gt;자연어에 포함된 상황이나 사건의 관계를 예측하도록 요구하는 데이터셋이 최근 몇 개가 소개되어 왔다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;여러 타당한 결말 중 가장 올바른 스토리 결말을 선택하는 Story Cloze(혹은 ROC Stories)&lt;/li&gt;
  &lt;li&gt;초기 상황에 기초하여 다음 장면을 예측하는 SWAG(Situations with Adversarial Generations)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이러한 데이터셋에 대해서는 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/21/OpenAI-GPT-1-Improving-Language-Understanding-by-Generative-Pre-Training/&quot;&gt;GPT&lt;/a&gt;나 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/23/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding/&quot;&gt;BERT&lt;/a&gt;이 이미 사람 수준의 성능을 내지만, 대명사가 어떻게 다른 부분과 연관이 되어 있으며 어떻게 세상의 지식과 상호작용을 하는지 등에 관해서는 별로 성공적이지 못했다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.aclweb.org/anthology/N19-1421.pdf&quot;&gt;CQA&lt;/a&gt;는 9500개의, 질문 + 1개의 정답 + 2개의 헷갈리는 오답으로 구성되어 있는 데이터셋으로 단지 분포상의 편향(biases)에서 정보를 얻기보다는 질문에서 추론하도록 하는 것을 요구하지만, 언어적인 면에서 좋지 않은 쪽으로 편향되어 있음이 발견되었다. 이를테면, 여자와 관련된 부분에서는 부정적인 의미의 문맥이 있다거나 하는.&lt;/p&gt;

&lt;p&gt;SOTA 언어모델은 사람에 비해 CQA 데이터셋에서 굉장히 낮은 성능을 보인다. CQA는 모델의 상식추론 능력을 측정하는 benchmark를 제공함에도 정확히 어떤 부분이 모델이 추론을 행하는지는 여전히 불확실하다. CoS-E는 이 benchmark에 더해, 다른 한편으로 모델의 추론능력을 연구, 평가 및 분석할 수 있도록 하는 설명문을 제공한다.&lt;/p&gt;

&lt;h3 id=&quot;22-natural-language-explanations&quot;&gt;2.2. Natural language explanations&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://people.csail.mit.edu/taolei/papers/emnlp16_rationale.pdf&quot;&gt;Lei et al.&lt;/a&gt;에서는 감정분석 접근법의 타당성을 입증할 수 있는, 어떤 추론 결과를 내기 위해 필요한 구문을 입력에서 강조(선택)하는 방식을 제안했다. 분류데이터를 위한 사람이 만든 자연어 설명문은 의미분석을 학습하기 위해 사용되어왔고 분류기를 학습시키는 데 사용할 수 있는, noisy한 분류 데이터를 생성하였다. 그러나 전이성(interpretability)은 SNLI(Stanford Natural Language Inference)에서 성능저하를 보인다고 한다.&lt;br /&gt;
그러나, e-SNLI와는 다르게, CQA를 위한 설명문은 설명-예측 단계로 성능을 향상시킬 수 있다. 또한 VQA에도 사용 가능하며, 자동생성된 것과 사람이 만든 설명문을 함께 사용하는 것이 따로 사용하는 것보다 더 좋은 결과를 내었다.&lt;/p&gt;

&lt;h3 id=&quot;23-knowledge-transfer-in-nlp&quot;&gt;2.3. Knowledge Transfer in NLP&lt;/h3&gt;

&lt;p&gt;자연어처리는 Word2Vec이나 GloVe와 같은 사전학습된 단어벡터를 통한 지식의 이전(transfer)에 의존한다. 맥락과 관련된(contextualized) 단어벡터의 사용은 여러 task에서 획기적인 성공을 이뤘다. 이러한 모델들은 적은 수의 parameter만 학습시킬 필요가 있고 따라서 적은 데이터만 갖고 있어도 학습이 가능하다는 장점이 있다. 잘 fine-tuned 된 언어모델은 설명문 생성과 함께 조정될 때 더 효과적이며 언어적으로 상식 정보를 얻어낸다는 점도 실험적으로 증명되었다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-common-sense-explanationscos-e&quot;&gt;3. Common Sense Explanations(CoS-E)&lt;/h2&gt;

&lt;p&gt;이 CoS-E 데이터셋은 아마존의 MTurk(Amazon Mechanical Turk)를 통해 수집되었다. CQA 데이터셋은 &lt;em&gt;question token split&lt;/em&gt; 과 &lt;em&gt;random split&lt;/em&gt; 두 개로 이루어져 있다. CoS-E 데이터셋과 이 논문의 모든 실험은 더 어려운 &lt;em&gt;random split&lt;/em&gt; 을 사용하여 진행되었다. CQA v1.11에 대한 CoS-E도 만들었다.&lt;/p&gt;

&lt;p&gt;사람들은 질문, 선택지, 정답이 주어지면 “왜 이것이 가장 적절한 답으로 예측되었는가?”라는 질문을 받는다. 그리고&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;주어진 정답이 왜 정답일지를 알려줄 수 있는 부분을 질문에서 선택하며,&lt;/li&gt;
  &lt;li&gt;또한 이 질문 뒤에 숨어 있을 상식적인 내용을 설명하는 자연어 문구를 작성하도록&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;지시받았다. (참고: 이는 CoS-E 데이터셋의 설명과 일치함.)&lt;/p&gt;

&lt;p&gt;그래서 CQA v1.0에 대해 7610(train random split) + 950(dev random split)개의 설명문을, v1.11에 대해 9741 + 1221개의 설명문을 수집하였다. 또한 여기서부터는 질문에서 선택된 부분을 &lt;strong&gt;&lt;em&gt;CoS-E-selected&lt;/em&gt;&lt;/strong&gt;, 작성한 자연어 문구(open-ended)는 &lt;strong&gt;&lt;em&gt;CoS-E-open-ended&lt;/em&gt;&lt;/strong&gt; 라 한다.&lt;/p&gt;

&lt;p&gt;MTurk에서는 사람들의 답변의 품질이 좋다는 것을 보장할 수 없기 때문에, 다음과 같은 처리를 거쳤다:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;질문에서 아무 것도 선택하지 않거나&lt;/li&gt;
  &lt;li&gt;작성한 설명문이 4단어 이하이면 답변하지 않은 것으로 처리되며&lt;/li&gt;
  &lt;li&gt;‘이 정답은 답이 되는 유일한 것이다’와 같은 답변은 모두 제거하였다.&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2020-02-08-Explain Yourself - Leveraging Language Models for Commonsense Reasoning/03.png&quot; width=&quot;80%&quot; alt=&quot;Examples&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 그림은 CoS-E v1.0 데이터셋의 분포를 보여준다.&lt;br /&gt;
이 논문의 실험에서는 CoS-E를 오직 학습(training) 과정에만 사용하여 SOTA 결과를 얻었으며, CoS-E 데이터셋을 사용한 경우가 그렇지 않은 경우보다 성능이 더 좋다는 것을 실험적으로 보였다.&lt;/p&gt;

&lt;p&gt;CoS-E는 crowd-sourcing으로 얻어진 것이기 때문에 noisy할 수는 있지만 그만큼 다양성이 확보되었으며 충분한 품질을 갖고 있는 것으로 보인다고 한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;4-알고리즘algorithm&quot;&gt;4. 알고리즘(Algorithm)&lt;/h2&gt;

&lt;p&gt;CAGE(Commonsense Auto-Generated Explanations)를 제안하고 이를 CQA task에 적용한다. CAGE는 언어모델에 의해 생성되었으며 분류모델의 보조 입력으로 사용된다. CQA 데이터셋의 각 샘플은 질문 $q$, 선택지 $c0, c1, c2$, 정답 레이블 $a$로 구성된다. CoS-E 데이터셋은 왜 $a$가 가장 적절한지를 말해주는, 사람이 만든 설명문 $e_h$가 추가된다. CAGE의 출력은 생성한 설명문 $e$가 $e_h$에 가까워지도록 학습하는 언어모델이다.&lt;/p&gt;

&lt;h3 id=&quot;41-commonsense-auto-generated-explanationscage&quot;&gt;4.1. Commonsense Auto-Generated Explanations(CAGE)&lt;/h3&gt;

&lt;p&gt;CAGE를 분류모델에 적용하기 위해, 언어모델(LM)을 CoS-E 데이터셋으로부터 설명문을 생성하도록 fine-tune했다. 이 언어모델은 여러 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/17/Attention-Is-All-You-Need/&quot;&gt;transformer&lt;/a&gt; 레이어로 이루어진, 사전학습된 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/21/OpenAI-GPT-1-Improving-Language-Understanding-by-Generative-Pre-Training/&quot;&gt;OpenAI GPT&lt;/a&gt;이다.&lt;br /&gt;
여기서, 설명문 생성과 관련하여 두 가지 설정:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;설명 후 예측(explain-and-then-predict(reasoning))&lt;/li&gt;
  &lt;li&gt;예측 후 설명(predict-and-then-explain(rationalization))&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;으로 진행하였다.&lt;/p&gt;

&lt;h4 id=&quot;reasoning&quot;&gt;Reasoning&lt;/h4&gt;

&lt;p&gt;이 방법이 이 논문의 주된 접근법이다. 언어모델은 질문, 선택지, 사람의 설명문으로 fine-tuned 되었으며 실제 정답 label로는 학습되지 않았다. 그래서, 학습하는 동안 입력 문맥(context)은 다음과 같이 정의된다:&lt;/p&gt;

&lt;p&gt;$ C_{RE} = “q, c0, c1 \ or\  c2? $ commonsense says&lt;/p&gt;

&lt;p&gt;모델은 조건부 언어모델링 목적함수에 따라 설명문 $e$를 생성한다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_i  log P (e_i \vert e_{i-k}, ..., e_{i-1}, C_{RE} ; \Theta )&lt;/script&gt;

&lt;p&gt;$k$는 문맥범위(context window)의 크기(이 논문에서는 항상 $ k \ge \vert e \vert $로 전체 설명문이 문맥에 포함됨)이다.&lt;br /&gt;
이 방식은 상식 질답 문제의 추론 단계에서 추가 문맥정보를 전달하기 위해 설명문을 자동생성하므로 &lt;em&gt;reasoning&lt;/em&gt; 이라 부르기로 하였다.&lt;/p&gt;

&lt;p&gt;또한 실험의 완전성을 위해, 추론과 설명의 단계를 바꿔보았는데, 그것이 다음에 설명할 &lt;strong&gt;rationalization&lt;/strong&gt;이다.&lt;/p&gt;

&lt;h4 id=&quot;rationalization&quot;&gt;Rationalization&lt;/h4&gt;

&lt;p&gt;언어모델은 post-hoc rationalization을 생성하기 위해 입력과 더불어 예측된 label을 조건으로 한다. 그래서 fine-tuning 단계에서 입력 문맥은 다음과 같다.&lt;/p&gt;

&lt;p&gt;$ C_{RE} = “q, c0, c1 \ or\  c2?\  a$ because&lt;/p&gt;

&lt;p&gt;목적함수는 reasoning의 것과 유사하지만 모델은 학습 중에도 입력 질문에 대한 실제 정답을 볼 수 있다. 언어모델은 예측 label에 조건을 갖기 때문에 설명문은 상식추론으로 고려될 수 없다. 대신 설명문은 모델이 더 이해 및 해석하기 쉽도록 만드는 &lt;em&gt;rationalization&lt;/em&gt; 을 제공한다. 이 접근법은 현 최고의 모델보다 6% 더 높은 성능을 가지며 품질 좋은 설명문을 생성해 낸다.&lt;/p&gt;

&lt;p&gt;CAGE에 대해서, 최대길이 20, batch size 36, 10 epoch 동안 학습시겨 가장 좋은 BLEU 점수와 perplexit를 갖는 모델은 선택했다. 학습률(learning rate)는 $1e^{-6}$, 초반 0.002까지 선형적으로 증가하다가(warm-up lr) 0.01만큼 decay되는 방식을 채택했다.&lt;/p&gt;

&lt;h3 id=&quot;42-commonsense-predictions-with-explanations&quot;&gt;4.2. Commonsense Predictions with Explanations&lt;/h3&gt;

&lt;p&gt;CoS-E의 사람의 설명문이나 언어모델의 추론 중 하나를 갖고 있을 때 CQA task에 대한 예측모델을 학습시킬 수 있다. 모든 BERT 모델의 입력 샘플의 시작 부분에 들어가는 &lt;code class=&quot;highlighter-rouge&quot;&gt;[CLS]&lt;/code&gt; token에 해당하는 최종 상태(final state)를 입력으로 받는 이진 분류기를 추가함으로써 다지선다형 질문 task에 fine-tuning 될 수 있는 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/23/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding/&quot;&gt;BERT&lt;/a&gt;를 분류기로 사용하였다. 이를 CQA task에도 적용했는데,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터셋의 각 샘플에 대해
    &lt;ul&gt;
      &lt;li&gt;BERT를 fine-tuning하기 위한 일련의 세 입력을 구성하고&lt;/li&gt;
      &lt;li&gt;각 입력은 (질문, 구분자 &lt;code class=&quot;highlighter-rouge&quot;&gt;[SEP]&lt;/code&gt;, 선택지 중 하나)로 구성된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;만약 CoS-E나 CAGE의 설명문을 추가한다면
    &lt;ul&gt;
      &lt;li&gt;각 입력은 (질문, 구분자 &lt;code class=&quot;highlighter-rouge&quot;&gt;[SEP]&lt;/code&gt;, 설명문, 구분자 &lt;code class=&quot;highlighter-rouge&quot;&gt;[SEP]&lt;/code&gt;, 선택지 중 하나)로 이루어진다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;BERT를 위해 설명문은 한 질문에 대해 같은 입력표현을 공유한다. 선택지에 대해서도 공유하는 것은 약간의 성능저하를 보였다.&lt;/p&gt;

&lt;h3 id=&quot;43-transfer-to-out-of-domain-datasets&quot;&gt;4.3. Transfer to out-of-domain datasets&lt;/h3&gt;

&lt;p&gt;Out-of-domain NLP 데이터셋에 fine-tuning 없이 전이학습을 시키는 것은 낮은 성능을 기록한다고 알려져 있다.&lt;br /&gt;
이 논문에서는 CQA에서 SWAG와 Story Cloze Test(둘 모두 CQA같은 다지선다형이다)에 대해서 전이학습을 연구했다. CQA에 fine-tuned된 GPT 언어모델을 SWAG에 대한 설명문을 생성하기 위해 사용하였다. 그리고 이를 통해 BERT 분류기를 학습시켜 두 데이터셋에 평가를 진행했다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;5-실험-결과experimental-results&quot;&gt;5. 실험 결과(Experimental Results)&lt;/h2&gt;

&lt;p&gt;모든 모델은 BERT에 기초하며, CoS-E나 CAGE를 쓰지 않을 것이 baseline이 되며, 모든 실험은 CQA dev-random-split에서 수행되었다. 또한 final test split에서도 핵심 모델을 평가하였다.&lt;/p&gt;

&lt;p&gt;CoS-E 설명을 사용할수록 성능이 높아짐을 확인할 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2020-02-08-Explain Yourself - Leveraging Language Models for Commonsense Reasoning/04.png&quot; width=&quot;80%&quot; alt=&quot;Examples&quot; /&gt;&lt;/center&gt;

&lt;p&gt;아직 사람에 비해서는 모든 모델이 한참 못 미치지만, CoS-E와 CAGE를 사용함으로써 성능이 좋아졌다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2020-02-08-Explain Yourself - Leveraging Language Models for Commonsense Reasoning/05.png&quot; width=&quot;80%&quot; alt=&quot;Examples&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위의 표의 마지막에 있는 89.8%이라는 수치는 설명문을 제공받은 사람은 실제 정답을 갖고 있었기 때문에 공정한 수치는 아니라고 하지만, CoS-E-open-ended를 사용했을 때 얼마만큼 성능을 향상시킬 수 있을지에 대한 상한선을 보여준 것이라 한다. 또한 질문이 없는 상태에서 진행한 실험도 있는데, 질문 없이 어떤 정답이 가장 정답일 것 같은지를 설명문을 보고 판단하는 실험이다.&lt;br /&gt;
그리고 open-ended CoS-E의 경우 질문에 이미 있는 쓸모 있는 정보를 알려주는 것을 넘어 중요한 정보를 제공한다는 것을 보여준다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2020-02-08-Explain Yourself - Leveraging Language Models for Commonsense Reasoning/06.png&quot; width=&quot;60%&quot; alt=&quot;Examples&quot; /&gt;&lt;/center&gt;

&lt;p&gt;CQA v1.11에 대한 실험도 진행하였고 그 결과는 위 그림에서 볼 수 있다.&lt;/p&gt;

&lt;p&gt;전이학습에 대한 결과는 아래 그림에서 볼 수 있는데, CQA에서 SWAG와 Story Cloze로 전이된 설명문을 추가한 경우 약간의 성능저하가 있음을 보였다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2020-02-08-Explain Yourself - Leveraging Language Models for Commonsense Reasoning/07.png&quot; width=&quot;80%&quot; alt=&quot;Examples&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;6-분석-및-토의analysis-and-discussion&quot;&gt;6. 분석 및 토의(Analysis and Discussion)&lt;/h2&gt;

&lt;p&gt;CAGE-reasoning은 72%의 성능을 보였는데, CoS-E-open-ended의 모든 정보를 활용한다면 최대 90% 정도까지 성능이 올라갈 수 있음을 보였기 때문에, 추가적인 분석이 더 필요하다.&lt;br /&gt;
CAGE-reasoning과 CoS-E-open-ended 간 BLEU 점수는 4.1이며 perplexity는 32를 보였다.&lt;/p&gt;

&lt;p&gt;아래 그림은 CQA, CoS-E, CAGE 샘플을 가져온 것인데, CAGE-reason이 일반적으로 CoS-E보다 조금 더 간단한 구성을 보이는데, 이 조금 더 선언적인 부분이 CoS-E-open-ended보다 더 유익한 경우가 있다(실제 단어 차이는 거의 없다). CAGE-reasoning은 43%의 경우에서 선택지 중 적어도 하나를 포함하는데, 모델의 실제 예측 선택지는 21%만이 그러하였다. 이는 답을 직접적으로 가리키는 것보다 더 효과적인 부분이 CAGE-reasoning에 있음을 보여준다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2020-02-08-Explain Yourself - Leveraging Language Models for Commonsense Reasoning/08.png&quot; width=&quot;100%&quot; alt=&quot;Examples&quot; /&gt;&lt;/center&gt;

&lt;p&gt;CAGE-rationalization이 CAGE-reasoning보다 조금 더 나은 것 같기도 하지만, 실제 질문 없이 정답을 추측하는 부분에서는 별 향상이 없다.&lt;/p&gt;

&lt;p&gt;CoS-E나 CAGE가 noisy하다고 해도, 모델의 성능이 낮은 것이 이것 때문이라 볼 수는 없다. 만약 CQA의 세 선택지 중 하나를 호도하는 선택지로 일부러 바꾼 경우 모델의 성능은 60%에서 30%로 떨어졌다. 에러의 70%는 호도하는 설명문에 의해 만들어졌고, 그 중 57%는 대신 CoS-E 설명문으로 학습된 모델에 의해 올바르게 정답을 맞췄다. 이는 유익한 설명문의 효과를 보여준다.&lt;/p&gt;

&lt;p&gt;CQA v1.11에서는 BERT를 1.5% 차이로 앞섰는데, CQA v1.11에서 잘못 예측한 예시는 아래에서 볼 수 있다. 잘못 예측한 것 중 많은 부분은 생성된 설명문에 맞는 정답을 포함하는 경우가 있었다(dresser drawer과 cleanness 등). 이러한 경우는 관련 있는 정보에 더 집중하도록 하는 명시적인 방법이 필요로 함을 보여준다. 그리고 “forest”와 “compost pile” 같은 의미적으로 비슷한 다른 선택지를 고르는 경우도 빈번했는데, 이는 새로운 CQA 데이터셋에서 설명문을 단지 덧붙이는 것만으로는 충분하지 않음을 보여준다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2020-02-08-Explain Yourself - Leveraging Language Models for Commonsense Reasoning/09.png&quot; width=&quot;100%&quot; alt=&quot;Examples&quot; /&gt;&lt;/center&gt;

&lt;p&gt;SWAG와 Story Cloze에 맞춰 생성한 설명문은 유익한 정보를 담고 있는 것을 발견했지만, 전이학습에 대한 실험에서 분류기가 이를 제대로 활용하지는 못했다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2020-02-08-Explain Yourself - Leveraging Language Models for Commonsense Reasoning/10.png&quot; width=&quot;100%&quot; alt=&quot;Examples&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;7-결론-및-향후-연구conclusion-and-future-work&quot;&gt;7. 결론 및 향후 연구(Conclusion and Future Work)&lt;/h2&gt;

&lt;p&gt;CoS-E라는 새로운 데이터셋을 제시하였고, CAGE framework를 제안하였으며, 여기서 생성된 설명문(explanations)은 예측을 위해 분류기에서 효율적으로 사용될 수 있었다. 이로써 단지 SOTA를 달성한 것 뿐만 아니라, 이해할 수 있는(interpretable) 상식추론과 관련해 설명문을 연구하는 새로운 길을 열었다.&lt;/p&gt;

&lt;p&gt;CAGE는 답을 예측하기 위한 사전 작업으로 설명문을 생성하는 데 집중했는데, 설명문을 통한 언어모델은 정답 예측에 있어 함께 학습될 수도 있다. 이는 더 많은 task에 적용될 수 있을 것이다. 많은 task에 대해 충분한 설명문 데이터셋(CoS-E)가 있으면 다른 task에 대해서도 유용한 설명문을 생성하는 언어모델을 만들 수도 있다.&lt;/p&gt;

&lt;p&gt;그리고, 설명문은 편향이 없어야 할 것이다. 예를 들어 CQA에서는 ‘여성’과 ‘부정적인 문맥’의 연관도가 다른 쪽에 비해 더 높았는데, 이러한 편향이 있음은 모델 학습에 있어 분명 고려되어야 한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Acknowledgements&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;언제나 있는 감사의 인사. 그림과 reviewer 등등&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;refenrences&quot;&gt;Refenrences&lt;/h2&gt;

&lt;p&gt;논문 참조. 많은 레퍼런스가 있다.&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>파이썬 Error 처리</title>
   <link href="http://localhost:4000/error/"/>
   <updated>2020-01-12T00:00:00+09:00</updated>
   <id>http://localhost:4000/error</id>
   <content type="html">&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;파이썬에서 에러를 처리하고 관리하는 데에는 다양한 이유가 있다. 실제 Applicaion 상에서 에러가 발생하지 않도록 개발과 테스트 단계에서 미리 에러를 식별하고 수정하는 것은, 어떤 프로그램을 만들 때 굉장히 중요한 과정이라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;기본적으로 파이썬에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;BaseException&lt;/code&gt;이라는 class를 통해 에러를 관리하도록 도와준다. 이 class는 모든 내장 exception들의 base class이다. 만약 사용자가 직접 에러 class를 만들고 싶을 때는 이 에러를 사용하는 것이 &lt;strong&gt;아니라&lt;/strong&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;Exception&lt;/code&gt; class를 사용해야 한다.&lt;/p&gt;

&lt;p&gt;코딩을 하다보면 여러 종류의 에러를 보았을 것이다. 예를 들어 아래와 같은 에러가 대표적일 것이다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;AssertionError&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;FileNotFoundError&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;SyntaxError&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;대체 이 에러들은 다 어떻게 만들어지고, 어떻게 구성되는 것일까? 사실 이 에러들은 앞서 설명한 &lt;code class=&quot;highlighter-rouge&quot;&gt;BaseException&lt;/code&gt; class의 하위 class로 이루어진다. 그 전체 구조는 아래와 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;BaseException&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;SystemExit&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;KeyboardInterrupt&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;GeneratorExit&lt;/span&gt;
 &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;StopIteration&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;StopAsyncIteration&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ArithmeticError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;FloatingPointError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;OverflowError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ZeroDivisionError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;AssertionError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;AttributeError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;BufferError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;EOFError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ImportError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ModuleNotFoundError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;LookupError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;IndexError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;KeyError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;MemoryError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NameError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;UnboundLocalError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;OSError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;BlockingIOError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ChildProcessError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ConnectionError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;BrokenPipeError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ConnectionAbortedError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ConnectionRefusedError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ConnectionResetError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;FileExistsError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;FileNotFoundError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;InterruptedError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;IsADirectoryError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NotADirectoryError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PermissionError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ProcessLookupError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;TimeoutError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ReferenceError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;RuntimeError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NotImplementedError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;RecursionError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;SyntaxError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;IndentationError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;         &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;TabError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;SystemError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;TypeError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ValueError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;UnicodeError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;         &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;UnicodeDecodeError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;         &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;UnicodeEncodeError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;         &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;UnicodeTranslateError&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Warning&lt;/span&gt;
           &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;DeprecationWarning&lt;/span&gt;
           &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;PendingDeprecationWarning&lt;/span&gt;
           &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;RuntimeWarning&lt;/span&gt;
           &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;SyntaxWarning&lt;/span&gt;
           &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;UserWarning&lt;/span&gt;
           &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;FutureWarning&lt;/span&gt;
           &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ImportWarning&lt;/span&gt;
           &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;UnicodeWarning&lt;/span&gt;
           &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;BytesWarning&lt;/span&gt;
           &lt;span class=&quot;o&quot;&gt;+--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ResourceWarning&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;굉장히 많다. 이 에러와 경고(Warning)들을 다 외우고 있을 필요는 없을 것이다. 하지만 인지는 하고 있는 편이 좋다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;2-exception-처리-try-except-finally&quot;&gt;2. Exception 처리: try, except, finally&lt;/h2&gt;
&lt;h3 id=&quot;21-일반적인-처리&quot;&gt;2.1. 일반적인 처리&lt;/h3&gt;
&lt;p&gt;try 블록을 수행하는 과정에서 에러가 발생하면 except 블록이 수행된다. 만약 에러가 발생하지 않았다면, except 블록은 수행되지 않는다. 만약 에러의 발생 유무와 상관없이 꼭 어떤 과정을 수행하고 싶다면 finally 블록에 이를 담으면 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 예시 1
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;nothing&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ImportError&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;No&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;named&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'nothing'&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 예시 2
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ZeroDivisionError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Error: You cannot divide integer by zero&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;You&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cannot&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;divide&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;integer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zero&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고로 &lt;code class=&quot;highlighter-rouge&quot;&gt;assert 조건, &quot;에러 메시지&quot;&lt;/code&gt; 인 &lt;strong&gt;assert 구문&lt;/strong&gt;을 통해 에러를 관리할 수도 있다.&lt;/p&gt;

&lt;h3 id=&quot;22-특별한-요청&quot;&gt;2.2. 특별한 요청&lt;/h3&gt;
&lt;p&gt;아래에는 위와는 다르게 조금은 특별한(?) 요청을 하고 싶을 때 사용할 수 있는 기능들이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;만약 에러를 그냥 회피하고 싶다면 except 블록에 &lt;code class=&quot;highlighter-rouge&quot;&gt;pass&lt;/code&gt;를 입력하면 된다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Exception&lt;/code&gt;이 발생하였을 때 프로그램을 중단하고 싶으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;raise SystemExit&lt;/code&gt;을 except 블록에 입력하면 된다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Exception&lt;/code&gt;을 일부러 발생하고 싶을 때에도 &lt;code class=&quot;highlighter-rouge&quot;&gt;raise&lt;/code&gt; 구문을 사용하면 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;3번 째 경우에 대한 예시를 첨부하겠다. &lt;code class=&quot;highlighter-rouge&quot;&gt;BaseBandit&lt;/code&gt;이라는 부모 class가 있고, 사용자는 이 부모 class를 상속받아 &lt;code class=&quot;highlighter-rouge&quot;&gt;TalkativeBandit&lt;/code&gt;이라는 자식 class를 만들고 싶다고 하자.&lt;/p&gt;

&lt;p&gt;그런데 이 때, 자식 class에 반드시 &lt;code class=&quot;highlighter-rouge&quot;&gt;operate&lt;/code&gt;이란 메서드를 구현하도록 미리 설정을 해두고 싶다. 모니터 구석에 메모를 해두는 것 외에 방법이 없을까? 이 때 부모 class인 &lt;code class=&quot;highlighter-rouge&quot;&gt;BaseBandit&lt;/code&gt;에 미리 아래와 같은 코드를 구현해 놓으면 원하는 바를 쟁취할 수 있을 것이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 부모 class 구현
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BaseBandit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;operate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NotImplementedError&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 자식 class 구현
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TalkativeBandit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BaseBandit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;stay&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Don't talk&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TalkativeBandit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 자식 class에서는 operate 메서드를 구현하지 않았으므로
# 부모 class의 operate 메서드가 호출된다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;operate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 에러가 발생한다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Traceback&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;most&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;call&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;C:\Users\...\interactiveshell.py&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2961&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run_code&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;code_obj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_global_ns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_ns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;ipython-input-17-fdf0f46c74b7&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;operate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;ipython-input-12-af85936c9668&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;operate&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;NotImplementedError&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;NotImplementedError&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;operate&lt;/code&gt; 메서드를 제대로 구현한다면, 별 문제 없이 코드를 진행할 수 있을 것이다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;3-exception-추적&quot;&gt;3. Exception 추적&lt;/h2&gt;
&lt;p&gt;바로 위의 예시를 보자. &lt;code class=&quot;highlighter-rouge&quot;&gt;Traceback (most recent call last)&lt;/code&gt;란 문구를 볼 수 있을 것이다. 이는 Exception을 역으로 추적한다는 뜻이다.&lt;/p&gt;

&lt;p&gt;사용자가 직접 추적 과정을 만들고 싶을 때 stack trace를 표시하고 출력하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;traceback&lt;/code&gt; 모듈과 로그 기록을 관리하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;logging&lt;/code&gt; 모듈을 사용하면 편리하다.&lt;/p&gt;

&lt;p&gt;가장 기초적인 추적 방법은 아래와 같다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;traceback&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;IndexError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;--- Exception Occured ---&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;traceback&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;print_exc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 출력 결과
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;---&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Occured&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Traceback&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;most&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;call&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;ipython-input-19-0acccd16d042&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;IndexError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;    
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;빈 튜플에 indexing을 시도했으므로 에러가 발생하는 것은 당연하다.&lt;br /&gt;
그 에러는 &lt;code class=&quot;highlighter-rouge&quot;&gt;IndexError&lt;/code&gt; 인데, 우리는 &lt;code class=&quot;highlighter-rouge&quot;&gt;traceback.print_exc&lt;/code&gt; 메서드를 통해 stack trace 정보를 출력할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;limit=None&lt;/code&gt;이 기본이며 이 때는 제한 없이 stack trace를 출력한다. 위 예시와 같이 1을 입력하면 단 한 개의 stack trace 정보를 출력한다는 뜻이다. &lt;code class=&quot;highlighter-rouge&quot;&gt;file, chain&lt;/code&gt; argument 설정을 통해 파일 출력 위치를 설정하거나 연쇄적인 Exception 출력 설정을 관리할 수 있다.&lt;/p&gt;

&lt;p&gt;왜 이런 과정을 거쳐야 할까? 만약 이와 같이 try-except를 통해 Exception을 관리해주지 않는다면, 우리는 모든 에러를 잡기 전까지 프로그램 전체를 돌릴 수 없을 것이다.&lt;/p&gt;

&lt;p&gt;이번에는 logging 모듈과 합작하여 Exception을 추적해보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;traceback&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;logging&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;basicConfig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;example.log&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%(asctime)s %(levelname)s %(message)s&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;IndexError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;traceback&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format_exc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 출력 결과
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Traceback&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;most&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;call&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;C:\Users\...\interactiveshell.py&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2961&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run_code&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;code_obj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_global_ns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_ns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;ipython-input-18-16da8da0daa5&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;IndexError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;tuple&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;logging 모듈을 통해 우리는 &lt;code class=&quot;highlighter-rouge&quot;&gt;example.log&lt;/code&gt;라는 파일에 에러에 관한 기록을 해둘 수 있었다.&lt;br /&gt;
이 파일에는 다음과 같은 로그 기록이 남아있다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2020-01-12 18:38:50,633 ERROR Traceback (most recent call last):
  File &quot;&amp;lt;ipython-input-18-16da8da0daa5&amp;gt;&quot;, line 6, in &amp;lt;module&amp;gt;
    tuple()[0]
IndexError: tuple index out of range
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;4-exception-만들기&quot;&gt;4. Exception 만들기&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Exception&lt;/code&gt; class 상속을 통해 Exception을 직접 만들 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SizeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 에러 메시지를 출력하고 싶으면 아래와 같은 특별 메서드를 구현해야 한다.
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__str__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Size does not fit&quot;&lt;/span&gt;
    
&lt;span class=&quot;c1&quot;&gt;# 기준이 되는 base
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 비교대상인 data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# np.array의 shape을 비교하는 함수이다.
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compare&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SizeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;All Clear&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 첫 번째 테스트
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compare&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 첫 번째 결과
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Traceback&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;most&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;call&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;C:\Users\...\interactiveshell.py&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2961&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run_code&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;exec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;code_obj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_global_ns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_ns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;ipython-input-36-c1718418c4b8&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;compare&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;ipython-input-35-8ec7197ddfb7&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compare&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SizeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;SizeError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;does&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 두 번째 테스트
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compare&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 두 번째 결과
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;All&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Clear&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://docs.python.org/3/library/exceptions.html&quot;&gt;파이썬 공식문서&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://m.blog.naver.com/PostView.nhn?blogId=wideeyed&amp;amp;logNo=221576227901&amp;amp;proxyReferer=https%3A%2F%2Fwww.google.com%2F&quot;&gt;참고 블로그1&lt;/a&gt;
&lt;a href=&quot;https://wikidocs.net/30&quot;&gt;참고 블로그2&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>파이썬 압축 모듈 간단 예시</title>
   <link href="http://localhost:4000/zip/"/>
   <updated>2020-01-11T00:00:00+09:00</updated>
   <id>http://localhost:4000/zip</id>
   <content type="html">&lt;h2 id=&quot;1-zlib-모듈&quot;&gt;1. zlib 모듈&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;zlib&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;long_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;b&quot;who are you&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 압축하기
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compressed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zlib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compress&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;long_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 압축 풀기
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decompressed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zlib&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decompress&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compressed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 동일한지 확인
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;long_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decompressed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;2-gzip-모듈&quot;&gt;2. gzip 모듈&lt;/h2&gt;
&lt;p&gt;위에서 사용한 zlib 모듈과 동일하게 compress, decompress 메서드를 사용한다. 파일을 열 때는 &lt;code class=&quot;highlighter-rouge&quot;&gt;open&lt;/code&gt; 메서드를 이용하면 된다. 여는 작업에 대한 코드만 첨부한다. bzip2(bz2), lzma(xz) 형식 파일에 대해서도 유사한 메서드를 이용한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;gzip&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gzip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;data.gz&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;rt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;content&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;3-zipfile-모듈&quot;&gt;3. zipfile 모듈&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;zipfile&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# zip 파일이 맞는지 확인
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zipfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_zipfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;trasnactions.zip&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# zip 파일 열기
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zipfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ZipFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;trasnactions.zip&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# zip 파일 내 이름 확인 및 추후 사용을 위해 저장
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;namelist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'transaction1.txt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'transaction2.txt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 첫 번째 파일 압축 해제 과정
# 하나만 압축 해제할 때
# ZipInfo 얻기
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zipinfo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getinfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Filename: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zipinfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;date_time: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zipinfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;date_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;transaction1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;txt&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date_time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2020&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;19&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;44&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zipinfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 전부 압축 해제할 때
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extractall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 끝나고 닫아주기
&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;4-tarfile-모듈&quot;&gt;4. tarfile 모듈&lt;/h2&gt;
&lt;p&gt;위와 유사하다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tarfile&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# tarfile이 맞는지 확인
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tarfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_tarfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;transactions.tar&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tarfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;transactions.tar&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getnames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'transaction1.txt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'transaction2.txt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 하나만 압축 해제
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tarinfo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getmember&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getnames&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tarinfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tarinfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tarinfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mtime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tarinfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;transaction1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;txt&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;74&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1578739467&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;493&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;tar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tarinfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 전체 압축 해제
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extractall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;파이썬 라이브러리 레시피, 프리렉
https://docs.python.org/3/library/zipfile.html
https://docs.python.org/3/library/tarfile.html&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>파이썬 collections, heapq 모듈 설명</title>
   <link href="http://localhost:4000/collections-heapq/"/>
   <updated>2020-01-10T00:00:00+09:00</updated>
   <id>http://localhost:4000/collections-heapq</id>
   <content type="html">&lt;h2 id=&quot;1-collections-모듈&quot;&gt;1. collections 모듈&lt;/h2&gt;
&lt;h3 id=&quot;11-collectionscounter-객체&quot;&gt;1.1. collections.Counter 객체&lt;/h3&gt;
&lt;p&gt;collections 모듈에서 가장 기본을 이루는 class는 &lt;code class=&quot;highlighter-rouge&quot;&gt;collections.Counter&lt;/code&gt;이다. 이 class에 argument로 반복 가능한 (iterable) 객체를 지정하거나 dictionary와 같은 mapping 객체를 지정하면 Counter 객체를 생성할 수 있다. 예를 들어보면,&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;collections&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# counter = collections.Counter({1: 1, 2: 2, 3: 1})
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;주석 처리된 line이 바로 후자의 방법에 해당한다. 이렇게 생성된 객체는 수정될 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이 외에도 여러 계산이 가능한데, 아래를 참고하길 바란다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;연산자&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-=&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;뺀다. 결과가 음수면 그 요소는 삭제된다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&amp;amp;=&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;좌변의 Counter 객체 요소 중 우변의 Counter 객체 요소에 미포함되어 있는 &lt;br /&gt;&lt;br /&gt; key의 요소를 삭제한다. 요소의 값은 둘 중 작은 쪽의 값이 된다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;l=&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2개의 Counter 객체 전체의 요소로부터 새롭게 Counter 객체를 생성한다. &lt;br /&gt;&lt;br /&gt; key가 같으면 두 값 중 큰 쪽의 값이 된다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;위 누계 연산자에서 =를 빼고 &lt;code class=&quot;highlighter-rouge&quot;&gt;+, -, &amp;amp;, |&lt;/code&gt; 만 사용할 경우 이항 연산자로 작용한다.&lt;/p&gt;

&lt;p&gt;또한, 이 객체에서 미등록 key를 참조한다 하더라도 KeyError는 발생하지 않는다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;12-collectionschainmap-사전-통합&quot;&gt;1.2. collections.ChainMap: 사전 통합&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;dict1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'banana'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dict2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'apple'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ChainMap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dict1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dict2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'apple'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위와 같이 ChainMap 메서드는 여러 사전 객체를 모아 하나로 통합하는 기능을 갖고 있다. 만약 통합한 객체에 변화를 줄 경우, 원래의 사전들에도 그 변경 사항이 반영된다. &lt;code class=&quot;highlighter-rouge&quot;&gt;clear&lt;/code&gt; 메서드를 사용하면 사전을 삭제할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;13-collectionsdefaultdict-기본-값이-있는-사전&quot;&gt;1.3. collections.defaultdict: 기본 값이 있는 사전&lt;/h3&gt;
&lt;p&gt;일반적으로 사전 객체에 미등록된 key를 참조하면 KeyError가 발생한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;collections.defaultdict&lt;/code&gt;는 이러한 문제를 해결하기에 적합한 객체이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'orange'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_default_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'default-value'&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 여기서 get_default_value와 같은 callable 객체나 None을 입력할 수 있다.
# None을 입력할 경우 일반 사전과 마찬가지로 KeyError가 발생한다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;defaultdict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_default_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orange&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ham'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;'default-value'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;만약 기본 값으로 수치 0이나 빈 사전, 리스트를 반환하고 싶다면 int, dict, list형 객체를 지정하면 된다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;defaultdict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;defaultdict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;defaultdict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;14-collectionsordereddict-순서가-있는-사전&quot;&gt;1.4. collections.OrderedDict: 순서가 있는 사전&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;for loop&lt;/strong&gt;와 같은 과정 속에서 등록한 순서대로 요소를 추출하고 싶으면 이 class를 이용하면 좋다. 시퀀스를 이용하여 객체를 생성하면 순서대로 등록된 것을 확인할 수 있다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;mydict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OrderedDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;orange&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;banana&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mydict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;OrderedDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'orange'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'banana'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그러나 키워드 인수나 일반 사전으로 초깃값을 등록하면 순서가 무시된다. &lt;code class=&quot;highlighter-rouge&quot;&gt;OrderedDict&lt;/code&gt; 객체에는 유용한 기능들이 있는데, 아래를 참조하면 좋을 것이다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;mydict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OrderedDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;orange&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;banana&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;blueberry&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mango&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# popitem 에서 last=True로 하면 마지막 요소를 사전에서 삭제하고 반환하고,
# False로 하면 첫 요소에 효과를 적용한다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mydict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;popitem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# move_to_end에서 last=True로 하면 지정한 키를 맨 끝으로 이동시키고, False이면 맨 처음으로 이동시킨다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mydict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;move_to_end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;banana&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mydict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;OrderedDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'orange'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'blueberry'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'banana'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;15-collectionsnamedtuple&quot;&gt;1.5. collections.namedtuple&lt;/h3&gt;
&lt;p&gt;데이터를 효율적으로 관리하기에 적합한 class가 바로 namedtuple이다. 속성 이름을 지정하여 가독성을 높이고 튜플을 활용하여 원하는 요소를 쉽게 추출하도록 하게 해준다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;point&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;namedtuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;point&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;X, Y, Z&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;point&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;2-heapq-모듈&quot;&gt;2. heapq 모듈&lt;/h2&gt;
&lt;p&gt;데이터를 정렬된 상태로 저장하고, 이를 바탕으로 효율적으로 최솟값을 반환하기 위해서는 이 &lt;strong&gt;heapq&lt;/strong&gt; 모듈을 사용하면 매우 편리하다. 사용하기 위해서는 최소 heap을 먼저 생성해야 한다. 빈 리스트를 생성해서 heapq 모듈의 메서드를 호출할 때마다 이를 heap argument의 인자로 투입해야 한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;heapq&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# heappush(heap, item): heap에 item을 추가함
# 주의점: keyword 인자를 입력하면 Error가 발생함
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heaqp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heappush&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;heaqp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heappush&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# heappop(heap): heap에서 최솟값을 삭제하고 그 값을 반환함
# 최솟값을 삭제하지 않고 참조하고 싶다면 heap[0]을 쓰자
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heapq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heappop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이 외에도 여러 메서드를 사용할 수 있다. 만약 어떤 변화하는 시퀀스에서 최솟값을 얻고 싶다고 하자. 아래와 같은 코딩이 가능하다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;79&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;62&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# heapify(heap): heap의 요소를 정렬함
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heapq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heapify&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# heappush(heap, item): heap에 item을 추가한 뒤, 최솟값을 삭제하고 그 값을 반환함
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heapq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heappushpop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# heapreplace(heap, item): 최솟값을 삭제한 뒤, heap에 item을 추가하고 삭제한 값을 반환함
# 주의점: 추가한 값 아님
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heapq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heapreplace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;파이썬 라이브러리 레시피, 프리렉&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>추천 시스템의 기본 - 03. Factorization Machines 설명 및 Tensorflow 구현</title>
   <link href="http://localhost:4000/FM/"/>
   <updated>2019-12-21T00:00:00+09:00</updated>
   <id>http://localhost:4000/FM</id>
   <content type="html">&lt;p&gt;본 글의 전반부에서는 먼저 &lt;strong&gt;Factorization Machines&lt;/strong&gt; 논문을 리뷰하면서 본 모델에 대해 설명할 것이다. 후반부에서는 텐서플로를 활용하여 &lt;strong&gt;FM&lt;/strong&gt; 모델을 구현해 볼 것이다. 논문의 전문은 &lt;a href=&quot;https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf&quot;&gt;이곳&lt;/a&gt;에서 확인할 수 있다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;1-factorization-machines-논문-리뷰&quot;&gt;1. Factorization Machines 논문 리뷰&lt;/h2&gt;
&lt;h3 id=&quot;10-abstract&quot;&gt;1.0. Abstract&lt;/h3&gt;
&lt;p&gt;본 논문에서는 SVM과 Factorization model들의 장점을 결합한 &lt;strong&gt;FM&lt;/strong&gt;이라는 새로운 모델을 소개한다. SVM과 마찬가지로 &lt;strong&gt;FM&lt;/strong&gt;은 그 어떤 실수 값의 피쳐 벡터를 Input으로 받아도 잘 작동하는 일반적인 예측기이다. 그러나 SVM과 다르게 이 모델은 &lt;code class=&quot;highlighter-rouge&quot;&gt;Factorized Parameter&lt;/code&gt;를 이용하여 모든 Interaction을 모델화하여 아주 희소한 상황에서도 Interaction들을 예측할 수 있다는 장점을 갖고 있다.&lt;/p&gt;

&lt;p&gt;본 논문에서는 &lt;strong&gt;FM&lt;/strong&gt;의 모델 방정식이 선형시간 내에서 계산되어 바로 최적화될 수 있음을 증명한다. 따라서 SVM과 달리 dual form에서의 변환(transformation)은 필요하지 않아 본 모델의 파라미터들은 해를 구할 때 Support 벡터의 도움 없이 바로 예측될 수 있다.&lt;/p&gt;

&lt;p&gt;Matrix Factorization, SVD++, PITF, FPMC 등 다양한 모델들이 존재하는데, 이들은 오직 특정한 Input 데이터에서만 잘 작동한다는 한계를 지닌다. 반면 &lt;strong&gt;FM&lt;/strong&gt;은 Input 데이터를 지정하여 이러한 모델을 따라할 수 있다. 따라서 Factorization 모델에 대한 전문적인 지식이 없더라도 &lt;strong&gt;FM&lt;/strong&gt;은 사용하기에 있어 굉장히 쉽다.&lt;/p&gt;

&lt;h3 id=&quot;11-introduction&quot;&gt;1.1. Introduction&lt;/h3&gt;
&lt;p&gt;SVM은 유명한 예측 알고리즘이지만 협업 필터링과 같은 환경에서 SVM은 그리 중요한 역할을 하지 못한다. 본 논문에서는 SVM이 굉장히 희소한 데이터의 비선형적(complex) 커널 공간에서 reliable parameter(hyperplane: 초평면)를 학습할 수 없기 때문에 이러한 task에서 효과적이지 못함을 보여줄 것이다. 반면에 Tensor Factorization Model은 일반적인 예측 데이터에 대해서 그리 유용하지 않다는 단점을 가진다.&lt;/p&gt;

&lt;p&gt;본 논문에서는 새로운 예측기인 &lt;strong&gt;FM&lt;/strong&gt;을 소개할 것인데, 본 모델은 범용적인 예측 모델이지만 또한 매우 희소한 데이터 환경 속에서도 reliable parameter를 추정할 수 있다. &lt;strong&gt;FM&lt;/strong&gt;은 모든 nested된 변수 간 상호작용을 모델화하지만 SVM이 Dense Parametrization을 사용하는 것과 달리 factorized parametrization을 사용한다.&lt;/p&gt;

&lt;p&gt;FM의 모형식은 선형 시간으로 학습될 수 있으므로 파라미터들의 숫자에 따라 학습시간이 결정된다. 이는 SVM처럼 학습 데이터를 저장할 필요 없이 직접적인 최적화화 모델 파라미터의 저장을 가능하게 한다.&lt;/p&gt;

&lt;p&gt;요약하자면 &lt;strong&gt;FM&lt;/strong&gt;의 장점은 아래와 같다.
1) 굉장히 희소한 데이터에서도 파라미터 추정을 가능하게 한다.
2) 선형 complexity를 갖고 있기 때문에 primal하게 최적화될 수 있다.
3) 어떤 실수 피쳐 벡터를 Input으로 받아도 잘 작동한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;12-prediction-under-sparsity&quot;&gt;1.2. Prediction under Sparsity&lt;/h3&gt;
&lt;p&gt;가장 일반적인 예측 문제는 실수 피쳐 벡터 x에서 Target domain T (1 또는 0)로 매핑하는 함수를 추정하는 것이다. 지도학습에서는 (x, y) 튜플이 stacked된 D라는 학습데이터셋이 존재한다고 가정된다. 우리는 또한 랭킹 문제에 대해 논의해볼 수 있는데, 이 때 함수 y는 피쳐 벡터 x에 점수를 매기고 이를 정렬하는데 사용된다. Scoring 함수는 pairwise한 학습 데이터로부터 학습될 수 있는데, 이 때 피쳐 튜플인 $ (x^(A), x^(B)) $는 $ x^(A) $가 $ x^(B) $보다 높은 순위를 지닌다는 것을 의미한다. pairwise 랭킹 관계가 비대칭적이기 때문에, 오직 positive 학습 instance만을 사용해도 충분하다.&lt;/p&gt;

&lt;p&gt;본 논문에서 우리는 x가 매우 희소한 상황을 다룬다. 범주형 변수가 많을수록 더욱 데이터는 희소해지기 마련이다.&lt;/p&gt;

&lt;p&gt;$m(x)$: 피쳐 벡터 x에서 0이 아닌 원소의 개수&lt;br /&gt;
$\overline{m}_D$: 학습 데이터셋 D에 속하는 모든 x에 대해 $m(x)$의 평균&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example 1&lt;/strong&gt;&lt;br /&gt;
영화 평점 데이터를 갖고 있다고 하자. User $u \in U$가 영화(Item) $i \in I$를 특정 시점 $t \in \R$에 $r \in {1, 2, 3, 4, 5}$의 점수로 평점을 주었을 때 데이터는 아래와 같은 형상을 취할 것이다.&lt;/p&gt;

&lt;p&gt;data S = {(Alice, Titanic, 2010-1, 5), (Bob, Star Wars, 2010-2, 3) … }&lt;/p&gt;

&lt;p&gt;아래 그림은 이 문제 상황에서 S라는 데이터셋에서 어떻게 피쳐 벡터가 생성되는지를 보여준다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-21-FM/01.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;한 행에는 하나의 User, 하나의 Item이 들어가는 것을 확인할 수 있다. 모든 영화에 대한 평점 Matrix는 행의 합이 1이 되도록 Normalized되었다. 마지막 갈색 행렬은 주황색 행렬에서 확인한 active(가장 최근에 평점을 매긴)item 바로 이전에 평점을 매긴 Item이 무엇인지 알려주고 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;13-factorizaion-machines-본문&quot;&gt;1.3. Factorizaion Machines 본문&lt;/h3&gt;
&lt;h4 id=&quot;a-factorization-machine-model&quot;&gt;A. Factorization Machine Model&lt;/h4&gt;
&lt;p&gt;2차 모델 방정식은 아래와 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-21-FM/02.JPG&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;$V$ 내부의 행 $v_i$는 k개의 factor를 지닌 i번째 변수를 설명한다. k는 0을 포함한 자연수이며, factorization의 차원을 정의하는 하이퍼 파라미터이다. 2-way FM(2차수)은 변수간의 단일 예측변수와 결과변수 간의 상호작용 뿐 아니라 pairwise한(한 쌍의) 예측변수 조합과 결과변수 사이의 상호작용도 잡아낸다.&lt;/p&gt;

&lt;p&gt;부가적으로 설명을 하면,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$x_i$: X 데이터 셋의 하나의 행 벡터(feature vector)&lt;/li&gt;
  &lt;li&gt;$w_0$: global bias&lt;/li&gt;
  &lt;li&gt;$w_i$: i번째 변수의 영향력을 모델화 함&lt;/li&gt;
  &lt;li&gt;$\hat{w}_{i, j}$ = $&amp;lt;v_i, v_j&amp;gt;$: i, j번째 변수간의 상호작용을 모델화 함&lt;/li&gt;
  &lt;li&gt;$v$ 벡터: factor vector&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;FM&lt;/strong&gt; 모델은 각 상호작용에 대해 $w_{i, j}$라는 모델 파라미터를 그대로 사용하는 것이 아니라, 이를 factorize하여 사용한다. 나중에 확인하겠지만, 이 부분이 희소한 데이터임에도 불구하고 고차원의 상호작용에 대한 훌륭한 파라미터 추정치를 산출할 수 있는 중요한 역할을 하게 된다.&lt;/p&gt;

&lt;p&gt;k가 충분히 크면 positive definite 행렬 W에 대하여 $W = V \bullet V^t$을 만족시키는 행렬 $V$는 반드시 존재한다. 이는 &lt;strong&gt;FM&lt;/strong&gt;모델이 k가 충분히 크면 어떠한 상호작용 행렬 $W$도 표현할 수 있음을 나타낸다. 그러나 sparse한 데이터 환경에서는, 복잡한 상호작용 W를 추정하기 위한 충분한 데이터가 없기에 작은 k를 선택할 수 밖에 없는 경우가 많다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-21-FM/03.JPG&quot; width=&quot;90%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 그림을 보면 알 수 있듯이, x벡터 하나당 1개의 예측 값을 산출하게 된다.&lt;/p&gt;

&lt;p&gt;참고로, 본 논문에서는 위 그림의 p 대신 n이라고 적혀있는데, 이 &lt;strong&gt;p&lt;/strong&gt;는 예측 변수의 수를 의미하기 때문에, 관례적으로 더 많이 쓰이는 &lt;strong&gt;p&lt;/strong&gt;로 표기한 것이니 착오 없길 바란다.&lt;/p&gt;

&lt;p&gt;Sparse한 환경에서, 일반적으로 변수들 간의 상호작용을 직접적이고 독립적으로 추정하기 위한 충분한 데이터가 없는 경우가 많다. &lt;strong&gt;FM&lt;/strong&gt;은 이러한 환경에서도 상호작용들을 추정할 수 있는데, 이는 왜냐하면 이 모델은 상호작용 파라미터들을 factorize하여 상호작용 파라미터들 사이의 독립성을 깰 수 있기 때문이다.&lt;/p&gt;

&lt;p&gt;일반적으로 이것은 하나의 상호작용을 위한 데이터가 다른 관계된 상호작용들의 파라미터들을 추정하는 데 도움을 준다는 것읠 의미한다.&lt;/p&gt;

&lt;p&gt;앞서 언급했던 예를 들어보자,&lt;br /&gt;
Alice와 Star Trek 사이의 상호작용을 추정하여 영화평점(Target y)을 예측하고 싶다고 하자. 당연하게도 학습데이터에는 두 변수 $x_a$와 $x_{ST}$가 모두 0이 아닌 경우는 존재하지 않으므로, direct estimate $w_{A, ST}$는 0이 될 것이다.&lt;/p&gt;

&lt;p&gt;그러나 factorized 상호작용 파라미터인 $&amp;lt;V_{A}, V_{ST}&amp;gt;$를 통해 우리는 상호작용을 측정할 수 있다. Bob과 Charlie는 모두 유사한 factor vector $V_B$, $V_C$를 가질 것인데, 이는 두 사람 모두 Star Wars ($V_{SW}$)와 관련하여 유사한 상호작용을 갖고 있기 때문이다. (취향이 비슷하다.) 즉, $&amp;lt;V_{B}, V_{SW}&amp;gt;$과 $&amp;lt;V_{C}, V_{SW}&amp;gt;$가 유사하다는 뜻이다.&lt;/p&gt;

&lt;p&gt;Alice($V_A$)는 평점 예측에 있어서 Titanic과 Star Wars 두 factor와 상호작용이 다르기 때문에 Charlie와는 다른 factor vector를 가질 것이다. Bob은 Star Wars와 Star Trek에 대해 유사한 상호작용을 가졌기 때문에 Star Trek과 Star Wars의 factor vector는 유사할 가능성이 높다. 즉, Alice와 Star Treck의 factor vector의 내적은 Alice와 Star Wars의 factor vector의 내적 값과 매우 유사할 것이다. (직관적으로 말이 된다.)&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;이제 계산적 측면에서 모델을 바라볼 것이다. 앞서 확인한 방정식의 계산 복잡성은 $O(kp^2)$이지만, 이를 다시 변형하여 선형적으로 계산 시간을 줄일 수 있다. pairwise 상호작용 부분은 아래와 같이 재표현할 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-21-FM/04.JPG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;이 부분이 굉장히 중요한데, 실제로 코드로 구현할 때 이와 같은 재표현 방식이 없다면 굉장히 난감한 상황에 맞닥드리게 될 것이다.&lt;/p&gt;

&lt;p&gt;또한 x의 대부분의 원소가 0이므로 실제로는 0이 아닌 원소들에 대해서만 계산이 수행된다.&lt;/p&gt;

&lt;h4 id=&quot;b-factorizaion-machine-as-predictors&quot;&gt;B. Factorizaion Machine as Predictors&lt;/h4&gt;
&lt;p&gt;FM은 회귀, 이항 분류, 랭킹 문제를 풀기 위해 활용될 수 있다. 그리고 이 모든 문제에서 L2 정규화 항은 과대적합을 막기 위해 추가된다.&lt;/p&gt;

&lt;h4 id=&quot;c-learning-factorizatino-machines&quot;&gt;C. Learning Factorizatino Machines&lt;/h4&gt;
&lt;p&gt;앞서 확인한 것처럼, FM은 선형적으로 계산되는 모델 방정식을 지니고 있다. 따라서 $w_0, w, V$와 같은 모델 파라미터들은 Gradient Descent 방법을 통해 효과적으로 학습될 수 있다. FM 모델의 Gradient는 아래와 같이 표현될 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-21-FM/05.JPG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;$\sum_{j=1}^n v_{j, f} x_j$는 i에 대해 독립적이기 때문에 우선적으로 미리 계산될 수 있다. 일반적으로 각각의 Gradient는 상수적 시간 O(1)만에 계산될 수 있다. 그리고 (x, y)를 위한 모든 파라미터 업데이터는 희소한 환경에서 $O(kp)$ 안에 이루어질 수 있다.&lt;/p&gt;

&lt;p&gt;우리는 element-wise하거나 pairwise한 Loss를 계산하기 위해 SGD를 사용하는 일반적인 implementation인 LIBFM2를 제공한다.&lt;/p&gt;

&lt;h4 id=&quot;d-d-way-factorizatino-machine&quot;&gt;D. d-way Factorizatino Machine&lt;/h4&gt;
&lt;p&gt;2-way FM은 쉽게 d-way FM으로 확장할 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-21-FM/06.JPG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;h4 id=&quot;e-summary&quot;&gt;E. Summary&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;FM&lt;/strong&gt; 모델은 모든 상호작용을 있는 그대로 사용하는 것이 아니라 factorized 상호작용을 이용하여 피쳐 벡터 x의 값 사이에 있는 가능한 상호작용들을 모델화한다. 이러한 방식은 2가지 장점을 지닌다.&lt;/p&gt;

&lt;p&gt;1) 아무리 희소한 환경에서도 값들 사이의 상호작용을 추정할 수 있다. 또한 이는 관측되지 않은 상호작용을 일반화하는 것도 가능하게 한다.&lt;br /&gt;
2) 학습 및 예측에 소요되는 시간이 선형적이고, 이에 따라 파라미터의 수도 선형적이다. 이는 SGD를 이용하여 다양한 Loss Function들을 최적화하는 것을 가능하게 한다.&lt;/p&gt;

&lt;p&gt;(후략)&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;2-tensorflow를-활용한-구현&quot;&gt;2. Tensorflow를 활용한 구현&lt;/h2&gt;
&lt;h3 id=&quot;21-준비&quot;&gt;2.1. 준비&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# FM
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow.keras.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BinaryAccuracy&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MinMaxScaler&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# GPU 확인
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list_physical_devices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'GPU'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 자료형 선언
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_floatx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 데이터 로드
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scaler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MinMaxScaler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_breast_cancer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'target'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scaler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;데이터는 sklearn에 내장되어 있는 breast_cancer 데이터를 사용하였다. 30개의 변수를 바탕으로 암 발생 여부를 예측하는 데이터이다. &lt;strong&gt;p&lt;/strong&gt;는 예측 변수의 개수이고, &lt;strong&gt;k&lt;/strong&gt;는 잠재 변수의 개수이다.&lt;/p&gt;

&lt;h3 id=&quot;22-fm-모델-선언&quot;&gt;2.2. FM 모델 선언&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 모델의 파라미터 정의
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;linear_terms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduce_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
            &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_terms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interactions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_hat&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;모델 자체는 아주 복잡할 것은 없다. &lt;code class=&quot;highlighter-rouge&quot;&gt;linear terms&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;interactions&lt;/code&gt;라고 정의한 부분이 아래 수식의 밑줄 친 부분에 해당한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-21-FM/07.JPG&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;interactions&lt;/code&gt; 부분이 아주 중요한데, 이 부분을 어떻게 구현하느냐가 속도의 차이를 만들어 낼 수 있기 때문이다. 논문에서는 아래와 같이 이 상호작용 항을 재표현할 수 있다고 하였다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-21-FM/08.JPG&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 &lt;code class=&quot;highlighter-rouge&quot;&gt;interactions&lt;/code&gt; 부분은 위 식을 코드로 표현한 것인데, $\sum$ 항을 벡터화 하여 구현하였다.&lt;/p&gt;

&lt;p&gt;설명을 위해, (k=2, p=3) shape을 가진 $V$ 행렬과 (p=3, 1)의 shape을 가진 $x$ 벡터가 있다고 하자. 사실 $(\sum_{i=1}^n v_{i,f } x_i)^2$ 부분을 계산하면 $V^T x$의 모든 원소를 더한 것과 동일하다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-21-FM/10.JPG&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 그림의 결과는 $(v_{11}x_1 + v_{21}x_2 + v_{31}x_3)^2 + (v_{12}x_1 + v_{22}x_2 + v_{32}x_3)^2$와 동일할 것이다. 식의 나머지 부분도 같은 방법으로 생각하면 위와 같은 코드로 표현할 수 있을 것이다.&lt;/p&gt;

&lt;h3 id=&quot;213-학습-코드&quot;&gt;2.1.3. 학습 코드&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Forward
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_on_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GradientTape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binary_crossentropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_logits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                   &lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                                   &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# loss를 모델의 파라미터로 편미분하여 gradients를 구한다.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sources&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainable_variables&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# apply_gradients()를 통해 processed gradients를 적용한다.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply_gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainable_variables&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# accuracy: update할 때마다 정확도는 누적되어 계산된다.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# 반복 학습 함수
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stratify&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;train_ds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_tensor_slices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;test_ds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_tensor_slices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BinaryAccuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss_history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_on_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;loss_history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;스텝 {:03d}에서 누적 평균 손실: {:.4f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;스텝 {:03d}에서 누적 정확도: {:.4f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;


    &lt;span class=&quot;n&quot;&gt;test_accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BinaryAccuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;테스트 정확도: {:.4f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;epochs = 50으로 실행한 결과는 아래와 같다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;스텝&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;000&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;에서&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;누적&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;평균&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;손실&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.2317&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;스텝&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;000&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;에서&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;누적&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;정확도&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5692&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;스텝&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;002&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;에서&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;누적&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;평균&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;손실&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9909&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;스텝&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;002&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;에서&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;누적&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;정확도&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6271&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;스텝&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;048&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;에서&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;누적&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;평균&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;손실&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2996&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;스텝&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;048&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;에서&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;누적&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;정확도&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8996&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;테스트&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;정확도&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9500&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;p&gt;http://nowave.it/factorization-machines-with-tensorflow.html&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>추천 시스템의 기본 - 02. Matrix Factorization 논문 리뷰</title>
   <link href="http://localhost:4000/Matrix-Factorization/"/>
   <updated>2019-12-20T00:00:00+09:00</updated>
   <id>http://localhost:4000/Matrix Factorization</id>
   <content type="html">&lt;p&gt;본 글은 2009년에 발표된 &lt;strong&gt;Matrix Factorization Techniques for Recommender Systems&lt;/strong&gt; 논문을 리뷰하고 간단히 요약 정리한 글이다. 논문 원본은 &lt;a href=&quot;https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf&quot;&gt;이곳&lt;/a&gt;에서 다운 받을 수 있다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;컨텐츠 기반 필터링&lt;/code&gt;은 각 사용자나 아이템에 대해 프로필을 만들고, 그 특성을 구체화하는 방식으로 이루어진다. 반면 위 방식의 대안이라고 할 수 있는 &lt;code class=&quot;highlighter-rouge&quot;&gt;협업 필터링&lt;/code&gt;은 어떤 명시적(Explicit) 프로필을 만들지 않고, 이전 구매 기록이나 제품 평가 기록 등 과거 사용자 행동에만 의존해서 시스템을 구성한다. 이 방식은 유저-아이템 간의 상관관계를 찾아내는 것이 주 목적이라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;협업 필터링&lt;/code&gt;은 &lt;strong&gt;Domain-free&lt;/strong&gt; 즉, 특별히 이 분야에 대한 지식이 필요하지 않다는 장점을 가진다. 반면 새로운 사용자와 아이템을 다루기에 부적합하다는 &lt;strong&gt;Cold Start Problem&lt;/strong&gt;이라는 한계를 갖고 있다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;협업 필터링&lt;/code&gt;은 &lt;strong&gt;근접 이웃 방법&lt;/strong&gt;과 &lt;strong&gt;잠재 요인 방법&lt;/strong&gt;로 나뉜다. 후자의 경우 평점 패턴에서 20~100가지의 factor(요인)을 추론하는 것을 목적으로 한다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;2-mf-methods-and-a-basic-mf-model&quot;&gt;2. MF Methods and A Basic MF Model&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;잠재 요인 협업 필터링&lt;/code&gt;을 구현하는 가장 좋은 방법 중 하나는 &lt;strong&gt;Matrix Factorization&lt;/strong&gt;이다. 
기본적으로 이 방법은 평점 패턴으로부터 추론한 요인 벡터들을 통해 사용자와 아이템의 특성을 잡아낸다. 이 때 사용자와 아이템 사이의 강한 관련성이 있다면 추천이 시행된다. 이 방법은 확장성, 높은 정확도, 유연성이라는 장점을 가진다.&lt;/p&gt;

&lt;p&gt;추천 시스템은 여러 종류의 Input Data를 활용할 수 있다. 물론 가장 좋은 것은 양질의 &lt;strong&gt;명시적 피드백&lt;/strong&gt;(Explicit Feedback)이 될 것인데, 이는 영화 평점이나 좋아요/싫어요와 같은 아이템에 대한 사용자의 선호 결과를 의미한다. 일반적으로 이러한 피드백은 그리 많이 이루어지지 않기 때문에, 이를 행렬로 정리하면 희소(Sparse) 행렬이 될 수 밖에 없다.&lt;/p&gt;

&lt;p&gt;만약 이러한 명시적 피드백 조차 활용할 수 없을 때는, 추천 시스템은 &lt;strong&gt;암시적 피드백&lt;/strong&gt;(Implicit Feedback)을 이용하여 사용자의 선호를 파악하게 된다. 이는 구매내역이나 검색기록, 검색 패턴, 커서의 움직임 등을 의미하며 이를 통해 사용자의 선호를 파악하는 것이 목표라고 할 수 있겠다.&lt;/p&gt;

&lt;p&gt;Matrix Factorization(이하 MF 또는 행렬 분해) 모델은 사용자와 아이템 모두를 차원 f의 결합 잠재요인 공간에 매핑하는데, 사용자-아이템 상호작용은 이 공간에서 내적으로 모델링 된다.&lt;/p&gt;

&lt;p&gt;아이템 i는 $ q_i $로, 사용자 u는 $ p_u $라는 벡터로 표현된다. 이 둘의 내적은 &lt;strong&gt;사용자-아이템 사이의 상호작용&lt;/strong&gt;을 반영하며 이는 곧 아이템에 대한 사용자의 전반적인 관심을 표현한다고 볼 수 있다. 식은 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{r_{ui}} = q^{T}_i p_u&lt;/script&gt;

&lt;p&gt;이 모델은 사실 &lt;strong&gt;SVD&lt;/strong&gt;(Singular Vector Decomposition)과 매우 유사한데, 추천 시스템에서는 결측값의 존재로 이 SVD를 직접적으로 사용하는 것은 불가능하다. 결측값을 채워 넣는 것 역시 효율적이지 못하고 데이터의 왜곡 가능성 때문에 고려하기 힘들다.&lt;/p&gt;

&lt;p&gt;따라서 오직 관측된 평점만을 직접적으로 모델링하는 방법이 제시되었으며, 이 때 과적합을 방지하기 위해 규제 항이 포함되었다. 요인 벡터 $ q_i, p_u $를 학습하기 위해 시스템은 관측된 평점 세트를 바탕으로 아래 식을 최소화하는 것을 목적으로 한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_{q, p} \sum_{(u, i) \in K} ( r_{ui} - q^T_i p_u  )^2 + \lambda (\Vert{q_i}\Vert^2 + \Vert{p_u}\Vert^2)&lt;/script&gt;

&lt;p&gt;이 때, &lt;strong&gt;K&lt;/strong&gt;는 $ r_{ui} $가 측정된(known) 값일 때의 (u, i) 세트를 의미한다. 결과적으로 이 모델은 알려지지 않은 평점을 예측하는 것이 목적이기 때문에 과적합을 방지해야 하고, 이를 위해 규제항이 필요하고 $ \lambda $가 이 규제의 정도를 제어한다. $ \lambda $는 주로 Cross-Validation에 의해 결정된다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;3-learning-algorithms-and-adding-biases&quot;&gt;3. Learning Algorithms and Adding Biases&lt;/h2&gt;
&lt;p&gt;이전 장에서 본 식을 최소화하기 위한 방법으로는 2가지가 제시된다.&lt;/p&gt;
&lt;h3 id=&quot;31-stochastic-gradient-descent&quot;&gt;3.1. Stochastic Gradient Descent&lt;/h3&gt;
&lt;p&gt;각각의 훈련 세트에 대해 본 알고리즘은 $ r_{ui} $를 예측하고 다음과 같은 예측 오차를 산출한다.&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;e_{ui} = r_{ui} - q^T_i p_u&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;이후 $ q_i $와 $ p_u $를 아래와 같이 업데이트 한다.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;q_i := q_i + \gamma (e_{ui} p_u - \lambda q_i)&lt;/script&gt;&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;p_u := p_u + \gamma (e_{ui} q_i - \lambda p_u)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;확률적 경사하강법은 구현이 쉽고 빠르다는 장점을 지닌다.&lt;/p&gt;

&lt;h3 id=&quot;32-alternating-least-squares&quot;&gt;3.2. Alternating Least Squares&lt;/h3&gt;
&lt;p&gt;$ q_i $와 $ p_u $가 둘다 미지의 값이기 때문에 앞서 최소화하려고 했던 식은 convex하지 못하다. 그러나 만약 둘 중 하나를 고정(fixed)할 수 있다면, 이 최적화 문제는 quadratic하게 바뀌어 해를 구할 수 있게 된다. 따라서 &lt;strong&gt;ALS&lt;/strong&gt;는 $ q_i $를 고정했다가 다음 번에는 $ p_u $를 고정하는 방식으로 작동한다. $ p_u $가 고정되어 있다면 본 알고리즘은 최소제곱법으로 $ q_i $를 다시 계산한다. 이러한 방법으로 목적 함수(2장에서 본 최소화 시켜야 할 식)를 최소화할 수 있는 것이다.&lt;/p&gt;

&lt;p&gt;3.1장에서 본 &lt;strong&gt;SGD&lt;/strong&gt;가 일반적으로 편리한 방법이긴 하지만 아래의 2가지 경우에는 이 &lt;strong&gt;ALS&lt;/strong&gt;가 효과를 발휘하기도 한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;시스템이 병렬화를 지원하는 경우&lt;/li&gt;
  &lt;li&gt;시스템이 암시적 데이터에 집중되어 있는 경우&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;33-adding-biases&quot;&gt;3.3. Adding Biases&lt;/h3&gt;
&lt;p&gt;$ \hat{r_{ui}} = q^{T}_i p_u $ 식은 여러 평점 결과를 만들어 내는 사용자와 아이템 간의 상호관계를 파악하는 것이 목적이다. 그런데 사실 많은 경우에 이 상호작용 외에 사용자나 아이템 자체의 특성이 이러한 평점 결과에 영향을 미친다. 이것을 우리는 &lt;strong&gt;biases&lt;/strong&gt; 또는 &lt;strong&gt;intercepts&lt;/strong&gt;라고 부른다. 이를 앞서 보았던 방정식과 목적 함수에 적용해보면 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{r_{ui}} = \mu + b_i + b_u + q^{T}_i p_u&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_{p, q, b} \sum_{(u, i) \in K} ( r_{ui} - \mu - b_i - b_u - q^T_i p_u  )^2 + \lambda (\Vert{q_i}\Vert^2 + \Vert{p_u}\Vert^2 + b^2_u + b^2_i)&lt;/script&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;4-additional-input-sources-and-temporal-dynamics&quot;&gt;4. Additional Input Sources and Temporal Dynamics&lt;/h2&gt;
&lt;p&gt;종종 시스템은 &lt;strong&gt;Cold Start&lt;/strong&gt; 문제에 직면하게 되는데, 평점 데이터에 기반한 추천 시스템을 만드는 상황에서는 사용자들이 평점 결과를 거의 남기지 않는 상황이 이 문제에 해당한다고 볼 수 있다. 이럴 때에는 사용자에 대한 추가적인 정보 소스들을 모두 통합할 필요가 있다. 즉, &lt;strong&gt;행동 정보&lt;/strong&gt;(Behavior Information)들이 필요하다는 것이다. 예를 들어 소매업자는 고객의 구매 기록이나 검색 기록 등을 활용할 수 있을 것이다.&lt;/p&gt;

&lt;p&gt;단순화하기 위해 Boolean 암시적 피드백이 있는 경우를 생각해보자. $ N(u) $는 사용자 $u$가 암시적 선호를 표현한 아이템의 집합을 의미한다. 시스템은 이를 통해 사용자의 프로필을 만들어 낸다. $ N(u) $에 속한 아이템에 대한 선호를 표현한 사용자는 아래 벡터와 같이 표현된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{i \in N(u)} x_i&lt;/script&gt;

&lt;p&gt;이 식을 정규화하는 것이 일반적으로 더 좋은 결과를 가져오기에, 정규화를 하겠다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;|N(u)|^{-0.5} \sum_{i \in N(u)} x_i&lt;/script&gt;

&lt;p&gt;또 중요한 정보는 인구학적 정보와 같은 &lt;strong&gt;사용자 속성&lt;/strong&gt;(User Attributes)이다. 유사하게 표현하면 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{a \in A(u)} y_a&lt;/script&gt;

&lt;p&gt;모든 Signal Source를 통합하여 개선된(Enhanced) 사용자 표현식은 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{r_{ui}} = \mu + b_i + b_u + q^T_i [p_u + |N(u)|^{-0.5} \sum_{i \in N(u)} x_i + \sum_{a \in A(u)} y_a]&lt;/script&gt;

&lt;p&gt;지금까지의 모델은 사실 정적(static)인 모델이었다. 즉, 시간의 변화를 반영하지 못한다는 뜻이다. 그러나 현실에서는 제품에 대한 인식, 인기는 새로운 선택지가 늘어남에 따라 시시각각 변하기 마련이다. 또한 고객들의 성향도 진화하여 그들의 취향은 때때로 변화한다. 따라서 추천 시스템은 시간에 따라 변하는 사용자-아이템 상호작용의 동적(dynamic)인 성질을 반영하는 &lt;strong&gt;Temporal Effect&lt;/strong&gt;에 대해 설명할 수 있어야 한다.&lt;/p&gt;

&lt;p&gt;총 3개의 항이 변화한다.&lt;br /&gt;
$ b_i(t) $: 아이템의 인기는 시간에 따라 변한다.&lt;br /&gt;
$ b_u(t) $: 사용자의 성향도 시간에 따라 변한다. (baseline rating)&lt;br /&gt;
$ p_u(t) $: 시간이 흐름에 따라 아이템에 대한 사용자의 선호는 변화할 수 있다.&lt;/p&gt;

&lt;p&gt;단 (설정에 따라) 아이템의 성격은 (이미 만들어졌기에) 변하지 않으므로 아이템은 시간에 관한 함수로 구성되지 않는다. 최종적으로 정리하면 아래와 같은 식이 만들어진다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{r_{ui}}(t) = \mu + b_i(t) + b_u(t) + q^T_i p_u(t)&lt;/script&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;5-inputs-with-varying-confidence-levels&quot;&gt;5. Inputs with varying confidence levels&lt;/h2&gt;
&lt;p&gt;모든 관측값이 같은 &lt;strong&gt;신뢰도&lt;/strong&gt;(confidence)를 가지는 것은 아니다. 예를 들어 어떤 적대적 사용자는 별 이유 없이 낮은 평점을 제공할 수도 있는 것이다. 따라서 추천 시스템을 더욱 공고히 하기 위해서는, 예측된 선호도에 &lt;strong&gt;신뢰도&lt;/strong&gt;를 붙여야(attach) 한다. 이 &lt;strong&gt;신뢰도&lt;/strong&gt;는 action의 빈도를 설명하는 실수 값인데, 예를 들어 특정 사용자가 특정 show를 얼마나 오래, 자주 보았는가와 같은 값이 &lt;strong&gt;신뢰도&lt;/strong&gt;가 될 수 있다. 이러한 특성을 목적 함수에 반영하면 아래와 같이 될 것이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min_{p, q, b} \sum_{(u, i) \in K} c_{ui}( r_{ui} - \mu - b_i - b_u - q^T_i p_u  )^2 + \lambda (\Vert{q_i}\Vert^2 + \Vert{p_u}\Vert^2 + b^2_u + b^2_i)&lt;/script&gt;

</content>
 </entry>
 
 <entry>
   <title>추천 시스템의 기본 - 01. 잠재요인 협업필터링 (Latent Factor Collaborative Filtering)</title>
   <link href="http://localhost:4000/Recommendation-System/"/>
   <updated>2019-12-17T00:00:00+09:00</updated>
   <id>http://localhost:4000/Recommendation System</id>
   <content type="html">&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;추천시스템은 이제는 너무 많은 산업에서 도입하고 있는 시스템이기에 웬만큼 참신하지 않은 이상 새롭게 들리지 않는 것이 현실이다. 그러나 소비자의 입장에서 추천시스템을 보는 것과, 이 시스템의 개발자가 추천시스템을 바라 보는 것에는 큰 차이가 있다. 성공적으로 추천 엔진을 도입한 산업, 기업들이 있는 반면 여러 가지 어려움으로 인해 실질적인 효과가 떨어지는 산업, 기업도 있기 마련이다.&lt;/p&gt;

&lt;p&gt;사용자(User)의 행동 양식, 인구학적(Demographic) 정보, 아이템(Item)의 특성, 외부 변수 등 수많은 변인들을 관리하고 분석해서 사용자에게 가장 알맞는 아이템을 추천해주는 일은 분명 쉬운 일은 아니다. 이러한 어려움을 극복하기 위해 연구자들은 과거부터 여러 종류의 추천 시스템을 개발해왔는데, 지금부터 그에 대해 조금씩 알아보고자 한다.&lt;/p&gt;

&lt;p&gt;추천 시스템을 만드는 방법에는 굉장히 다양한 방식이 존재하지만, 본 글에서는 가장 핵심이 되는 방법론들에 대해서만 간단히 언급하고자 한다. 추천 시스템은 크게 &lt;code class=&quot;highlighter-rouge&quot;&gt;컨텐츠 기반 필터링(Content Based Filtering)&lt;/code&gt; 방식과 &lt;code class=&quot;highlighter-rouge&quot;&gt;협업 필터링(Collaborative Filterin)&lt;/code&gt; 방식으로 나뉜다. 협업 필터링은 또 &lt;code class=&quot;highlighter-rouge&quot;&gt;최근접 이웃(Nearest Neighbor) 협업 필터링&lt;/code&gt;과 &lt;code class=&quot;highlighter-rouge&quot;&gt;잠재 요인(Latent Factor) 협업 필터링&lt;/code&gt;으로 나뉜다.&lt;/p&gt;

&lt;p&gt;과거에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;컨텐츠 기반 필터링&lt;/code&gt;과 &lt;code class=&quot;highlighter-rouge&quot;&gt;최근접 이웃 협업 필터링&lt;/code&gt;이 더욱 주목을 받았지만, 2009년에 있었던 &lt;strong&gt;넷플릭스 추천 컴퍼티션&lt;/strong&gt;에서 &lt;strong&gt;행렬 분해(Matrix Factorization)&lt;/strong&gt;를 이용한 &lt;code class=&quot;highlighter-rouge&quot;&gt;잠재 요인 협업 필터링&lt;/code&gt; 방식이 우승을 차지하면서, 연구자들은 이 방식에 큰 관심을 갖게 되었다. 현재로서는 많은 경우에 이 방식이 우위를 차지하지만, 상황에 따라서는 다른 방식이 더 좋은 결과를 낼 때도 많고, 하이브리드 형식으로 결합하는 방식 또한 좋은 효율을 보여주는 경우도 많다.&lt;/p&gt;

&lt;p&gt;아래에서 보충 설명을 하겠지만 추천 시스템의 대표적인 방법론들을 구조화하면 아래와 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-17-Recommendation System/01.JPG&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;앞으로 총 4개의 시리즈로 이어질 추천 시스템에 관한 글들은, 위에서 언급한 &lt;code class=&quot;highlighter-rouge&quot;&gt;잠재 요인 협업 필터링&lt;/code&gt;과 이 방법론에서 출발하여 발전된 알고리즘에 대해 다룰 예정이다. 간단히 순서를 보면 아래와 같다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;잠재요인 협업필터링&lt;/li&gt;
    &lt;li&gt;Matrix Factorization Techiques for Recommender Systems 논문 리뷰&lt;/li&gt;
    &lt;li&gt;Factorization Machines 설명&lt;/li&gt;
    &lt;li&gt;Field-aware Factorization machines 설명&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Matrix Factorization&lt;/strong&gt; 개념에 &lt;strong&gt;Support Vector Machine&lt;/strong&gt;의 개념을 결합한 것이 &lt;strong&gt;Factorization Machines&lt;/strong&gt;이다. 여기서 더 나아가 개별 feature들의 메타정보(field)를 알고리즘에 반영한 것이 &lt;strong&gt;Field-aware Factorization Machines&lt;/strong&gt;이다. 줄여서 각각 &lt;strong&gt;FM&lt;/strong&gt;과 &lt;strong&gt;FFM&lt;/strong&gt;이라고 부르는 것이 일반적이다.&lt;/p&gt;

&lt;p&gt;로지스틱 모델과 달리 &lt;strong&gt;FFM&lt;/strong&gt;은 가중치를 latent vector화 했기 때문에 연산량과 메모리 사용량이 더 많은 단점이 있지만, 최근 여러 논문에서는 system tuning을 통해 실제 광고 서빙에 사용하는 데 큰 지장이 없음을 밝혔다. 여력이 될 때 더욱 최신 연구들에 대해서도 글을 추가하도록 할 것이다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;2-추천-시스템의-개요&quot;&gt;2. 추천 시스템의 개요&lt;/h2&gt;
&lt;h3 id=&quot;21-컨텐츠-기반-필터링&quot;&gt;2.1. 컨텐츠 기반 필터링&lt;/h3&gt;
&lt;p&gt;어떤 사용자가 특정 아이템을 선호할 때, 그 아이템과 비슷한 컨텐츠를 가진 다른 아이템을 추천하는 것이 이 방식의 기본 아이디어이다. 추가적으로 설명하자면, 이 방식은 사용자와 아이템에 대한 프로필을 만들고 그 특징을 활용한다. 예를 들어 어떤 특정 영화는 장르, 출연배우, 박스오피스 인기도 등 여러 특성을 지니게 될 텐데 이 &lt;strong&gt;특성&lt;/strong&gt;(&lt;strong&gt;컨텐츠&lt;/strong&gt;)들이 이 영화의 프로필을 형성하는 것이다.&lt;/p&gt;

&lt;h3 id=&quot;22-최근접-이웃-협업-필터링&quot;&gt;2.2. 최근접 이웃 협업 필터링&lt;/h3&gt;
&lt;p&gt;모든 협업 필터링은 사용자-아이템 행렬 데이터에 의존한다. 사용자가 남긴 평점(rating) 데이터를 기반하여 남기지 않은 데이터를 추론하는 형식이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-17-Recommendation System/02.JPG&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;h4 id=&quot;221-사용자-기반-최근접-이웃-협업-필터링&quot;&gt;2.2.1. 사용자 기반 최근접 이웃 협업 필터링&lt;/h4&gt;
&lt;p&gt;특정 사용자와 유사한 사용자들을 선정하고, 이들을 TOP-N이라고 명명한 뒤 이들이 선호하는 아이템을 특정 사용자에게 추천하는 방식이다.&lt;/p&gt;

&lt;h4 id=&quot;222-아이템-기반-최근접-이웃-협업-필터링&quot;&gt;2.2.2. 아이템 기반 최근접 이웃 협업 필터링&lt;/h4&gt;
&lt;p&gt;어떤 사용자가 A라는 아이템을 선호한다고 할 때, 그 사용자는 A와 유사한 B라는 아이템 역시 선호할 것이라는 가정 하에 추천을 진행하는 방식이다. 아이템 기반 방식이 사용자 기반 방식 보다 정확도가 높은 것이 일반적이기에 본 방식이 더욱 자주 사용된다.&lt;/p&gt;

&lt;h3 id=&quot;23-잠재-요인-협업-필터링&quot;&gt;2.3. 잠재 요인 협업 필터링&lt;/h3&gt;
&lt;p&gt;사용자-아이템 평점 행렬에 잠재되어 있는 어떤 요인(factor)이 있다고 가정하고, 행렬 분해를 통해 그 요인들을 찾아내는 방식이다. 이 &lt;strong&gt;잠재 요인&lt;/strong&gt;은 구체적으로 정의하는 것이 때로는 어렵지만, 실제 시스템에서는 추천의 근거를 마련하는 데에 있어 큰 역할을 수행한다.&lt;/p&gt;

&lt;p&gt;예를 들어보면, 영화 장르를 &lt;strong&gt;잠재 요인&lt;/strong&gt;으로 설정할 수 있다. 어떤 사용자는 판타지 영화를 다른 어떤 영화보다 좋아한다고 하면, 이 사용자에게 있어 영화를 선택할 때 가장 중요한 기준(요인)은 판타지 영화이냐 아니냐가 될 가능성이 높다. 그리고 이 사용자에게 다른 영화를 추천해준다고 한다면, 판타지 영화를 추천하는 것이 가장 합리적일 가능성이 높다는 것이다. &lt;code class=&quot;highlighter-rouge&quot;&gt;잠재 요인 협업 필터링&lt;/code&gt;은 이러한 &lt;strong&gt;요인&lt;/strong&gt;들을 찾아 추천에 활용하게 된다.&lt;/p&gt;

&lt;p&gt;지금부터는 이 &lt;strong&gt;행렬 분해&lt;/strong&gt;를 어떻게 진행하는지에 대해 알아보도록 하겠다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;3-singular-value-decomposition&quot;&gt;3. Singular Value Decomposition&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;특이값 분해&lt;/code&gt;는 &lt;strong&gt;Spectral Decomposition&lt;/strong&gt;의 일반화 버전이라고 생각하면 쉽다. 즉, 정방행렬이라는 조건을 만족하지 않아도(행과 열의 개수가 달라도) 다차원 행렬을 저차원 행렬로 분해하는 차원 축소 기법이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Spectral Decomposition&lt;/strong&gt;에 따르면 정방행렬 A는 아래와 같이 표현할 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A = P\Lambda P' = P\Lambda P^T = \sum_{i=1}^{p} \lambda_i e_i e_i'&lt;/script&gt;

&lt;p&gt;여기서 $P$는 $\lambda$에 대응하는 고유벡터들을 열벡터로 가지는 &lt;strong&gt;직교행렬&lt;/strong&gt;이다. $\Lambda$는 $A$의 고유값들을 대각원소로 가지는 &lt;strong&gt;대각행렬&lt;/strong&gt;이다.&lt;/p&gt;

&lt;p&gt;(m, n), m&amp;gt;n인 직사각 행렬 $A$에 대해 &lt;code class=&quot;highlighter-rouge&quot;&gt;특이값 분해&lt;/code&gt;를 실시하면 아래와 같이 표현될 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A = U\Sigma V^T&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;$U$: (m, m), $A$의 left singular 벡터로 구성된 직교행렬&lt;/li&gt;
  &lt;li&gt;$V$: (n, n), $A$의 right singular 벡터로 구성된 직교행렬&lt;/li&gt;
  &lt;li&gt;$\Sigma$: (m, n), 주 대각성분이 $\sqrt{\lambda_i}$인 직사각 대각행렬&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$AA^T$를 위 식으로 표현하면 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;AA^T = U\Sigma V^T V\Sigma U^T  = U(\Sigma \Sigma^T) U^T&lt;/script&gt;

&lt;p&gt;여기서 $\Sigma \Sigma^T$는 $\Lambda$이다. (직접 계산해보라) 이 때문에 결과적으로 식은 아래와 같이 정리된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;AA^T = U\Lambda U^T&lt;/script&gt;

&lt;p&gt;여기서 $U$는 &lt;strong&gt;정방행렬&lt;/strong&gt;이기에 위에서 본 &lt;strong&gt;Spectral Decomposition&lt;/strong&gt;의 식을 참조하면, $U$는 $AA^T$를 &lt;strong&gt;Eigenvalue Decomposition&lt;/strong&gt;으로 직교대각화하여 얻은 &lt;strong&gt;직교행렬&lt;/strong&gt;임을 알 수 있다. $A$의 rank가 k일 때, 이 $U$의 왼쪽에서부터 k번째 열벡터까지를 &lt;strong&gt;좌특이벡터&lt;/strong&gt;(Left Singular Vectors)라고 부른다.&lt;/p&gt;

&lt;p&gt;같은 방식으로 $A^TA = V\Lambda V^T$에서 $V$는 $A^TA$를 &lt;strong&gt;Eigenvalue Decomposition&lt;/strong&gt;으로 직교대각화하여 얻은 &lt;strong&gt;직교행렬&lt;/strong&gt;이 된다.&lt;/p&gt;

&lt;p&gt;SVD를 기하학적으로 설명하면, $V^T, U$에 의해서 A 행렬의 방향이 변화하게 되고 $\Sigma$에 의해서 scale이 조정된다고 볼 수 있다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;4-잠재-요인-협업-필터링의-matrix-factorization&quot;&gt;4. 잠재 요인 협업 필터링의 Matrix Factorization&lt;/h2&gt;
&lt;p&gt;위에서 설명한 SVD는 잠재요인을 밝혀내기에 아주 적합한 방법이지만, 실제 현실에서 원행렬 A에는 결측값이(당연히 모든 사용자가 모든 아이템에 대해 평점을 남겼다면, 굳이 추천 시스템이 필요하지 않을 것이다.) 많다. 따라서 이를 대체할 근사적인 방법이 필요하며, 그 방법에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;SGD(Stochastic Gradient Descent)&lt;/code&gt; 또는 &lt;code class=&quot;highlighter-rouge&quot;&gt;ALS(Alternating Least Squares)&lt;/code&gt;가 있다. 이 방법들에 대해서는 &lt;a href=&quot;https://greeksharifa.github.io/machine_learning/2019/12/20/Matrix-Factorization/&quot;&gt;다음 글&lt;/a&gt;을 참조하기 바란다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SGD&lt;/code&gt;를 이용해서 행렬을 분해하면 다음과 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-17-Recommendation System/03.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;이 때 요인의 개수는 하이퍼파라미터로 임의로 조정하거나, Cross-Validation을 통해 최적의 값을 찾을 수 있다. 위에서 분해된 행렬을 다시 내적하여 원 행렬을 예측해보면 아래와 같이 크게 차이가 나지 않음을 알 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-17-Recommendation System/04.JPG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;5-간단한-예제&quot;&gt;5. 간단한 예제&lt;/h2&gt;
&lt;p&gt;위에서 봤던 행렬 분해를 코드로 구현해보자. 좀 더 자세한 설명을 원한다면 아래 Reference에 있는 “파이썬 머신러닝 완벽 가이드”를 찾아보길 바란다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean_squared_error&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;R&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NaN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NaN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NaN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NaN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NaN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NaN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NaN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NaN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 실제 R 행렬과 예측 행렬의 오차를 구하는 함수
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calculate_rmse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;non_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;full_pred_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 여기서 non_zeros는 아래 함수에서 확인할 수 있다.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;x_non_zero_ind&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;non_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;non_zeros&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;non_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y_non_zero_ind&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;non_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;non_zeros&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;non_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 원 행렬 R에서 0이 아닌 값들만 추출한다.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;R_non_zeros&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_non_zero_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_non_zero_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 예측 행렬에서 원 행렬 R에서 0이 아닌 위치의 값들만 추출하여 저장한다.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;full_pred_matrix_non_zeros&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;full_pred_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_non_zero_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_non_zero_ind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;mse&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean_squared_error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_non_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;full_pred_matrix_non_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rmse&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rmse&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;matrix_factorization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_lambda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;num_users&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_items&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_users&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# R&amp;gt;0인 행 위치, 열 위치, 값을 non_zeros 리스트에 저장한다.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;non_zeros&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_users&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# SGD 기법으로 P, Q 매트릭스를 업데이트 함
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;non_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# 잔차 구함
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;eij&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# Regulation을 반영한 SGD 업데이터 적용
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eij&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_lambda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eij&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_lambda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;rmse&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_rmse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;non_zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;iter step: {0}, rmse: {1:4f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rmse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matrix_factorization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pred_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3.99062329&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.89653623&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.30649077&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.00210666&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.66340846&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;6.69571106&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;4.97792757&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.97850229&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.98066034&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0028451&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;6.67689303&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.39076095&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.98728588&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;3.9769208&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;3.98610743&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;4.96790858&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.00517956&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.00634763&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.01691675&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.14044567&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;6-surprise-모듈을-활용한-예제&quot;&gt;6. Surprise 모듈을 활용한 예제&lt;/h2&gt;
&lt;p&gt;Movielens 데이터를 이용하여 &lt;code class=&quot;highlighter-rouge&quot;&gt;잠재 요인 협업 필터링&lt;/code&gt;을 간단히 시연해보도록 하겠다. 본 모듈은 추천 시스템에 널리 쓰이는 대표적인 알고리즘들을 패키지화한 것으로, 사이킷런의 API와 프레임워크와 굉장히 유사하다. 다만 엄격한 Input 체계를 갖추고 있는데, 반드시 &lt;code class=&quot;highlighter-rouge&quot;&gt;사용자 ID&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;아이템 ID&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;평점&lt;/code&gt;만이 포함되어 있는 Row 레벨 형태의 데이터만 Input으로 받아들인다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Surprise 패키지: scikit-surprise
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;surprise&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SVD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Reader&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;surprise.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_builtin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ml-100k'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;위에서 쓴 &lt;code class=&quot;highlighter-rouge&quot;&gt;load_builtin&lt;/code&gt; 메서드는 Movielens 홈페이지에 들를 필요 없이 해당 사이트의 데이터를 다운로드 받고 로드하는 메서드인데, 사실 앞으로 다른 데이터를 쓴다면 크게 쓸 일이 없다. Surprise 모듈은 데이터 로드를 위해 2개의 메서드를 추가적으로 제공한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# load_from_file: OS 파일 로딩
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ratings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/ratings.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ratings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/ratings_noh.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# line_format: 칼럼을 순서대로 나열함. 공백으로 분리
# rating_scale: 평점의 단위
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Reader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line_format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'user item rating timestamp'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;','&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;rating_scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_from_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/ratings_noh.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# load_from_df: Pandas DataFrame 으로 로딩
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ratings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/ratings.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;reader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Reader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rating_scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_from_df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ratings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'userId'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'movieId'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'rating'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reader&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 데이터셋을 훈련 데이터와 테스트 데이터로 분할한 뒤 적합을 해보자.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;trainset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 알고리즘 객체 생성
# SVD: n_factors(K), n_epochs(디폴트 20), biased=True(베이스라인 사용자 편향 적용 여부)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;algo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SVD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_factors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;algo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;예측을 위해선 &lt;code class=&quot;highlighter-rouge&quot;&gt;test&lt;/code&gt; 메서드와 &lt;code class=&quot;highlighter-rouge&quot;&gt;predict&lt;/code&gt; 메서드가 제공되는데, 전자의 경우 테스트 데이터셋 전체에 대한 예측 값을, 후자의 경우 하나의 개체에 대한 예측 값을 출력한다. 따라서 &lt;code class=&quot;highlighter-rouge&quot;&gt;predict&lt;/code&gt;의 결과를 모은 것이 &lt;code class=&quot;highlighter-rouge&quot;&gt;test&lt;/code&gt;의 결과라고 보면 이해하기 쉽다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;algo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;testset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;testset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'120'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'282'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_ui&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;4.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;est&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3.66&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;...,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;details&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'was_impossible'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}),&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;Prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'882'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'291'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_ui&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;4.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;est&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3.97&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;...,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;details&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'was_impossible'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}),&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;Prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'535'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'507'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_ui&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;5.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;est&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;4.15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;...,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;details&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'was_impossible'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# userID, itemID 는 string 으로 입력해야 함
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;196&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;iid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;302&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;algo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;196&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;302&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;r_ui&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;est&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;4.30&lt;/span&gt;   &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'was_impossible'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 정확도 평가
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rmse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Cross-Validation&lt;/strong&gt;을 통해 파라미터를 조정할 수도 있다. 코드 구현은 아래와 같다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;#cross_validate(algo=algo, data=data, measures=['RMSE', 'MAE'], cv=5, verbose=True)
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;algo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SVD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'n_epochs'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'n_factors'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SVD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;measures&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'RMSE'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'MAE'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rmse'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rmse'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;좀 더 자세한 정보와 다양한 기능에 대해 알아보고 싶다면 아래 공식 문서를 참조하길 바란다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;파이썬 머신러닝 완벽 가이드, 권철민, 위키북스
&lt;a href=&quot;https://brunch.co.kr/@kakao-it/84&quot;&gt;카카오 리포트&lt;/a&gt;
&lt;a href=&quot;https://surprise.readthedocs.io/en/stable/getting_started.html&quot;&gt;Surprise 모듈 문서&lt;/a&gt;
&lt;a href=&quot;https://rfriend.tistory.com/185&quot;&gt;SVD 설명&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>파이썬 numba 모듈 설명</title>
   <link href="http://localhost:4000/numba/"/>
   <updated>2019-12-16T00:00:00+09:00</updated>
   <id>http://localhost:4000/numba</id>
   <content type="html">&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;파이썬을 사용하다 보면 편리한 기능에 감탄하는 경우가 많지만 종종 속도에 대한 아쉬움을 느낄 때가 있다. 특히 머신러닝과 관련된 작업들을 하다 보면, 데이터 처리를 하는 과정에 있어서 좀 더 빠른 진행을 요구하는 경우가 많은데, 이를 위한 모듈 중 하나가 &lt;strong&gt;Numba&lt;/strong&gt;이다.&lt;/p&gt;

&lt;p&gt;공식문서를 확인해보면 아래와 같은 설명을 찾을 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Numba makes Python code fast.&lt;br /&gt;
Numba is an open source JIT compiler that translates a subset of Python and NumPy code into fast machine code.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;해석하면, 파이썬과 넘파이 코드를 빠르게 실행시켜주는 JIT 컴파일러라고 할 수 있겠다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Numba&lt;/strong&gt;의 작동원리는 다음과 같다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;데커레이팅된 함수에 대한 파이썬 bytecode를 일ㄹ고 이를 함수의 입력 인수 유형에 대한 정보와 결합한다.&lt;/li&gt;
    &lt;li&gt;코드를 분석하고 최적화한 후, LLVM compiler library를 사용하여 함수의 machine code 버전을 반들고, 이를 사용자의 CPU 능력에 맞춘다.&lt;/li&gt;
    &lt;li&gt;이 compiled된 버전이 앞으로 그 함수를 호출할 때마다 사용된다.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Numba&lt;/strong&gt;를 사용하기 위해서 새로운 언어를 배운다거나 할 필요는 전혀 없다. 역시 공식문서에서는 아래와 같이 밝히고 있다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;You don’t need to replace the Python interpreter, run a separate compilation step, 
or even have a C/C++ compiler installed.&lt;br /&gt;
Just apply one of the Numba decorators to your Python function, and Numba does the rest.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Numba 모듈이 모든 파이썬 코드를 최적화해주는 것은 아니다. 일부 파이썬 코드와 Numpy에 대해서만 작동하며 대다수의 다른 모듈을 이용한 코드를 최적화 시켜주지는 못한다. &lt;strong&gt;예를 들어 Numba은 Pandas를 이해하지 못한다.&lt;/strong&gt; 그럼에도 특정 목적에 따라 충분히 활용할 수 있는 가치가 있는 모듈이라고 할 수 있겠다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;2-기본적인-사용법&quot;&gt;2. 기본적인 사용법&lt;/h2&gt;
&lt;h3 id=&quot;21-예시&quot;&gt;2.1. 예시&lt;/h3&gt;
&lt;p&gt;예시를 살펴보면서 &lt;strong&gt;Numba&lt;/strong&gt;의 효과를 확인해보도록 하겠다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;perf_counter&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numba&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jit&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 일반적인 loop
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;pure_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Numba 모듈 사용
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nopython&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;numba_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 시간 재기: 일반
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;perf_counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pure_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perf_counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 시간 재기에 앞서 먼저 Compile을 해준다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numba_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 시간 재기: Numba
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;perf_counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;numba_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perf_counter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과는 아래와 같다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;mf&quot;&gt;6.040823099999898&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;# 일반
&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;4.590000003190653e-05&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Numba
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;pure 파이썬 코드보다 훨씬 빠르다는 것을 확인할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;22-jit-데커레이터의-모드&quot;&gt;2.2. @jit 데커레이터의 모드&lt;/h3&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;@jit&lt;/code&gt; 데커레이터는 &lt;strong&gt;nopython&lt;/strong&gt;과 &lt;strong&gt;object&lt;/strong&gt;라는 2가지 compilation 모드로 작동한다. 위 예제에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;nopython=True&lt;/code&gt;를 통해 Numba에게 &lt;strong&gt;nopython&lt;/strong&gt; 모드로 작동하라고 지시한 셈인데, 이 모드는 decorate된 function을 근본적으로 compile하여 Python Interpreter의 개입 없이 전체가 작동하도록 한다.&lt;/p&gt;

&lt;p&gt;만약 &lt;strong&gt;nopython&lt;/strong&gt; 모드가 잘 작동하지 않을 경우, Numba은 &lt;strong&gt;object&lt;/strong&gt; 모드를 통해 compile 할 수 있다. &lt;code class=&quot;highlighter-rouge&quot;&gt;@jit(nopython=True)&lt;/code&gt;가 아닌 &lt;code class=&quot;highlighter-rouge&quot;&gt;@jit&lt;/code&gt;이라고만 데커레이팅하면 이 모드가 작동하게 된다. 본 모드에서는 Numba은 loop를 식별하여 machine code에서 compile하며 나머지는 Intereter code에서 compile하게 된다. 더 나은 성능을 기대한다면 이 모드가 아닌 &lt;strong&gt;nopython&lt;/strong&gt; 모드를 사용해야 한다.&lt;/p&gt;

&lt;h3 id=&quot;23-다른-compilation-옵션들&quot;&gt;2.3. 다른 Compilation 옵션들&lt;/h3&gt;
&lt;h4 id=&quot;231-nogil&quot;&gt;2.3.1. nogil&lt;/h4&gt;
&lt;p&gt;Numba가 파이썬 코드를 native type과 변수에서만 작동하는 native code로 최적화하고 싶을 때, 파이썬의 GIL(Global Interpreter Lock)을 유지하는 것은 불필요하다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;@jit(nogil=True)&lt;/code&gt; 옵션을 사용하면 Numba는 GIL을 해제할 것이다.&lt;/p&gt;

&lt;h4 id=&quot;232-cache&quot;&gt;2.3.2. cache&lt;/h4&gt;
&lt;p&gt;파이썬 프로그램을 호출할 때, 컴파일 시간을 피하기 위해 function의 결과를 파일 기반 cache에 쓰도록 Numba에 지시할 수 있다. 이를 실행하기 위해서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;@jit(cache=True)&lt;/code&gt; 옵션을 사용하면 된다.&lt;/p&gt;

&lt;h4 id=&quot;233-parallel&quot;&gt;2.3.3. parallel&lt;/h4&gt;
&lt;p&gt;parallel semantics를 가진 function에 대해 자동화된 병렬화를 제공한다. 반드시 &lt;code class=&quot;highlighter-rouge&quot;&gt;nopython=True&lt;/code&gt; 모드에서만 실행되어야 하며 &lt;code class=&quot;highlighter-rouge&quot;&gt;@jit(nopython=True, parallel=True)&lt;/code&gt;를 통해 사용할 수 있다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;http://numba.pydata.org/numba-doc/latest/user/index.html&quot;&gt;공식문서&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>파이썬 logging Module 설명</title>
   <link href="http://localhost:4000/logging/"/>
   <updated>2019-12-13T00:00:00+09:00</updated>
   <id>http://localhost:4000/logging</id>
   <content type="html">&lt;h2 id=&quot;1-logging-module-소개&quot;&gt;1. logging Module 소개&lt;/h2&gt;
&lt;h3 id=&quot;11-introduction&quot;&gt;1.1. Introduction&lt;/h3&gt;
&lt;p&gt;logging 모듈은 파이썬 자체에 내장되어 있는 모듈로 사용이 간편함에도 불구하고 훌륭한 기능으로 널리 사용되고 있다. logging은 소프트웨어가 작동 중일 때 발생하는 여러 ‘사건’을 추적하고, 개발자는 이를 통해 어떤 ‘사건’이 발생하였고 따라서 앞으로 어떤 해결책을 강구해야 할지 판단하게 된다. 이러한 ‘사건’들은 각각 중요도가 다를 것인데, 본 logging 모듈은 이 중요도를 &lt;strong&gt;level&lt;/strong&gt;이라고 정의하고 있다. &lt;strong&gt;level&lt;/strong&gt;에 대한 설명은 아래 1.2장에서 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;지금은 잠시 간단한 예시를 확인해 보자. 예를 들어 다음과 같은 메서드를 만들었다고 하자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ZeroDivisionError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exception&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Division by zero is not possible&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;당연하게도 b에 0을 대입하면 에러가 발생할 것이다. 개발 코드 중에 실수로 b에 0을 대입할 가능성이 있다고 하자. 그렇다면 언제 어떻게 에러가 발생하는지 기록으로 남겨두면 좋을 것이다. 그래야 디버깅이 편리하고 효율적으로 이루어질 수 있다.&lt;/p&gt;

&lt;p&gt;실제로 에러가 발생하면 다음과 같은 형식으로 메시지가 뜰 것이다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;22&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;29&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;49&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;091&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ERROR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Division&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zero&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;possible&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Traceback&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;most&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recent&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;call&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;File&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;ipython-input-38-41356b58271d&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cal&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;ZeroDivisionError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;division&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zero&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위에서 볼 수 있는 메시지의 형식과 내용 등은 모두 logging 모듈로 제어할 수 있다. 예를 들어 root의 경우 RootLogger을 의미하는데, 사용자가 직접 설정한 Logger 이름이 출력되게 할 수 있다. 이러한 기능은 수많은 파일과 class 등이 난무할 때 어디서 문제가 발생하였는지 쉽게 알 수 있게 해줄 것이다.&lt;/p&gt;

&lt;p&gt;본 글은 우선적으로 logging 모듈의 가장 기본적인 기능들을 정리하는 데에 초점을 맞추었다. logger Module에 대해 더욱 자세히 알고 싶다면 아래 Reference에 있는 참고 사이트를 확인하길 바란다.&lt;/p&gt;

&lt;h3 id=&quot;12-작동-원리-확인&quot;&gt;1.2. 작동 원리 확인&lt;/h3&gt;
&lt;p&gt;1) Level 설정&lt;br /&gt;
logging은 &lt;strong&gt;level&lt;/strong&gt; 설정을 통해 메시지의 중요도를 구분한다. 총 5개의 기본 &lt;strong&gt;level&lt;/strong&gt;이 제공되는데, 설정에 변화를 주지 않는다면 &lt;strong&gt;WARNING&lt;/strong&gt;이 기본 &lt;strong&gt;level&lt;/strong&gt;로 지정되어 있다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Level&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;DEBUG&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;간단히 문제를 진단하고 싶을 때 필요한 자세한 정보를 기록함&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;INFO&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;계획대로 작동하고 있음을 알리는 확인 메시지&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;WARNING&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;소프트웨어가 작동은 하고 있지만,&lt;br /&gt;&lt;br /&gt;예상치 못한 일이 발생했거나 할 것으로 예측된다는 것을 알림&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;ERROR&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;중대한 문제로 인해 소프트웨어가 몇몇 기능들을 수행하지 못함을 알림&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;CRITICAL&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;작동이 불가능한 수준의 심각한 에러가 발생함을 알림&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;2) logging work flow 확인&lt;br /&gt;
본 모듈을 작동시키는 중요한 구성 요소들은 아래와 같다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;logger, handler, filter, formatter&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Log 사건 정보들은 LogRecord Instance 안에 있는 위 요소들 사이에서 전송되는 것이다.&lt;/p&gt;

&lt;p&gt;이들의 역할을 알아보면,&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Logger&lt;/strong&gt;: 어플리케이션 코드가 직접 사용할 수 있는 인터페이스를 제공함&lt;br /&gt;
&lt;strong&gt;Handler&lt;/strong&gt;: logger에 의해 만들어진 log 기록들을 적합한 위치로 보냄&lt;br /&gt;
&lt;strong&gt;Filter&lt;/strong&gt;: 어떤 log 기록들이 출력되어야 하는지를 결정함&lt;br /&gt;
&lt;strong&gt;Formatter&lt;/strong&gt;: log 기록들의 최종 출력본의 레이아웃을 결정함&lt;/p&gt;

&lt;p&gt;logging은 &lt;strong&gt;Logger class&lt;/strong&gt;의 Instance (=logger)를 선언하는 것으로 부터 시작한다. 각 logger는 &lt;strong&gt;name&lt;/strong&gt;을 가지는데, 이 &lt;strong&gt;name&lt;/strong&gt;들은 &lt;strong&gt;마침표&lt;/strong&gt;를 통해 계층적 관계를 형성하게 된다. 즉 예를 들어 &lt;strong&gt;Basket.html&lt;/strong&gt;이라는 logger가 있다고 한다면, 이는 &lt;strong&gt;Basket&lt;/strong&gt;이라는 logger가 &lt;strong&gt;html&lt;/strong&gt;이라는 logger의 부모 역할을 하게 되는 것이다. 파이썬의 부모-자식 상속 관계를 투영한 것으로, 설정을 변화시키지 않으면 자식 logger는 부모 logger의 여러 특성들을 물려받게 된다.&lt;/p&gt;

&lt;p&gt;이후 &lt;strong&gt;Handler&lt;/strong&gt;를 통해 log 기록들을 어디에 표시하고, 어디에 기록할지 결정하게 된다. &lt;strong&gt;Filter&lt;/strong&gt;는 logging 모듈을 간단히 사용할 때는 잘 쓰이지는 않지만 &lt;strong&gt;level&lt;/strong&gt;보다 더 복잡한 필터링을 원할 때 사용된다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Formatter&lt;/strong&gt;는 실제로 출력되는 형식을 결정한다.&lt;/p&gt;

&lt;p&gt;work flow에 대해 더욱 자세히 알고 싶다면 &lt;a href=&quot;https://docs.python.org/3.7/library/logging.html#filter&quot;&gt;이곳&lt;/a&gt;을 참조하기 바란다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;2-실질적인-사용법&quot;&gt;2. 실질적인 사용법&lt;/h2&gt;
&lt;h3 id=&quot;21-차례대로-logging-준비하기&quot;&gt;2.1. 차례대로 logging 준비하기&lt;/h3&gt;
&lt;h4 id=&quot;211-logger-생성&quot;&gt;2.1.1. logger 생성&lt;/h4&gt;
&lt;p&gt;logging instance인 logger는 아래와 같은 구문으로 생성한다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getLogger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위 &lt;strong&gt;“name”&lt;/strong&gt; 에는 String이 들어가는데, 아무것도 입력하지 않을 경우 &lt;strong&gt;root logger&lt;/strong&gt;가 생성된다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;root logger&lt;/strong&gt;는 모든 logger의 부모와 같은 존재로, 다른 모든 logger는 설정을 변화시키지 않으면 &lt;strong&gt;root logger&lt;/strong&gt;의 자식이다. &lt;strong&gt;root logger&lt;/strong&gt;을 바로 사용할 수도 있지만, 기능과 목적에 따라 다른 logger들을 생성하는 것이 낫다.&lt;/p&gt;

&lt;h4 id=&quot;212-logger에-level-부여하기&quot;&gt;2.1.2. logger에 level 부여하기&lt;/h4&gt;
&lt;p&gt;logger를 생성했다면, 이제는 기본적인 &lt;strong&gt;level&lt;/strong&gt;을 부여해줄 차례다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setLevel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INFO&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;앞서 생성한 logger에 INFO &lt;strong&gt;level&lt;/strong&gt;을 부여하였다. 이제 이 logger 객체는 &lt;strong&gt;INFO&lt;/strong&gt; 이상의 메시지를 출력할 수 있다.&lt;br /&gt;
&lt;strong&gt;level&lt;/strong&gt;을 소문자로 바꾸어 메서드로 사용하면 메시지를 출력할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Message&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;현재로서 이 logger는 오직 console에만 메시지를 출력할 수 있을 뿐이다. 더욱 정교하게 만들기 위해서는 &lt;strong&gt;handler&lt;/strong&gt;가 필요하다.&lt;/p&gt;

&lt;h4 id=&quot;213-handler와-formatter-설정하기&quot;&gt;2.1.3. handler와 formatter 설정하기&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;handler&lt;/strong&gt; object는 log 메시지의 &lt;strong&gt;level&lt;/strong&gt;에 따라 적절한 log 메시지를 지정된 위치에 전달(dispatch)하는 역할을 수행한다.&lt;/p&gt;

&lt;p&gt;logger는 &lt;strong&gt;addHandler&lt;/strong&gt; 메서드를 통해 이러한 handler를 추가할 수 있다. &lt;strong&gt;handler&lt;/strong&gt;는 기능과 목적에 따라 여러 개일 수 있으며, 각 handler는 다른 level과 다른 format을 가질 수도 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;handler&lt;/strong&gt;의 종류는 15개 정도가 있는데, 가장 기본적인 것은 &lt;strong&gt;StreamHandler&lt;/strong&gt;와 &lt;strong&gt;FileHandler&lt;/strong&gt;이다. 전자는 Stream(console)에 메시지를 전달하고, 후자는 File(예를 들어 info.log)에 메시지를 전달하는 역할을 한다. 다른 &lt;strong&gt;handler&lt;/strong&gt;가 궁금하다면 &lt;a href=&quot;https://docs.python.org/3.7/howto/logging.html#useful-handlers&quot;&gt;이곳&lt;/a&gt;을 참조하기 바란다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;handler&lt;/strong&gt; 객체의 level까지 설정했다면, 이제 이 메시지를 어떤 형식으로 출력할지에 대해 고민해야 한다.&lt;br /&gt;
이 때 필요한 것이 &lt;strong&gt;formatter&lt;/strong&gt;이다. 아래와 같이 생성한다. format을 좀 더 편리하게 작성하는 방법에 대해서는 3장에서 설명하겠다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Formatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;fmt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# 메시지 출력 형태. None일 경우 raw 메시지를 출력.
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;datefmt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 날짜 출력 형태. None일 경우 '%Y-%m-%d %H:%M:%S'.
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;style&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'%'&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# '%', '{', '$' 중 하나. `fmt`의 style을 결정.
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 준비는 끝났다. handler 객체는 아래와 같이 만들어진다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# handler 객체 생성
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream_handler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StreamHandler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;file_handler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FileHandler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;information.log&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# formatter 객체 생성
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;formatter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Formatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%(asctime)s - %(name)s - %(levelname)s - %(message)s&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# handler에 level 설정
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream_handler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setLevel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INFO&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;file_handler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setLevel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DEBUG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# handler에 format 설정
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream_handler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setFormatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;formatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;file_handler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setFormatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;formatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;부가적으로 하나 더 설명하자면, 위에 있는 간단한 예시의 경우 단지 하나의 logger를 생성했을 뿐이지만, 실제로는 여러개의 logger를 계층적으로 사용할 가능성이 높다. 이러한 계층적인 구조와 관련하여, 앞의 1.2장에서 언급한 부모-자식 관계와 관련하여 염두에 두어야 할 부분이 있다.&lt;/p&gt;

&lt;p&gt;자식 logger는 부모 logger와 관련된 handler로 메시지를 &lt;strong&gt;전파&lt;/strong&gt;(propagate)한다. 즉, 부모 logger의 설정은 자식 logger과 연결되어 있다. 이 때문에 사실 모든 logger에 대해 handler를 일일히 정의하고 설정하는 것은 불필요한 일이라고 볼 수 있다. 따라서 가장 효율적인 방법은 최상위 logger에 대해 handler 설정을 완료하고 때에 따라 자식 logger를 생성하는 것이 될 것이다. 만약 이러한 연결을 원치 않는다면, 아래와 같이 logger의 propagate attribute를 False로 설정해주면 된다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;propagate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;214-logger에-생성한-handler-추가하기&quot;&gt;2.1.4. logger에 생성한 handler 추가하기&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addHandler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream_handler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addHandler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_handler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위 과정을 거치면, 지금까지 설정한 모든 것들이 logger에 담기게 된다.&lt;/p&gt;

&lt;h3 id=&quot;22-빠른-setting&quot;&gt;2.2. 빠른 Setting&lt;/h3&gt;
&lt;p&gt;위에서 차근차근 알아본 logging 모듈 사용법을 확실히 익혔다면, 기본적인 Setting 환경을 만들어두고 이를 조금씩 변형하여 사용하는 것이 편리할 것이다.&lt;/p&gt;

&lt;p&gt;Setting을 진행하는 방법에는 여러가지가 있는데, 본 글에서는 그 중 1) json 파일로 setting하는 법과 2) 파이썬 코드로 하는 법에 대해 설명할 것이다. 본 예제에서는 INFO를 기본 level로 설정한다.&lt;/p&gt;

&lt;h4 id=&quot;221-json-파일로-세팅&quot;&gt;2.2.1. json 파일로 세팅&lt;/h4&gt;
&lt;p&gt;아래와 같은 json 파일을 만들어보자.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;version&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;formatters&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;basic&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;format&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;%(asctime)s - %(name)s - %(levelname)s - %(message)s&quot;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;

    &lt;span class=&quot;s&quot;&gt;&quot;handlers&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;console&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;class&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;logging.StreamHandler&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;level&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;INFO&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;formatter&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;basic&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;stream&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;ext://sys.stdout&quot;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;

        &lt;span class=&quot;s&quot;&gt;&quot;file_handler&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;class&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;logging.FileHandler&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;level&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;DEBUG&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;formatter&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;basic&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;&quot;filename&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;info.log&quot;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;

    &lt;span class=&quot;s&quot;&gt;&quot;root&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;level&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;INFO&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;handlers&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;console&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;file_handler&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;첫 문단에서 &lt;strong&gt;basic&lt;/strong&gt;이라는 이름의 format을 만들었다. 앞으로 설정을 변경하지 않는 이상 [시간-logger이름-level이름-메시지] 형식으로 출력됨을 의미한다.&lt;/p&gt;

&lt;p&gt;두 번째 문단과 세 번째 문단은 2개의 handler에 대한 설정이다. &lt;strong&gt;console&lt;/strong&gt;은 말 그대로 console(Stream)에 출력되는 handler로, logging.StreamHandler class로 구성되며 위에서 설정한 &lt;strong&gt;basic&lt;/strong&gt; format을 사용함을 알 수 있다. 이 handler의 level은 INFO이다. &lt;strong&gt;file_handler&lt;/strong&gt;는 디렉토리 내에 info.log란 파일을 생성하여 로그를 기록하면서 저장하는 handler이다. 이 handler의 level은 DEBUG이다.&lt;/p&gt;

&lt;p&gt;마지막 문단에서는 root logger에 대한 설정을 마무리하고 있다.&lt;/p&gt;

&lt;p&gt;이제 json 파일을 읽어오자.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;logging.json&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;rt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;config&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictConfig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getLogger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;222-코드로-세팅&quot;&gt;2.2.2. 코드로 세팅&lt;/h4&gt;
&lt;p&gt;사실 코드로 세팅한다는 것은 위에 있는 정보들을 코드로 입력한다는 것에 불과하다. 위에서 자세히 설명한 것을 다시 한 번 확인하는 수준이라고 생각하면 될 것이다. 특별할 것이 없으므로 바로 확인해보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;make_logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;#1 logger instance를 만든다.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getLogger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;#2 logger의 level을 가장 낮은 수준인 DEBUG로 설정해둔다.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setLevel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DEBUG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;#3 formatter 지정
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;formatter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Formatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%(asctime)s - %(name)s - %(levelname)s - %(message)s&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;#4 handler instance 생성
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;console&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StreamHandler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;file_handler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FileHandler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test.log&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;#5 handler 별로 다른 level 설정
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setLevel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INFO&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;file_handler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setLevel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DEBUG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;#6 handler 출력 format 지정
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setFormatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;formatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;file_handler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setFormatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;formatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;#7 logger에 handler 추가
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addHandler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addHandler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;file_handler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;#2 과정&lt;/strong&gt;에서 만일 가장 낮은 수준으로 level을 설정하지 않는다면, 아래 handler들에서 &lt;strong&gt;setLevel&lt;/strong&gt;을 한 것이 무의미해진다는 점을 꼭 알아두길 바란다. (handler 별로 다른 level 설정하기)&lt;/p&gt;

&lt;p&gt;위 코드를 보면 &lt;strong&gt;console&lt;/strong&gt;에 표기되는 &lt;strong&gt;StreamHandler&lt;/strong&gt;에는 &lt;strong&gt;INFO&lt;/strong&gt; level을, &lt;strong&gt;파일&lt;/strong&gt;에 기록되는 &lt;strong&gt;FileHandler&lt;/strong&gt;에는 &lt;strong&gt;DEBUG&lt;/strong&gt; level을 설정한 것을 확인할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;debug&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warning&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위와 같은 코드를 입력하면, &lt;strong&gt;console&lt;/strong&gt; 창에는 아래와 같이 기록되지만,&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;133&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INFO&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;679&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;root&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;WARNING&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;test.log file&lt;/strong&gt;에는 아래와 같이 기록됨을 확인할 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-12-13-logging/01.JPG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;3-format-편리하게-설정하기&quot;&gt;3. Format 편리하게 설정하기&lt;/h2&gt;
&lt;p&gt;바로 위의 log 기록들은 사실 아주 도움이 되는 정보들이라고 하기는 어렵다. line 번호도 없고, file 이름도 없다. logging 모듈은 이러한 log 기록들을 남길 때 굉장히 다양한 형식을 지원하고 있다. 그 형식에 대해 알아보기 전에 먼저 log 기록들, 즉 &lt;strong&gt;LogRecord Objects&lt;/strong&gt;에 대해 알아보도록 하자.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LogRecord 객체&lt;/strong&gt;는 Logger에 의해 자동적으로 생성되며, 수동으로 생성하려면 &lt;strong&gt;makeLogRecord&lt;/strong&gt; 메서드를 이용하면 된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;logging.LogRecord(name, level, pathname, lineno, msg, …)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여기서 pathname은 logging call이 만들어지는 소스 파일의 전체 pathname을 의미한다.&lt;br /&gt;
lineno는 logging call이 만들어지는 소스파일의 라인 번호를 말한다.&lt;br /&gt;
msg는 event description 메시지를 의미한다.&lt;/p&gt;

&lt;p&gt;이 LogRecord는 여러 속성(attribute)을 갖고 있는데, 이 속성들은 format을 정의하는데 활용된다.&lt;br /&gt;
그 리스트와 설명은 아래와 같다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;속성 이름&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;format&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;asctime&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;%(asctime)s&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;인간이 읽을 수 있는 시간 표시&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;created&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;%(created)f&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;logRecord가 만들어진 시간&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;filename&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;%(filename)s&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;pathname의 file 이름 부분&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;funcName&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;%(funcName)s&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;logging call을 포함하는 function의 이름&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;levelname&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;%(levelname)s&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;메시지의 Text logging level: 예) INFO&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;lineno&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;%(lineno)d&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;logging call이 발생한 코드의 line 숫자&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;module&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;%(module)s&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;filename의 모듈 이름 부분&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;message&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;%(message)s&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;메시지&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;name&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;%(name)s&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;logger의 이름&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;pathname&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;%(pathname)s&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;full pathname&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;thread&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;%(thread)d&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;thread ID&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;threadName&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;%(threadName)s&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;thread 이름&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;간단한 예는 아래와 같다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;LOG_FORMAT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;[%(asctime)-10s] (줄 번호: %(lineno)d) %(name)s:%(levelname)s - %(message)s&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;basicConfig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LOG_FORMAT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logging&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getLogger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;setting&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setLevel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;logger&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sth happened&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2019&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;53&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;29&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;889&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;줄&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;번호&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;setting&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;INFO&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sth&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;happened&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://docs.python.org/3.7/howto/logging.html#when-to-use-logging&quot;&gt;공식문서&lt;/a&gt;
https://hamait.tistory.com/880
https://www.machinelearningplus.com/python/python-logging-guide/
https://snowdeer.github.io/python/2017/11/17/python-logging-example/&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>Light GBM 설명 및 사용법</title>
   <link href="http://localhost:4000/Light-GBM/"/>
   <updated>2019-12-09T00:00:00+09:00</updated>
   <id>http://localhost:4000/Light GBM</id>
   <content type="html">&lt;h2 id=&quot;1-light-gbm-a-highly-efficient-gradient-boosting-decision-tree-논문-리뷰&quot;&gt;1. Light GBM: A Highly Efficient Gradient Boosting Decision Tree 논문 리뷰&lt;/h2&gt;
&lt;h3 id=&quot;11-background-and-introduction&quot;&gt;1.1. Background and Introduction&lt;/h3&gt;
&lt;p&gt;다중 분류, 클릭 예측, 순위 학습 등에 주로 사용되는 &lt;strong&gt;Gradient Boosting Decision Tree (GBDT)&lt;/strong&gt;는 굉장히 유용한 머신러닝 알고리즘이며, XGBoost나 pGBRT 등 효율적인 기법의 설계를 가능하게 하였다. 이러한 구현은 많은 엔지니어링 최적화를 이룩하였지만 고차원이고 큰 데이터 셋에서는 만족스러운 결과를 내지 못하는 경우도 있었다. 왜냐하면 모든 가능한 분할점에 대해 정보 획득을 평가하기 위해 데이터 개체 전부를 스캔해야 했기 때문이다. 이는 당연하게도, 굉장히 시간 소모적이다.&lt;/p&gt;

&lt;p&gt;본 논문은 이 문제를 해결하기 위해 2가지 최신 기술을 도입하였다.&lt;br /&gt;
첫 번째는 &lt;strong&gt;GOSS: Gradient-based One-Side Sampling&lt;/strong&gt;이며, 기울기가 큰 데이터 개체가 정보 획득에 있어 더욱 큰 역할을 한다는 아이디어에 입각해 만들어진 테크닉이다. 큰 기울기를 갖는 개체들은 유지되며, 작은 기울기를 갖는 데이터 개체들은 일정 확률에 의해 랜덤하게 제거된다.&lt;/p&gt;

&lt;p&gt;두 번째는 &lt;strong&gt;EFB: Exclusive Feature Bundling&lt;/strong&gt;으로, 변수 개수를 줄이기 위해 상호배타적인 변수들을 묶는 기법이다. 원핫 인코딩된 변수와 같이 희소한(Sparse) 변수 공간에서는 많은 변수들이 상호 배타적인 경우가 많다. (0이 굉장히 많기 때문에) 본 테크닉은, 최적 묶음 문제를 그래프 색칠 문제로 치환하고 일정 근사 비율을 갖는 Greedy 알고리즘으로 이 문제를 해결한다.&lt;/p&gt;

&lt;h3 id=&quot;12-preliminaries&quot;&gt;1.2. Preliminaries&lt;/h3&gt;
&lt;p&gt;GBDT는 Decision Tree의 앙상블 모델이다. 각각의 반복에서 GBDT는 음의 기울기(잔차 오차)를 적합함으로써 Decision Tree를 학습시킨다. 이 학습 과정에서 가장 시간이 많이 소모되는 과정이 바로 최적의 분할점들을 찾는 것인데, 이를 위한 대표적인 방법에는 &lt;strong&gt;Pre-sorted(사전 정렬) 알고리즘&lt;/strong&gt;과 &lt;strong&gt;Histogram-based 알고리즘&lt;/strong&gt;이 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pre-sorted 알고리즘&lt;/strong&gt;의 경우 사전 정렬한 변수 값에 대해 가능한 모든 분할점을 나열함으로써 간단하게 최적의 분할점을 찾을 수 있지만, 효율적이지 못하다는 단점이 있다. &lt;strong&gt;Histogram-based 알고리즘&lt;/strong&gt;은 연속적인 변수 값을 이산적인 구간(bin)으로 나누고, 이 구간을 사용하여 학습과정 속에서 피쳐 히스토그램을 구성한다.&lt;/p&gt;

&lt;p&gt;학습 데이터의 양을 줄이기 위해 가장 쉽게 생각할 수 있는 방법은 Down Sampling이 될 것이다. 이는 만약 데이터 개체의 중요도(Weight)가 설정한 임계값을 넘지 못할 경우 데이터 개체들이 필터링되는 과정을 말한다. SGB의 경우 약한 학습기를 학습시킬 때 무작위 부분집합을 사용하지만, SGB를 제외한 Down Sampling 방식은 AdaBoost에 기반하였기 때문에 바로 GBDT에 적용시킬 수 없다. 왜냐하면 AdaBoost와 달리 GBDT에는 데이터 개체에 기본 가중치가 존재하지 않기 대문이다.&lt;/p&gt;

&lt;p&gt;비슷한 방식으로 피쳐 수를 줄이기 위해서는, 약한(Weak) 피쳐를 필터링하는 것이 자연스러울 것이다. 그러나 이러한 접근법은 변수들 사이에 중대한 중복요소가 있을 것이라는 가정에 의존하는데, 실제로는 이 가정이 옳지 않을 수도 있다.&lt;/p&gt;

&lt;p&gt;실제 상황에서 사용되는 대용량 데이터셋은 많은 경우에 희소한(Sparse) 데이터셋일 확률이 높다. Pre-sorted 알고리즘에 기반한 GBDT의 경우 0값을 무시함으로써 학습 비용을 절감할 수 있지만, Histogram-based 알고리즘에 기반한 GBDT에는 효율적인 희소값 최적화 방법이 없다. 그 이유는 Histogram-based 알고리즘은 피쳐 값이 0이든 1이든, 각 데이터 개체마다 피쳐 구간(Bin) 값을 추출해야하기 때문이다. 따라서 Histogram-based 알고리즘에 기반한 GBDT가 희소 변수를 효과적으로 활용할 방안이 요구된다. 이를 해결하기 위한 방법이 바로 앞서 소개한 &lt;strong&gt;GOSS&lt;/strong&gt;와 &lt;strong&gt;EFB&lt;/strong&gt;인 것이다. &lt;strong&gt;GOSS&lt;/strong&gt;는 데이터 개체 수를 줄이고, &lt;strong&gt;EFB&lt;/strong&gt;는 피쳐 수를 줄이는 방법론이다.&lt;/p&gt;

&lt;h3 id=&quot;13-goss-gradient-based-one-sided-sampling&quot;&gt;1.3. GOSS: Gradient-based One-Sided Sampling&lt;/h3&gt;
&lt;p&gt;AdaBoost에서 Sample Weight는 데이터 개체의 중요도를 알려주는 역할을 수행하였다. GBDT에서는 기울기(Gradient)가 이 역할을 수행한다. 각 데이터 개체의 기울기가 작으면 훈련 오차가 작다는 것을 의미하므로, 이는 학습이 잘 되었다는 뜻이다. 이후 이 데이터를 그냥 제거한다면 데이터의 분포가 변화할 것이므로, 다른 접근법(GOSS)이 필요하다.&lt;/p&gt;

&lt;p&gt;GOSS의 아이디어는 직관적이다. 큰 Gradient(훈련이 잘 안된)를 갖는 데이터 개체들은 모두 남겨두고, 작은 Gradient를 갖는 데이터 개체들에서는 무작위 샘플링을 진행하는 것이다. 이를 좀 더 상세히 설명하자면 아래와 같다.&lt;/p&gt;

&lt;p&gt;1) 데이터 개체들의 Gradient의 절대값에 따라 데이터 개체들을 정렬함&lt;br /&gt;
2) 상위 100a% 개의 개체를 추출함&lt;br /&gt;
3) 나머지 개체들 집합에서 100b% 개의 개체를 무작위로 추출함&lt;br /&gt;
4) 정보 획득을 계산할 때, 위의 2-3 과정을 통해 추출된 Sampled Data를 상수( $ \frac{1-a} {b} $ )를 이용하여 증폭시킴&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-09-Light GBM/01.JPG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 그림에 대하여 추가적으로 부연설명을 하면,&lt;br /&gt;
&lt;strong&gt;topN, randN&lt;/strong&gt;은 2, 3 과정에서 뽑는 개수를 의미하며,&lt;br /&gt;
&lt;strong&gt;topSet, randSet&lt;/strong&gt; 은 2, 3 과정에서 뽑힌 데이터 개체 집합을 의미한다.&lt;br /&gt;
&lt;strong&gt;w[randSet] x= fact&lt;/strong&gt;은 증폭 벡터를 구성하는 과정으로, 증폭 벡터는 randSet에 해당하는 원소는 fact 값을 가지고, 나머지 원소는 1의 값을 가지는 벡터이다.&lt;/p&gt;

&lt;p&gt;마지막으로 &lt;strong&gt;L: Weak Learner&lt;/strong&gt;에 저장된 정보는, 훈련데이터, Loss, 증폭된 w벡터로 정리할 수 있겠다.&lt;/p&gt;

&lt;h3 id=&quot;14-efb-exclusive-feature-bundling&quot;&gt;1.4. EFB: Exclusive Feature Bundling&lt;/h3&gt;
&lt;p&gt;희소한 변수 공간의 특성에 따라 배타적인 변수들을 하나의 변수로 묶을 수 있다. 그리고 이를 배타적 변수 묶음(Exclusive Feature Bundle)이라고 부른다. 정교하게 디자인된 변수 탐색 알고리즘을 통해, 각각의 변수들로 했던 것과 마찬가지로 변수 묶음들로부터도 동일한 변수 히스토그램들을 생성할 수 있게 된다.&lt;/p&gt;

&lt;p&gt;이제 1) 어떤 변수들이 함께 묶여야 하는지 정해야 하며, 2) 어떻게 묶음을 구성할 것인가에 대해 알아볼 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;정리&lt;/strong&gt;: 변수들을 가장 적은 수의 배타적 묶음으로 나누는 문제는 NP-hard이다.&lt;br /&gt;
(NP-hard의 뜻을 알아보기 위해서는 &lt;a href=&quot;https://wkdtjsgur100.github.io/P-NP/&quot;&gt;이곳&lt;/a&gt;을 참조하길 바란다.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;증명&lt;/strong&gt;: 그래프 색칠 문제를 본 논문의 문제로 환원한다. 그래프 색칠 문제는 NP-hard이므로 우리는 결론은 추론 가능하다.&lt;/p&gt;

&lt;p&gt;$ G = (V, E) $ 라는 임의의 그래프가 있다고 하자. 이 G의 발생 행렬(Incidence Matrix)의 &lt;strong&gt;행&lt;/strong&gt;들이 우리 문제의 &lt;strong&gt;변수&lt;/strong&gt;에 해당한다. 위 정리에서 최적의 묶음 전략을 찾는 것은 NP-hard라고 하였는데, 이는 다항 시간 안에 정확한 해를 구하는 것이 불가능하다는 의미이다. 따라서 좋은 근사 알고리즘을 찾기 위해서는 최적 묶음 문제를 그래프 색칠 문제로 치환해야 한다. 이 치환은 &lt;strong&gt;변수(feature)&lt;/strong&gt;들을 &lt;strong&gt;꼭짓점(vertices)&lt;/strong&gt;으로 간주하고 만약 두 변수가 상호배타적일 경우 그들 사이에 &lt;strong&gt;변(edge)&lt;/strong&gt;을 추가하는 방식으로 이루어진다. 이후 Greedy 알고리즘을 사용한다.&lt;/p&gt;

&lt;p&gt;1)에 관한 알고리즘을 설명하자면 다음과 같다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;각 변마다 가중치가 있는 그래프를 구성하는데, 여기서 가중치는 변수들간의 &lt;strong&gt;충돌(conflicts)&lt;/strong&gt;을 의미한다. 여기서 충돌이란 non-zero value가 동시에 존재하여 상호배타적이지 않은 상황을 의미한다.&lt;/li&gt;
    &lt;li&gt;그래프 내에 있는 꼭짓점 차수에 따라 내림차순으로 변수들을 정렬한다.&lt;/li&gt;
    &lt;li&gt;정렬한 리스트에 있는 각 변수를 확인하면서 이들을 작은 충돌(γ로 제어함)이 있는 기존 묶음에 할당하거나, 새로운 묶음을 만든다.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-09-Light GBM/02.JPG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;이 알고리즘의 시간 복잡도는 변수들의 개수의 제곱에 해당하며, 이는 나름 괜찮은 수준이지만 만약 변수들의 수가 매우 많다면 개선이 필요하다고 판단된다. 따라서 본 논문은 그래프를 직접 구성하지 않고 0이 아닌 값의 개수에 따라 정렬하는 방식(0이 아닌 값이 많을 수록 충돌을 일으킬 확률이 높으므로)으로 알고리즘을 수정하였다.&lt;/p&gt;

&lt;p&gt;2)에 관해서 이야기하자면, 가장 중요한 것은 변수 묶음들로부터 원래(original) 변수들의 값을 식별할 수 있어야 한다는 것이다. Histogram-based 알고리즘은 변수의 연속적인 값 대신 이산적인 구간(bin)을 저장하므로, 배타적 변수들을 각각 다른 구간에 두어 변수 묶음을 구성할 수 있다. 이는 변수의 원래 값에 offset을 더하는 것으로 이루어 질 수 있다.&lt;/p&gt;

&lt;p&gt;예를 들어 변수 묶음에 변수 2개가 속한다고 할 때,&lt;br /&gt;
원래 변수 A는 [0, 10)의 값을 취하고, 원래 변수 B는 [0, 20)의 값을 취한다.&lt;br /&gt;
이대로 두면 [0, 10) 범위 내에서 두 변수는 겹칠 것이므로,&lt;br /&gt;
변수 B에 offset 10을 더하여 가공한 변수가 [10, 30)의 값을 취하게 한다.&lt;br /&gt;
이후 A, B를 병합하고 [0, 30] 범위의 변수 묶음을 사용하여 기존의 변수 A, B를 대체한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-09-Light GBM/04.JPG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-09-Light GBM/03.JPG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;2-light-gbm-적용&quot;&gt;2. Light GBM 적용&lt;/h2&gt;
&lt;p&gt;본 글에서는 Kaggle-Santander 데이터를 이용하여 간단한 적용 예시를 보이도록 하겠다. 초기에 lightgbm은 독자적인 모듈로 설계되었으나 편의를 위해 scikit-learn wrapper로 호환이 가능하게 추가로 설계되었다. 본 글에서는 scikit-learn wrapper Light GBM을 기준으로 설명할 것이다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Santander Data
&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;ID&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;var3&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;var15&lt;/span&gt;   &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;saldo_medio_var44_ult3&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;var38&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;TARGET&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;23&lt;/span&gt;   &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;                       &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;39205.17&lt;/span&gt;       &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;34&lt;/span&gt;   &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;                       &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;49278.03&lt;/span&gt;       &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;     &lt;span class=&quot;mi&quot;&gt;23&lt;/span&gt;   &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;                       &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;67333.77&lt;/span&gt;       &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rows&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;371&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;n_estimators&lt;/strong&gt; 파라미터는 반복 수행하는 트리의 개수를 의미한다. 너무 크게 지정하면 학습 시간이 오래 걸리고 과적합이 발생할 수 있으니, 파라미터 튜닝 시에는 크지 않은 숫자로 지정하는 것이 좋다. &lt;strong&gt;num_leaves&lt;/strong&gt; 파라미터는 하나의 트리가 가질 수 있는 최대 리프의 개수인데, 이 개수를 높이면 정확도는 높아지지만 트리의 깊이가 커져 모델의 복잡도가 증가한다는 점에 유의해야 한다.&lt;/p&gt;

&lt;p&gt;먼저 기본적인 모델을 불러온다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;lightgbm&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LGBMClassifier&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lgbm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LGBMClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html&quot;&gt;공식문서&lt;/a&gt;을 참조하면 아래와 같은 몇몇 주의사항을 볼 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Light GBM은 leaf-wise 방식을 취하고 있기 때문에 수렴이 굉장히 빠르지만, 파라미터 조정에 실패할 경우 과적합을 초래할 수 있다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;max_depth&lt;/strong&gt; 파라미터는 트리의 최대 깊이를 의미하는데, 위에서 설명한 &lt;strong&gt;num_leaves&lt;/strong&gt; 파라미터와 중요한 관계를 지닌다. 과적합을 방지하기 위해 &lt;strong&gt;num_leaves&lt;/strong&gt;는 2^(&lt;strong&gt;max_depth&lt;/strong&gt;)보다 작아야 한다. 예를 들어 &lt;strong&gt;max_depth&lt;/strong&gt;가 7이기 때문에, 2^(&lt;strong&gt;max_depth&lt;/strong&gt;)=98이 되는데, 이 때 num_leaves를 이보다 작은 70~80 정도로 설정하는 것이 낫다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;min_child_samples&lt;/strong&gt; 파라미터는 최종 결정 클래스인 Leaf Node가 되기 위해서 최소한으로 필요한 데이터 개체의 수를 의미하며, 과적합을 제어하는 파라미터이다. 이 파라미터의 최적값은 훈련 데이터의 개수와 &lt;strong&gt;num_leaves&lt;/strong&gt;에 의해 결정된다. 너무 큰 숫자로 설정하면 under-fitting이 일어날 수 있으며, 아주 큰 데이터셋이라면 적어도 수백~수천 정도로 가정하는 것이 편리하다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;sub_sample&lt;/strong&gt; 파라미터는 과적합을 제어하기 위해 데이터를 샘플링하는 비율을 의미한다.&lt;/p&gt;

&lt;p&gt;지금까지 설명한 &lt;strong&gt;num_leaves&lt;/strong&gt;, &lt;strong&gt;max_depth&lt;/strong&gt;, &lt;strong&gt;min_child_samples&lt;/strong&gt;, &lt;strong&gt;sub_sample&lt;/strong&gt; 파라미터가 Light GBM 파라미터 튜닝에 있어서 가장 중요한 파라미터들이다. 이들은 하나씩 튜닝할 수도 있고, 한 번에 튜닝할 수도 있다. 학습 데이터의 성격과 여유 시간에 따라 선택해야 한다. 이들에 대한 최적값을 어느 정도 확보했다면, 다음 단계로 넘어가도 좋다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;colsample_bytree&lt;/strong&gt; 파라미터는 개별 트리를 학습할 때마다 무작위로 선택하는 피쳐의 비율을 제어한다. &lt;strong&gt;reg_alpha&lt;/strong&gt;는 L1 규제를, &lt;strong&gt;reg_lambda&lt;/strong&gt;는 L2 규제를 의미한다. 이들은 과적합을 제어하기에 좋은 옵션들이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;learning_rate&lt;/strong&gt;은 후반부에 건드리는 것이 좋은데, 초반부터 너무 작은 학습률을 지정하면 효율이 크게 떨어질 수 있기 때문이다. 정교한 결과를 위해, 마지막 순간에 더욱 좋은 결과를 도출하기 위해 영혼까지 끌어모으고 싶다면, &lt;strong&gt;learning_rate&lt;/strong&gt;는 낮추고 &lt;strong&gt;num_estimators&lt;/strong&gt;는 크게 하여 최상의 결과를 내보도록 하자.&lt;/p&gt;

&lt;p&gt;다음은 위에서 처음 소개한 Santander Data를 바탕으로 한 예시이다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'max_depth'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;'min_child_samples'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
          &lt;span class=&quot;s&quot;&gt;'subsample'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GridSearchCV&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lgbm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_grid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;early_stopping_rounds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eval_metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'auc'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;eval_set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;최적 파라미터: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_params_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lgbm_roc_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;roc_auc_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict_proba&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;average&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'macro'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ROC AUC: {0:.4f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lgbm_roc_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 위 결과를 적용하여 재학습
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lgbm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LGBMClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_estimators&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_leaves&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subsample&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                      &lt;span class=&quot;n&quot;&gt;min_child_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;evals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lgbm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;early_stopping_rounds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eval_metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'auc'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;eval_set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;roc_auc_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict_proba&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;average&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'macro'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ROC AUC: {0:.4f}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;3-window에서-light-gbm---gpu-사용하기&quot;&gt;3. Window에서 Light GBM - GPU 사용하기&lt;/h2&gt;
&lt;p&gt;위에서 본 예시처럼, 작은 데이터셋을 이용하고 있다면 큰 문제가 없겠지만, 큰 데이터셋으로 학습을 진행할 경우 GPU의 도움이 지극히 필요한 것이 현실이다. 지금부터는 GPU를 이용하여 Light GBM을 학습시키는 과정에 대해 설명하겠다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://lightgbm.readthedocs.io/en/latest/index.html&quot;&gt;LightGBM 공식 문서&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree&quot;&gt;논문&lt;/a&gt;
파이썬 머신러닝 완벽 가이드, 권철민, 위키북스&lt;/p&gt;
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>Seaborn Module 사용법</title>
   <link href="http://localhost:4000/Seaborn-Module/"/>
   <updated>2019-12-05T00:00:00+09:00</updated>
   <id>http://localhost:4000/Seaborn Module</id>
   <content type="html">&lt;h2 id=&quot;1-seaborn-모듈-개요&quot;&gt;1. Seaborn 모듈 개요&lt;/h2&gt;
&lt;p&gt;Seaborn은 Matplotlib에 기반하여 제작된 파이썬 데이터 시각화 모듈이다. 고수준의 인터페이스를 통해 직관적이고 아름다운 그래프를 그릴 수 있다. 본 글은 Seaborn 공식 문서의 Tutorial 과정을 정리한 것임을 밝힌다.&lt;/p&gt;

&lt;p&gt;그래프 저장 방법은 아래와 같이 matplotlib과 동일하다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gcf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;savefig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'graph.png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dpi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bbox_inches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tight&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;facecolor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;white&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;2-plot-aesthetics&quot;&gt;2. Plot Aesthetics&lt;/h2&gt;
&lt;h3 id=&quot;21-style-management&quot;&gt;2.1. Style Management&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;sns.set_style(style=None, rc=None)&lt;/strong&gt;&lt;br /&gt;
:: 그래프 배경을 설정함&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;em&gt;style&lt;/em&gt; = “darkgrid”, “whitegrid”, “dark”, “white”, “ticks”&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;rc&lt;/em&gt; = [dict], 세부 사항을 조정함&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;sns.despine(offset=None, trim=False, top=True, right=True, left=False, bottom=False)&lt;/strong&gt;&lt;br /&gt;
:: Plot의 위, 오른쪽 축을 제거함&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;em&gt;top, right, left, bottom&lt;/em&gt; = True로 설정하면 그 축을 제거함&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;offset&lt;/em&gt; = [integer or dict], 축과 실제 그래프가 얼마나 떨어져 있을지 설정함&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;만약 일시적으로 Figure Style을 변경하고 싶다면 아래와 같이 with 구문을 사용하면 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axes_style&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;darkgrid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;211&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;violinplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;212&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;barplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/01.png&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;전체 Style을 변경하여 지속적으로 사용하고 싶다면, 아래와 같은 절차를 거치면 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axes_style&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 배경 스타일을 darkgrid로 적용하고 투명도를 0.9로
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_style&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;darkgrid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;axes.facecolor&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;0.9&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 혹은 간단하게 darkgrid만 적용하고 싶다면,
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;darkgrid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;22-color-management&quot;&gt;2.2. Color Management&lt;/h3&gt;
&lt;p&gt;현재의 Color Palette를 확인하고 싶다면 다음과 같이 코드를 입력하면 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;current_palette&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;palplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;우리는 이 Palette를 무궁무진하게 변화시킬 수 있는데, 가장 기본적인 테마는 총 6개가 있다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;deep, muted, pastel, bright, dark, colorblind&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;지금부터 color_palette 메서드를 통해 palette를 바꾸는 법에 대해 알아볼 것이다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;sns.color_palette(palette=None, n_colors=None)&lt;/strong&gt;&lt;br /&gt;
:: color palette를 정의하는 색깔 list를 반환함&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;em&gt;palette&lt;/em&gt; = [string], Palette 이름&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;n_colors&lt;/em&gt; = [Integer]&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Palette에는 위에서 본 6가지 기본 테마 외에도, hls, husl, Set1, Blues_d, RdBu 등 수많은 matplotlib palette를 사용할 수 있다. 만약 직접 RGB를 설정하고 싶다면 아래와 같이 설정하는 것도 가능하다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;new_palette&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;#9b59b6&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;#3498db&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;#95a5a6&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;#e74c3c&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;#34495e&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;#2ecc71&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;혹은 &lt;strong&gt;xkcd&lt;/strong&gt;를 이용하여 이름으로 색깔을 불러올 수도 있다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;colors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;windows blue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;amber&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;greyish&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;faded green&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;dusty purple&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;palplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xkcd_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Categorical Color Palette 대표 예시&lt;/strong&gt;&lt;br /&gt;
위에서부터 paired, Set2&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/paired.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/Set2.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Sequential Color Palette 대표 예시&lt;/strong&gt;&lt;br /&gt;
위에서부터 Blues, BuGn_r, GnBu_d&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/Blues.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/BuGn_r.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/GnBu_d.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;또 하나 유용한 기능은 cubehelix palette이다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cubehelix_palette&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cubehelix_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rot&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;light&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                          &lt;span class=&quot;n&quot;&gt;reverse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as_cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multivariate_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cubehelix_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;light&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as_cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kdeplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shade&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/cube1.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;간단한 인터페이스를 원한다면 아래와 같은 방식도 가능하다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;light_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;green&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reverse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as_cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;palt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dark_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;purple&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reverse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as_cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dark_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;palegreen&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reverse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as_cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;양쪽으로 발산하는 Color Palette를 원한다면, 아래와 같은 방식으로 코드를 입력하면 된다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;diverging_palette&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;coolwarm&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;diverging_palette&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diverging_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_neg&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_pos&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;85&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                          &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;center&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'light'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as_cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# h_neg, h_pos = anchor hues, [0, 359]
# s: anchor saturation
# l: anchor lightness
# n: number of colors in the palette
# center: light or dark
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아래 결과는 다음과 같다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/diverging.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;또한, 만약 color_palette 류의 메서드로 하나 하나 설정을 바꾸는 것이 아니라 전역 설정을 바꾸고 싶다면, &lt;strong&gt;set_palette&lt;/strong&gt;를 이용하면 된다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'hust'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고로 cubeleix palette를 이용하여 heatmap을 그리는 방법에 대해 첨부한다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;49&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tril_indices_from&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;palette&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cubehelix_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_colors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rot&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;light&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reverse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;as_cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;heatmap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/heatmap.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;3-plotting-functions&quot;&gt;3. Plotting Functions&lt;/h2&gt;
&lt;p&gt;Seaborn의 Plotting 메서드들 중 가장 중요한 위치에 있는 메서드들은 아래와 같다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;메서드&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;기능&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;종류&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;relplot&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2개의 연속형 변수 사이의 통계적 관계를 조명&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;scatter, line&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;catplot&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;범주형 변수를 포함하여 변수 사이의 통계적 관계를 조명&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;swarm, strip, box, violin, bar, point&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;데이터의 분포를 그리기 위해서는 distplot, kdeplot, jointplot 등을 사용할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;31-visualizing-statistical-relationships&quot;&gt;3.1. Visualizing statistical relationships&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;sns.relplot(x, y, kind, hue, size, style, data, row, col, col_wrap, row_order, col_order, palette, …)&lt;/strong&gt;&lt;br /&gt;
:: 2개의 연속형 변수 사이의 통계적 관계를 조명함, 각종 옵션으로 추가적으로 변수를 삽입할 수도 있음&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;em&gt;hue, size, style&lt;/em&gt; = [string], 3개의 변수를 더 추가할 수 있음&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;col&lt;/em&gt; = [string], 여러 그래프를 한 번에 그릴 수 있게 해줌. 변수 명을 입력하면 됨&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;kind&lt;/em&gt; = [string], scatter 또는 line 입력&lt;/li&gt;
    &lt;li&gt;자세한 설명은 &lt;a href=&quot;http://seaborn.pydata.org/generated/seaborn.relplot.html#seaborn.relplot&quot;&gt;이곳&lt;/a&gt;을 확인&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;311-scatter-plot&quot;&gt;3.1.1. &lt;strong&gt;Scatter plot&lt;/strong&gt;&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;total_bill&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;tip&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;size&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sizes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/scatter.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;h4 id=&quot;312-line-plot&quot;&gt;3.1.2. &lt;strong&gt;Line plot&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;일반적인 Line Plot&lt;/strong&gt;
    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cumsum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;line&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/line1.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;같은 x 값에 여러 y가 존재할 때 (Aggregation)&lt;/strong&gt;&lt;br /&gt;
데이터가 아래와 같이 생겼다고 가정하자. (timepoint 값에 여러 개의 signal 값이 존재하는 상황)&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;subject&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;timepoint&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;event&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;region&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;signal&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;s13&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;18&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;stim&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;parietal&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-0.017&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;s5&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;14&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;stim&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;parietal&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-0.081&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;s12&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;14&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;stim&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;parietal&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-0.810&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;s11&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;18&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;stim&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;parietal&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-0.0461&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;s10&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;18&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;stim&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;parietal&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;-0.0379&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;이 때, 위와 같은 경우에는 자연스럽게 Confidence Interval이 추가된다. 만약 이를 제거하고 싶으면, argument에 ci=None을 추가하면 되며, 만약 ci=”sd”로 입력하면, 표준편차가 표시된다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;timepoint&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;signal&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;line&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fmri&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;우측이 ci=”sd”이다.&lt;/p&gt;
&lt;div&gt;&lt;span&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/line2.JPG&quot; width=&quot;40%&quot; /&gt;&lt;/span&gt;
&lt;span&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/line3.JPG&quot; width=&quot;40%&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;p&gt;여러 변수 사이의 관계를 탐구하기 위해 다음과 같은 그래프를 그릴 수도 있다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cubehelix_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;light&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_colors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;timepoint&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;signal&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;region&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;event&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;palette&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dashes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;markers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;line&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fmri&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/02.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;h4 id=&quot;313-여러-그래프-한-번에-그리기&quot;&gt;3.1.3. &lt;strong&gt;여러 그래프 한 번에 그리기&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;여러 그래프를 한 번에 그리고 싶다면 아래와 같은 방법을 사용하면 된다. 이는 다른 seaborn 메서드에도 두루 적용할 수 있는 방법이다. col에 지정된 변수 내 값이 너무 많으면, col_wrap[integer]을 통해 한 행에 나타낼 그래프의 수를 조정할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Showing multiple relationships with facets
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;timepoint&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;signal&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;subject&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;region&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;event&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;line&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;estimator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fmri&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/03.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;32-plotting-with-categorical-data&quot;&gt;3.2. Plotting with categorical data&lt;/h3&gt;
&lt;p&gt;범주형 변수를 포함한 여러 변수들의 통계적 관계를 조명하는 catplot은 kind=swarm, strip, box, violin, bar, point 설정을 통해 다양한 그래프를 그릴 수 있게 해준다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;sns.catplot(x, y, kind, hue, data, row, col, col_wrap, order, row_order, col_order, hue_order, palette, …)&lt;/strong&gt;&lt;br /&gt;
:: 범주형 변수를 포함한 여러 변수들의 통계적 관계를 조명함&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;em&gt;x, y, hue&lt;/em&gt; = [string], 그래프를 그릴 변수들의 이름&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;row, col&lt;/em&gt; = [string], faceting of the grid를 결정할 범주형 변수의 이름&lt;/li&gt;
    &lt;li&gt;자세한 설명은 &lt;a href=&quot;http://seaborn.pydata.org/generated/seaborn.catplot.html#seaborn.catplot&quot;&gt;이곳&lt;/a&gt;을 확인&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;321-categorical-scatterplots-strip-swarm&quot;&gt;3.2.1. Categorical Scatterplots: strip, swarm&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;catplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;day&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;total_bill&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jitter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;catplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;day&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;total_bill&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sex&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;swarm&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Sun&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Sat&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Thur&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Fri&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div&gt;&lt;span&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/cat1.JPG&quot; width=&quot;40%&quot; /&gt;&lt;/span&gt;
&lt;span&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/cat2.JPG&quot; width=&quot;40%&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;p&gt;swarm 그래프는 그래프 포인트끼리 겹치는 것을 막아준다. (overlapping 방지) 가로로 그리고 싶으면, x와 y의 순서를 바꿔주면 된다.&lt;/p&gt;

&lt;h4 id=&quot;322-distribution-of-observations-within-categories-box-violin&quot;&gt;3.2.2. Distribution of observations within categories: box, violin&lt;/h4&gt;
&lt;p&gt;위와 같은 그래프에서 분포를 잘 알아보기 위해서는 다음과 같은 기능을 사용하면 된다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;weekend&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;day&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Sat&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Sun&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;catplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;day&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;total_bill&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;weekend&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'v'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;box&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dodge&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;catplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;total_bill&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;day&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;violin&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cut&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div&gt;&lt;span&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/cat3.JPG&quot; width=&quot;40%&quot; /&gt;&lt;/span&gt;
&lt;span&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/cat4.JPG&quot; width=&quot;40%&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;p&gt;그래프 내부에 선(Inner Stick)을 추가하고 싶거나, Scatter Plot과 Distribution Plot을 동시에 그리고 싶다면 아래의 기능을 사용하면 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Inner Stick 사용
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;violinplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;day&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;total_bill&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sex&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inner&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;stick&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;palette&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Set3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 결합: 분포와 실제 데이터까지 한번에 보여주는 방법
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;catplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;day&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;total_bill&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;violin&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inner&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;swarmplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;day&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;total_bill&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;k&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div&gt;&lt;span&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/cat5.JPG&quot; width=&quot;40%&quot; /&gt;&lt;/span&gt;
&lt;span&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/cat6.JPG&quot; width=&quot;40%&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;h4 id=&quot;323-statistical-estimation-within-categories-barplot-countplot-pointplot&quot;&gt;3.2.3. Statistical Estimation within categories: barplot, countplot, pointplot&lt;/h4&gt;
&lt;p&gt;아래는 기본적인 Barplot, Countplot, Pointplot을 그리는 방법에 대한 소개이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# bar
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;catplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sex&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;survived&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;class&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bar&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;titanic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 그냥 count를 세고 싶다면
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;catplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;deck&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;count&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;palette&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ch:.25&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;titanic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# point
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;catplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;class&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;survived&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;sex&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;titanic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;palette&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;male&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;g&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;female&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;m&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;point&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;markers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;^&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;o&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linestyles&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;-&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;--&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/cat7.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/cat8.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/cat9.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;h4 id=&quot;324-showing-multiple-relationships-with-facets&quot;&gt;3.2.4. Showing multiple relationships with facets&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# catplot 역시 relplot 처럼 col argument를 사용해 여러 그래프를 그릴 수 있음
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;catplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;day&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;total_bill&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;smoker&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;time&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aspect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;swarm&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tips&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/cat10.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;33-visualizing-the-distribution-of-a-dataset&quot;&gt;3.3. Visualizing the distribution of a dataset&lt;/h3&gt;
&lt;h4 id=&quot;321-일변량-분포&quot;&gt;3.2.1. 일변량 분포&lt;/h4&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;sns.distplot(a, bins, hist=True, rug=False, fit=None, color=None, vertical=False, norm_hist=False, axlabel, label, ax …)&lt;/strong&gt;&lt;br /&gt;
:: 관찰 값들의 일변량 분포를 그림&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;em&gt;a&lt;/em&gt; = [Series, 1d array, list], Observed data이며, Series에 name 속성이 있다면 이것이 label로 사용될 것임&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;hist&lt;/em&gt; = [bool], True면 히스토그램을 그림&lt;/li&gt;
    &lt;li&gt;자세한 설명은 &lt;a href=&quot;http://seaborn.pydata.org/generated/seaborn.distplot.html#seaborn.distplot&quot;&gt;이곳&lt;/a&gt;을 확인&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;다음은 예시이다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bins&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kde&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rug&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/04.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;sns.kdeplot(data, data2, shade=False, vertical=False, kernel=’gau’, bw=’scott’, gridsize=100, cut=3, legend=True …)&lt;/strong&gt;&lt;br /&gt;
:: 일변량 or 이변량의 Kernel Density Estimate 그래프를 그림&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;em&gt;data&lt;/em&gt; = [1d array-like], Input Data&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;data2&lt;/em&gt; = [1d array-like], 2번째 Input Data, 옵션이며 추가할 경우 이변량 KDE가 그려질 것임&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;bw&lt;/em&gt; = {‘scott’, ‘silverman’, scalar, pair of scalars}, kernel size를 결정함, 히스토그램에서의 bin size와 유사한 역할을 수행함, bw 값이 작을 수록 실제 데이터에 근접하게 그래프가 그려짐&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;gridsize&lt;/em&gt; = [int], Evaluation Grid에서의 이산형 포인트의 개수&lt;/li&gt;
    &lt;li&gt;&lt;em&gt;cut&lt;/em&gt; = [scalar], 그래프의 시작 지점을 설정함&lt;/li&gt;
    &lt;li&gt;자세한 설명은 &lt;a href=&quot;http://seaborn.pydata.org/generated/seaborn.distplot.html#seaborn.distplot&quot;&gt;이곳&lt;/a&gt;을 확인&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kdeplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shade&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bw: 0.2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kdeplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shade&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bw: 2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'best'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kde&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div&gt;&lt;span&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/05.JPG&quot; width=&quot;40%&quot; /&gt;&lt;/span&gt;
&lt;span&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/06.JPG&quot; width=&quot;40%&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;h4 id=&quot;322-이변량-분포&quot;&gt;3.2.2. 이변량 분포&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Prep
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cov&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multivariate_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;x&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;y&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multivariate_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cubehelix_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rot&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;light&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Scatter plot
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jointplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;x&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;y&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'k'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Hexbin plot
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axes_style&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;white&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jointplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;hex&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Kernel Density Estimation
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jointplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;x&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;y&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;kde&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/07.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/08.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/09.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;이변량 분포에서 KDE와 rug를 결합하면 아래와 같은 그래프를 그릴 수도 있다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kdeplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rugplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;g&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rugplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertical&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/10.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;만약 Density의 연속성을 부드럽게 표현하고 싶다면, Contour Level을 조 정하면 된다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cubehelix_palette&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as_cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;light&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reverse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kdeplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_levels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shade&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/11.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;h4 id=&quot;323-pairwise-관계-시각화&quot;&gt;3.2.3. Pairwise 관계 시각화&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'iris'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pairplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PairGrid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iris&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map_diag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kdeplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map_offdiag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kdeplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Blues_d&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_levels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-12-05-Seaborn Module/12.JPG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;4-multi-plot-grids&quot;&gt;4. Multi-plot grids&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://seaborn.pydata.org/tutorial/axis_grids.html&quot;&gt;이곳&lt;/a&gt;을 참조할 것&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;http://seaborn.pydata.org/tutorial.html&quot;&gt;Seaborn 공식 문서&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>Imbalanced Learning</title>
   <link href="http://localhost:4000/Imbalanced-Learning/"/>
   <updated>2019-10-01T00:00:00+09:00</updated>
   <id>http://localhost:4000/Imbalanced Learning</id>
   <content type="html">&lt;h2 id=&quot;1-imbalanced-learning-불균형-학습-개요&quot;&gt;1. Imbalanced Learning (불균형 학습) 개요&lt;/h2&gt;

&lt;p&gt;비정상 거래 탐지와 같은 케이스의 경우, 정상적인 거래 보다는 정상 범위에서 벗어난 것으로 판단되는 거래 기록의 비중이 현저하게 작을 것이다. 그런데 보통의 알고리즘으로 이러한 비정상 거래를 찾아내기 에는 이러한 데이터의 불균형이 중요한 이슈로 작용하는데, 본 글에서는 이러한 불균형 학습과 관련된 논의를 해보고자 한다.&lt;/p&gt;

&lt;p&gt;알고리즘 자체로 Class 불균형을 해소하는 방법을 제외하면, Over-Sampling과 Under-Sampling 방법이 가장 대표적인 방법이라고 할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;11-over-sampling&quot;&gt;1.1. Over-Sampling&lt;/h3&gt;
&lt;p&gt;Over-Sampling은 부족한 데이터를 추가하는 방식으로 진행되며, 크게 3가지로 구분할 수 있다.&lt;/p&gt;

&lt;p&gt;첫 번째 방법은 무작위 추출인데, 단순하게 랜덤하게 부족한 Class의 데이터를 복제하여 데이터셋에 추가하는 것이다.&lt;/p&gt;

&lt;p&gt;두 번째 방법은 위와 달리 기존 데이터를 단순히 복사하는 것에 그치지 않고, 어떠한 방법론에 의해 합성된 데이터를 생성하는 것이다. 이후에 설명할 &lt;strong&gt;SMOTE&lt;/strong&gt; 기법이 본 방법의 대표적인 예에 해당한다.&lt;/p&gt;

&lt;p&gt;세 번째 방법은 어떤 특별한 기준에 의해 복제할 데이터를 정하고 이를 실행하는 것이다.&lt;/p&gt;

&lt;h3 id=&quot;12-under-sampling&quot;&gt;1.2. Under-Sampling&lt;/h3&gt;
&lt;p&gt;Over-Sampling과 반대로 Under-Sampling은 정상 데이터의 수를 줄여 데이터셋의 균형을 맞추는 것인데, 주의해서 사용하지 않으면 매우 중요한 정보를 잃을 수도 있기 때문에 확실한 근거를 바탕으로 사용해야 하는 방법이다.&lt;/p&gt;

&lt;p&gt;Under-Sampling의 대표적인 예로는 RUS가 있고, 이는 단순히 Random Under Sampling을 뜻한다.&lt;/p&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;2-smote-기법&quot;&gt;2. SMOTE 기법&lt;/h2&gt;
&lt;p&gt;SMOTE는 Synthetic Minority Oversampling TEchnique의 약자로, 2002년에 처음 등장하여 현재(2019.10)까지 8천 회가 넘는 인용 수를 보여주고 있는 Over-Sampling의 대표적인 알고리즘이다.&lt;/p&gt;

&lt;p&gt;알고리즘의 원리 자체는 간단하다. Boostrap이나 KNN 모델 기법을 기반으로 하는데, 그 원리는 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;소수(위 예시에선 비정상) 데이터 중 1개의 Sample을 선택한다. 이 Sample을 기준 Sample이라 명명한다.&lt;/li&gt;
  &lt;li&gt;기준 Sample과 거리(유클리드 거리)가 가까운 k개의 Sample(KNN)을 찾는다. 이 k개의 Sample 중 랜덤하게 1개의 Sample을 선택한다. 이 Sample을 KNN Sample이라 명명한다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;새로운 Synthetic Sample은 아래와 같이 계산한다.
&lt;script type=&quot;math/tex&quot;&gt;X_{new} = X_i + (X_k - X_i) * \delta&lt;/script&gt;&lt;/p&gt;

    &lt;p&gt;$X_{new}$: Synthetic Sample&lt;br /&gt;
$X_i$: 기준 Sample&lt;br /&gt;
$X_k$: KNN Sample&lt;br /&gt;
$\delta$: 0 ~ 1 사이에서 생성된 난수&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;본 과정을 일정 수 만큼 진행하면 아래 그림과 같이 새로운 합성 데이터가 생성됨을 알 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-10-01-Imbalanced Learning/01.png&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;간단한 예시를 보면,&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;seaborn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.datasets&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_classification&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;imblearn.over_sampling&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SMOTE&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MinMaxScaler&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_classification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_informative&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;n_redundant&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_clusters_per_class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;scaler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MinMaxScaler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feature_range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scaler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# SMOTE 이전
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concatenate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'col1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'col2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'result'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'col1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'col2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'result'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# SMOTE 이후
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SMOTE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'auto'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'regular'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k_neighbors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concatenate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'col1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'col2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'result'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'col1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'col2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'result'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음 그림들에서 위는 SMOTE 이전의 데이터를, 아래는 SMOTE 이후의 데이터 분포를 보여준다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-10-01-Imbalanced Learning/02.JPG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-10-01-Imbalanced Learning/03.JPG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;3-추가할-것&quot;&gt;3. 추가할 것&lt;/h2&gt;
&lt;p&gt;MSMOTE, Borderline SMOTE, Adasyn&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://mkjjo.github.io/python/2019/01/04/smote_duplicate.html&quot;&gt;참고 블로그&lt;/a&gt;&lt;br /&gt;
파이썬 머신러닝 완벽 가이드, 권철민, 위키북스&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>Contextual Bandit and Tree Heuristic</title>
   <link href="http://localhost:4000/Contextual-Bandit-and-Tree-Heuristic/"/>
   <updated>2019-09-18T00:00:00+09:00</updated>
   <id>http://localhost:4000/Contextual Bandit and Tree Heuristic</id>
   <content type="html">&lt;h2 id=&quot;1-contextual-bandit의-개념&quot;&gt;1. Contextual Bandit의 개념&lt;/h2&gt;
&lt;p&gt;Contextual Bandit 문제를 알기 위해선 Multi-Armed Bandit 문제의 개념에 대해 숙지하고 있어야 한다.&lt;br /&gt;
위 개념에 대해 알기를 원한다면 &lt;a href=&quot;https://sumniya.tistory.com/9&quot;&gt;여기&lt;/a&gt;를 참고하기 바란다.&lt;/p&gt;

&lt;p&gt;Multi-Armed Bandit 문제에서 Context 개념이 추가된 Contextual Bandit 문제는 대표적으로 추천 시스템에서 활용될 수 있다. 단 전통적인 추천 시스템을 구축할 때는 Ground Truth y 값, 즉 실제로 고객이 어떠한 상품을 좋아하는지에 대한 해답을 안고 시작하지만, Contextual Bandit과 관련된 상황에서는 그러한 이점이 주어지지 않는다.&lt;/p&gt;

&lt;p&gt;그림을 통해 파악해보자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-09-18-Contextual Bandit and Tree Heuristic/01.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-09-18-Contextual Bandit and Tree Heuristic/02.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;첫 번째 그림은 전통적인 추천시스템에 관한 것이고, 두 번째 그림은 Contextual Bandit 문제와 관련된 것이다.&lt;/p&gt;

&lt;p&gt;온라인 상황에서 우리가 고객에게 어떠한 상품을 제시하였을 때, 고객이 그 상품을 원하지 않는다면 우리는 새로운 시도를 통해 고객이 어떠한 상품을 좋아할지 파악하도록 노력해야 한다. 이것이 바로 &lt;strong&gt;Exploration&lt;/strong&gt;이다.&lt;/p&gt;

&lt;p&gt;만약 고객이 그 상품에 호의적인 반응을 보였다면, 이 또한 중요한 데이터로 적재되어 이후에 동일 혹은 유사한 고객에게 상품을 추천해 주는 데에 있어 이용될 것이다. 이 것이 &lt;strong&gt;Exploitation&lt;/strong&gt;이다.&lt;/p&gt;

&lt;p&gt;위 그림에 나와 있듯이, Contextual Bandit 문제 해결의 핵심은, Context(고객의 정보)를 활용하여 Exploitation과 Exploration의 균형을 찾아 어떤 Action을 취할 것인가에 대한 효과적인 학습을 진행하는 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-lin-ucb&quot;&gt;2. Lin UCB&lt;/h2&gt;
&lt;p&gt;Lin UCB는 &lt;strong&gt;A contextual-bandit approach to personalized news article recommendation&lt;/strong&gt;논문에 처음 소개된 알고리즘으로, Thompson Sampling과 더불어 Contextual Bandit 문제를 푸는 가장 대표적이고 기본적인 알고리즘으로 소개되어 있다.&lt;/p&gt;

&lt;p&gt;이 알고리즘의 기본 개념은 아래와 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-09-18-Contextual Bandit and Tree Heuristic/03.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;Context Vector를 어떻게 구성할 것인가에 따라 Linear Disjoint Model과 Linear Hybrid Model로 구분된다. Hyperparameter인 Alpha가 커질 수록 Exploration에 더욱 가중치를 두게 되며, 결과는 이 Alpha에 다소 영향을 받는 편이다.&lt;/p&gt;

&lt;p&gt;본 알고리즘은 이후 Tree Heuristic과의 비교를 위해 테스트 용으로 사용될 예정이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-tree-heuristic&quot;&gt;3. Tree Heuristic&lt;/h2&gt;

&lt;h3 id=&quot;31-tree-boost&quot;&gt;3.1 Tree Boost&lt;/h3&gt;
&lt;p&gt;Tree Heuristic에 접근하기 위해서는 먼저 그 전신이라고 할 수 있는 Tree Boost 알고리즘에 대해 알아야 한다. 본 알고리즘은 &lt;strong&gt;A practical method for solving contextual bandit problems using decision trees&lt;/strong&gt; 논문에서 소개되었다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-09-18-Contextual Bandit and Tree Heuristic/04.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;Tree Boost는 Thompson Sampling의 개념을 차용하여 설계된 알고리즘이다. 위의 Lin UCB가 Context와 Reward 사이의 관계를 선형적으로 정의하였다면, 본 알고리즘은 Tree 계열의 모델로써 이 관계를 정의한다.&lt;/p&gt;

&lt;p&gt;Tree Boost의 작동 원리를 알아 보자. 한 고객의 정보가 입수되었다. 이 정보는 1개의 Context Vector라고 할 수 있다. 우리가 취할 수 있는 Action이 총 k개 있다고 가정하면, 각각의 Action과 연결된 Tree 모델에 방금 입수한 Context Vector를 투입하고 Reward가 1이 될 확률(Score)값을 얻는다. 가장 높은 값을 갖는 Action을 선택하여 고객에게 제시한다.&lt;/p&gt;

&lt;p&gt;제시가 끝난 후에 고객의 반응(Reward가 1인지, 0인지)이 확인되었다면, 이를 제시하였던 Action의 Sub-data에 적재한다. 즉, 각 데이터(Design Matrix)는 제시한 Action의 Sub-data에 소속되는 것이다. 이 Sub-data들을 모두 모으면 전체 데이터가 구성된다.&lt;/p&gt;

&lt;p&gt;Sub-data 내에서 부트스트랩을 여러 번 진행하고 그 중 하나를 선택하여 Tree 모델에 적합시키는데, 이 과정이 Exploration 과정에 해당하며, 선택된 데이터셋과 Tree 모델은 Thompson Sampling에서 사용되는 샘플 1개에 해당한다.&lt;/p&gt;

&lt;p&gt;이후에 설명하겠지만, Tree Boost의 성능은 뛰어난 편이다. 그러나 이 모든 과정을 거치기에는 굉장히 많은 시간이 소요되며, 신속성이 중요한 평가 포인트라고 할 수 있는 Contextual Bandit 알고리즘들 사이에서 현실적으로 우위를 보이기는 어려운 것이 사실이다. 따라서 아래에 있는 Tree Heuristic이라는 알고리즘이 제시되었다고 볼 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;32-tree-heuristic&quot;&gt;3.2 Tree Heuristic&lt;/h3&gt;
&lt;p&gt;Tree Boost와의 가장 큰 차이점은 바로, 한 Trial에 한 번만 적합을 진행하여 속도를 향상시켰다는 점이다. Tree Boost의 경우 각 Action 마다 부트스트랩 과정을 여러 번 시키고, 또 선택된 데이터에 Action 수 만큼 모델을 적합해야 했기 때문에 굉장히 오랜 시간이 소요되었는데 Tree Heuristic은 그러한 과정을 겪을 필요가 없는 것이다.&lt;/p&gt;

&lt;p&gt;알고리즘의 실질적인 작동원리는 아래 그림과 코드를 보면 상세히 설명되어 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2019-09-18-Contextual Bandit and Tree Heuristic/05.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
Tree Heuristic Implementation with Striatum Module
본 알고리즘은 Striatum Module의 가장 기본적인 class들을 활용하였음
&quot;&quot;&quot;&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;warnings&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;striatum.bandit.bandit&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BaseBandit&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;striatum.storage&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.externals.joblib&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delayed&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.multiclass&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_fit_binary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;OneVsRestClassifier&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.preprocessing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LabelBinarizer&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.tree&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DecisionTreeClassifier&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# 터미널을 클린하게 해야 함
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warnings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simplefilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ignore'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;category&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;FutureWarning&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;warnings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simplefilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ignore'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;category&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;UserWarning&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CustomOneVsRestClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OneVsRestClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    현재 scikit-learn의 OneVsRestClassifier class 의 경우,
    내부에 있는 Classifier 객체들이 독립적이지 않아 개별 접근이 불가능함
    따라서 개별 접근이 가능하게 (각 Action 별로 다른 모델이 필요하므로)
    본 클래스를 수정해주어야 함

    참조: https://www.oipapio.com/question-3339267
    &quot;&quot;&quot;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;estimators&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CustomOneVsRestClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimators&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimators&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;estimators&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label_binarizer_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LabelBinarizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparse_output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label_binarizer_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit_transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tocsc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label_binarizer_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes_&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ravel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# This is where we change the training method
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimators_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Parallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_jobs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delayed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_fit_binary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;estimator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;&quot;not %s&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label_binarizer_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label_binarizer_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;column&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;estimator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimators&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RecommendationCls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    우리가 추천한 Action 의 정보들을 저장할 클래스
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TreeHeuristic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BaseBandit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    Tree Heuristic Algorithm:
    Context 와 Reward 의 관계를 Tree Model 로서 정의내리고,
    Decision Tree 의 학습결과에 기반하여 Beta 분포 Sampling 을 진행하여 Action 을 선택하는 알고리즘임
    &quot;&quot;&quot;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;history_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;model_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;action_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;n_actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TreeHeuristic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                            &lt;span class=&quot;n&quot;&gt;recommendation_cls&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RecommendationCls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 1) history_storage 에는 매 trial 에서 진행되었던 기본적인 record 가 담겨 있음
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# 2) model_storage 는 Lin UCB 에서는 model parameter 가 저장되는 공간인데, 본 알고리즘에선 사실 쓰임새는 없음
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# 3) action_storage 에는 선택된 Action 의 ID 와 Score 가 저장됨
&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# oracle: Action 수 만큼의 Decision Tree 를 담고 있음
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# n_actions: Action 수
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# n_features: Feature 수
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# D: Action 별로 적재한 데이터, 딕셔너리구조이며 value 자리에는 각 Action 에 맞는 np.array 가 적재됨
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# first_context = 첫 손님, 처음 Input 으로 주어지는 Context
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;#               -&amp;gt; 얘를 저장하여 가짜 데이터를 만듦, build 메서드를 참고
&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CustomOneVsRestClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_actions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_actions&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;first_context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        1) first_context 저장 및 n_features 저장
        2) Action objects 를 self._action_storage 에 저장함
        3) 가짜 데이터를 집어 넣어 D 를 만듦
        4) 초기 fitting 을 진행 함

        :param first_context: np.array (n_features, ) 첫 번째 context
        :param actions: list of action objects(Striatum 모듈 기본 class), action 의 종류를 담고 있음
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;first_context&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;first_context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_action_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Add Fabricated Data
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# 적합을 진행하려고 하는데 만약 Label 이 오직 0만 존재한다거나 하는 상황이 오면
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Classifier 를 그 데이터에 적합시키는 것은 불가능함
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# 가짜 데이터를 D 에 미리 적재함으로써 이 문제를 해결함 (논문 참조)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# 데이터의 개수가 늘어날 수록 이 가짜 데이터의 영향력은 약화됨
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# D 에서 각 Action 에 맞는 np.array 의 마지막 열은 실제 Reward 값이며, 그 외의 열에는 Feature 값이 들어감
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_action_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 위에서 만든 가짜 데이터를 적합함
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_action_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;oracle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimators&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;oracle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sample_from_beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        :param context: np.array (n_features, ), 고객 1명의 context 임
        :return: history_id -- 저장 기록 index
                 recommendations -- 수행한 action 과 그 action 의 score 를 저장하는 class,
                                    위에서 만든 RecommendationCls class 의 Instance 임

        아래 loop 내의 코드는 Decision Tree 내부에 접근하는 과정을 다루고 있음
        접근 방법 참고:
        https://lovit.github.io/machine%20learning/2018/04/30/get_rules_from_trained_decision_tree/
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Prediction 을 위해 reshaping 을 해줌
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;context_vector&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_action_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;oracle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimators&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# 각 DT 모델에 context 를 투입하여 당도한 leaf node 의 index 를 얻음
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;leaf_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oracle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context_vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# 해당 leaf node 의 n0, n1 값을 얻음
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# n0: number of failure in the leaf node selected
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# n1: number of success in the leaf node selected
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;n0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oracle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;leaf_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;n1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oracle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tree_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;leaf_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# 이를 베타분포에 반영해주고, 여기서 sampling 을 진행함
&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Sample 값 중 가장 높은 값을 갖는 Action 을 선택함
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;recommendation_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_action_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;recommendations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_recommendation_cls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_action_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recommendation_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;history_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_history_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recommendations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;history_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recommendations&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        추천한 Action 의 결과로 받은 Reward 와 Context 를 결합하여 데이터 딕셔너리 D 업데이트를 진행 함

        :param action_id: integer, D 에서 어떤 데이터를 업데이트할지 결정함
        :param context: np.array (n_samples, ), 고객 1명의 context 임
        :param reward: 실제 Reward -- 0 또는 1
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# new_data: context 와 reward 를 붙인 np.array
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;new_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 해당 Action 의 데이터에 적재함
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        해당 Action 에 소속된 Decision Tree 를 적합하여 업그레이드 함

        :param action_id: integer
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;action_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_action_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;oracle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimators&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;oracle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;history_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rewards&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        self._history_storage.unrewarded_histories 에 있는,
        아직 Reward 를 받지 못한 기록들을 제거함

        :param history_id: Integer, sample_from_beta 메서드의 output
        :param rewards: Dictionary, {action_id : 0 or 1}
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_history_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rewards&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;add_action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        새로운 Action 이 추가되었을 때,
        1) action_storage 를 업데이트하고
        2) D 에 새로운 가짜 데이터를 적재하며
        3) oracle 에 새로 추가된 Action 의 개수만큼 Decision Tree 를 추가하여
        4) 앞서 만든 가짜 데이터에 적합함

        :param actions: set of actions
        &quot;&quot;&quot;&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_context&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_action_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;num_new_actions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 새롭게 정의된 Decision Tree 에 적합을 시작할 수 있게 기본 (가짜) 데이터셋을 넣어줌
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# 이어서 새롭게 Decision Tree 들을 추가된 Action 의 개수 만큼 만들어준 이후
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# 각 Action 에 매칭되는 Decision Tree 에 적합함
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;new_trees&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_new_actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_action_obj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_tree&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_trees&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# 여기서 new_action_obj 는 Striatum 패키지의 기본 class 로 짜여 있어
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# 그 class 의 attribute 인 id 를 불러와야 integer 인 action_id 를 쓸 수 있음
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;new_action_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_action_obj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;new_tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][:,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# 새로 적합한 Decision Tree 를 추가해 줌
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;estimators&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oracles&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;remove_action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        이제는 필요 없어진 Action을 제거한다.

        :param action_id: integer
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_action_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;remove&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;del&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# Preparation
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;make_arm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arm_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    선택할 수 있는 Action 의 리스트를 받아
    Striatum 모듈의 Action Object 로 변환함

    이 작업을 거쳐야 위 Action Object 들을 Tree Heuristic 과 같은 Contextual Bandit class 의
    내부 Attribute 인 _action_storage 에 저장할 수 있음

    :param arm_ids: list,
    :return:
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;arms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arm_id&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arm_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;arm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arm_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;arms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arms&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# Training: Movie Lens Data
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_movielens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;163683&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 데이터 전처리 방법에 대해 알고자 한다면...
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# 참고: https://striatum.readthedocs.io/en/latest/auto_examples/index.html#general-examples
&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;streaming_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'streaming_batch.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'user_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;user_feature&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'user_feature.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;index_col&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;arm_ids&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'actions.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'movie_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;reward_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'reward_list.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;streaming_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;streaming_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 아래 n_actions 인자에서 처음 시점에서의 Action 의 개수를 정의 함
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TreeHeuristic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MemoryHistoryStorage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MemoryModelStorage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MemoryActionStorage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_actions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_arm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arm_ids&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arm_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;reward_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Starting Now...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_feature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;streaming_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;history_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recommendations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample_from_beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;watched_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reward_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'user_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;streaming_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recommendations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;watched_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'movie_id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# 잘 못 맞췄으면 0점을 얻음
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recommendations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recommendations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# 잘 맞춨으면 1점을 얻음
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recommendations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recommendations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;reward_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action_chosen&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_action_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_chosen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Step: {} -- Average Reward: {}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reward_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reward_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Time: {}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'r'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Cumulative Average Reward of &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; Tree Heuristic: Movie Lens Data&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# Training: Cover Type Data
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_covtype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;581000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;covtype.data&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;54&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;54&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_dummies&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_arm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TreeHeuristic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MemoryHistoryStorage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MemoryModelStorage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MemoryActionStorage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_actions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;reward_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Starting Now...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;history_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recommendations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample_from_beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 실제 Reward 를 받고 이를 누적함
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;actual_reward&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recommendations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;reward_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actual_reward&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history_id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recommendations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actual_reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# D는 매 trial 마다 업데이트해 주어야 함
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recommendations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actual_reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# batch size 만큼을 모아서 적합해줌
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action_chosen&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_action_storage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update_tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action_chosen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 로그는 100개 마다 찍음
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Step: {} -- Average Reward: {}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reward_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reward_sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Time: {}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'r'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Cumulative Average Reward Flow of &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; Tree Heuristic: Cover type Data&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Test는 전통적으로 자주 애용되었던 Movielens 데이터와 Covtype 데이터로 진행할 수 있다. 아래 속도와 관련된 지표는 GPU가 없는 Laptop에 의한 것임을 밝혀둔다.&lt;/p&gt;

&lt;p&gt;위 두 데이터의 경우, Tree Heuristic 알고리즘이 Lin UCB보다 우수한 성능을 보이는 것으로 확인되었다. 비록 Lin UCB보다는 속도 면에서 열위를 보이기는 하지만, Tree 구조에 기반한 모델이므로 해석에 있어 강점을 보일 수 있다는 점과 우수한 성능 때문에 충분히 기능할 수 있는 알고리즘으로 판단된다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Test1: Covtype Data&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;알고리즘&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;10% Dataset&lt;br /&gt;&lt;br /&gt;(58,100)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;20% Dataset&lt;br /&gt;&lt;br /&gt;(116,200)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;50% Dataset&lt;br /&gt;&lt;br /&gt;(290,500)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;100% Dataset&lt;br /&gt;&lt;br /&gt;(581,000)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;비고&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Lin UCB&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.7086&lt;br /&gt;&lt;br /&gt;(23.66초)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.7126&lt;br /&gt;&lt;br /&gt;(49.39초)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.7165&lt;br /&gt;&lt;br /&gt;(137.19초)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.7180&lt;br /&gt;&lt;br /&gt;(5분 39초)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;alpha=0.2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Tree Heuristic&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.7154&lt;br /&gt;&lt;br /&gt;(100.65초)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.7688&lt;br /&gt;&lt;br /&gt;(6분 48초)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8261&lt;br /&gt;&lt;br /&gt;(2463.70초)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8626&lt;br /&gt;&lt;br /&gt;(2시간 37분)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3000 trial이&lt;br /&gt;&lt;br /&gt;지날 때 마다 적합&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Test2: Movielens Data&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;알고리즘&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;10% Dataset&lt;br /&gt;&lt;br /&gt;(16,400)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;20% Dataset&lt;br /&gt;&lt;br /&gt;(32,700)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;50% Dataset&lt;br /&gt;&lt;br /&gt;(81,800)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;100% Dataset&lt;br /&gt;&lt;br /&gt;(163,600)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;비고&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Lin UCB&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.7521&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.7668&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.7746&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.7567&lt;br /&gt;&lt;br /&gt;(6분 14초)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;alpha=0.2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Tree Heuristic&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.7683&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8017&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8183&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0.8346&lt;br /&gt;&lt;br /&gt;(33분 16초)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;100 trial이&lt;br /&gt;&lt;br /&gt;지날 때 마다 적합&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;http://rob.schapire.net/papers/www10.pdf&quot;&gt;Lin UCB 논문&lt;/a&gt;
&lt;a href=&quot;http://auai.org/uai2017/proceedings/papers/171.pdf&quot;&gt;Tree Heuristic 논문&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>OpenAI GPT-2 - Language Models are Unsupervised Multitask Learners</title>
   <link href="http://localhost:4000/OpenAI-GPT-2-Language-Models-are-Unsupervised-Multitask-Learners/"/>
   <updated>2019-08-28T00:00:00+09:00</updated>
   <id>http://localhost:4000/OpenAI GPT-2 - Language Models are Unsupervised Multitask Learners</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 2019년 2월 &lt;em&gt;Alec Radford&lt;/em&gt; 등이 발표한 OpenAI GPT-2: Language Models are Unsupervised Multitask Learners를 살펴보도록 한다.&lt;/p&gt;

&lt;p&gt;코드와 논문은 &lt;a href=&quot;https://openai.com/blog/better-language-models/&quot;&gt;여기&lt;/a&gt;에서 볼 수 있지만, 전체버전은 성능이 너무 강력하다는 이유로 공개되지 않았다.&lt;/p&gt;

&lt;p&gt;중요한 부분만 적을 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;openai-gpt-2---language-models-are-unsupervised-multitask-learners&quot;&gt;OpenAI GPT-2 - Language Models are Unsupervised Multitask Learners&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf&quot;&gt;OpenAI GPT-2 - Language Models are Unsupervised Multitask Learners&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;홈페이지: &lt;strong&gt;&lt;a href=&quot;https://openai.com/blog/better-language-models/&quot;&gt;OpenAI&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Tensorflow code: &lt;strong&gt;&lt;a href=&quot;https://github.com/openai/gpt-2&quot;&gt;Official Code&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;초록abstract&quot;&gt;초록(Abstract)&lt;/h2&gt;

&lt;p&gt;질답(QA), 기계번역, 독해, 요약과 같은 자연어처리 과제들은 대개 과제에 특화된 dataset과 지도학습을 통해 이루어졌다. 이 논문에서, 언어모델은 WebText라는 수백만 개의 웹페이지를 모은 새로운 dataset에서 학습될 때 어떤 명시적인 지도 없이 이러한 과제들을 학습하기 시작했음을 보인다. 문서와 질문이 있을 때 대답을 생성하는 언어모델은 CoQA dataset에서 55 F1 score를 달성하였고 이는 127k 이상의 학습데이터 사용 없이 4개 중 3개의 기준시스템을 능가한 것이다.&lt;br /&gt;
이 언어모델의 capacity는 zero-shot task transfer의 성공에 필수적이다. 이 논문에서 제시되는 가장 큰 모델 GPT-2는 15억 개의 Transformer parameter를 가지며 zero-shot 환경에서 8개 중 7개에서 state-of-the-art를 달성하였는데 이 큰 모델도 WebText에서 과소적합(underfitting) 현상을 보인다. 모델에서 나온 예는 이러한 개선점을 반영하며 일관성 있는 텍스트 단락을 포함한다. 이러한 발견은 자연적 설명으로부터 과제수행능력을 배우는 언어처리모델을 개발하는 촉망되는 방법을 시사한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-서론introduction&quot;&gt;1. 서론(Introduction)&lt;/h2&gt;

&lt;p&gt;기계학습 시스템은 큰 dataset과 고용량의 모델, 지도학습 등을 통해 빠르게 발전해왔다. 이러한 방법으로 개발된 모델들은 불안정하며 매우 좁은 범위의 문제에서만 뛰어난 능력을 발휘한다. 그래서 데이터를 수동 분류하는 과정 없이도 더 범용적인 모델을 개발할 필요가 있다.&lt;/p&gt;

&lt;p&gt;현재 기계학습체계를 개발하는 주된 방법은 목표 과제에 맞는 dataset을 찾아서, 이를 학습/검증 단계로 나누어 학습 후 IID(independet and identically distributed)로 성능을 측정하는 방법이다. 이는 좁은 범위의 과제에서는 매우 효과적이나 범용적인 이해를 필요로 하는 독해나 다양한 이미지 분류시스템 등의 문제에서는 높은 성능을 내지 못했다.&lt;br /&gt;
많은 연구가 단일 영역의 dataset과 단일 과제에만 맞춘 학습에만 치중되었었다. 최근에야 넓은 범위의 dataset과 여러 과제에 대한 GLUE benchmark 등이 제안되기 시작했다.&lt;/p&gt;

&lt;p&gt;다중작업 학습(Multitask learning)은 일반성능을 높이는 유망한 방법이지만 아직 초기 연구 단계이다. 최근에는 &lt;a href=&quot;https://arxiv.org/abs/1901.11373&quot;&gt;Learning and Evaluating General Linguistic Intelligence&lt;/a&gt; 등의 연구가 성능 향상을 이뤄냈지만, 최근의 기계학습 시스템은 일반화를 위해서는 수십만 개 정도의 학습 샘플을 필요로 하는데 이는 다중작업 학습을 위해서는 그 몇 배가 필요하다는 것을 뜻한다.&lt;/p&gt;

&lt;p&gt;가장 성능이 높은 언어처리모델은 사전학습(pre-training)과 지도 세부학습(supervised fine-tuning)의 결합으로 만들어졌다. 이 접근법은 transfer과 더불어 긴 역사를 가졌다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;단어벡터를 학습시킨 후 과제특화된(task-specific) 모델구조에 입력으로 넣고&lt;/li&gt;
  &lt;li&gt;순환형 네트워크의 문맥표현이 전이되고&lt;/li&gt;
  &lt;li&gt;최근에는 과제특화된 모델구조는 더 이상 중요하지 않으며 많은 self-attention block만으로 충분하다고 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이러한 방법들은 여전히 지도학습을 필요로 한다. 만약 지도 데이터가 최소한으로 또는 전혀 필요하지 않다면, 일반상식 추론이나 감정분석과 같은 특정 과제들을 수행하는 데 큰 발전이 있을 것이다.&lt;/p&gt;

&lt;p&gt;이 논문에서는, 위의 두 방향의 연구를 결합하여 전이학습의 더 일반적인 방법의 흐름을 잏는다. 언어모델이 어떤 parameter나 모델구조의 변화 없이도 zero-shot setting 하에서 downstream task를 수행할 수 있음을 보인다. 이 접근법은 언어모델이 zero-shot setting 하에서 넓은 범위의 과제를 수행할 수 있는 가능성을 보이며, 전도유망하고 경쟁력 있으며 과제에 따라서는 state-of-the-art를 달성하였다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-접근법approach&quot;&gt;2. 접근법(Approach)&lt;/h2&gt;

&lt;p&gt;핵심은 언어모델링(language modeling)이다. 언어모델링은 보통 각 원소가 일련의 symbol $(s_1, s_2, …, s_n)$으로 구성된 예제 $(x_1, x_2, …, x_n)$에서 비지도분포 추정을 하는 것으로 정의된다. 언어는 자연적으로 연속된 순서를 가지므로 보통 조건부확률의 곱으로 이루어진 symbol에 따른 합동확률로 구해진다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x) = \prod_{i=1}^n p(s_n \vert s_1, ..., s_{n-1})&lt;/script&gt;

&lt;p&gt;이 접근법은 어떤 조건부확률 $p(s_{n-k}, …, s_n \vert s_1, …, s_{n-k-1})$만큼이나 $p(x)$의 다루기 쉬운 샘플링을 가능하게 하였다. 최근에는 이러한 조건부확률을 매우 잘 계산하는 Transformer 등이 만들어졌다.&lt;/p&gt;

&lt;p&gt;단일 과제 수행의 학습은 조건부분포 $p(output \vert input)$를 추정하는 확률 framework로 표현될 수 있다. 범용시스템은 여러 다른 과제들을 수행할 수 있어야 하기 때문에 같은 입력이라도 입력뿐 아니라 과제의 종류라는 조건이 들어가야 한다. 따라서 $p(output \vert input, task)$로 표현되어야 한다. 이는 다중학습과 메타학습 환경에서 다양하게 형식을 갖는다.&lt;br /&gt;
과제 조건을 다는 것은 모델구조 수준이나 MAML 최적화 framework에서 알고리즘 수준에서 구현되기도 한다. 그러나 &lt;a href=&quot;https://arxiv.org/abs/1806.08730&quot;&gt;McCann&lt;/a&gt;에서 나온 것과 같이, 언어는 과제/입력/출력 모두를 일련의 symbol로 명시하는 유연한 방법을 제공한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;예를 들어 번역학습은 (프랑스어로 번역, 영어 텍스트, 프랑스어 텍스트)로 표현된다(translate to french, english text, french text).&lt;/li&gt;
  &lt;li&gt;독해는 (질문에 대답, 문서, 질문, 대답)이다(answer the question, document, question, answer).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;McCann은 MQAN이라는 단일 모델로 학습하는 것이 가능했다고 설명하며 이 형식으로 많은 과제를 수행하였다고 한다.&lt;/p&gt;

&lt;p&gt;언어모델링은 또한 어떤 symbol이 예측할 출력인지에 대한 명시적인 지도 없이도 McCann의 과제들을 학습할 수 있다. Sequence의 부분집합에 대해서만 평가하더라도 지도목적함수는 비지도목적함수와 같기 때문에, 전역최소값(global minimum)은 비지도학습에서와 지도학습에서 같은 값을 가진다. 즉 비지도목적함수에서 수렴하게 할 수 있다. 예비실험에서, 충분히 큰 언어모델은 이런 toy-ish 환경에서 다중작업 학습이 가능했으나 학습은 명시적 지도학습에서보다 훨씬 느렸다.&lt;/p&gt;

&lt;p&gt;대화(dialog) 데이터는 꽤 괜찮은 학습 방법이지만, 상호작용이 필요없는 인터넷 사이트에 존재하는 방대한 양의 데이터가 더 낫다는 판단을 내렸다. 충분한 용량을 가지는 언어모델이라면 데이터 조달 방법과는 관련없이 더 나은 예측을 위한 수행을 시작할 것이라는 추측이 있다. 만약 지금 가능하다면, 아마 현실적으로 비지도 다중작업 학습이 될 것이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-28-OpenAI GPT-2 - Language Models are Unsupervised Multitask Learners/01.png&quot; width=&quot;80%&quot; alt=&quot;Examples&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;21-training-dataset&quot;&gt;2.1. Training Dataset&lt;/h3&gt;

&lt;p&gt;많은 선행연구에서 사용된 dataset은 뉴스와 같이 한 영역에서만 가져온 데이터로 구성되어 있었다. 이 논문에서는 가능한 한 다양한 출처로부터 가져오려고 하였다.&lt;/p&gt;

&lt;p&gt;이러한 점에서 촉망받는 것은 &lt;a href=&quot;www.commoncrawl.org&quot;&gt;Common Crawl&lt;/a&gt;과 갈은 web scraping 자료인데, 이 중 많은 양이 이해할 수 없는(unintelligible, 또는 품질이 떨어지는) 데이터라 한다. 따라서 이 논문에서는 단순 크롤링이 아닌 고품질의 데이터를 얻는 다른 방법을 사용하기로 했다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;사람에 의해 필터링된 글만을 사용하기로 하였다:
    &lt;ul&gt;
      &lt;li&gt;Reddit에서 3 karma 이상을 받은 글에 포함된 외부링크의 글을 가져왔다.&lt;/li&gt;
      &lt;li&gt;결과적으로 45M개의 링크를 가져왔다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dataset 이름은 &lt;strong&gt;WebText&lt;/strong&gt;라 하였다.&lt;/li&gt;
  &lt;li&gt;텍스트 추출을 위해 &lt;a href=&quot;http://www2013.w3c.br/companion/p89.pdf&quot;&gt;Dragnet&lt;/a&gt;과 &lt;a href=&quot;https://github.com/codelucas/newspaper&quot;&gt;Newspaper 내용추출기&lt;/a&gt;를 사용했다.&lt;/li&gt;
  &lt;li&gt;2017년 12월 이후의 글과 위키피디아 글은 제거했으며, 중복제거 등을 거쳐 8M개의 문서, 40GB의 텍스트를 확보하였다.
    &lt;ul&gt;
      &lt;li&gt;위키피디아는 다른 dataset에서 흔하고, 학습과 측정 단계에서의 데이터가 겹치는 문제로 인해 분석이 복잡해질 수 있어 제외했다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;22-input-representation&quot;&gt;2.2. Input Representation&lt;/h3&gt;

&lt;p&gt;범용언어모델은 어떤 문자열의 확률도 계산할 수 있어야 한다. 현재 대규모 언어모델은 소문자화, 토큰화, 모델링 가능한 문자열이 차지하는 공간을 제한하기 위한 사전외 token과 같은 전처리 과정을 거친다. Unicode 문자열을 UTF-8 형식으로 처리하는 것은 이를 우아하게 만족시키며 byte수준 언어모델은 One Billion Word Benchmark와 같은 대규모 dataset에서 단어수준 언어모델에 뒤떨어진다. WebText에서도 역시 그러한 성능차이를 확인하였다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1508.07909&quot;&gt;Byte Pair Encoding(BPE)&lt;/a&gt;&lt;/strong&gt;는 글자(byte)와 단어의 적당한 중간 단위를 쓴다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;이는 자주 나오는 symbol sequence의 단어수준 입력과 자주 나오지 않는 symbol sequence의 글자수준 입력을 적절히 보간(interpolate)한다.&lt;/li&gt;
  &lt;li&gt;그 이름과는 달리 BPE 구현은 byte sequence가 아닌 Unicode code points에서 동작한다. 이러한 구현은 모든 Unicode 문자열을 모델링하기 위해 전체 Unicode symbol의 공간만큼을 필요로 한다.&lt;/li&gt;
  &lt;li&gt;multi-symbol token을 추가하기 전 13만 개의 token을 포함하는 기본사전을 필요로 하게 된다. 이는 보통의 3만 2천~6만 4천 token의 사전보다 엄청나게 큰 것이다.
    &lt;ul&gt;
      &lt;li&gt;이와는 달리 byte수준의 BPE의 사전은 256개만의 token을 포함한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;그러나 BPE를 byte sequence에 직접 적용하는 것은 BPE가 token 사전을 구춘하기 위한 heuristic에 기반한 greedy frequency를 사용하기 때문에 최적이 아니게 된다.&lt;/li&gt;
  &lt;li&gt;BPE는 dog의 다양한 형태, &lt;code class=&quot;highlighter-rouge&quot;&gt;dog.&lt;/code&gt;나 &lt;code class=&quot;highlighter-rouge&quot;&gt;dog!&lt;/code&gt;나 &lt;code class=&quot;highlighter-rouge&quot;&gt;dog?&lt;/code&gt; 등을 가진다.
    &lt;ul&gt;
      &lt;li&gt;이는 한정적인 사전과 모델의 공간을 최적이 아니게 사용하게 된다.&lt;/li&gt;
      &lt;li&gt;이를 피하기 위해 BPE가 어떤 byte sequence로부터도 문자 범주를 넘어 병합하는 것을 막았다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;여러 vocab token의 최소부분만을 추가할 때 압축효율성을 크게 증가시키는 공간을 위한 예외를 두었다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이러한 입력표현은 단어수준 언어모델의 경험적 이점과 문자수준 접근법의 일반성을 결합할 수 있게 한다. 이 논문의 접근법이 어떤 Unicode 문자열에든 확률을 부여할 수 있기 때문에, 이는 이 논문의 모델을 전처리, 토큰화, 사전크기 등과 관련없이 어떤 dataset에서도 평가할 수 있게 만든다.&lt;/p&gt;

&lt;h3 id=&quot;23-model&quot;&gt;2.3. Model&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/17/Attention-Is-All-You-Need/&quot;&gt;Transformer&lt;/a&gt;가 기본 구조이며, &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/21/OpenAI-GPT-1-Improving-Language-Understanding-by-Generative-Pre-Training/&quot;&gt;OpenAI Gpt-1&lt;/a&gt;의 구조를 대부분 따른다. 약간의 차이는 있는데,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Layer 정규화가 &lt;a href=&quot;https://arxiv.org/abs/1603.05027&quot;&gt;pre-activation residual network&lt;/a&gt;처럼 각 sub-block의 입력으로 옮겨졌다.
    &lt;ul&gt;
      &lt;li&gt;추가 layer 정규화가 마지막 self-attention block 이후에 추가되었다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;모델 깊이에 따른 residual path의 누적에 관한 부분의 초기화 방법이 변경되었다.
    &lt;ul&gt;
      &lt;li&gt;$N$이 residual layer의 수라 할 때, residual layer의 가중치에 $1 / \sqrt{N}$을 곱했다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;사전은 50,257개로 확장되었다.&lt;/li&gt;
  &lt;li&gt;문맥고려범위(context size)가 512~1024개의 token으로 늘어났으며 batch size도 512로 증가했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-실험experiments&quot;&gt;3. 실험(Experiments)&lt;/h2&gt;

&lt;p&gt;모델은 크기가 각각 다른 4개를 만들어 실험했다. 각 모델의 크기는 다음과 같다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Parameters&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Layers&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;d_{model}&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;117M&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;12&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;768&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;345M&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;24&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1024&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;762M&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;36&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1280&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1542M&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;48&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1600&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;가장 작은 모델은 크기가 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/21/OpenAI-GPT-1-Improving-Language-Understanding-by-Generative-Pre-Training/&quot;&gt;OpenAI GPT-1&lt;/a&gt;와 같고, 두 번째는 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/23/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding/&quot;&gt;BERT&lt;/a&gt;와 같다. 가장 큰 모델인 GPT-2는 10배 이상 크다.&lt;/p&gt;

&lt;p&gt;각 모델의 learning rate는 WebText의 5%를 떼서 만든 held-out 샘플을 사용하여 수동 조정하였다. 모든 모델은 여전히 WebText에 과소적합(underfitted)되었으며 더 오래 학습시키면 더 높은 성능을 얻을 수 있을 것이다.&lt;/p&gt;

&lt;h3 id=&quot;31-language-modeling&quot;&gt;3.1. Language Modeling&lt;/h3&gt;

&lt;p&gt;GPT-2는 문자단위(byte level)로 되어 있어 손실이 있는 전처리나 토큰화 등이 필요하지 않으며, 어떤 언더 모델 benchmark에도 사용할 수 있다. 평가는 WebText 언어모델에 따른 dataset의 로그확률을 계산하는 방식으로 통일했다. WebText 언어모델은 일반 분포를 심하게 벗어난 것, 이를테면 대단히 규격화된 텍스트, 분리된 구두점이나 축약형, 섞인 문장에 대해 평가받으며, &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;UNK&amp;gt;&lt;/code&gt;는 WebText에 400억 byte 중 26번밖에 나타나지 않는다.&lt;/p&gt;

&lt;p&gt;결과는 아래 표에 나와 있으며, 어떤 세부조정도 거치지 않고 zero-shot 환경에서 8개 중 7개에서 state-of-the-art를 달성하였다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-28-OpenAI GPT-2 - Language Models are Unsupervised Multitask Learners/02.png&quot; width=&quot;100%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;32-childrens-boot-test&quot;&gt;3.2. Children’s Boot Test&lt;/h3&gt;

&lt;p&gt;품사(고유명사, 명사, 동사, 전치사)에 따른 언어 모델의 성능을 측정하기 위한 dataset이다. &lt;a href=&quot;https://arxiv.org/abs/1511.02301&quot;&gt;원 논문&lt;/a&gt;에 소개된 내용을 따라 각 선택의 확률과 언어모델의 선택에 따른 문장의 나머지 부분에 대한 확률을 계산하고 가장 높은 확률의 선택지를 선택하게 했다. 결과는 89.1% $\to$ 93.3%가 되었다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-28-OpenAI GPT-2 - Language Models are Unsupervised Multitask Learners/03.png&quot; width=&quot;80%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;33-lambada&quot;&gt;3.3. LAMBADA&lt;/h3&gt;

&lt;p&gt;텍스트의 장거리 의존성(long-range dependencies)을 평가한다. 간단히 말하면 정확도는 19% $\to$ 52.66%, perplexity는 99.8 $\to$ 8.6으로 향상시켰다.&lt;/p&gt;

&lt;h3 id=&quot;34-winograd-schema-challenge&quot;&gt;3.4. Winograd Schema Challenge&lt;/h3&gt;

&lt;p&gt;텍스트에 존재하는 중의성(또는 모호한 부분, ambiguities)을 해석하는 능력을 측정함으로써 일반상식 추론능력을 평가한다. GPT-2는 정확도를 7% 증가시켜 70.70%를 달성했다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-28-OpenAI GPT-2 - Language Models are Unsupervised Multitask Learners/04.png&quot; width=&quot;80%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;35-reading-comprehension&quot;&gt;3.5. Reading Comprehension&lt;/h3&gt;

&lt;p&gt;CoQA(The Conversation Question Answering dataset)을 7개의 분야에서 가져온 문서에서 질문자-답변자의 자연어 대화로 이루어진 dataset이다. CoQA 테스트는 독해능력과 대화에 기반한 모델의 답변능력을 평가한다. GPT-2는 55 F1 score를 달성해 4개 중 3개의 다른 모델을 능가했는데 이는 심지어 주어진 127k 이상의 수동 수집된 질답 쌍으로 학습시키지 않은 것이다. 지도가 포함된 state-of-the-art인 BERT는 89 F1 score에 근접하였다. 그러나 어떤 세부조정 없이 55점을 달성했다는 것은 상당히 고무적인 일이다.&lt;/p&gt;

&lt;h3 id=&quot;36-summarization&quot;&gt;3.6. Summarization&lt;/h3&gt;

&lt;p&gt;CNN과 Daily Mail dataset으로 요약 능력을 평가했다. 총합 6.4점의 향상을 보였다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-28-OpenAI GPT-2 - Language Models are Unsupervised Multitask Learners/05.png&quot; width=&quot;80%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;37-translation&quot;&gt;3.7. Translation&lt;/h3&gt;

&lt;p&gt;번역에서는 예상외로 별로 좋은 결과를 내지 못했다고 한다.&lt;/p&gt;

&lt;h3 id=&quot;38-question-answering&quot;&gt;3.8. Question Answering&lt;/h3&gt;

&lt;p&gt;답변한 문장이 ‘완전히 일치하는’ 평가 방법을 썼을 때 GPT-2는 약 4.1%의 정확도를 보여 일반적으로 5.3배의 정확도를 보인다. 그러나 GPT-2가 생성한 30개의 가장 ‘자신있는’ 답변은 아래 그림에 나와 있는데 이는 정보검색과 문서추출 질답을 병행한 열린분야 질답 시스템에 비하면 50%까지 낮은 성능을 보인다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-28-OpenAI GPT-2 - Language Models are Unsupervised Multitask Learners/06.png&quot; width=&quot;100%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;4-일반화-vs-암기generalization-vs-memorization&quot;&gt;4. 일반화 vs 암기(Generalization vs Memorization)&lt;/h2&gt;

&lt;p&gt;최근 연구에서 많이 사용되는 데이터셋 중에는 거의 동일한 이미지를 여럿 포함하는 것이 있는데, 예를 들면 CIFAR-10의 경우 3.3%의 이미지가 train / test 세트에서 겹친다. 이는 기계학습 시스템의 일반화 성능을 과대평가하게 만든다. 이는 성능 측정에 방해 요인이 되기 때문에 데이터셋이 이러한 요인이 없는지 확인하는 것은 중요하다.&lt;/p&gt;

&lt;p&gt;그래서 WebText에 대해 8-gram 학습세트 토큰을 포함하는 Bloom 필터를 만들어 테스트해보았고, 결과는 다음과 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-28-OpenAI GPT-2 - Language Models are Unsupervised Multitask Learners/07.png&quot; width=&quot;100%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;p&gt;물론 WebText는 써도 괜찮다는 결론이 나왔다. 그런데 다른 데이터셋의 경우에는 생각보다 높은 겹침(overlap) 현상이 나타나는 것을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;비슷한 텍스트들이 성능에 어떤 영향을 미치는지 이해하고 정량화하는 것은 중요한 부분이다. 더 나은 데이터중복제거(de-duplication) 기술은 매우 중요하며, 중복제거에 기반한 n-gram overlap을 사용하는 것은 훌륭한 방법이며 이 논문에서는 이를 추천한다.&lt;/p&gt;

&lt;p&gt;WebText LM의 성능을 결정하는 또 다른 잠재적 방법은 암기(기억, memorization)이 held-out set에 어떤 영향을 미치는지 살펴보는 것이다. train / test set에 대해 성능을 평가한 다음 그림은 그 거대한 GPT-2가 WebText에 대해 여전히 과소적합(underfitted)되었으며 암기에 의한 것이 아님을 보여준다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-28-OpenAI GPT-2 - Language Models are Unsupervised Multitask Learners/08.png&quot; width=&quot;70%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;5-관련-연구related-work&quot;&gt;5. 관련 연구(Related Work)&lt;/h2&gt;

&lt;p&gt;이 논문의 많은 부분은 더 큰 데이터셋으로 학습된 더 큰 언어모델의 성능을 측정하는 데 쓰였다. 다른 많은 연구들도 이와 비슷하다(scaled RNN based LM 등).&lt;/p&gt;

&lt;p&gt;iWeb Corpus와 같은 거대한 웹페이지의 텍스트 말뭉치를 필터링하고 구축하는 대안을 제시하거나, 언어문제를 위한 사전학습 방법, 벡터표현, seq2seq 등이 연구되었으며 최근 연구들은 언어모델의 사전학습이 잡담이나 대화 같은 어려운 생성문제에 맞춰 세부조정할 때 도움이 된다는 것을 밝혀내었다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;6-토의discussion&quot;&gt;6. 토의(Discussion)&lt;/h2&gt;

&lt;p&gt;많은 연구들은 지도/비지도 사전학습 표현에 대한 학습, 이해, 비판적 평가에 관해 연구를 진행해 왔다. 이 논문은 비지도 학습이 아직 연구할 거리가 더 남아 있음을 밝혔다.&lt;/p&gt;

&lt;p&gt;GPT-2의 zero-shot 학습 성능은 독해 등에서 좋은 성능을 보였으나 요약과 같은 문제에서는 기본적인 성능만을 보여주었다. 꽤 괜찮긴 해도 실제 사용하기엔 여전히 무리이다.&lt;/p&gt;

&lt;p&gt;GPT-2의 성능이 많은 과제에서 괜찮긴 한데, 세부조정을 통한 그 한계가 얼마인지는 분명하지 않다. 그렇지만 이 논문의 저자들은 decaNLP나 GLUE와 갈은 벤치마크에서 세부조정(fine-tuning)할 것을 계획하고 있다고 한다.&lt;br /&gt;
또 GPT-2의 학습데이터와 그 크기가 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/23/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding/&quot;&gt;BERT&lt;/a&gt;에서 말한 단방향 표현의 비효율성을 극복할 수 있을 만큼 충분한지도 확실치 않다고 한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;7-결론conclusion&quot;&gt;7. 결론(Conclusion)&lt;/h2&gt;

&lt;p&gt;큰 크기의 언어모델이 충분히 크고 다양한 데이터셋에서 학습된다면 많은 분야와 데이터셋에서 괜찮은 성능을 보여준다. GPT-2의 zero-shot은 8개 중 7개의 주요 언어 과제에서 state-of-the-art를 달성하였다.&lt;br /&gt;
모델이 zero-shot으로 다양한 과제에서 잘 수행한다는 것은 대용량의 모델이 외부 지도 없이 충분히 크고 다양한 말뭉치로부터 학습하면 많은 문제를 잘 수행할 가능성을 최대화할 것을 제시한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Acknowledgements&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;언제나 있는 감사의 인사&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;refenrences&quot;&gt;Refenrences&lt;/h2&gt;

&lt;p&gt;논문 참조. 많은 레퍼런스가 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;8-appendix-a-samples&quot;&gt;8. Appendix A: Samples&lt;/h2&gt;

&lt;h3 id=&quot;81-model-capacity&quot;&gt;8.1. Model capacity&lt;/h3&gt;

&lt;p&gt;가장 작은 WebText LM과 GPT-2가 본 적 없는(unseen) WebTest 테스트 기사에 대해 생성한 문장들을 비교하여 나열한 것이 표 7~11에 있다. 256개의 단어(token)을 주고 다음 256를 생성하는 것이다. 논문에 따르면 잘 된 것을 골라 가져온 것은 아니라고 한다.&lt;br /&gt;
그 중 하나를 가져와 보았다. 기계가 생성한 문장치고 깔끔하다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-28-OpenAI GPT-2 - Language Models are Unsupervised Multitask Learners/09.png&quot; width=&quot;100%&quot; alt=&quot;Generation Results&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;82-text-memorization&quot;&gt;8.2. Text Memorization&lt;/h3&gt;

&lt;p&gt;게티즈버그 연설 유명한 인용문이나 연설 같은 문장이 주어질 때 GPT-2가 (그대로) ‘암기’하는 행동을 보이는 것이 관찰되었다.&lt;br /&gt;
이런 현상이 얼마나 일어나는지 보기 위해 test set 기사를 주고 GPT-2가 생성한 문장과 실제 문장의 완성한 것과의 overlap 비율을 비교해 보았다.&lt;br /&gt;
결과는 기준보다 그 비율이 낮다고 한다.&lt;/p&gt;

&lt;h3 id=&quot;83-diversity&quot;&gt;8.3. Diversity&lt;/h3&gt;

&lt;p&gt;표 12는 같은 문장을 주고 나머지를 생성하라 했을 때 얼마나 다양한 문장들을 생성하는지 본 것이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-28-OpenAI GPT-2 - Language Models are Unsupervised Multitask Learners/10.png&quot; width=&quot;100%&quot; alt=&quot;Generation Results&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;84-robustness&quot;&gt;8.4. Robustness&lt;/h3&gt;

&lt;p&gt;표 13은 앞에서 언급 한 유니콘 뉴스 기사를 보여준다. 이 모델이 분포 문맥을 다룰 수는 있지만 이러한 샘플의 품질은 일반적으로 낮다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-28-OpenAI GPT-2 - Language Models are Unsupervised Multitask Learners/11.png&quot; width=&quot;100%&quot; alt=&quot;Generation Results&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
   <link href="http://localhost:4000/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding/"/>
   <updated>2019-08-23T00:00:00+09:00</updated>
   <id>http://localhost:4000/BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 2018년 10월 &lt;em&gt;Jacob Devlin&lt;/em&gt; 등이 발표한 BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding를 살펴보도록 한다.&lt;/p&gt;

&lt;p&gt;어쩐지 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/20/ELMo-Deep-contextualized-word-representations/&quot;&gt;ELMo&lt;/a&gt;를 매우 의식한 듯한 모델명이다.&lt;/p&gt;

&lt;p&gt;코드와 사전학습(기학습)된 모델은 &lt;a href=&quot;https://github.com/google-research/bert&quot;&gt;여기&lt;/a&gt;에서 볼 수 있다.&lt;/p&gt;

&lt;p&gt;중요한 부분만 적을 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding&quot;&gt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1810.04805&quot;&gt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Pytorch code: &lt;strong&gt;&lt;a href=&quot;https://github.com/dhlee347/pytorchic-bert&quot;&gt;Github: dhlee347&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;초록abstract&quot;&gt;초록(Abstract)&lt;/h2&gt;

&lt;p&gt;이 논문에서는 새로운 언어표현모델(language representation model)인 &lt;strong&gt;BERT&lt;/strong&gt;(&lt;strong&gt;B&lt;/strong&gt;idirectional &lt;strong&gt;E&lt;/strong&gt;ncoder &lt;strong&gt;R&lt;/strong&gt;epresentations from &lt;strong&gt;T&lt;/strong&gt;ransformers)를 소개한다. 최근의 언어표현모델과는 다르게 BERT는 모든 layer의 좌우 문맥 모두에서 깊은 양방향 표현(deep bidirectional representations)를 사전학습(pre-train)하도록 설계되었다. 결과적으로 사전학습된 BERT는 QA나 언어추론 등 대부분의 과제(task)에서, 해당 과제에 특화된 모듈을 추가하지 않고 딱 하나의 추가 출력 layer만 붙여도 state-of-the-art 결과를 얻을 수 있었다.&lt;/p&gt;

&lt;p&gt;BERT는 개념적으로 간단하고 경험적으로 강력하다. GLUE benchmark에서 7.7% 상승한 80.5%, MultiNLI에서 4.6$ 상승한 86.7%, SQuAD v1.1에서 1.5 상승한 93.2(F1 score), SQuAD v2.0에서 5.1 상승한 83.1 F1 score를 기록하였다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-서론introduction&quot;&gt;1. 서론(Introduction)&lt;/h2&gt;

&lt;p&gt;언어모델 사전학습은 자연어처리 과제들에서 효과적이다. 사전학습된 언어표현을 downstream task에 적용하는 데는 두 가지 전략이 있는데&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;사전학습된 표현을 특정과제에 특화된(task-specific) 모델구조에 추가하는 특성기반 접근법(feature-based approach), 예로 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/20/ELMo-Deep-contextualized-word-representations/&quot;&gt;ELMo&lt;/a&gt;가 있다.&lt;/li&gt;
  &lt;li&gt;특정과제에 특화된 parameter를 최소로 추가하여, 간단히 사전학습된 &lt;em&gt;모든&lt;/em&gt; parameter를 세부조정(fine-tune)함으로써 downstream task에서 학습하는 방법, 예로 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/21/OpenAI-GPT-1-Improving-Language-Understanding-by-Generative-Pre-Training/&quot;&gt;Generative Pre-trained Transformer(OpenAI GPT)&lt;/a&gt;가 있다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이 두 접근법은 범용언어표현을 학습하기 위해 단방향 언어모델을 사용하기 때문에 사전학습기간 동안 같은 목적함수를 공유한다.&lt;br /&gt;
그러나 이러한 방법은, 특히 fine-tuning 접근법은 사전학습된 표현의 능력을 제한시킨다. 가장 큰 한계는 표준언어모델은 단방향이며 이것이 사전학습하는 동안 모델구조의 선택권을 제한한다. 예로 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/21/OpenAI-GPT-1-Improving-Language-Understanding-by-Generative-Pre-Training/&quot;&gt;OpenAI GPT&lt;/a&gt;의 경우, 좌$\rightarrow$우 구조를 사용하였는데 이는 Transformer의 self-attention layer에서 모든 token이 이전 token에만 의존하게 만든다.&lt;/p&gt;

&lt;p&gt;이 논문에서는 fine-tuning을 기반으로 한 BERT라는 접근법을 제안한다. 이 모델은 &lt;strong&gt;MLM&lt;/strong&gt;(Masked Language Model) 사전학습을 사용하여 단방향성을 제거하였다. 이는&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;입력의 일부 token을 무작위로 &lt;code class=&quot;highlighter-rouge&quot;&gt;[mask]&lt;/code&gt; token으로 치환하고, 목적은 주변 문맥으로부터 마스크 처리된 단어를 유추하는 것이다.&lt;/li&gt;
  &lt;li&gt;좌$\rightarrow$우 사전학습 언어모델과는 다르게 MLM objective는 좌/우 문맥을 결합하여 깊은 양방향(deep bidirectional) Transformer을 미리 학습시킬 수 있게 한다.&lt;/li&gt;
  &lt;li&gt;추가로 &lt;strong&gt;NSP&lt;/strong&gt;(Next Sentence Prediction) 과제를 사용하여 문자-쌍 표현을 미리 결합학습(jointly pre-train)할 수 있게 하였다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그래서 이 논문의 기여한 바는&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;언어표현을 위한 양방향 사전학습의 중요성을 보여주었다. 즉 deep bidirectional representation을 사전학습할 수 있다.&lt;/li&gt;
  &lt;li&gt;사전학습된 표현은 특정과제에 특화된 구조를 만들기 위해 조정을 계속할 필요를 줄여준다는 것을 보였다.&lt;/li&gt;
  &lt;li&gt;11개의 NLP 과제에서 state-of-the-art 결과를 얻어내었다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-관련-연구related-work&quot;&gt;2. 관련 연구(Related work)&lt;/h2&gt;

&lt;p&gt;범용언어표현의 사전학습 연구는 긴 역사가 있다. 간단히 살펴보자.&lt;/p&gt;

&lt;h3 id=&quot;21-unsupervised-feature-based-approaches&quot;&gt;2.1. Unsupervised Feature-based Approaches&lt;/h3&gt;

&lt;p&gt;넓은 범위에서 사용가능한 단어의 표현을 학습시키는 것은 비신경망 모델과 신경망 모델 모두에서 많은 연구가 이러우졌다. 현대 NLP 체계에서 사전학습된 단어 embedding은 굉장한 성과를 거두었는데, 이 벡터를 학습시키기 위해서 좌$\rightarrow$우 언어모델 objective 또는 좌우 문맥으로부터 정확/부정확한 단어를 가려내는 방법 등이 사용되었다.&lt;br /&gt;
이러한 접근법은 문장/문단 embedding과 갈은 더 세부적인 부분으로 일반화되었다. 문장표현을 학습하기 위해서 다음 후보문장의 순위를 매기거나, 이전문장의 표현이 주어졌을 때 다음문장의 좌$\rightarrow$우 생성을 하거나, auto-encoder의 noise를 줄이는 방법 등이 사용되었다.&lt;/p&gt;

&lt;p&gt;ELMo와 그 이전 모델들은 전통적인 단어 embedding을 다른 차원으로 일반화했다. 이들은 문맥에 민감한 특성들을 좌$\rightarrow$우 및 우$\rightarrow$좌 모델로부터 추출했다. 각 token의 문맥 표현은 좌$\rightarrow$우 및 우$\rightarrow$좌 표현의 결합으로 만들어진다.&lt;br /&gt;
이외 여러 모델이 있으나 전부 특정기반이며 또한 깊은 양방향 학습이 이루어지지 못했다.&lt;/p&gt;

&lt;h3 id=&quot;22-unsupervised-fine-tuning-approaches&quot;&gt;2.2. Unsupervised Fine-tuning Approaches&lt;/h3&gt;

&lt;p&gt;이 방법은 미분류된(unlabeled) 문자로부터 사전학습된 단어 embedding을 얻는 것부터 시작한다.&lt;/p&gt;

&lt;p&gt;더 최근에는, 문맥 token 표현을 생성하는 문장/문서 인코더가 미분류 문자로부터 사전학습되고 지도 downstream task에 맞춰 세부조정되었다. 이 접근법의 장점은 parameter의 수가 적다는 것이다.&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/21/OpenAI-GPT-1-Improving-Language-Understanding-by-Generative-Pre-Training/&quot;&gt;OpenAI GPT&lt;/a&gt;는 GLUE benchmark에서 높은 성능을 기록핬다. 좌$\rightarrow$우 언어모델링과 auto-encoder objective가 이러한 모델에 사용되었다.&lt;/p&gt;

&lt;h3 id=&quot;23-transfer-learning-from-supervised-data&quot;&gt;2.3. Transfer Learning from Supervised Data&lt;/h3&gt;

&lt;p&gt;언어추론이나 기계번역 등의 분야에서 지도가 있는 task에서 큰 dataset으로 효과적인 전이학습을 하려는 연구가 있어왔다. Computer vision 연구는 또한 ImageNet 등 사전학습된 큰 모델로부터의 전이학습이 중요함을 보였다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-bert&quot;&gt;3. BERT&lt;/h2&gt;

&lt;p&gt;이 framework에는 크게 두 가지 단계가 있다: &lt;em&gt;pre-training&lt;/em&gt;(사전학습)과 &lt;em&gt;fine-tuning&lt;/em&gt;(세부조정)이다.&lt;br /&gt;
&lt;em&gt;pre-training&lt;/em&gt; 동안 모델은 다른 사전학습된 과제, 미분류된 데이터로 학습된다.&lt;br /&gt;
&lt;em&gt;fine-tuning&lt;/em&gt; 동안 BERT 모델은 사전학습된 parameter로 초기화된 후, 모든 parameter가 downstream task로부터 분류된 데이터를 사용하여 세부조정된다. 각 downstream task는 그들이 같은 사전학습된 parameter로 초기화되었다 하더라도 독립된 fine-tuned 모델이다. 다음 Figure 1에 나오는 QA 예제로 설명이 이어질 것이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-23-BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding/01.png&quot; width=&quot;100%&quot; alt=&quot;Architecture&quot; /&gt;&lt;/center&gt;

&lt;p&gt;BERT의 다른 모델과 구분되는 특징은 여러 다른 과제에 대해서도 통합된 모델구조를 갖는다는 것이다. 사전학습된 모델구조와 최종 downstream 구조에는 최소한의 차이만 존재한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Model Architecture&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;BERT의 모델구조는 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/17/Attention-Is-All-You-Need/&quot;&gt;Attention Is All You Need&lt;/a&gt;의 &lt;strong&gt;Transformer&lt;/strong&gt;를 기반으로 한 multi-layer bidirectional Transformer encoder이다. Transformer를 썼기 때문에 특별할 것이 없으며 그 구현은 원본과 거의 같기 때문에 자세한 설명은 생략한다. &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/17/Attention-Is-All-You-Need/#3-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%EC%84%B1model-architecture&quot;&gt;여기&lt;/a&gt;에서 인코더 부분을 살펴보자.&lt;/p&gt;

&lt;p&gt;Layer의 수를 $L$, 은닉층의 크기를 $H$, self-attention head의 수를 $A$라 한다.&lt;br /&gt;
BERT에는 두 가지 모델이 있는데&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;BERT_base: $L=12, H=768, A=12$. 전체 parameter 수: 110M&lt;/li&gt;
  &lt;li&gt;BERT_large: $L=24, H=1024, A=16$. 전체 parameter 수: 340M&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;BERT_base는 비교를 위해 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/21/OpenAI-GPT-1-Improving-Language-Understanding-by-Generative-Pre-Training/&quot;&gt;OpenAI GPT&lt;/a&gt;와 같은 크기를 가지도록 만들었다. 그러나 BERT Transformer는 양뱡향 self-attention을 사용하고 GPT Transformer는 모든 token이 왼쪽 문맥만 참조하도록 제한된 self-attention을 사용한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Input/Output Representations&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;BERT가 다양한 downstream task를 처리할 수 있게 하기 위해, 입력표현은 단일 문장인지 문장들의 쌍(Q &amp;amp; A 등)인지 구분되어야 한다. 여기서 “문장”이란 실제 언어학적 문장이 아닌 인접한 문자들의 연속으로 본다. “Sequence”가 BERT의 입력 token sequence가 되는데, 이는 단일 문장이나 문장의 쌍이 될 수 있다.&lt;/p&gt;

&lt;p&gt;이 논문에서는 3만 개의 단어 수를 갖는 &lt;a href=&quot;https://arxiv.org/abs/1609.08144&quot;&gt;WordPiece&lt;/a&gt; embedding을 사용한다. 모든 sequence의 첫 번째 token은 &lt;code class=&quot;highlighter-rouge&quot;&gt;[CLS]&lt;/code&gt;라는 특별한 분류 token이다. 이 token과 연관된 최종 은닉상태는 분류문제에서 sequence 표현을 총합하는 것으로 사용된다. 문장의 쌍은 한 개의 문장으로 합쳐지는데 두 가지 방법으로 구분된다:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;[SEP]&lt;/code&gt;라는 특별한 token이 두 문장 사이에 들어간다.&lt;/li&gt;
  &lt;li&gt;문장들의 모든 token에 해당 토큰이 문장 A에 속하는지 B에 속하는지에 대한 정보를 담은 embedding이 추가된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위 그림에서처럼, 입력 embedding을 $E$라 하면, &lt;code class=&quot;highlighter-rouge&quot;&gt;[CLS]&lt;/code&gt; token의 최종 은닉벡터 $C$와 $i$번째 입력 token에 대한 최종 은닉벡터 $T_i$는 $C \in \mathbb{R}^H, T_i \in \mathbb{R}^H$를 만족한다.&lt;/p&gt;

&lt;p&gt;주어진 token에 대해 그 입력표현은 연관된 token, segment, position embedding의 합으로 구성된다. 이 구조는 Figure 2에서 볼 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-23-BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding/02.png&quot; width=&quot;100%&quot; alt=&quot;BERT input representation&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;31-pre-training-bert&quot;&gt;3.1. Pre-training BERT&lt;/h3&gt;

&lt;p&gt;BERT를 사전학습시키기 위해 전통적인 좌$\rightarrow$우 또는 우$\rightarrow$좌 언어모델을 사용하지 않는다. 대신, 다음의 두 가지 비지도 task를 사용하여 학습시켜 놓는다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Task #1: Masked LM&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;직관적으로, 깊은 양방향 모델은 좌$\rightarrow$우 모델 또는 얕은 양방향 모델보다 더 강력할 것이다. 그러나, 전통적인 언어모델은 단방향으로만 쉽게 학습가능한데, 양방향 조건은 각 단어가 간접적으로 ‘그 단어 자체’를 의미할 수 있으며, 모델은 자명하게 다층 문맥 안에서 목표 단어를 예측할 수 있기 때문이다.&lt;/p&gt;

&lt;p&gt;양방향 모델을 학습시키기 위해 입력 token을 무작위로 masking한 다음, 문맥을 통해 해당 단어를 예측하게 한다. 문학에서 &lt;em&gt;Cloze&lt;/em&gt; task라고도 하지만 이 과정을 MLM(masked LM)라 부르기로 한다.&lt;br /&gt;
이 경우, mask token과 연관된 최종 은닉벡터는 표준 LM처럼 단어집합 내 출력 softmax로 넘어간다. Denoising auto-encoder과는 다르게 전체 입력이 아닌 masked word만을 예측한다.&lt;/p&gt;

&lt;p&gt;이것이 양방향 사전학습 모델을 얻을 수 있도록 해주지만, &lt;code class=&quot;highlighter-rouge&quot;&gt;[mask]&lt;/code&gt; token은 &lt;em&gt;fine-tuning&lt;/em&gt; 단계에 나타나지 않기 때문에 &lt;em&gt;pre-training&lt;/em&gt; 단계와 &lt;em&gt;fine-tuning&lt;/em&gt; 단계 간 mismatch가 생긴다는 단점이 있다. 이를 완화하기 위해, 어떤 token을 항상 &lt;code class=&quot;highlighter-rouge&quot;&gt;[mask]&lt;/code&gt; token으로 바꿔버리지 않는다. 구체적으로는,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;학습데이터 생성자는, 전체 token 중 무작위로 15%를 선택한다.&lt;/li&gt;
  &lt;li&gt;선정된 위치의 token은
    &lt;ul&gt;
      &lt;li&gt;80%의 확률로 &lt;code class=&quot;highlighter-rouge&quot;&gt;[mask]&lt;/code&gt; token으로 치환되고,&lt;/li&gt;
      &lt;li&gt;10%의 확률로 무작위 token으로 치환되고,&lt;/li&gt;
      &lt;li&gt;10%의 확률로 그대로 남는다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그러면 $T_i$는 cross entropy loss로 원본 token을 예측한다. 이 과정의 변형은 부록 C.2에서 다룬다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Task #2: Next Sentence Prediction(NSP)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;QA(Question Answering)나 NLI(Natural Language Inference) 등의 많은 중요한 문제는 언어모델에는 직접적으로 포착되지 않는 두 문장 사이의 &lt;strong&gt;관계&lt;/strong&gt;(relationship)를 이해하는 것에 기반한다. 문장 간 관계를 모델이 학습하도록, 아무 단일 언어 말뭉치에서 생성될 수 있는 이진화된 다음 문장 예측(binarized &lt;em&gt;next sentence prediction&lt;/em&gt;)을 사전학습시켰다.&lt;br /&gt;
구체적으로, 학습 예제에서 문장 A와 B를 선택하는데,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;학습 데이터의 50%는 A와 B가 이어지는 문장이고(&lt;code class=&quot;highlighter-rouge&quot;&gt;IsNext&lt;/code&gt;로 분류됨)&lt;/li&gt;
  &lt;li&gt;학습 데이터의 50%는 B는 A와는 아무 관련 없는 무작위로 선택된 문장(&lt;code class=&quot;highlighter-rouge&quot;&gt;NotNext&lt;/code&gt;로 분류됨)이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Figure 1에 나와 있듯이 $C$는 NSP(Next Sentence Prediction)을 위해 사용된다. 이렇게 간단함에도 이 task가 QA와 NLI에 굉장히 유용함을 Section 5.1에서 보일 것이다.&lt;br /&gt;
이 NSP task는 표현 학습에 긴밀히 연관되어 있지만, 이전 연구에서는 오직 문장 embedding만 downstream task로 이전(transfer)이 됐는데, BERT는 end-task 모델 parameter를 초기화하기 위해 모든 parameter를 이전시킨다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pre-training data&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;사전학습 과정은 언어모델 사전학습에서 이미 있던 것을 거의 따라간다. 사전학습 말뭉치로 BooksCorpus(800M 단어)와 English Wikipedia(2,500M 단어)를 사용했다. 위키피디아에 대해서는 문자 정보만을 추출했다.&lt;br /&gt;
긴 연속적 seqeunce를 추출하기 위해서는, 순서가 섞인 문장들의 집합인 Billion Word Benchmark같은 것보다는 문서단위 말뭉치를 쓰는 것이 매우 중요하다.&lt;/p&gt;

&lt;h3 id=&quot;32-fine-tuning-bert&quot;&gt;3.2. Fine-tuning BERT&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Fine-tuning&lt;/em&gt; 단계는 Transformer의 self-attention mechanism이 적절한 입력과 출력은 교환해냄으로써, BERT가 많은 downstream task이 문자 또는 문자 쌍을 포함함에도 이들을 모델링할 수 있게 해주기 때문에 간단하다.&lt;br /&gt;
문자 쌍을 포함하는 문제에 대해 일반적인 패턴은 양방향 교차 attention을 적용하기 전 문자 쌍을 독립적으로 encoding하는 것이다.&lt;br /&gt;
BERT는 이 두 단계를 통합하기 위해 self-attention mechanism을 사용했다. 이는 두 문장 간 &lt;em&gt;양방향&lt;/em&gt; 교차 attention을 효과적으로 포함하는 self-attention으로 결합한 문자 쌍을 encoding하는 것으로 이루어진다.&lt;/p&gt;

&lt;p&gt;각 task마다, task-specific한 입출력을 BERT에 연결하고 모든 parameter를 end-to-end로 세부조정(fine-tune)했다.&lt;/p&gt;

&lt;p&gt;입력 단계에서, 사전학습에서 나온 문장 A와 문장 B는&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;‘의역에서의 문장 쌍(sentence pairs in paraphrasing)’이나&lt;/li&gt;
  &lt;li&gt;‘함의에서 가장-전제 쌍(hypothesis-premise pairs in entailment)’이나&lt;/li&gt;
  &lt;li&gt;‘질답에서 질문-지문 쌍(question-passage pairs in question answering)’이나&lt;/li&gt;
  &lt;li&gt;‘문서분류나 sequence tagging에서의 퇴색된 문장-공집합 쌍(a degenerate text-∅ pair in text classification or sequence tagging)’&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;과 유사하다.&lt;/p&gt;

&lt;p&gt;출력 단계에서,&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;token 표현은, sequence tagging이나 QA처럼, token-level task을 위한 출력층으로 넘어가고,&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;[CLS]&lt;/code&gt; 표현은, 함의나 감정분석처럼, 분류를 위한 출력층으로 넘어간다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;em&gt;pre-training&lt;/em&gt;과 비교하여, &lt;em&gt;fine-tuning&lt;/em&gt;은 상대적이로 연산량이 적다. 이 논문의 모든 결과는 같은 사전학습된 모델로부터 시작했을 때 단일 Cloud TPU에서 최대 한 시간, GPU에서 몇 시간 정도 안에 재현될 수 있다.&lt;br /&gt;
실험 결과는 Section 4에, 더 자세한 것은 부록 A.5를 보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;4-실험experiments&quot;&gt;4. 실험(Experiments)&lt;/h2&gt;

&lt;h3 id=&quot;41-glue&quot;&gt;4.1. GLUE&lt;/h3&gt;

&lt;p&gt;GLUE benchmark는 다양한 자연어이해 문제들을 모아놓은 것이다.&lt;br /&gt;
GLUE에 대해 세부조정하기 위해, 입력 sequence를 Section 3에서 언급한 대로 변환하고, 첫 번째 token(&lt;code class=&quot;highlighter-rouge&quot;&gt;[CLS]&lt;/code&gt;)와 연관된 최종 은닉벡터 $C \in \mathbb{R}^H$를 총합 표현으로 사용한다. &lt;em&gt;fine-tuning&lt;/em&gt; 단계에서 새로 도입하는 유일한 parameter는 분류 layer weights $W \in \mathbb{R}^{K \times H}$($K$는 분류의 수)이다. 이제 $C$와 $W$의 표준 분류 loss log(softmax($CW^T$))를 계산한다.&lt;br /&gt;
모든 GLUE task에 대해 batch size 32, 3 epochs으로 실험한 결과는 다음과 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-23-BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding/03.png&quot; width=&quot;100%&quot; alt=&quot;GLUE Results&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;각 task마다 Dev set에서 최적의 learning rate를 선택했다.&lt;/li&gt;
  &lt;li&gt;BERT_large는 작은 dataset에 대해 &lt;em&gt;fine-tuning&lt;/em&gt; 학습이 불안정할 때가 있어서, 무작위 시작을 여러 번 하여 가장 좋은 것을 선택했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;BERT_base만으로도 state-of-the-art 결과를 얻었으며, BERT_large는 그보다도 더 뛰어난 성능을 보여준다.&lt;/p&gt;

&lt;h3 id=&quot;42-squad-v11&quot;&gt;4.2. SQuAD v1.1&lt;/h3&gt;

&lt;p&gt;Stanford Question Answering Dataset은 10만여 개의 질답 쌍으로 구성되어 있다. 질문과 그에 대한 답을 포함하는 위키피디아 지문이 주어지면, 해당 지문에서 답이 되는 부분을 찾는 과제이다.&lt;/p&gt;

&lt;p&gt;Figure 1에서 보인 것과 같이, QA task에서는 입력 질문(A)과 지문(B)을 하나의 결합된 sequence로 둔다. &lt;em&gt;fine-tuning&lt;/em&gt; 중에 새로 추가하는 것은 시작벡터 $S \in \mathbb{R}^H$와 종료벡터 $E \in \mathbb{R}^H$ 뿐이다. 답이 지문의 $i$번째 span(단어뭉치)의 시작이 될 확률은 지문에서 다음 식으로 계산된다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P_i = \frac{e^{S \cdot T_i}}{\sum_f e^{S \cdot T_i}}&lt;/script&gt;

&lt;p&gt;유사한 식이 span의 끝에도 사용된다. 위치 $i \sim j$의 점수는 $S \cdot T_i + E \cdot T_j$로 정의되며, $j \ge i$이면서 최대 점수를 갖는 span이 예측 결과가 된다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-23-BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding/04.png&quot; width=&quot;100%&quot; alt=&quot;SQuAD Results&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;43-squad-v20&quot;&gt;4.3. SQuAD v2.0&lt;/h3&gt;

&lt;p&gt;SQuAD v2.0은 (짧은) 답이 지문에 없는 경우를 포함시켜 더 확장한, 더 현실적인 task이다.&lt;/p&gt;

&lt;p&gt;이를 위해 답이 없는 경우는 답이 되는 span의 시작과 끝이 &lt;code class=&quot;highlighter-rouge&quot;&gt;[CLS]&lt;/code&gt;인 것으로 바꿔서 생각하는 것으로 해결한다. 이 때 점수는 다음과 같이 계산된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s_{null}(\text{null span}) = S \cdot C + E \cdot C, \quad s_{\hat{i}, j}(\text{non-null span}) = \max_{j \ge i} S \cdot T_i + E \cdot T_j&lt;/script&gt;

&lt;p&gt;F1을 최대화하기 위해, non-null span이 답이 되려면 한계점 $\tau$에 대해 $ s_{\hat{i}, j} &amp;gt; s_{null} + \tau$이어야 한다.&lt;/p&gt;

&lt;h3 id=&quot;44-swag&quot;&gt;4.4. SWAG&lt;/h3&gt;

&lt;p&gt;Situations With Adversarial Generations dataset은 113k개의 배경상식을 평가하는 문장 쌍으로 되어 있다. 이어지는 문장으로 4개 중 가장 그럴듯하게 이어지는 문장을 고르는 과제이다.&lt;/p&gt;

&lt;p&gt;여기서도 첫 번째 문장(A)과 나머지 4개 선택지(B)로 묶어 진행하였고, 추가되는 parameter는 벡터 하나뿐인데, 이 벡터와 &lt;code class=&quot;highlighter-rouge&quot;&gt;[CLS]&lt;/code&gt; token 표현 $C$와의 내적이 softmax로 정규화된 각 선택지의 점수를 나타낸다.&lt;/p&gt;

&lt;p&gt;batch size 16, learning rate 2e^-5, 3 epochs로 진행한 결과는 다음과 같다. 역시 성능이 상당히 좋다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-23-BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding/05.png&quot; width=&quot;60%&quot; alt=&quot;SWAG Results&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;5-ablation-studies&quot;&gt;5. Ablation Studies&lt;/h2&gt;

&lt;p&gt;이 섹션에서는 특정 부분을 빼거나 교체해서 해당 부분의 역할을 알아보는 ablation 분석을 수행한다. 한국어로 번역하기 참 어려운 단어이다.&lt;/p&gt;

&lt;p&gt;추가 연구는 부록 C에서 찾아볼 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;51-effect-of-pre-training-tasks&quot;&gt;5.1. Effect of Pre-training Tasks&lt;/h3&gt;

&lt;p&gt;다음 두 가지 경우와 BERT_base를 비교한다: (No NSP), (LTR &amp;amp; No NSP).&lt;br /&gt;
MLM 대신 좌$\rightarrow$우(left-to-right, LTR) LM을 사용한 것으로, 이러한 제약은 &lt;em&gt;pre-training&lt;/em&gt;뿐 아니라 &lt;em&gt;fine-tuning&lt;/em&gt;에도 적용되었는데 두 단계 사이의 mismatch를 피하기 위해서다. 이는 같은 dataset, 입력표현, fine-tuning scheme을 사용하여 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/21/OpenAI-GPT-1-Improving-Language-Understanding-by-Generative-Pre-Training/&quot;&gt;OpenAI GPT&lt;/a&gt;와도 직접비교가 가능하다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-23-BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding/06.png&quot; width=&quot;60%&quot; alt=&quot;Effect of Pre-training Tasks&quot; /&gt;&lt;/center&gt;

&lt;p&gt;NSP를 제거했을 때에도, MLM을 LTR로 바꿨을 때에도 성능이 크게 하락함을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;직관적으로, SQuAD에서는 token-level 은닉상태가 오른쪽 문맥에 대한 정보가 없기 때문에 이러한 결과가 명백하다.&lt;/p&gt;

&lt;h3 id=&quot;52-effect-of-model-size&quot;&gt;5.2. Effect of Model Size&lt;/h3&gt;

&lt;p&gt;Layer 수, hidden units, attention head 등의 hyperparameter를 각각 바꿔보면서 최적의 모델을 찾아 보았다.&lt;/p&gt;

&lt;p&gt;일반적으로 모델 크기가 커지면 성능도 향상되는데, 이 논문에서는 충분히 사전 학습되었다는 가정 하에 극단적으로 크기를 키우는 것 또한 아주 작은 규모의 과제에서도 큰 성능 향상이 있다는 것을 첫 번째로 보여주기도 했다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-23-BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding/07.png&quot; width=&quot;60%&quot; alt=&quot;Effect of Model Size&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;53-feature-based-approach-with-bert&quot;&gt;5.3. Feature-based Approach with BERT&lt;/h3&gt;

&lt;p&gt;BERT의 모든 결과는 간단한 분류 layer만 사전학습된 모델에 추가하는 fine-tuning 접근법을 사용했고, 모든 parameter는 downstream task에서 결합학습되었다.&lt;br /&gt;
그러나 이러한 특성기반 접근법에서, 고정된 특성이 사전학습된 모델로부터 추출될 때 특정 이점을 갖는다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;모든 task가 Transformer 인코더 구조로 쉽게 표현될 수 있는 것은 아니며, 따라서 특정과제에 특화된 모델구조가 추가될 필요가 있다.&lt;/li&gt;
  &lt;li&gt;학습데이터에 대한 한 번의 ‘비싼’ 사전 계산에 대한 연산량 관점에서의 이득이 있고 이 표현 위에서 연산량이 적은 모델에 대한 많은 실험을 진행할 수 있다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;BERT에 특성기반 접근법을 적용할 과제로는 CoNLL-2003 Named Entity Recognition(NER) task이 선정되었다. BERT에는 WordPiece 모델을 사용했고, 데이터에서 제공된 최대한의 문서 문맥을 포함시켰다.&lt;br /&gt;
fine-tuning 접근법을 피하기 위해, BERT의 어떤 parameter에 대해서도 fine-tuning 없이 하여 하나 또는 더 많은 layer에 대해 활성값을 추출한 특성기반 접근법을 사용하였다. 이러한 문맥 embedding은 분류 layer에 들어가기 전 무작위 초기화된 768차원 2-layer BiLSTM의 입력으로 사용되었다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-23-BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding/08.png&quot; width=&quot;60%&quot; alt=&quot;Feature-based Approach with BERT&quot; /&gt;&lt;/center&gt;

&lt;p&gt;BERT_large는 거의 state-of-the-art 성능을 가지며, 이는 BERT가 세부조정과 특성기반 접근법 모두에서 효율적임을 보여준다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;6-결론conclusion&quot;&gt;6. 결론(Conclusion)&lt;/h2&gt;

&lt;p&gt;최근 경험적 향상은 언어모델에서의 전이학습, 비지도 사전학습 등에 의해 이루어졌다. 특히, 이러한 결과들은 자원이 적은 task에서도 깊은 양방향 구조에서 이점을 얻도록 하였다. 이 논문의 가장 큰 기여는 같은 사전학습된 모델을 넓은 범위의 NLP task에 적용시킬 수 있도록 하는 깊은 &lt;em&gt;양방향&lt;/em&gt; 구조를 일반화한 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;refenrences&quot;&gt;Refenrences&lt;/h2&gt;

&lt;p&gt;논문 참조. 레퍼런스가 많다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;appendix&quot;&gt;Appendix&lt;/h2&gt;

&lt;h3 id=&quot;a-additional-details-for-bert&quot;&gt;A. Additional Details for BERT&lt;/h3&gt;

&lt;p&gt;부록 A.1은 MLM이 어떻게 masking을 하는지, NSP는 어떤지 예시와 함께 자세히 설명한다. 예시는 다음과 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-23-BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding/09.png&quot; width=&quot;100%&quot; alt=&quot;MLM &amp;amp; NSP&quot; /&gt;&lt;/center&gt;

&lt;p&gt;부록 A.2와 A.3은 각각 &lt;em&gt;pre-training&lt;/em&gt; 단계와 &lt;em&gt;fine-tuning&lt;/em&gt; 단계를 부가 설명한다.&lt;/p&gt;

&lt;p&gt;부록 A.4는 다른 모델과의 구조 차이를 설명한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-23-BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding/10.png&quot; width=&quot;100%&quot; alt=&quot;BERT, OpenAI GPT, ELMo&quot; /&gt;&lt;/center&gt;

&lt;p&gt;부록 A.5는 다른 task에 fine-tuning을 적용하는 방법을 설명한다. 그림으로 설명한 것은 다음과 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-23-BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding/11.png&quot; width=&quot;100%&quot; alt=&quot;Fine tuning on different tasks&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;b-detailed-experimental-setup&quot;&gt;B. Detailed Experimental Setup&lt;/h3&gt;

&lt;p&gt;부록 B.1은 GLUE benchmark에서 사용한 실험 세팅을 더 자세히 설명한다. 재현하고 싶다면 눈여겨보자.&lt;/p&gt;

&lt;h3 id=&quot;c-additional-ablation-studies&quot;&gt;C. Additional Ablation Studies&lt;/h3&gt;

&lt;p&gt;부록 C.1은 학습단계(Training Steps)의 수를 바꿔서 실험했다. 실험 결과는&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;BERT는 엄청난 사전학습을 필요로 한다(128k words/batch * 1M steps).&lt;/li&gt;
  &lt;li&gt;MLM 사전학습은 LTR보다 더 느리게 수렴하지만(최대 15%만이 치환되므로), 최종 정확도는 더 높다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;부록 C.2는 masking 과정을 변화시켰을 때의 실험이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-23-BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding/12.png&quot; width=&quot;100%&quot; alt=&quot;Ablation Study for Masking&quot; /&gt;&lt;/center&gt;

&lt;p&gt;결국 처음 설명한 80%-10%-10% 비율이 가장 적절했다는 결론이다.&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>OpenAI GPT-1 - Improving Language Understanding by Generative Pre-Training</title>
   <link href="http://localhost:4000/OpenAI-GPT-1-Improving-Language-Understanding-by-Generative-Pre-Training/"/>
   <updated>2019-08-21T00:00:00+09:00</updated>
   <id>http://localhost:4000/OpenAI GPT-1 - Improving Language Understanding by Generative Pre-Training</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 2018년 6월 &lt;em&gt;Alec Radford&lt;/em&gt; 등이 발표한 OpenAI GPT-1: Improving Language Understanding by Generative Pre-Training를 살펴보도록 한다.&lt;/p&gt;

&lt;p&gt;코드와 논문은 &lt;a href=&quot;https://openai.com/blog/language-unsupervised/&quot;&gt;여기&lt;/a&gt;에서 볼 수 있다.&lt;/p&gt;

&lt;p&gt;중요한 부분만 적을 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;openai-gpt-1---improving-language-understanding-by-generative-pre-training&quot;&gt;OpenAI GPT-1 - Improving Language Understanding by Generative Pre-Training&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf&quot;&gt;OpenAI GPT-1 - Improving Language Understanding by Generative Pre-Training&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;홈페이지: &lt;strong&gt;&lt;a href=&quot;https://openai.com/blog/language-unsupervised/&quot;&gt;OpenAI&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Tensorflow code: &lt;strong&gt;&lt;a href=&quot;https://github.com/openai/finetune-transformer-lm&quot;&gt;Official Code&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;초록abstract&quot;&gt;초록(Abstract)&lt;/h2&gt;

&lt;p&gt;자연어이해는 원문함의, 질답, 의미 유사성 평가, 문서분류 등 넓은 범위의 과제로 이루어져 있다. 미분류 상태의 큰 말뭉치가 풍부함에도, 이러한 특정 과제의 학습을 위한 분류된 데이터는 부족하며, 모델이 적절히 수행하도록 만드는 것을 어렵게 한다.&lt;br /&gt;
이 논문에서는 이러한 과제들에서의 큰 성능 향상은, 언어모델을 다양한 미분류 말뭉치로 생성적 사전학습(&lt;em&gt;generative pre-training&lt;/em&gt;)을 시킨 후 각 특정 과제에 맞춘 세부조정(fine-tuning) 과정을 거쳐 가능하다. 이전의 접근법과는 달리 모델구조는 최소한으로 변화시키면서 효과적인 전이(transfer)를 얻기 위한 세부조정 단계에서 과제에 맞는 입력표현(input representations)을 사용했다. 그리고 이 접근법이 다양한 과제에 대해 효과적임을 보일 것이다.&lt;/p&gt;

&lt;p&gt;이 논문에서 제시하는 과제에 대한 별다른 지식이 없는(task-agnostic) 모델은 특정과제에 특화된 구조를 사용하는 모델의 성능을 뛰어넘는데 연구된 12개의 과제 중 9개에서는 state-of-the-art를 달성하였다. 예를 들어 상식추론(&lt;em&gt;Cloze&lt;/em&gt;)에서는 8.9%, QA에서는 5.7%, 원문함의에서는 1.5% 상승하였다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-서론introduction&quot;&gt;1. 서론(Introduction)&lt;/h2&gt;

&lt;p&gt;원본 그대로의 텍스트에서 효과적으로 학습하는 능력은 NLP에서 지도학습에 대한 의존성을 낮추는 데 있어 매우 중요하다. 대부분의 딥러닝 방법은 수동으로 분류된 방대한 양의 데이터를 필요로 하는데 이는 분류된 자원의 부족으로 인한 많은 범위로의 응용에 제약을 건다. 이러한 상황에서 미분류 데이터로부터 언어적 정보를 얻어낼 수 있는 모델은 힘들게 분류된 데이터를 만드는 것의 훌륭한 대안이 될 뿐만 아니라, 괜찮은 지도 방법이 있다 하더라도 비지도학습이 더 좋을 결과를 얻기도 한다. 사전학습된 단어 embedding이 그러한 예이다.&lt;/p&gt;

&lt;p&gt;그러나 미분류 텍스트에서 단어 수준 정보 이상의 것을 얻는 것은 다음 두 가지 이유로 어렵다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;어떤 최적화 목적함수가 전이(transfer)에 유용한 텍스트 표현(representation)을 배우는 데 효과적인지 불분명하다. 최근 연구들은 언어모델링이나 기계번역, 담화 일관성(discourse coherence) 등 다양한 objective에서 각 방법이 다른 과제에서는 다른 방법을 능가하는 것을 보여 왔다.&lt;/li&gt;
  &lt;li&gt;학습된 표현을 다른 과제로 전이하는 가장 효과적인 방법에 대한 일치된 의견이 없다. 존재하는 방법들은 복잡한 학습전략이나 부가 학습 목적함수를 더하는 등 모델 구성에 과제에 특화된(task-specific) 변화를 주어야 한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이러한 불확실성은 언어처리에 대한 효과적인 준지도학습 접근법의 개발을 어렵게 한다.&lt;/p&gt;

&lt;p&gt;이 논문에서는 비지도 사전학습(unsupervised pre-training)과 지도 세부조정(supervised fine-tuning)의 조합을 사용하여 언어이해 과제를 위한 준지도학습 접근법을 탐색한다. 목표는 약간의 조정만으로 넓은 범위의 과제에 전이 및 적용할 수 있는 범용 표현을 학습하는 것이다. 미분류 대량의 말뭉치와 수동으로 주석을 단(annotated) 학습예제를 갖는 여러 dataset에 대한 접근가능을 가정한다. 또한 학습은 두 단계를 거치게 된다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;신경망모델의 초기 parameter를 학습하기 위해 미분류 데이터에 대한 언어모델링 목적함수를 사용한다.&lt;/li&gt;
  &lt;li&gt;이 parameter를 연관된 지도 목적함수를 사용하여 목표 과제에 적용시킨다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;모델 구성은 기계번역, 문서생성, 구문분석 등에 상당한 성능을 보이는 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/17/Attention-Is-All-You-Need/#3-%EB%AA%A8%EB%8D%B8-%EA%B5%AC%EC%84%B1model-architecture&quot;&gt;&lt;em&gt;Transformer&lt;/em&gt;&lt;/a&gt;를 사용한다. 이 모델은 RNN 등에 비해 장거리 의존성을 다루는 데 뛰어나 더 많은 구조화된 memory를 쓸 수 있게 한다. 전이 중에는 traversal-style 접근법에서 얻은 과제특화된 입력적응을 이용하며 입력은 한 개의, 일련의 ‘연속된 token’으로 주어진다. 이러한 적응방법은 사전학습된 모델의 구조를 바꾸는 것을 최소화한다.&lt;/p&gt;

&lt;p&gt;이 접근법을 네 가지(자연어추론, 질답, 의미 유사성, 문서분류)에 대해 평가한다. 과제에 대한 지식이 없는 이 범용 모델은 12개 중 9개의 과제에서 state-of-the-art 결과를 보이며 선전했다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-관련-연구related-work&quot;&gt;2. 관련 연구(Related work)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Semi-supervised learning for NLP&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이 연구는 자연어의 준지도학습에 넓게 걸쳐 있다. 이 체계는 sequence labeling이나 문서분류 등의 응용에 큰 관심을 불러일으켰다.&lt;/p&gt;

&lt;p&gt;초기의 연구는 나중에 지도모델의 특징으로 사용될, 단어수준이나 구 수준의 통계를 계산하기 위해 미분류 데이터를 사용했다. 지난 몇 년간 연구자들은 미분류 말뭉치로부터 학습된 단어 embedding의 장점(다양한 과제에서의 성능 향상 가능성)을 발견했다. 그러나 이 접근법은 주로 단어 수준 표현을 학습할 뿐이다.&lt;/p&gt;

&lt;p&gt;최근의 연구는 미분류 데이터로부터 단어수준 이상의 정보를 학습하려 하고 있다. 구 수준이나 문장 수준의 embedding은 미분류 데이터로부터 학습될 수 있으며 다양한 문제에서 텍스트를 적절한 벡터표현으로 변환할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Unsupervised pre-training&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;목표가 지도학습 목적함수를 수정하는 것이 아닌 좋은 초기화 지점을 찾는 것일 때, 비지도 사전학습은 준지도학습의 특별한 경우가 된다. 초기에는 이미지 분류나 회귀문제에 사용했다. 후속 연구는 사전학습이 정규화처럼 동작하며 DNN에서 더 좋은 일반화를 가능하게 함을 보였다. 최근에는 이미지분류, 음성인식, 다의어 명확화, 기계번역 등에 사용되고 있다.&lt;/p&gt;

&lt;p&gt;GPT와 가장 유사한 연구는 신경망을 언어모델링 목적함수를 사용하여 사전학습시키고 지도 하에 목표 과제에 맞춰 세부조정하는 것을 포함한다. 그러나 어떤 언어적 정보를 포착하는 데 있어 LSTM의 사용은 이를 좁은 범위에 한정시킨다. 하지만 Transformer를 사용함으로써 넓은 범위에 걸친 언어적 구조와 정보를 학습할 수 있게 하였고 나아가 다양한 과제에 사용할 수 있게 되었다.&lt;br /&gt;
다른 접근법은 목표 과제에 맞춘 감독학습 중에 사전학습된 언어/기계번역 모델에서 얻은 은닉표현을 부가정보르 사용하였는데 이는 상당한 양의 parameter를 추가하는데, GPT는 그렇지 않다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Auxiliary training objectives&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;보조 학습 목적함수를 추가하는 것은 준지도학습의 대안이다. &lt;a href=&quot;https://ronan.collobert.com/pub/matos/2008_nlp_icml.pdf&quot;&gt;A unified architecture for natural language processing deep neural networks with multitask learning&lt;/a&gt;이 여러 NLP task에 사용되었으며, 최근에는 &lt;a href=&quot;https://arxiv.org/abs/1704.07156&quot;&gt;Semi-supervised Multitask Learning for Sequence Labeling&lt;/a&gt;이 목표 과제에 보조 언어모델링 목적함수를 추가해 sequence labeling task에서 성능향상을 얻었다. GPT도 보조목적함수를 추가하지만, 비지도 사전학습이 이미 목표 과제에 대한 여러 언어적 정보를 학습했다는 것을 보일 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-framework&quot;&gt;3. Framework&lt;/h2&gt;

&lt;p&gt;학습은 두 단계로 진행된다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;큰 말뭉치에서 대용량의 언어모델을 학습한다.&lt;/li&gt;
  &lt;li&gt;분류 데이터를 써서 특정 과제에 맞춰 모델을 세부조정한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;31-unsupervised-pre-training&quot;&gt;3.1. Unsupervised pre-training&lt;/h3&gt;

&lt;p&gt;token의 비지도 말뭉치 $\mathcal{U} = {u_1, …, u_n}$이 주어질 때, 다음 우도를 최대화하도록 표준언어모델링 목적함수를 사용한다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_1(\mathcal{U}) = \sum_i \log P(u_i \vert u_{i-k}, ..., u_{i-1}; \Theta)&lt;/script&gt;

&lt;p&gt;$k$는 문맥고려범위(context window)이고 조건부확률 $P$는 parameter가 $\Theta$인 신경망을 사용하도록 설계된다. 이들은 확률적 경사하강법(SGD)에 의해 학습된다.&lt;/p&gt;

&lt;p&gt;GPT는 언어모델로 Transformer의 변형인 multi-layer &lt;em&gt;Transformer decoder&lt;/em&gt;를 사용한다. 이 모델은 입력 문맥 token에 multi-headed self-attention을 적용한 후, 목표 token에 대한 출력분포를 얻기 위해 position-wise feedforward layer를 적용한다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_0 = UW_e + W_p \qquad \qquad \qquad \qquad \ \ \qquad&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_l = \text{transformer_block}(h_{l-1}) \ \ \forall l \in [1, n]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(u) = \text{softmax}(h_n W_e^T) \qquad \qquad \qquad \quad \ \ \qquad&lt;/script&gt;

&lt;p&gt;$U = (u_{-k}, …, u_{-1})$는 token의 문맥벡터, $n$은 layer의 수, $W_e$는 token embedding 행렬, $W_p$는 위치 embedding 행렬이다.&lt;/p&gt;

&lt;p&gt;(참고: 논문에는 위 식에서 $\forall l$이 $\forall i$로 오타가 나 있다)&lt;/p&gt;

&lt;h3 id=&quot;32-supervised-fine-tuning&quot;&gt;3.2. Supervised fine-tuning&lt;/h3&gt;

&lt;p&gt;위 $L_1(\mathcal{U})$ 우도에 따라 모델을 학습시키고 나면, parameter를 목표 과제에 맞춰 세부조정한다. 분류된 dataset $\mathcal{C}$이 있고 각 구성요소가 일련의 입력 token $x^1, …, x^m$ 및 그 정답(label) $y$로 되어 있다고 하자. 입력은 최종 transformer block의 활성값 $h_l^m$을 얻기 위해 위의 사전학습된 모델에 전달하고 이 결과는 다시 $y$를 예측하기 위해 parameter $W_y$와 함께 선형 출력층으로 전달된다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(y \vert x^1, ..., x^m) = \text{softmax}(h_l^m W_y)&lt;/script&gt;

&lt;p&gt;이는 다음 우도를 최대화하도록 한다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_2(\mathcal{C}) = \sum_{(x, y)} \log P(y \vert x^1, ..., x^m)&lt;/script&gt;

&lt;p&gt;세부조정 단계에 언어모델을 보조 목적함수로 포함시키는 것은 다음 이유에서 학습을 돕는다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;지도 모델의 일반화를 향상시키고&lt;/li&gt;
  &lt;li&gt;수렴을 가속화한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이는 이전 연구들과 결을 같이한다.&lt;/p&gt;

&lt;p&gt;구체적으로, weight $\lambda$에 대해 다음 목적함수를 최적화한다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_3(\mathcal{C}) = L_2(\mathcal{C}) + \lambda \ast L_1(\mathcal{C})&lt;/script&gt;

&lt;p&gt;종합적으로, 세부조정 단계에서 추가된 parameter는 $W_y$과 구분자 token을 위한 embedding 뿐이다.&lt;/p&gt;

&lt;h3 id=&quot;33-task-specific-input-transformations&quot;&gt;3.3. Task-specific input transformations&lt;/h3&gt;

&lt;p&gt;텍스트 분류와 같은 몇몀 과제에 대해서는 모델 세부조정을 위에서 언급한 방법으로 직접 할 수 있다. 그러나 질답과 원문함의와 같은 과제에서는 입력 형태가 문장의 2~3개 쌍인 등 많이 다르므로 이를 처리해주어야 한다. 그 방법은 아래 Figure 1에 나와 있는데, 질문/텍스트/선택지/가정/전제 등을 하나씩 따로 구분자(delimiter)로 구분하여 하나로 연결하는 방식을 쓴다. 구체적인 방법은 다음과 갈다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Textual entailment&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;함의 문제에서는 전제 $p$와 가정 $h$를 구분자 &lt;code class=&quot;highlighter-rouge&quot;&gt;$&lt;/code&gt;로 연결하였다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Similarity&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;두 개의 텍스트 사이에 순서가 딱히 없으므로 텍스트 두 개를 다른 순서로 이어붙여 총 2개를 입력으로 쓴다. 이는 각각의 Transformer에 입력으로 들어간다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Question Answering and Commonsense Reasoning&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;문맥 문서 $z$, 질문 $q$, 가능한 답변 ${a_k}$이라 하면, &lt;code class=&quot;highlighter-rouge&quot;&gt;[z; q; $; a_k]&lt;/code&gt;로 연결하고 입력의 개수는 답변의 개수만큼 생성된다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-21-OpenAI GPT-1 - Improving Language Understanding by Generative Pre-Training/01.png&quot; width=&quot;100%&quot; alt=&quot;Architecture&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;4-실험experiments&quot;&gt;4. 실험(Experiments)&lt;/h2&gt;

&lt;h3 id=&quot;41-setup&quot;&gt;4.1. Setup&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Unsupervised pre-training&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;언어모델을 학습하기 위한 dataset으로 7천 개의 다양한 분야의 미출판 책에 대한 내용을 포함하는 &lt;a href=&quot;https://arxiv.org/abs/1506.06724&quot;&gt;BooksCorpus&lt;/a&gt;를 사용한다. 이는 특히 넓은 범위에 걸친 언어적 정보를 포함하기에 중요하다. 대안이 되는 dataset으로는 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/20/ELMo-Deep-contextualized-word-representations/&quot;&gt;ELMo&lt;/a&gt;에서 사용된 1B Word Benchmark가 있다. 이는 크기는 비슷하지만 문장들이 서로 섞여 있어 장거리 의존정보가 파괴되어 있다.&lt;/p&gt;

&lt;p&gt;사용하는 dataset 정보는 아래와 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-21-OpenAI GPT-1 - Improving Language Understanding by Generative Pre-Training/02.png&quot; width=&quot;100%&quot; alt=&quot;List of dataset&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;strong&gt;Model specifications&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Transformer의 세부 세팅을 대부분 따르지만, Encoder-Decoder 중 Decoder만 사용한다. 이 decoder는 &lt;a href=&quot;https://greeksharifa.github.io/nlp(natural%20language%20processing)%20/%20rnns/2019/08/17/Attention-Is-All-You-Need/#31-encoder-and-decoder-stacks&quot;&gt;원본&lt;/a&gt;은 6번 반복되지만, GPT는 12번 반복한다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Parameter&lt;/th&gt;
      &lt;th&gt;Descrption&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;State dimension&lt;/td&gt;
      &lt;td&gt;decoder: 768, inner state: 3072&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Batch size&lt;/td&gt;
      &lt;td&gt;64 random sample $\times$ 512 token/sample&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Schedule&lt;/td&gt;
      &lt;td&gt;100 epochs,&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Optimizer&lt;/td&gt;
      &lt;td&gt;Adam&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Learning Rate&lt;/td&gt;
      &lt;td&gt;0~2000 step까지 2.5e-4까지 증가, 이후 cosine 함수를 따라 0으로 서서히 감소&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;warmup_steps&lt;/td&gt;
      &lt;td&gt;4000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Regularization&lt;/td&gt;
      &lt;td&gt;L2($w=0.01$)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Activation&lt;/td&gt;
      &lt;td&gt;GELU(Gaussian Error Linear Unit)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;논문에는 안 나와있지만 모델의 크기는 parameter가 117M개이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fine-tuning details&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;비지도 사전학습에서 사용한 hyperparameter를 그대로 사용했다. $p=0.1$의 dropout을 추가했다.&lt;br /&gt;
learning rate는 6.25e-5와 batch size는 32, 세부조정은 3 epoch 동안 진행되었으며 learning rate decay는 warmup을 포함해 각 학습당 0.2%였고, $\lambda=0.5$이다.&lt;/p&gt;

&lt;h3 id=&quot;42-supervised-fine-tuning&quot;&gt;4.2. Supervised fine-tuning&lt;/h3&gt;

&lt;p&gt;자연어추론, 질답, 의미유사성, 문서분류에 대해 평가를 진행하였으며 이 중 일부는 GLUE benchmark에 포함되어 있다. 결과는 아래 Table 2, 3에 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Natural Language Inference&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Image caption(SNLI), 문서화된 음성, 대중소설, 정부 보고서(MNLI), 위키피디아 기사(QNLI), 과학시험(SciTail), 뉴스기사(RTE) 등의 다양한 데이터로 실험하였다. 각 0.6~5.8% 정도 성능이 향상되었다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-21-OpenAI GPT-1 - Improving Language Understanding by Generative Pre-Training/03.png&quot; width=&quot;100%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;strong&gt;Question answering and commonsense reasoning&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;중고등학교 시험에서 나온 영어지문과 관련 질문으로 구성된 RACE dataset으로 진행하였다. 또 Story Cloze에 대해서도 진행했는데 이는 무려 8.9%까지 높은 성능을 내며 결과를 종합했을 때 GPT가 넓은 범위에 걸친 문맥 정보도 잘 포착해냄을 알 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-21-OpenAI GPT-1 - Improving Language Understanding by Generative Pre-Training/04.png&quot; width=&quot;100%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;strong&gt;Semantic Similarity&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;QQP에 대해서는 BiLSTM + ELMo + Attention을 사용한 모델보다도 특히 성능이 향상되었다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-21-OpenAI GPT-1 - Improving Language Understanding by Generative Pre-Training/05.png&quot; width=&quot;100%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;strong&gt;Classification&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;두 개의 다른 텍스트 분류 과제에 대해서도 평가를 진행했다. CoLA(The Corpus of Linguistic Acceptability)는 어떤 문장이 문법적으로 옳은지를 전문가가 평가한 답변과, 학습된 모델에 대한 언어적 편향에 대한 테스트를 포함한다.  SST-2(The Stanford Sentiment Treebank)는 표준 이진 분류 문제이다. CoLA에 대해서는 35.0 $\to$ 45.4점으로, SST-2에서는 68.9 $\to$ 72.8점으로 상승하였다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;종합하면, 12개의 task 중 9개에서 state-of-the-art를 달성하였다.&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;5-분석analysis&quot;&gt;5. 분석(Analysis)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Impact of number of layers transferred&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;아래 Figure 2의 왼쪽은 layer의 수를 다르게 하면서 RACE와 MultiNLI에 대해 실험을 진행한 것인데, transferring embedding이 성능 향상을 가져오며, 각 transformer layer 당 9%까지 향상시킨다(on MultiNLI)는 내용이다. 이는 사전학습된 모델의 각각의 layer가 문제를 푸는 데 있어 유용한 기능을 포함한다는 것을 의미한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-21-OpenAI GPT-1 - Improving Language Understanding by Generative Pre-Training/06.png&quot; width=&quot;100%&quot; alt=&quot;Impact of number of layers transferred&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;strong&gt;Zero-shot Behaviors&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;저자는 근본적인 generative model이 LM capability를 향상시키기 위해 많은 task를 수행하는 법을 배울 수 있고, LSTM과 비교해서 transformer의 attentional memory가 transfer에 도움이 된다고 가정하였다
Transformer를 통한 언어모델의 사전학습이 효과적인지에 대한 가정이 하나 있다. 기반 생성모델은 언어모델링 역량을 향상시키기 위해 평가에 포함된 여러 과제를 수행하는 것을 학습하였으며, Transformer의 attentional memory는 LSTM에 비해 전이를 더 원활하게 해 준다는 것이다. 지도 세부조정 없이 과제를 수행하기 위해 기반 생성모델을 사용하는 일련의 체험적 해결책(heuristic solutions)을 사용했다. 이 결과를 위 Figure 2의 오른쪽 부분에 시각화하였다.&lt;br /&gt;
이 체험적 해결책의 성능은 안정적이며 학습에 따라 꾸준히 증가하는 것으로 보아 생성적 사전학습은 과제와 관련된 넓은 범위의 기능성(functionality)의 학습을 뒷받침한다. 또한 LSTM은 zero-shot 성능에서 큰 편차를 보여 Transformer 구조의 귀납적 편향이 전이를 돕는다고 할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ablation studies&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;세 가지 분석을 수행하였다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;세부조정 단계에서 보조 LM 목적함수는 NLI task와 QQP에 도움을 주는데, 큰 dataset에서는 이점이 있지만 작은 dataset에서는 그렇지 못함을 보여준다.&lt;/li&gt;
  &lt;li&gt;Transformer을 같은 구조의 2048 unit의 LSTM로 대체하였는데 5.6점의 점수 하락이 있었다. 성능이 좋은 경우는 MRPC 뿐이었다.&lt;/li&gt;
  &lt;li&gt;Transformer를 사전학습 없이 바로 지도학습을 하도록 해보았는데, 14.8%의 성능 하락이 있었다.&lt;/li&gt;
&lt;/ol&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-21-OpenAI GPT-1 - Improving Language Understanding by Generative Pre-Training/07.png&quot; width=&quot;100%&quot; alt=&quot;Ablation studies&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;6-결론conclusion&quot;&gt;6. 결론(Conclusion)&lt;/h2&gt;

&lt;p&gt;생성적 사전학습과 특정과제에 특화된 세부조정을 통해 학습된, 과제에 대해 별다른 지식이 없으며 자연어이해 능력이 뛰어난 단일 모델(framework)를 소개하였다. 넓은 범위에 걸친 언어적 정보를 포함하는 다양한 말뭉치에 대해 사전학습을 진행하여 중요한 일반지식과 질답, 의미유사성 평가, 함의 확인, 문서분류 등의 과제에서 성공적으로 전이되는 장거리 의존성을 처리하는 능력을 학습하여 12개 중 9개의 과제에 대해 state-of-the-art를 달성하였다. 특정 과제에 대한 성능을 높이는 비지도 사전학습은 기계학습연구의 중요한 목표가 되었다.&lt;br /&gt;
이 연구는 상당한 성능향상이 정말로 가능하며 어떤 모델(Transformers)과 dataset(장거리 의존성을 포함하는 텍스트)가 이 접근법에 가장 좋은지에 대한 조언을 제공한다. 이 연구가 자연어이해와 다른 분야에 대한 비지도학습에 대한 새로운 연구에 도움이 되기를 희망하며, 나아기 비지도학습이 언제 그리고 어떻게 작동하는지에 대한 우리의 이해를 증진시키기를 바란다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;refenrences&quot;&gt;Refenrences&lt;/h2&gt;

&lt;p&gt;논문 참조. 71개의 레퍼런스가 있다.&lt;/p&gt;

&lt;p&gt;부록은 없다(yeah).&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>ELMo - Deep contextualized word representations</title>
   <link href="http://localhost:4000/ELMo-Deep-contextualized-word-representations/"/>
   <updated>2019-08-20T00:00:00+09:00</updated>
   <id>http://localhost:4000/ELMo - Deep contextualized word representations</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 2018년 2월 &lt;em&gt;Matthew E. Peters&lt;/em&gt; 등이 발표한 Deep contextualized word representations를 살펴보도록 한다.&lt;/p&gt;

&lt;p&gt;참고로 이 논문의 제목에는 ELMo라는 이름이 들어가 있지 않은데, 이 논문에서 제안하는 모델의 이름이 ELMo이다.&lt;br /&gt;
Section 3에서 나오는 이 모델은 &lt;strong&gt;E&lt;/strong&gt;mbeddings from &lt;strong&gt;L&lt;/strong&gt;anguage &lt;strong&gt;Mo&lt;/strong&gt;dels이다.&lt;/p&gt;

&lt;p&gt;중요한 부분만 적을 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;elmo---deep-contextualized-word-representations&quot;&gt;ELMo - Deep contextualized word representations&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf&quot;&gt;Deep contextualized word representations&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;홈페이지: &lt;strong&gt;&lt;a href=&quot;https://openai.com/blog/language-unsupervised/&quot;&gt;OpenAI Blog&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;초록abstract&quot;&gt;초록(Abstract)&lt;/h2&gt;

&lt;p&gt;이 논문에서는 단어 사용의 복잡한 특성(문법 및 의미)과 이들이 언어적 문맥에서 어떻게 사용되는지(다의성)를 모델링하는, 새로운 종류의 &lt;strong&gt;&lt;em&gt;문맥과 깊게 연관된&lt;/em&gt; 단어표현(&lt;em&gt;Deep contextualized&lt;/em&gt; word representation)&lt;/strong&gt;을 소개한다. 이 논문에서의 word vector는 큰 말뭉치에서 학습된 deep bidirectional language model(&lt;strong&gt;biLM&lt;/strong&gt;)의 내부 상태로부터 학습한다. 이 표현(representation)은 이미 존재하는 모델에 쉽게 불일 수 있으며 이로써 QA 등 6개의 도전적인 NLP 문제에서 상당히 향상된 state-of-the-art 결과를 얻을 수 있음을 보였다. 또한 기학습된(pre-trained) 네트워크의 깊은 내부를 살펴보는 분석도 보인다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-서론introduction&quot;&gt;1. 서론(Introduction)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;기학습된 단어 표현(Pre-trained word representations)&lt;/strong&gt;은 많은 자연어이해 모델에서 중요한 요소였다. 그러나 문법, 의미, 다의성을 학습한 높은 품질의 representation을 얻는 것은 어려운 일이다. 이 논문에서는 쉽게 다른 모델에 적용가능하며 성능도 뛰어난 &lt;strong&gt;Deep contextualized word representation&lt;/strong&gt;을 소개한다.&lt;/p&gt;

&lt;p&gt;이 representation은 (문장 내) 각 token이 전체 입력 sequence의 함수인 representation를 할당받는다는 점에서 전통적인 단어 embedding과 다르다. 이를 위해 이어붙여진 &lt;strong&gt;language model(LM)&lt;/strong&gt;로 학습된 bidirectional LSTM(biLM)로부터 얻은 vector를 사용한다. 이 때문에 이를 &lt;strong&gt;ELMo(Embeddings from Language Models) representation&lt;/strong&gt;이라 부른다. 이는 LSTM layer의 최종 layer만을 취한 것이 아닌, 각 layer 결과를 가중합하여 얻어지며 이것이 성능이 더 좋다.&lt;br /&gt;
LSTM의 낮은 단계의 layer(입력과 가까운 층)는 품사 등 문법 정보를, 높은 단계의 layer(출력과 가까운 층)는 문맥 정보를 학습하는 경향이 있다.&lt;/p&gt;

&lt;p&gt;많은 실험에서 ELMo representation이 매우 뛰어남을 보여 주었는데, 상대적으로 에러율을 20% 줄이기도 하였다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-관련-연구related-work&quot;&gt;2. 관련 연구(Related work)&lt;/h2&gt;

&lt;p&gt;기학습된 단어 벡터(pretrained word vectors)는 많은 NLP 모델에서 매우 중요한 역할을 했다. 그러나 미리 학습된 단어 벡터는 다의어도 한 개의 벡터로 표현하기 때문에 문맥 정보를 고려하지 못한다.&lt;br /&gt;
이를 극복하기 위한 방안으로 보조단어 정보를 활용하거나 각 단어당 여러 벡터를 만드는 방법이 고려되었다. 이 논문의 방법(ELMo representation)은 보조정보로부터의 이점을 가지며 또한 명시적으로 여러 벡터를 만들 필요도 없다.&lt;/p&gt;

&lt;p&gt;문맥의존 표현을 학습하는 다른 연구로는 다음이 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;양방향 LSTM을 사용하는 context2vec(Melamud et al., 2016)&lt;/li&gt;
  &lt;li&gt;표현 안에 pivot word 자체를 포함하는 CoVe(McCann et al., 2017)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Deep biRNN의 낮은 단계의 layer를 사용하여 dependency parsing(Hashimoto et al., 2017)이나 CCG super tagging(Søgaard and Goldbert, 2016) 등의 문제에서 성능 향상을 시킨 연구도 있었다.&lt;br /&gt;
Dai and Le(2015)와 Ramachandran et al.(2017)에서는 언어모델(LM)로 인코더-디코더 쌍을 기학습시키고 특정 task에 fine-tune시켰다.&lt;/p&gt;

&lt;p&gt;이 논문에서는 미분류된 데이터로부터 biLM을 기학습시킨 후 weights를 고정시키고 task-specific한 부분을 추가하여 leverage를 증가시키고 풍부한 biLM representation을 얻을 수 있게 하였다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-elmo-embeddings-from-language-models&quot;&gt;3. ELMo: Embeddings from Language Models&lt;/h2&gt;

&lt;p&gt;다른 단어 embedding과는 다르게 ELMo word representation은 전체 입력 sequence의 함수이다. 이는 글자수준 합성곱(character convolutions, Sec. 3.1)로부터 얻은 biLM의 가장 위 2개의 layer의 선형함수(가중합, Sec. 3.2)으로 계산된다. 이는 준지도학습과 더불어 biLM이 대규모에서 기학습되며(Sec 3.4) 쉽게 다른 NLP 모델에 붙일 수 있도록(Sec 3.3) 해준다.&lt;/p&gt;

&lt;h3 id=&quot;31-bidirectional-language-models&quot;&gt;3.1. Bidirectional language models&lt;/h3&gt;

&lt;p&gt;$N$개의 token $(t_1, t_2, …, t_N)$이 있을 때, 전방언어모델(forward language model)은 $(t_1, …, t_{k-1})$이 주어졌을 때 token $t_k$가 나올 확률을 계산한다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(t_1, t_2, ..., t_N) = \prod_{k=1}^N p(t_k \vert t_1, t_2, ..., t_{k-1})&lt;/script&gt;

&lt;p&gt;최신 언어모델은 token embedding이나 문자단위 CNN을 통해 문맥-독립적 token representation $x_k^{NM}$을 계산하고 이를 전방 LSTM의 $L$개의 layer에 전달한다.&lt;br /&gt;
각 위치 $k$에서, 각 LSTM layer는 문맥-의존적 representation $\overrightarrow{h}_{k, j}^{LM}(j = 1, …, L)$을 출력한다.&lt;/p&gt;

&lt;p&gt;LSTM의 최상위 layer LSTM 출력 $\overrightarrow{h}_{k, L}^{LM}$은 Softmax layer와 함께 다음 token을 예측하는 데 사용된다.&lt;/p&gt;

&lt;p&gt;후방(backward) LSTM은 거의 비슷하지만 방향이 반대라는 것이 다르다. 식의 형태는 똑같지만 뒤쪽 token을 사용해 확률을 계산하고 token을 예측한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(t_1, t_2, ..., t_N) = \prod_{k=1}^N p(t_k \vert t_{k+1}, t_{k+2}, ..., t_N)&lt;/script&gt;

&lt;p&gt;즉 $(t_{k+1}, …, t_N)$이 주어졌을 때 representation $\overleftarrow{h}_{k, j}^{LM}$을 계산한다.&lt;/p&gt;

&lt;p&gt;biLM은 이 둘을 결합시킨 로그우도를 최대화한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\sum_{k=1}^N \Big( \log \ p(t_k \vert t_1, ..., t_{k-1}; \Theta_x, \overrightarrow{\Theta}_{LSTM}, \Theta_s) + \log \ p(t_k \vert t_{k+1}, ..., t_N; \Theta_x, \overleftarrow{\Theta}_{LSTM}, \Theta_s) \Big)&lt;/script&gt;

&lt;p&gt;$\Theta_x$는 token representation, $\Theta_s$는 Softmax layer이며 이 둘은 LSTM의 parameter과는 다르게 고정된다.&lt;/p&gt;

&lt;h3 id=&quot;32-elmo&quot;&gt;3.2. ELMo&lt;/h3&gt;

&lt;p&gt;ELMo는 biLM의 중간 layer representation을 task-specific하게 결합한다. biLM의 $L$개의 layer는 각 token $t_k$당 $2L+1$개의 representation을 계산한다.&lt;/p&gt;

&lt;p&gt;각 biLSTM layer에서&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_{k, 0}^{LM}: \text{token layer}, h_{k, j}^{LM} = [\overrightarrow{h}_{k, j}^{LM}; \overleftarrow{h}_{k, j}^{LM}]&lt;/script&gt;

&lt;p&gt;일 때&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R_k = \{ x_k^{LM}, \overrightarrow{h}_{k, j}^{LM}, \overleftarrow{h}_{k, j}^{LM} \vert j = 1, ..., L \} = \{ h_{k, j}^{LM} \vert j = 0, ..., L \}&lt;/script&gt;

&lt;p&gt;위의 식은 위치 $k$에서 $R_k$는 $1+L+L=2L+1$개의 representation으로 이루어져 있다는 뜻이다.&lt;/p&gt;

&lt;p&gt;Downstream model로의 포함을 위해, ELMo는 $R$의 모든 layer를 하나의 벡터 $\text{ELMo}_k = E(R_k; \Theta_e)$로 압축시킨다.&lt;/p&gt;

&lt;p&gt;가장 단순한 예로 ELMo가 단지 최상위 레이어를 택하는 $E(R_k) = h_{k, L}^{LM}$는 TagLM이나 CoVe의 것과 비슷하다.&lt;/p&gt;

&lt;p&gt;더 일반적으로, 모든 biLM layer의 task-specific한 weighting을 계산한다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{ELMo}_k^{task} = E(R_k; \Theta^{task}) = \gamma^{task} \sum_{j=0}^L s_j^{task} h_{k, j}^{LM}&lt;/script&gt;

&lt;p&gt;$s^{task}$는 softmax-정규화된 가중치이고 scalar parameter $\gamma^{task}$는 전체 ELMo 벡터의 크기를 조절하는 역할을 한다. $\gamma$는 최적화 단계에서 중요하다.&lt;br /&gt;
각 biLM layer에서의 활성함수는 다른 분포를 갖는데, 경우에 따라 가중치를 정하기 전 각 biLM layer에 정규화를 적용하는 데 도움이 되기도 한다.&lt;/p&gt;

&lt;h3 id=&quot;33-using-bilms-for-supervised-nlp-tasks&quot;&gt;3.3. Using biLMs for supervised NLP tasks&lt;/h3&gt;

&lt;p&gt;목표 NLP task에 대한 기학습된 biLM과 지도(supervised) 모델구성이 주어지면, 해당 task 모델을 향상시키도록 biLM을 쓰는 과정은 간단하다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;단지 biLM을 돌리고 각 단어마다 모든 layer representation을 기록한다.&lt;/li&gt;
  &lt;li&gt;그리고 모델이 이 representation들의 선형결합을 배우도록 한다.
    &lt;ul&gt;
      &lt;li&gt;먼저 biLM이 없는 지도 모델을 고려한다.&lt;/li&gt;
      &lt;li&gt;대부분의 NLP 지도 모델은 가장 낮은 단계의 layer에서 공통구조를 공유하는데, 이는 ELMo를 일관된 방법으로 추가할 수 있게 해 준다.&lt;/li&gt;
      &lt;li&gt;$(t_1, t_2, …, t_N)$이 주어지면 기학습된 단어 embedding(+글자기반 representation)을 사용하여 각 token 위치마다 문맥-독립적 token representation $x_k$를 만든다.&lt;/li&gt;
      &lt;li&gt;그러면 모델은 biRNN이든 CNN이든 FFN이든 사용하여 문맥-의존적 representation $h_k$를 생성한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ELMo를 지도 모델에 추가하려면&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;먼저 biLM의 weight를 고정시키고&lt;/li&gt;
  &lt;li&gt;ELMo 벡터 $\text{ELMo}_k^{task}$와 $x_k$를 이어붙인 후&lt;/li&gt;
  &lt;li&gt;ELMo enhanced representation $[x_k; \text{ELMo}_k^{task}]$를 task RNN에 전달한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;SNLI, SQuAD 등의 task에서는 $h_k$를 $[x_k; \text{ELMo}_k^{task}]$로 대체하면 성능이 더 향상되었다.&lt;br /&gt;
또한 ELMo에 dropout을 적용하는 것과, $\lambda \Vert w \Vert_2^2$를 loss에 더해 ELMo weight를 정규화하는 것이 ELMo weight에 inductive bias를 유도하여 모든 biLM layer의 평균에 더 가까워지도록 하여 성능에 도움을 주는 것을 발견하였다.&lt;/p&gt;

&lt;h3 id=&quot;34-pre-trained-bidirectional-language-model-architecture&quot;&gt;3.4. Pre-trained bidirectional language model architecture&lt;/h3&gt;

&lt;p&gt;기학습된 biLM은 이전 모델(Józefowicz et al. 2016)의 것과 비슷하지만 양방향 학습의 동시학습을 가능하게 하고 LSTM layer 사이에 residual connection을 추가하였다.&lt;/p&gt;

&lt;p&gt;완전히 문자기반인 입력 representation을 유지하면서도 모델복잡도와 계산요구량의 균형을 맞추기 위해, embedding과 은닉차원을 반으로 줄였다.&lt;br /&gt;
최종 모델은 4096개의 unit과 512차원의 projection layer, 1-2번 layer 사이 residual connection을 갖는 $L=2$ biLSTM을 사용한다.&lt;br /&gt;
그 결과 biLM은 각 입력 token마다 순수 문자기반 입력 때문에 학습셋을 벗어나는 것을 포함한, 3개의 layer of representation을 생성한다. 이는 전통적인 단어 embedding이 고정된 단어사전 하에서 token에 대해 단 한개의 layer of representation을 생성하는 것과 대비된다.&lt;/p&gt;

&lt;p&gt;1B word Benchmark로 10 epoch만큼 학습시킨 결과 perplexity가 30.0에서 39.7로 크게 늘었다.&lt;/p&gt;

&lt;p&gt;일단 기학습된 biLM은 어떤 task에서도 representation을 계산할 수 있다. 대부분의 downstream task에서는 fine-tuned biLM을 사용하였다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;4-평가evaluation&quot;&gt;4. 평가(Evaluation)&lt;/h2&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-20-ELMo - Deep contextualized word representations/01.png&quot; width=&quot;100%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;p&gt;6개의 NLP task에서 에러율을 상대적으로 6~20%만큼 줄였다.&lt;/p&gt;

&lt;p&gt;Question Answering 부문에선 SQuAD, Textual Entailment에서는 SNLI 데이터셋을 사용했으며, Semantic role labeling, Coreference resolution, Named entity extraction, Sentiment analysis 등의 task에서도 높은 점수를 기록했음을 볼 수 있다.&lt;br /&gt;
데이터셋과 어떤 향상이 있었는지에 대한 정보는 원문을 찾아보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;5-분석analysis&quot;&gt;5. 분석(Analysis)&lt;/h2&gt;

&lt;p&gt;이 섹션에서는 특정 부분을 빼거나 교체해서 해당 부분의 역할을 알아보는 ablation 분석을 수행한다.&lt;/p&gt;

&lt;h3 id=&quot;51-alternate-layer-weighting-schemes&quot;&gt;5.1. Alternate layer weighting schemes&lt;/h3&gt;

&lt;p&gt;biLM layer를 결합시키는 방법은 매우 다양하다. 또한 정규화 parameter $\lambda$도 매우 중요한 역할을하는데, $\lambda$가 크면(e.g., $\lambda=1$) 가중함수를 단순평균함수로 만들고, 작으면(e.g., $\lambda=0.001$) layer 가중치를 서로 달라지게 한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{ELMo}_k^{task} = E(R_k; \Theta^{task}) = \gamma^{task} \sum_{j=0}^L s_j^{task} h_{k, j}^{LM}&lt;/script&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-20-ELMo - Deep contextualized word representations/02.png&quot; width=&quot;80%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 결과에서 보듯이 단지 마지막 layer만 쓰는 것보다 모든 layer를 쓰는 것이 더 좋으며, 각각을 단순평균하는 것이 아닌 가중합을 하였을 때(이는 $\lambda$가 작은 것으로 구현됨) 더 성능이 좋아지는 것을 볼 수 있다.&lt;br /&gt;
즉 작은 $\lambda$가 ELMo에 도움이 되며 task의 종류에는 크게 영향받지 않는 것 같다.&lt;/p&gt;

&lt;h3 id=&quot;52-where-to-include-elmo&quot;&gt;5.2. Where to include ELMo?&lt;/h3&gt;

&lt;p&gt;이 논문에서는 단어 embedding을 biRNN의 최하층에만 넣었지만 일부 task에서는 biRNN의 출력에 ELMo를 포함시키는 것이 성능향상을 가져오는 것을 볼 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-20-ELMo - Deep contextualized word representations/03.png&quot; width=&quot;80%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;p&gt;단 위에서 보듯이 모든 경우에 좋은 것은 아니다. SQuAD와 SNLI 모델구성은 biRNN 뒤에 attention layer을 사용하므로 이 layer에 ELMo를 추가하는 것은 biLM의 내부 representatino에 직접 접근할 수 있도록 해 주며 SRL의 경우 task-specific한 문맥 representation이 더 중요하기 때문이라는 설명이 가능하다.&lt;/p&gt;

&lt;h3 id=&quot;53-what-information-is-captured-by-the-bilms-representations&quot;&gt;5.3. What information is captured by the biLM’s representations?&lt;/h3&gt;

&lt;p&gt;ELMo를 추가하는 것만으로 단어 벡터만 있을 때보다 성능이 향상되었기 때문에, biLM의 문맥적 representation은 단어 벡터가 잡아내지 못한 어떤 정보를 갖고 있어야 한다. 직관적으로 biLM은 다의어를 명확화(disambiguation, 다의어의 여러 뜻 중 어떤 의미로 쓰였는지 알아내는 것)한 정보를 갖고 있어야 한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-20-ELMo - Deep contextualized word representations/04.png&quot; width=&quot;100%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 표에서 GloVe 단어벡터에서 ‘play’ 와 비슷한 단어는 품사를 변형한 것 또는 스포츠에 관한 것만 유사 단어로 뜬다.&lt;br /&gt;
그러나 biLM에서는 ‘play’이 비슷한 의미로 쓰인 문장을 유사한 것으로 판단할 수 있음을 알 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Word sense disambiguation&lt;/strong&gt;&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-20-ELMo - Deep contextualized word representations/05.png&quot; width=&quot;80%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;p&gt;단어 의미 명확화에서 충분히 괜찮은 성능을 보여준다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;POS tagging&lt;/strong&gt;&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-20-ELMo - Deep contextualized word representations/06.png&quot; width=&quot;80%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;p&gt;품사 태깅도 꽤 잘 한다고 한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Implications for supervised tasks&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이러한 실험들은 왜 biLM에서 모든 layer가 중요한지를 알려 준다. 각 layer마다 잡아낼 수 있는 문맥정보가 다르기 때문이다.&lt;/p&gt;

&lt;h3 id=&quot;54-sample-efficiency&quot;&gt;5.4. Sample efficiency&lt;/h3&gt;

&lt;p&gt;ELMo를 추가했을 때는 그렇지 않을 때보다 학습속도도 빠르며(최대 49배 정도) 학습데이터가 적을 때도 훨씬 효율적으로 학습한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-20-ELMo - Deep contextualized word representations/07.png&quot; width=&quot;80%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;55-visualization-of-learned-weights&quot;&gt;5.5. Visualization of learned weights&lt;/h3&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-20-ELMo - Deep contextualized word representations/08.png&quot; width=&quot;100%&quot; alt=&quot;Results&quot; /&gt;&lt;/center&gt;

&lt;p&gt;입력 layer에서 task 모델은, 특히 corefenrece와 SQuAD에서 첫번째 biLSTM layer를 선호한다. 출력 layer에서 낮은 레이어에 조금 더 중점을 두지만 상대적으로 균형잡힌 모습을 보여준다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;6-결론conclusion&quot;&gt;6. 결론(Conclusion)&lt;/h2&gt;

&lt;p&gt;이 논문에서는 biLM으로부터 고품질의 깊은 문맥의존 representation을 학습하는 일반적인 방법을 소개했으며, 넓은 범위의 NLP 문제들에서 ELMo를 적용했을 때 많은 성능 향상을 가져오는 것을 보였다. 또한 ablation을 통해 biLM의 모든 layer들이 각각 효율적으로 문맥 정보를 포착하여, 이를 모두 사용하는 것이 좋다는 것을 보였다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;refenrences&quot;&gt;Refenrences&lt;/h2&gt;

&lt;p&gt;논문 참조. 레퍼런스가 많다.&lt;/p&gt;

&lt;p&gt;또한 이 논문이 일부 모듈의 원형으로 삼은 모델들의 구조를 살펴볼 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;appendix&quot;&gt;Appendix&lt;/h2&gt;

&lt;p&gt;부록에서는 $\gamma$의 중요성이나, 각 NLP task에서 ELMo를 붙였을 때 성능 향상이 이루어지는 예시들을 많이 들고 있다. 한번쯤 살펴보자.&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>Attention Is All You Need</title>
   <link href="http://localhost:4000/Attention-Is-All-You-Need/"/>
   <updated>2019-08-17T00:00:00+09:00</updated>
   <id>http://localhost:4000/Attention Is All You Need</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 2017년 6월(v1) &lt;em&gt;Ashish Vaswani&lt;/em&gt; 등이 발표한 Attention Is All You Need를 살펴보도록 한다.&lt;/p&gt;

&lt;p&gt;중요한 부분만 적을 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;attention-is-all-you-need&quot;&gt;Attention Is All You Need&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;Attention Is All You Need&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Pytorch code: &lt;strong&gt;&lt;a href=&quot;http://nlp.seas.harvard.edu/2018/04/03/attention.html&quot;&gt;Harvard NLP&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;초록abstract&quot;&gt;초록(Abstract)&lt;/h2&gt;

&lt;p&gt;성능 좋은 변환(번역) 모델은 인코더와 디코더를 포함한 복잡한 recurrent 또는 convolutional 신경망에 기반을 두고 있다. 최고 성능을 내는 모델 역시 attention mechanism을 사용하여 인코더와 디코더를 연결한다.&lt;br /&gt;
이 논문에서 recurrence와 convolution을 전부 제외하고 오직 attention mechanism에만 기반한 &lt;strong&gt;Transformer&lt;/strong&gt;라는 간단한 모델을 제안한다. 두 기계번역 task 실험에서는 이 모델은 병렬화와 학습시간 감소와 더불어 최고 수준의 품질을 가진다는 것을 보여준다. 이 모델은 WMT 2014 영어$\rightarrow$독일어 번역 task에서 이전보다 2 높은 28.4 BLEU를 달성하였다. 여기서 이 모델은 8개의 GPU로 8일 동안 학습시켜 41.8점의 BLEU state-of-the-art 단일 모델이다.&lt;br /&gt;
이 논문에서 &lt;strong&gt;Transformer&lt;/strong&gt;는 크거나 한정된 학습 데이터를 가지고서도 성공적으로 다른 task들에 일반화될 수 있음을 보인다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-서론introduction&quot;&gt;1. 서론(Introduction)&lt;/h2&gt;

&lt;p&gt;RNN, LSTM, GRU 등은 sequence 모델링과 언어모델 등 변환 문제, 기계번역 등의 문제에서 뛰어난 성과를 보였다.&lt;br /&gt;
Recurrent 모델은 보통 입력과 출력의 symbol position에 따라 계산을 수행한다. 계산 단계에서 위치를 적절히 맞추기 위해 이전 상태 $h_{t-1}$과 위치 $t$의 함수인 은닉상태 $h_t$를 생성한다. 이는 근본적으로 메모리 제한으로 인해 sequence가 길수록 병렬화를 힘들게 한다. 최근 들어 모델의 성능 자체는 비약적으로 상승했지만 위의 문제는 여전히 남아 있다.&lt;/p&gt;

&lt;p&gt;Attention mechanism은 입력과 출력 sequence의 거리에 상관없이 의존성을 모델링함으로써 다양한 과제에서의 sequence 모델링과 변환 모델에서 매우 중요한 부분이 되었다. 그러나 거의 대부분의 경우 recurrent 네트워크와 함께 사용되고 있다.&lt;/p&gt;

&lt;p&gt;이 논문에서는, &lt;strong&gt;Transformer&lt;/strong&gt;라는, recurrence를 제거하고 입력-출력 간 전역 의존성을 학습할 수 있는 attention mechanism만을 사용한 모델 구조를 제안한다. &lt;strong&gt;Transformer&lt;/strong&gt;는 병렬화를 비약적으로 달성하였으며 8개의 P100 GPU만으로 딱 12시간만을 학습하여 state-of-the-art 결과를 얻을 수 있게 한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-배경background&quot;&gt;2. 배경(Background)&lt;/h2&gt;

&lt;p&gt;연속적 계산을 줄이려는 노력은 Extended Neural GPU, ByteNet, ConvS2S 등의 모델을 탄생시켰으나 이들은 전부 CNN을 기본 블록으로 사용한다. 이러한 모델들은 임의의 위치의 input-output 사이의 관련성을 파악하기 위해서는 거리에 따라(선형 또는 로그 비례) 계산량이 증가하며, 이는 장거리 의존성을 학습하기 어렵게 한다.&lt;br /&gt;
Transformer는, 이를 상수 시간의 계산만으로 가능하게 하였다.&lt;/p&gt;

&lt;p&gt;intra-attention으로도 불리는 Self-attention은 sequence의 representation을 계산하기 위한 단일 sequence의 다른 위치를 연관시키는 attention mechanism이다. Self-attention은 많은 과제들에서 사용되었으며 성공적이었다.&lt;/p&gt;

&lt;p&gt;End-to-end 메모리 네트워크는 sequence-aligned recurrence 대신 recurrent attention mechanism에 기반하였으며 simple-language QA와 언어모델링 task 등에서 좋은 성과를 내었다.&lt;/p&gt;

&lt;p&gt;그러나, Transformer는 RNN이나 convolution 없이 오직 attention에 전적으로 의존한 첫 번째 변환 모델이다. 앞으로 이 모델에 대한 설명이 이어질 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-모델-구성model-architecture&quot;&gt;3. 모델 구성(Model Architecture)&lt;/h2&gt;

&lt;p&gt;Transformer는 크게 인코더와 디코더로 나뉘며, 인코더는 입력인 symbol representations $(x_1, …, x_n)$을 continuous representations $z = (z_1, …, z_n)$으로 매핑한다. $z$가 주어지면, 디코더는 한번에 한 원소씩 출력 sequence $(y_1, …, y_n)$를 생성한다.&lt;br /&gt;
각 단계는 자동회귀(auto-regressive)이며, 다음 단계의 symbol을 생성할 때 이전 단계에서 생성된 symbol을 추가 입력으로 받는다.&lt;/p&gt;

&lt;p&gt;Transformer는 인코더와 디코더 모두에서 쌓은 self-attention과 point-wise FC layer를 사용하며, 그 구성은 아래 그림에 나타나 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-17-Attention Is All You Need/01.png&quot; width=&quot;100%&quot; alt=&quot;Transformer Architecture&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;31-encoder-and-decoder-stacks&quot;&gt;3.1. Encoder and Decoder Stacks&lt;/h3&gt;

&lt;p&gt;인코더는 $N = 6$ 개의 동일한 레이어로 구성되며, 각 레이어는 아래 두 개의 sub-layer로 이루어져 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;multi-head self-attention mechanism&lt;/li&gt;
  &lt;li&gt;simple, position-wise fully connected feed-forward network&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;각 sub-layer의 출력값은 LayerNorm($x$ + Sublayer($x$))이고, Sublayer($x$)는 sub-layer 자체로 구현되는 함수이다. 이 residual connection을 용이하게 하기 위해, embedding layer를 포함한 모델의 모든 sub-layer는 $d_{model} = 512$차원의 출력값을 가진다.&lt;/p&gt;

&lt;p&gt;디코더 역시 $N = 6$ 개의 동일한 레이어로 구성되지만, 각 레이어는 인코더의 것과 동일한 두 개의 sub-layer 외에 한 가지를 더 가진다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;encoder stack의 출력값에 multi-head attention을 수행하는 sub-layer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;인코더와 비슷하게 residual connection이 각 sub-layer의 정규화 layer 뒤에 있다. 그리고 디코더가 출력을 생성할 때 다음 출력에서 정보를 얻는 것을 방지하기 위해 &lt;strong&gt;masking&lt;/strong&gt;을 사용한다. 이는 $i$번째 원소를 생성할 때는 $1 \sim i-1$번째 원소만 참조할 수 있도록 하는 것이다.&lt;/p&gt;

&lt;h3 id=&quot;32-attention&quot;&gt;3.2. Attention&lt;/h3&gt;

&lt;p&gt;Attention 함수는 &lt;em&gt;query + key-value&lt;/em&gt; $\rightarrow$ &lt;em&gt;output&lt;/em&gt; 으로의 변환을 수행한다. query, key, value, output은 모두 벡터이다. output은 value들의 가중합으로 계산되며, 그 가중치는 query와 연관된 key의 호환성 함수(compatibility function)에 의해 계산된다.&lt;/p&gt;

&lt;h4 id=&quot;321-scaled-dot-product-attention&quot;&gt;3.2.1. Scaled Dot-Product Attention&lt;/h4&gt;

&lt;p&gt;이 이름은 Attention을 계산하는데 dot-product를 쓰고, 그 결과에 scale 조정을 하기 때문에 이렇게 붙여졌다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-17-Attention Is All You Need/02.png&quot; width=&quot;100%&quot; alt=&quot;Scaled Dot-Product Attention &amp;amp; Multi-head Attention&quot; /&gt;&lt;/center&gt;

&lt;p&gt;입력은 $d_k$차원의 query와 key, $d_v$차원의 value로 구성된다. &lt;br /&gt;
query와 모든 key의 내적(dot product)을 계산하고, 각각 $\sqrt{d_k}$로 나누고, value의 가중치를 얻기 위해 softmax 함수를 적용한다.&lt;/p&gt;

&lt;p&gt;실제로는, query들에 대해 동시에 계산하기 위해 이를 행렬 $Q$로 묶는다. 모든 key와 value 역시 각각 행렬 $K$와 $V$로 표현된다. 이제 $Q, K, V$의 attention을 구하는 식은 다음과 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Attention(Q, K, V) = \text{softmax} \Big( \frac{QK^T}{\sqrt{d_k}} \Big) V&lt;/script&gt;

&lt;p&gt;가장 널리 쓰이는 attention 함수는 다음 두 가지다:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Additive attention: 단일 hidden layer의 feed-forward 네트워크를 사용하여 호환성 함수를 계산한다. $d_k$가 작을 때 성능이 더 좋다.&lt;/li&gt;
  &lt;li&gt;Dot-product attention: $d_k$가 더 클 때는 빠른 행렬곱 알고리즘에 힘입어 더 빠르고 더 공간 효율적이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;322-multi-head-attention&quot;&gt;3.2.2. Multi-Head Attention&lt;/h4&gt;

&lt;p&gt;$d_{model}$차원 key, value, query로 단일 attention function을 쓰는 것보다 query, key, value를 각각 $d_k, d_k, d_v$차원으로 각각 다르게 $h$번 학습시키는 것이 낫다. 여기서 $h$번 학습시킨다는 것은 단지 반복을 한다는 것이 아니라, 각 sub-layer에 동일한 부분이 $h$개 존재한다는 뜻이다. 위 그림의 오른쪽을 보자.&lt;br /&gt;
이렇게 각각 따로 계산된 $h$쌍의 $d_v$차원 출력은 이어붙인(concatenate) 후 한번 더 선형 함수에 통과시켜(projected) 최종 출력값이 된다.&lt;/p&gt;

&lt;p&gt;식으로 나타내면 다음과 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{MultiHead}(Q, K, V) = \text{Concat}(head_1, ..., head_h)W^O, where \ head_i=\text{Attention}(QW_i^Q, KW_i^K, VW_i^V)&lt;/script&gt;

&lt;p&gt;여기서 $ W_i^Q \in \mathbb{R}^{d_{model} \times d_k}, W_i^K \in \mathbb{R}^{d_{model} \times d_k}, W_i^V \in \mathbb{R}^{d_{model} \times d_v}, W^O \in \mathbb{R}^{hd_v \times d_{model}} $이며, 논문에서는 $h=8, d_k=d_v=d_{model}/h = 64$를 사용하였다.&lt;br /&gt;
각 head의 차원이 줄었기 때문에 단일 head attention과 계산량은 비슷하다.&lt;/p&gt;

&lt;h4 id=&quot;323-applications-of-attention-in-our-model&quot;&gt;3.2.3. Applications of Attention in our Model&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;“encoder-decoder attention” layer에서, query는 이전 디코더 layer에서 오며 memory key와 value는 encoder의 출력에서 온다. 이는 디코더가 입력의 모든 위치(원소)를 고려할 수 있도록 한다.&lt;/li&gt;
  &lt;li&gt;인코더는 self-attention layer를 포함한다. 여기서 모든 key, value, query는 같은 곳(인코더의 이전 layer의 출력)에서 온다. 따라서 인코더의 각 원소는 이전 layer의 모든 원소를 고려할 수 있다.&lt;/li&gt;
  &lt;li&gt;이는 디코더에서도 비슷하다. 그러나 auto-regressive 속성을 보존하기 위해 디코더는 출력을 생성할 시 다음 출력을 고려해서는 안 된다. 즉 이전에 설명한 &lt;strong&gt;masking&lt;/strong&gt;을 통해 이전 원소는 참조할 수 없도록 한다. 이 masking은 dot-product를 수행할 때 $-\infty$로 설정함으로써 masking out시킨다. 이렇게 설정되면 softmax를 통과할 때 0이 되므로 masking의 목적이 달성된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;33-position-wise-feed-forward-networks&quot;&gt;3.3. Position-wise Feed-Forward Networks&lt;/h3&gt;

&lt;p&gt;인코더와 디코더의 각 layer는 FC feed-forward 네트워크를 포함하는데, 이는 각 위치마다 동일하게 적용되지만 각각 따로 적용된다. 이는 ReLU 활성함수와 2개의 선형변환을 포함한다. kernel size가 1인 CNN과 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{FFN}(x) = \max(0, xW_1 + b_1)W_2 + b_2&lt;/script&gt;

&lt;p&gt;각 레이어에 이 부분은 독립적인 parameter를 사용한다. 논문에서는 $d_{model}=512, d_{ff} = 2048$을 사용했다.&lt;/p&gt;

&lt;h3 id=&quot;34-embeddings-and-softmax&quot;&gt;3.4. Embeddings and Softmax&lt;/h3&gt;

&lt;p&gt;다른 모델들과 비슷하게 embedding을 사용하였다. 이 모델에서는 2개의 embedding layer와 pre-softmax 선형변환 사이에 같은 weight 행렬을 사용했다. Embedding layer에는 $\sqrt{d_{model}}$을 곱한다.&lt;/p&gt;

&lt;h3 id=&quot;35-positional-encoding&quot;&gt;3.5. Positional Encoding&lt;/h3&gt;

&lt;p&gt;이 모델에는 recurrence도 convolution도 사용되지 않기 때문에 sequence에 있는 원소들의 위치에 대한 정보를 따로 넣어 주어야 한다. 그래서 인코더와 디코더 stack의 밑부분에 &lt;strong&gt;positional encodings&lt;/strong&gt;를 입력 embedding에 추가하였다. 이는 embedding과 갈은 $d_{model}$차원을 가지며, 따라서 더할 수 있다. 모델에서 사용된 것은 사인/코사인 함수이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\quad PE_{(pos, 2i)} = sin(pos/10000^{2i/d_{model}})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ PE_{(pos, 2i+1)} = cos(pos/10000^{2i/d_{model}})&lt;/script&gt;

&lt;p&gt;$pos$는 위치(position)이고 $i$는 차원이다.&lt;/p&gt;

&lt;p&gt;가능한 여러 함수 중 사인함수 버전을 선택한 이유는 학습 때보다 더 긴 sequence를 만나도 추정이 가능하기 때문이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;4-왜-self-attention인가why-self-attention&quot;&gt;4. 왜 Self-Attention인가(Why Self-Attention)&lt;/h2&gt;

&lt;p&gt;$(x_1, …, x_n) \rightarrow (z_1, …, z_n)$에 self-attention이 적합한 이유는&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;layer 당 전체 계산량이 적고&lt;/li&gt;
  &lt;li&gt;계산이 병렬화될 수 있다. 즉 병렬적으로 한번에 많은 계산을 할 수 있는데, recurrence의 경우 순차적으로 계산해야 하기 때문에 계산의 병렬화가 거의 불가능하다.&lt;/li&gt;
  &lt;li&gt;장거리 의존성(long-range 또는 long-term dependency) 때문이다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;장거리 의존성을 학습할 수 있는 중요 요인은 네트워크 상에서 횡단할 수 있는 경로의 길이인데, 길이가 짧을 때는 다 비슷하므로 최대 길이를 중점적으로 살펴보았다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-17-Attention Is All You Need/03.png&quot; width=&quot;100%&quot; alt=&quot;Why Self-Attention&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 표에서 볼 수 있듯 장거리 의존성의 학습 속도(또는 능력)에서 self-attention이 가장 좋다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;5-학습training&quot;&gt;5. 학습(Training)&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Parameter&lt;/th&gt;
      &lt;th&gt;Descrption&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;DataSet(German)&lt;/td&gt;
      &lt;td&gt;WMT 2014 English-German dataset(4.5M쌍의 문장, 37000 vocab)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DataSet(French)&lt;/td&gt;
      &lt;td&gt;WMT 2014 English-French dataset(36M쌍의 문장, 32000 vocab)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Batch size&lt;/td&gt;
      &lt;td&gt;25000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Hardware&lt;/td&gt;
      &lt;td&gt;8개의 P100 GPU&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Schedule&lt;/td&gt;
      &lt;td&gt;Base Model: 12시간=10만 step $\times$ 0.4초/step, Big Model: 36시간=30만 step&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Optimizer&lt;/td&gt;
      &lt;td&gt;Adam($\beta_1=0.9, \beta_2=0.98, \epsilon=10^{-9} $)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Learning Rate&lt;/td&gt;
      &lt;td&gt;$lrate = d_{model}^{-0.5} \cdot \min ($step_num$^{-0.5}$, step_num $\cdot$ warmup_steps $^{-1.5}) $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;warmup_steps&lt;/td&gt;
      &lt;td&gt;4000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Regularization&lt;/td&gt;
      &lt;td&gt;Residual Dropout($P_{drop} = 0.1$)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;6-결과results&quot;&gt;6. 결과(Results)&lt;/h2&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-17-Attention Is All You Need/04.png&quot; width=&quot;100%&quot; alt=&quot;Result 1&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-17-Attention Is All You Need/05.png&quot; width=&quot;100%&quot; alt=&quot;Result 2&quot; /&gt;&lt;/center&gt;

&lt;p&gt;Machine Translation, Model Variations, English Constituency Parsing에 대한 실험 결과이다. Base Model만 해도 충분히 최고 성능을 보여주며, 특히 Big Model의 경우 state-of-the-art를 상당한 수준으로 경신하는 성능을 보여 주었다.&lt;br /&gt;
이외에 따로 요약이 필요하지는 않아 자세한 조건이나 성능, 설명은 생략하도록 하겠다. 필요하면 논문 참조하는 편이 낫다.&lt;/p&gt;

&lt;h3 id=&quot;결과-부록&quot;&gt;결과: 부록&lt;/h3&gt;

&lt;p&gt;원래는 부록에 있는 자료이지만 결과 섹션으로 가져왔다.&lt;/p&gt;

&lt;p&gt;아래 그림에서는 &lt;em&gt;making&lt;/em&gt; 이라는 단어가 &lt;em&gt;making…more difficult&lt;/em&gt; 라는 구를 만드는 데 중요한 역할을 하는 것을 보여준다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-17-Attention Is All You Need/06.png&quot; width=&quot;100%&quot; alt=&quot;Attention Visaulizations&quot; /&gt;&lt;/center&gt;

&lt;p&gt;여러 개의 attention을 시각화한 자료는 다음 두 그림에서 확인할 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-17-Attention Is All You Need/07.png&quot; width=&quot;100%&quot; alt=&quot;Attention Head Visaulizations 1&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-08-17-Attention Is All You Need/08.png&quot; width=&quot;100%&quot; alt=&quot;Attention Head Visaulizations 1&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;7-결론conclusion&quot;&gt;7. 결론(Conclusion)&lt;/h2&gt;

&lt;p&gt;(여러 번 나온 말이지만) &lt;strong&gt;Transformer&lt;/strong&gt;는 recurrence와 convolution을 모두 제거한, 오직 attention에만 의존하는 새로운 종류의 모델이다. 이 모델은 계산량을 줄이고 병렬화를 적용해 학습 속도가 훨씬 빠를 뿐만 아니라 그 성능 또한 state-of-the-art를 달성하는 수준에 이르렀다.&lt;br /&gt;
또한 이러한 attention에 기반한 모델은 다른 task들에 적용할 수도 있다. 비단 텍스트뿐만 아니라 이미지, 오디오나 비디오 등의 상대적으로 큰 입력-출력을 요하는 task들에 효과적으로 사용할 수 있을 것이다.&lt;/p&gt;

&lt;p&gt;이 모델을 학습하고 평가한 코드는 &lt;a href=&quot;https://github.com/tensorflow/tensor2tensor&quot;&gt;여기&lt;/a&gt;에서 찾아볼 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;refenrences&quot;&gt;Refenrences&lt;/h2&gt;

&lt;p&gt;논문 참조. 40개의 레퍼런스가 있다.&lt;/p&gt;

&lt;hr /&gt;

</content>
 </entry>
 
 <entry>
   <title>Generating Sequences With Recurrent Neural Networks</title>
   <link href="http://localhost:4000/Generating-Sequences-WIth-Recurrent-Neural-Networks/"/>
   <updated>2019-07-15T00:00:00+09:00</updated>
   <id>http://localhost:4000/Generating Sequences WIth Recurrent Neural Networks</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 2013년 8월(v1) Alex Graves가 발표한 Generating Sequences With Recurrent Neural Networks를 살펴보도록 한다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.cs.toronto.edu/~graves/&quot;&gt;연구자의 홈페이지&lt;/a&gt;도 있다.&lt;/p&gt;

&lt;p&gt;중요한 부분만 적을 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;generating-sequences-with-recurrent-neural-networks&quot;&gt;Generating Sequences With Recurrent Neural Networks&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1308.0850&quot;&gt;Generating Sequences With Recurrent Neural Networks&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;초록abstract&quot;&gt;초록(Abstract)&lt;/h2&gt;

&lt;p&gt;이 논문은 LSTM(Long Short-term Memory) RNNs이 어떻게 넓은 범위의 구조를 가진 복잡한 시퀀스(sequences, 문장 등)를 만들 수 있는지(= 단순히 어느 시점에 하나의 부분만 예측하는 방법)를 보여준다. 이 접근법은 텍스트(이산값)와 손글씨(실수값)에 의해 보여질 것이다. 그리고 네트워크가 텍스트 문장에 대해 예측을 수행함으로써 손글씨 합성으로까지 확장한다. 이 결과 시스템은 다양한 스타일의 정말 실제 같은 필기체를 생성할 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;1-서론introduction&quot;&gt;1. 서론(Introduction)&lt;/h2&gt;

&lt;p&gt;RNNs(Recurrent Neural Networks)은 음악, 텍스트, 모션캡쳐 데이터 등과 같은 연속데이터를 생성하기 위해 사용되는 모델이다. RNN은 일반적으로 지금까지의 입력값과 모델 내부 parameter를 바탕으로 바로 다음 것이 무엇일지를 예측하는 모델이다.&lt;br /&gt;
RNN은 많은 경우 그 예측이 애매하며 불확실하다(fuzzy). 그 이유는 항상 확정적이며 똑같은 결과만을 내놓는다면 생성되는 문장이나 음악은 항상 똑같을 것인데 우리는 그런 것을 원하지 않으며, 또한 확률적인(stochastic) 방법이 정확한(exact) 일치 방법에 비해 차원의 저주(the curse of dimensionality)를 피하기 적합하며 그로 인해 시퀀스 또는 다변수 데이터를 모델링하는 데 더 뛰어나다.&lt;/p&gt;

&lt;p&gt;이론적으로는 충분히 큰 RNN은 어떤 복잡한 시퀀스(sequences)도 생성할 수 있어야 한다. 그러나 Vanilla RNN은 최근 몇 개의 입력값을 기억하며 이에 의존할 뿐 멀리 떨어진 이전 또는 장기적인 정보를 거의 기억하지 못한다.&lt;br /&gt;
이를 많은 부분 해결한 것이 바로 LSTM이다. 이 역시 기본적으로는 이전 정보를 기억하는 RNN 구조를 따르지만 조금 더 복잡한 구조를 가지며 장기적(long-range) 정보를 저장하는 데 뛰어난 능력을 보인다.&lt;/p&gt;

&lt;p&gt;이 논문에서는 다음과 같은 것들을 다룰 것이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Section 2: LSTM을 여럿 쌓을 ‘deep RNN’을 정의하고 어떻게 다음 단계를 예측하는 데 필요한 학습을 진행하며 시퀀스를 생성하는지 보여준다.&lt;/li&gt;
  &lt;li&gt;Section 3: Penn Treebank와 Hutter Prize Wikipedia 데이터셋에 대해 예측을 수행하고 state-of-the-art 수준임을 보인다.&lt;/li&gt;
  &lt;li&gt;Section 4: mixture density output layer를 사용하여 어떻게 실제 데이터에 적용할 수 있는지와 IAM Online Handwriting Database에 대한 실험 결과를 보인다.&lt;/li&gt;
  &lt;li&gt;Section 5: 예측 네트워크를 짧은 주석에 기반하도록 하여 확장시켜서 어떻게 손글씨 합성을 시킬 수 있는지를 보인다.&lt;/li&gt;
  &lt;li&gt;Section 6: 결론과 함께 추후 연구 방향을 제시한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;2-예측-네트워크prediction-network&quot;&gt;2. 예측 네트워크(Prediction Network)&lt;/h2&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/01.png&quot; width=&quot;100%&quot; alt=&quot;Deep RNN Architecture&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 그림은 이 논문에서 사용된 기본 RNN 모델의 구조이다. 입력값 $x = (x_1, …, x_T)$은 $N$층에 걸쳐 쌓인 재귀적으로 연결된 hidden layers를 통과하며 $h^n = (h_1^n, …, h_T^n)$ 를 계산하고 최종적으로 $N$층을 다 통과하면 출력벡터 시퀀스 $y = (y_1, …, y_T)$를 얻는다. 각 출력벡버 $y_t$는 가능한 다음 입력값 $x_{t+1}$에 대한 예측분포 $P(x_{t+1} \vert y_t)$를 뜻한다. 초기값 $x_1$은 언제나 null 벡터이다.&lt;/p&gt;

&lt;p&gt;입력과 모든 hidden layer, 그리고 모든 hidden layer와 출력과 ‘skip-connections’이 존재함을 기억하라. 이는 vanishing gradient 문제를 피해 깊은 신경망(DNN)을 학습시키기 용이하게 한다. $N=1$인 경우에 vanilla RNN과 같음을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;Hidden layer의 각 활성값은 $t=1…T, n=2…N$ 동안 반복적으로 계산된다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_t^1 = \mathcal{H}(W_{ih^1x_t} + W_{h^1h^1}h^1_{t-1} + b^1_h)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_t^n = \mathcal{H}(W_{ih^nx_t} + W_{h^{n-1}h^n}h^{n-1}_{t} + W_{h^nh^n}h^n_{t-1} + b^n_h)&lt;/script&gt;

&lt;p&gt;$W$는 각 레이어의 가중치 행렬이다. 은닉 시퀀스가 주어졌을 때, 출력 시퀀스는&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{y_t} = b_y + \sum^N_{n=1} W_{h^n y h_t^n}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_t = \mathcal{Y}(\hat{y_t})&lt;/script&gt;

&lt;p&gt;$\mathcal{Y}$는 출력레이어 함수이다.&lt;/p&gt;

&lt;p&gt;입력시퀀스 $x$에 대해 예측분포와 시퀀스 손실함수는&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Pr(x) = \prod_{t=1}^T Pr(x_{t+1} \vert y_t)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}(x) = -\prod_{t=1}^T \log Pr(x_{t+1} \vert y_t)&lt;/script&gt;

&lt;p&gt;로 정의된다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LSTM&lt;/strong&gt;의 구조에 대해서는 &lt;a href=&quot;https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/&quot;&gt;다른 블로그&lt;/a&gt;들에 자세히 잘 설명되어 있으니 참고하자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;3-문자-예측text-prediction&quot;&gt;3. 문자 예측(Text Prediction)&lt;/h2&gt;

&lt;p&gt;텍스트 데이터는 이산값이고, 이런 것들은 보통 ‘one-hot’ 방식으로 인코딩된다. 텍스트의 경우 단어(word) 수준으로 인코딩을 수행하게 되고, 이는 벡터의 크기가 단어 사전의 크기(보통 적어도 10만 이상)가 되는 문제가 발생한다.&lt;/p&gt;

&lt;p&gt;최근에는 단어 수준 대신 문자 수준으로 예측을 수행하는 방법이 많이 고려되고 있다. 이 방법의 장점은&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;단어 수준 인코딩에 비해 성능이 별로 떨어지지 않으며&lt;/li&gt;
  &lt;li&gt;벡터의 크기가 작고&lt;/li&gt;
  &lt;li&gt;이전에 나타나지 안았던(unknown) 단어에 대한 대비가 필요 없어지며&lt;/li&gt;
  &lt;li&gt;새로운 단어를 만들 가능성도 생긴다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;따라서 이 논문에서는 문자 단위로 생성하는 모델을 고려할 것이다.&lt;/p&gt;

&lt;h3 id=&quot;31-penn-treebank-experiments&quot;&gt;3.1. Penn Treebank Experiments&lt;/h3&gt;

&lt;p&gt;이 데이터셋은 Wall Street Journal corpus의 일부로 네트워크의 예측능력보다는 시퀀스 생성능력에 초점을 두고 실험할 것이다.&lt;br /&gt;
Penn Treebank 데이터셋은 100만 단어 정도의 작은 데이터셋이지만 언어 모델링 벤치마크에서 널리 사용된다. 93만 단어의 training set, 7만 4천 단어의 validation set, 8만 2천 단어의 test set을 포함한다. 단어는 1만 종류이며 나머지는 전부 unknown 처리되어 있다.&lt;/p&gt;

&lt;p&gt;이 실험은 Penn corpus에 대해 단어 수준과 문자 수준의 LSTM 예측기의 성능을 비교하는 것이다. 두 경우 모두 1000개의 LSTM unit을 사용했고, 단어/문자 수준 벡터의 크기는 다르다(49 vs 10000, 가중치행렬의 크기는 4.3M vs 54M).&lt;/p&gt;

&lt;p&gt;SGD(Stochastic Gradient Descent), learning rate 0.0001, momentum 0.99, LSTM derivates는 [-1, 1] 범위로 clip된다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/02.png&quot; width=&quot;100%&quot; alt=&quot;Penn Benchmark&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 실험의 결과를 두 가지로 요약하면&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;단어 수준 모델이 문자 수준 모델보다 약간 더 성능이 좋다는 것과&lt;/li&gt;
  &lt;li&gt;LSTM은 Vanilla RNN보다 훨씬 빠르고 새 데이터에 최적화된다는 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;32-wikipedia-experiments&quot;&gt;3.2. Wikipedia Experiments&lt;/h3&gt;

&lt;p&gt;2006년 Marcus Hutter, Jim Bowery, Matt Mahoney로부터 시작된 영문 위키피디아의 첫 1억(100M) 바이트의 데이터인 Wikipedia data는 다양한 단어와 문자를 포함한다. 아랍어나 중국어 등 비 라틴 알파벳 뿐만 아니라 메타데이터를 지정하는 XML 태그 등 그 종류가 꽤 방대하다.&lt;br /&gt;
첫 96M 바이트는 training set, 나머지 4M 바이트는 validation으로 사용된다. 데이터는 205 one-byte 유니코드 기호를 사용한다.&lt;/p&gt;

&lt;p&gt;여기서는 더 큰 모델을 사용했다. 700 LSTM unit을 포함하는 7층짜리 네터워크로 가중치행렬의 크기는 21.3M이다. momentum이 0.9인 것을 제외하면 다른 조건은 같다.&lt;/p&gt;

&lt;p&gt;Wikipedia는 글의 주제와 같은 수천 단어 이상일 수 있는 넓은 범위(long-range) 의존성을 포함하기 때문에 LSTM의 내부 상태는 매번 100 sequence 만큼만을 리셋한다. 즉 gradient를 근사하는 것인데, 이는 넓은 범위 의존성을 최대한 잃지 않으면서 학습속도를 높이는 방법이다.&lt;br /&gt;
아래 결과를 보면 Dynamic evaluation을 사용했을 때 성능이 더 좋게 나온다. 이는 위키피디아의 넓은 범위 일관성 때문인 것으로 보인다(예: 특정 단어들은 특정 글에서 더 빈번히 등장하며, 평가 중에 이에 맞출 수 있는 것이 더 유리하다).&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/03.png&quot; width=&quot;70%&quot; alt=&quot;Wikipedia Benchmark&quot; /&gt;&lt;/center&gt;

&lt;p&gt;논문에는 실제 위키피디아 페이지와, 예측 네트워크가 생성한 위키피디아 페이지를 보여주고 있는데 그 중 일부를 가져왔다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/06.png&quot; width=&quot;100%&quot; alt=&quot;Wikipedia Benchmark&quot; /&gt;&lt;/center&gt;

&lt;p&gt;보면 은근히 괜찮은 품질의 글을 생성해냈음을 볼 수 있다. 특히 봐줄 만한 이름들(Lochroom River, Mughal Ralvaldens, swalloped) 등의 모델이 직접 생성해낸 이름들이 눈의 띈다.&lt;/p&gt;

&lt;p&gt;괄호나 따옴표를 여닫는 것은 언어 모델의 메모리에 명백히 이를 알려주는 지시자가 있는데, 이는 좁은 범위(short-range)의 문맥으로는 모델링될 수 없어서 중간 글자들만으로는 예측할 수 없기 때문이다. 위 샘플 결과는 괄호나 따옴표의 적절한 수를 지켰을 뿐만 아니라 nested XML tag 등도 잘 구현해 내었다.&lt;br /&gt;
네터워크는 비 라틴 문자들, 키릴 문자나 한자, 아랍 문자 등을 생성했고, 이는 영어보다 더 기본적인 모델을 배운 것으로 보인다. 이 경우에도 봐줄 만한 이름들을 생성했다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;4-손글씨-예측handwriting-prediction&quot;&gt;4. 손글씨 예측(Handwriting Prediction)&lt;/h2&gt;

&lt;p&gt;예측 네트워크가 실수값 시퀀스(real-valued sequences)도 충분히 잘 생성할 수 있는지 확인하기 위해 &lt;em&gt;online&lt;/em&gt; 손글씨 데이터에 이를 적용해 보았다(&lt;em&gt;online&lt;/em&gt; 필기 데이터란 그냥 필기 이미지만 있는 &lt;em&gt;offline&lt;/em&gt; 데이터와는 달리 펜으로 해당 필기를 할 때 어떤 궤적을 그렸는지에 대한 정보가 있는 것이다). IAM-OnDB 데이터셋을 사용하였다.&lt;br /&gt;
IAM-OnDB 데이터셋은 221명의 사람이 Lancaster-Oslo-Bergen 말뭉치를 쓴 필기 데이터이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/07.png&quot; width=&quot;100%&quot; alt=&quot;IAM-OnDB&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;41-혼합밀도-출력값mixture-density-outputs&quot;&gt;4.1 혼합밀도 출력값(Mixture Density Outputs)&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Mixture Density Outputs&lt;/em&gt;의 아이디어는 혼합분포(mixture distribution)을 parameterise하기 위해 신경망의 출력값을 사용하는 것이다. 출력값의 부분집합은 혼합가중치(mixture weights)를 정의하기 위해, 남은 출력값은 독립적인 mixture components를 parameterise하도록 사용된다. Misture weight 출력값은 정규화, softmax 등을 거쳐 의미 있는 범위 안에 포함되도록 한다. 이는 Boltzmann machine이나 다른 무방향 모델과는 달리 density가 정규화되고 직접 미불되며 편향되지 않는 샘플을 고른다는 점에서 대비된다.&lt;/p&gt;

&lt;p&gt;손글씨 실험을 위해, 기본적인 RNN 구조는 Section 2에서 변하지 않았다. 각 입력벡터 $x_t$는 이전 입력으로부터의 pen offset을 정의하는 실수쌍 $x_1, x_2$로 구성되며, 벡터가 stroke로 끝나면(다음 벡터가 기록되기 전에 펜이 보드에서 떨어지면) 1, 아니면 0의 값을 갖는 이진값 $x_3$로 구성된다.&lt;br /&gt;
이변수 혼합 가우시안(A mixture of bivariate Gaussians)이 $x_1, x_2$를 베르누이 분포가 $x_3$을 예측한다.&lt;/p&gt;

&lt;p&gt;각 출력벡터 $y_t$는 stroke로 끝날 확률 $e$, 평균 $\mu^j$, 표준편차 $\sigma^j$, 상관계수 $\rho^j$, $M$ mixture components에 대한 혼합가중치 $\pi^j$로 구성된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;x_t \in \mathbb{R} \times \mathbb{R} \times \{0, 1\}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y_t = \Big( e_t, \{ \pi_t^j, \mu_t^j, \sigma_t^j, \rho_t^j \}_{j=1}^M \Big)&lt;/script&gt;

&lt;p&gt;평균과 표준편차는 2차원 벡터이고 나머지는 스칼라이다. 벡터 $y_t$는 네트워크 출력값 $\hat{y}_t$로부터 얻어지며,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{y}_t = \Big( \hat{e}_t, \{ \hat{w}_t^j, \mu_t^j, \sigma_t^j, \rho_t^j \}_{j=1}^M \Big) = b_y + \sum_{n=1}^N W_{h^ny}h_t^n&lt;/script&gt;

&lt;p&gt;이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/08.png&quot; width=&quot;100%&quot; alt=&quot;Mixture Density&quot; /&gt;&lt;/center&gt;

&lt;p&gt;이 density map에서 두 종류의 예측을 볼 수 있다:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;글자를 따라 존재하는 작은 점들(지금 써지고 있는 stroke를 예측)&lt;/li&gt;
  &lt;li&gt;세 개의 큰 원(다음 stroke의 시작점이 되는, stroke의 끝을 예측)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;끝획(end-of-stroke)는 더 큰 분산을 갖는데 이는 화이트보드에서 펜이 떨어졌을 때 그 위치가 기록되지 않기 때문이며, 따라서 다음 stroke와의 거리가 커질 수 있다.&lt;/p&gt;

&lt;p&gt;아래쪽 열지도는 갈은 sequence에서 misture component weights를 보여준다.&lt;/p&gt;

&lt;h3 id=&quot;42-실험experiments&quot;&gt;4.2 실험(Experiments)&lt;/h3&gt;

&lt;p&gt;네트워크는 RMSProp을 사용하였으며 가중치 업데이트 식은 다음과 갈다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/09.png&quot; width=&quot;70%&quot; alt=&quot;Equations&quot; /&gt;&lt;/p&gt;

&lt;p&gt;손글씨 예측 결과는 다음과 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/10.png&quot; width=&quot;100%&quot; alt=&quot;Handwriting Results&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;5-손글씨-합성handwriting-synthesis&quot;&gt;5. 손글씨 합성(Handwriting Synthesis)&lt;/h2&gt;

&lt;p&gt;손글씨 합성은 sequence가 매우 다른 길이를 가질 수 있고 그 사이의 alignment는 데이터가 생성되기 전까지 알려지지 않는다는 점에서 어렵다. 이는 각 글자가 필체, 크기, 펜 속도 등에 따라 매우 달라지기 때문이다.&lt;/p&gt;

&lt;p&gt;연속적인 예측을 할 수 있는 한 신경망 모델은 RNN transducer이다. 그러나 이전 연구 결과들은 만족스럽지 못하다.&lt;/p&gt;

&lt;h3 id=&quot;51-합성-네트워크synthesis-network&quot;&gt;5.1. 합성 네트워크(Synthesis Network)&lt;/h3&gt;

&lt;p&gt;네트워크 구조는 다음과 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/11.png&quot; width=&quot;100%&quot; alt=&quot;Architecture&quot; /&gt;&lt;/center&gt;

&lt;p&gt;길이 $U$의 글자 sequence $c$가 주어지고 길이 $T$의 data sequence $x$가 주어졌을 때, 시간 $t(1\le t \le T)$에서 $c$로의 soft window $w_t$는 $K$ Gaussian 함수의 혼합에 의해 정의된다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\phi(t, u) = \sum_{k=1}^K \alpha_t^k \text{exp} \Big( - \beta_t^k (\kappa_t^k - u)^2 \Big)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_t = \sum_{u=1}^U \phi(t, u)c_u&lt;/script&gt;

&lt;p&gt;$\phi(t, u)$는 시간 $t$에서 $c_u$의 window weight이고, $\kappa_t$는 window의 위치를 제어하며, $\beta_t$는 window의 너비를, $\alpha_t$는 혼합 내에서 window의 중요도를 제어한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/12.png&quot; width=&quot;100%&quot; alt=&quot;Window&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;52-실험experiments&quot;&gt;5.2. 실험(Experiments)&lt;/h3&gt;

&lt;p&gt;실험은 이전 section과 동일한 입력 데이터를 사용한다. IAM-OnDB는 이제 글자 sequence $c$를 정의한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/13.png&quot; width=&quot;100%&quot; alt=&quot;Synthesis Results&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/14.png&quot; width=&quot;100%&quot; alt=&quot;Synthesis Results&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;5355-samplingunbiased-biased-prime-sampling&quot;&gt;5.3~5.5 Sampling(Unbiased, Biased, Prime Sampling)&lt;/h3&gt;

&lt;p&gt;Bias를 다르게 하는 등의 변형을 거쳐 손글씨를 합성한 결과를 몇 개 가져왔다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/15.png&quot; width=&quot;100%&quot; alt=&quot;Synthesis Results&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/16.png&quot; width=&quot;100%&quot; alt=&quot;Synthesis Results&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/17.png&quot; width=&quot;100%&quot; alt=&quot;Synthesis Results&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/18.png&quot; width=&quot;100%&quot; alt=&quot;Synthesis Results&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-15-Generating Sequences WIth Recurrent Neural Networks/19.png&quot; width=&quot;100%&quot; alt=&quot;Synthesis Results&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;refenrences&quot;&gt;Refenrences&lt;/h2&gt;

&lt;p&gt;논문 참조. 33개의 레퍼런스가 있다.&lt;/p&gt;

&lt;hr /&gt;

</content>
 </entry>
 
 <entry>
   <title>2019 ICML Papers</title>
   <link href="http://localhost:4000/2019-ICML-Papers/"/>
   <updated>2019-07-11T00:00:00+09:00</updated>
   <id>http://localhost:4000/2019-ICML-Papers</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 2019년 ICML(International Conference on Machine Learning)에서 어떤 논문들이 accept되어 발표되었는지를 알아볼 것이다. 3424개의 논문이 접수되어 774개의 논문만이 구두 및 포스터 발표로 진행되었다.&lt;/p&gt;

&lt;p&gt;논문 리스트는 목차와 같다. 774개를 다 살펴볼 수는 없으므로 몇 개만 추려서 최근 동향을 살펴보도록 하자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;training-neural-networks-with-local-error-signals&quot;&gt;Training Neural Networks with Local Error Signals&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;      개요      &lt;/th&gt;
      &lt;th&gt;내용&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;저자&lt;/td&gt;
      &lt;td&gt;&lt;em&gt;Francesco Locatello et al&lt;/em&gt;. Google Research&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;논문 링크&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1811.12359&quot;&gt;https://arxiv.org/abs/1811.12359&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;블로그&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://ai.googleblog.com/2019/04/evaluating-unsupervised-learning-of.html&quot;&gt;https://ai.googleblog.com/2019/04/evaluating-unsupervised-learning-of.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;제출일&lt;/td&gt;
      &lt;td&gt;Submitted on 29 Nov 2018 (v1), last revised 18 Jun 2019 (this version, v4)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;이 논문은 표현(representation)에 대한 것인데, 논문에 쓰인 표현들이 참 어렵다.&lt;/p&gt;

&lt;p&gt;초록을 대략 번역하자면,&lt;/p&gt;

&lt;p&gt;풀린 표현(&lt;em&gt;disentangled&lt;/em&gt; representation)의 무감독 학습(&lt;em&gt;unsupervised&lt;/em&gt; learning)의 핵심 아이디어는 ‘실제 세계의 데이터는 무감독 학습 알고리즘에 의해 복구될 수 있는 몇 가지 설명요인에 의해 생성된다’는 것이다.&lt;/p&gt;

&lt;p&gt;이 논문에서, 풀린 표현의 무감독 학습은 모델과 데이터 모두에 대해 귀납적 편향(inductive biases) 없이는 본질적으로 불가능하다는 것을 이론적으로 보일 것이다. 또한 6개의 최신 무감독 풀림 학습(unsupervised disentangled learning) 방법과 풀림 측정방식(disentangled measures)을 구현하여 이를 여러 데이터셋에 대해 12000개 이상의 모델을 학습시킬 것이다.&lt;/p&gt;

&lt;p&gt;이로써&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;여러 방법들이 ‘대응되는 loss에 의한’ 성질들을 강제함에도 불구하고 감독 없이는 잘 풀린(well-disentangled) 모델은 식별될 수 없다는 사실과(&lt;em&gt;역자 주: 모델이 식별될 수 없다는 것은 이를테면 두 가지 모델이 생성한 각각의 결과가 있을 때, 그 결과만 보고 원래 모델이 무엇이었을지를 알 수 없다는 뜻이다&lt;/em&gt;),&lt;/li&gt;
  &lt;li&gt;‘풀린 정도가 증가한(increased disentanglement)’ 것도 downstream task의 학습의 샘플 복잡도의 감소로 이어지지는 않는다는 것&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;을 알아내었다.&lt;/p&gt;

&lt;p&gt;이같은 결과는 앞으로 풀린 학습에 대한 연구는&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;명백히 귀납적 편향과 감독에 의해야 하며,&lt;/li&gt;
  &lt;li&gt;학습된 표현의 풀림을 강제하는 것의 구체적인 이점을 조사하며,&lt;/li&gt;
  &lt;li&gt;여러 데이터셋을 다룰 수 있는 재현 가능한 실험 설정을 고려해보아야 한다&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;는 것을 말해준다.&lt;/p&gt;

&lt;p&gt;실제 논문 서론에서 주장하는 contribution은,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;풀린 표현의 무감독 학습은 ‘학습방법과 데이터셋 모두에 대한 귀납적 편향’ 없이는 본질적으로 불가능함을 이론적으로 보인 것&lt;/li&gt;
  &lt;li&gt;현재의 여러 무감독 풀림 학습 방법들을 조사 및 구현하여 이를 여러 데이터셋과 모델을 학습시킨 것&lt;/li&gt;
  &lt;li&gt;풀린 표현을 학습하고 평가하는 &lt;em&gt;disentanglement_lib&lt;/em&gt;라는 새로운 라이브러리를 공개한 것&lt;/li&gt;
  &lt;li&gt;상당한 계산량을 필요로 하는 1만 개 이상의 사전 학습된(pre-trained) 모델을 공개한 것&lt;/li&gt;
  &lt;li&gt;무감독 풀림 학습에 대한 여러 생각들을 검증해보았다:
    &lt;ul&gt;
      &lt;li&gt;고려된 모든 방법들이 샘플링된 posterior들의 차원(dimensions)의 독립성을 보장한다고 해도, 표현의 차원을 상관관계가 있다.&lt;/li&gt;
      &lt;li&gt;random seed와 hyperparameter이라는 무감독 조건 하에서 고려된 모델들이 풀린 표현을 더 잘 학습한다는 증거가 없다.&lt;/li&gt;
      &lt;li&gt;(데이터셋을 통한 훌륭한(학습이 잘 되는) hyperparameter들을 주는 것을 허용한다 할지라도) ‘ground-truth 레이블에 접근할 수 없는’ 잘 학습된 모델은 식별될 수 없다.&lt;/li&gt;
      &lt;li&gt;고려된 모델과 데이터셋에 대해, 학습의 샘플 복잡도의 감소와 같은 downstream task에 풀림이 유용하지 않다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;실험 결과에 의해, 향후 연구에 대한 세 가지 중요한 부분을 제안하였다: 이는 초록 부분과 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;rates-of-convergence-for-sparse-variational-gaussian-process-regression&quot;&gt;Rates of Convergence for Sparse Variational Gaussian Process Regression&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;      개요      &lt;/th&gt;
      &lt;th&gt;내용&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;저자&lt;/td&gt;
      &lt;td&gt;&lt;em&gt;David R. Burt, et al&lt;/em&gt;. University of Cambridge and PROWLER. io&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;논문 링크&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1903.03571&quot;&gt;https://arxiv.org/abs/1903.03571&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;제출일&lt;/td&gt;
      &lt;td&gt;Submitted on 8 Mar 2019 (v1), last revised 3 Jul 2019 (this version, v2)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;초록&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Gaussian process posteriors에 대한 훌륭한 변분 근사법(variational approximations)은 데이터셋 크기 $N$에 대해 $O(N^3)$의 시간이 걸리는 것을 막기 위해 개발되었다. 이 방법은 시간복잡도를 $O(N^3)$에서 $O(NM^2), M \ll N $의 시간으로 줄여 주었다.&lt;br /&gt;
$M$은 이 preocess를 요약하는 유도변수(&lt;em&gt;inducing&lt;/em&gt; variables)인데, 수행시간은 $N$에 선형 비례함에도 불구하고 실제로는 근사의 품질을 결정하는 $M$이 얼마나 큰지에 실질적인 영향을 더 받는다.&lt;br /&gt;
이 논문에서, $N$에 비해 훨씬 느리게 증가하는 어떤 $M$에 대해 높은 확률로 KL divergence를 임의로 작게 만들 수 있음을 보인다. 특히 Square Exponential kernel을 쓰는 D차원의 정규분포 입력에 대한 회귀의 경우 $M = O(log^D N)$이면 충분하다.&lt;br /&gt;
이 논문의 결과는 데이터셋이 커질수록 Gaussian process posteriors는 적은 비용으로 근사될 수 있으며, 연속학습 시나리오(continual learning scenarios)에서 $M$을 증가시키는 구체적인 방법을 보이는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;서론&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gaussian processes(GPs)&lt;/strong&gt;는 베이지안 모델에서 convenient priors인 함수에 대한 분포이다. 이는 좋은 불확실성 측정을 해내기 때문에 특히 회귀 모델에서 자주 사용되며, 사후확률(posterior)과 주변확률(marginal likelihood)에 대한 닫힌 표현(closed-form expressions)를 가진다. 이것의 가장 큰 단점은 학습 데이터 수 $N$에 대해 $O(N^3)$의 계산량과 $O(N^2)$의 메모리를 쓴다는 것이다. Low-rank approximations(&lt;em&gt;Quiñonero Candela &amp;amp; Rasmussen&lt;/em&gt;, 2005)는 전체 사후확률을 요약하는 $M$개의 유도변수를 사용하여 계산량을 $O(NM^2 + M^3)$, 메모리 사용량을 $O(NM + M^2)$로 줄였다.&lt;/p&gt;

&lt;p&gt;유도변수를 추가함으로써 계산량이 줄어드는 것은 알려져 있지만, 얼마나($M$) 필요한지에 대한 정보는 별로 없다. 데이터셋이 커질수록 우리는 품질저하 없이 근사상수의 수용력이 얼마나 될지 기대할 수 없다. 단지 $N$이 커질수록 $M$이 커져야 한다는 것만 알 뿔이다.&lt;/p&gt;

&lt;p&gt;근사 GPs는 종종 근사사후확률에서 전체사후확률과정으로의 KL divergence를 최소화하는 변분추론(variational inference)을 써서 학습된다(&lt;em&gt;Titsias&lt;/em&gt;, 2009, &lt;em&gt;Matthews et al&lt;/em&gt;, 2016). 이 논문에서는 근사사후확률의 품질을 위한 측정방법으로 KL divergence를 사용한다.&lt;br /&gt;
직관적인 가정 하에 유도변수의 수는 선형보다 느리게 증가하는 정도면 된다(예: 로그함수). 이는 많은 편향(bias)의 필요 없이 정확도와 불확실성에 대한 정확도를 보유한 근사사후확률만으로 큰 데이터셋에 대해 아주 희박한 근사만 있어도 된다는 것을 보여준다.&lt;/p&gt;

&lt;p&gt;이 논문에서 나오는 증명의 핵심 아이디어는 데이터의 공분산행렬에 대한 Nyström 근사의 품질에 의존하는 KL divergence의 상한(상계)를 사용하는 것이다. 이 error는 무한차원의 필수연산자라는 개념으로 이해될 수 있다. Stationery kernel에 대해 메인 결과는 사전확률(priors)는 샘플함수보다 더 매끈하며(smoother) 더 집중되어 있는(more concentrated) 데이터셋은 더 희박한(sparse) 근사만으로도 충분하다는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;메인 결과&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;학습 입력은 고정된 독립항등분포로부터 나온 것이라는 가정 하에, 적어도 $1-\delta$의 확률로&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;KL(Q \Vert \hat{P}) \le \mathcal{O} \Bigg( \frac{g(M, N)}{\sigma^2_n \delta}\Big(1 + \frac{c\Vert y \Vert^2_2}{\sigma^2_n}\Big) + N \epsilon \Bigg)&lt;/script&gt;

&lt;p&gt;$\hat{P}$은 posterior Gaussian process, $Q$는 변분근사, $y$는 학습 목표(training targets)이다.&lt;br /&gt;
함수 $g(M, N)$은 kernel과 입력의 분포에 의존하며, $N$에 따라 선형적으로 증가하며 $M$에 따라 빠르게 감소한다.&lt;br /&gt;
$\epsilon$은 초기품질을 결정짓는 인자로서 약간의 계산을 추가하여 임의로 작게 만들 수 있다($N$의 역승).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;참고: Gaussian process regression&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;학습 데이터&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{D}= \{ x_i, y_i \}^N_{i=1}, x_i \in \chi, y_i \in  \mathbb{R}&lt;/script&gt;

&lt;p&gt;가 관측되었을 때 Gaussian process regression을 고려해본다. 이 때 목표는 학습데이터의 제한된 수로 인해 $f(\cdot)$에 대한 불확실성을 갖고 있을 때 새로운 입력 $x^\ast$에 대해 출력값 $y^\ast$를 예측하는 것이다. $f$에 대한 사전확률을 두는 베이지안 접근법과 약간의 noise를 가진 곽츤 데이터에 대한 $f$의 우도를 고려할 때, 모델은&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f \sim \mathcal{GP}(\nu(\cdot), k(\cdot, \cdot)), \ y_i = f(x_i) + \epsilon_i, \ \epsilon_i \sim \mathcal{N}(0, \sigma^2_n)&lt;/script&gt;

&lt;p&gt;$\nu : \chi \rightarrow \mathbb{R}$은 평균함수이고 $k : \chi \times \chi \rightarrow \mathbb{R}$은 공분산함수이다.  로그주변우도(log marginal likelihood)는 근사의 품질과 사후확률근사가 연관되어 있다는 점에서 흥미로우며, 이는&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L} = -\frac{1}{2} y^T K_n^{-1} y - \frac{1}{2} log \vert K_n \vert - \frac{N}{2} log(2\pi), \quad K_n = K_{ff} + \sigma^2_n I, \ [K_{ff}]_{i, j} = k(x_i, x_j)&lt;/script&gt;

&lt;p&gt;으로 표현된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;training-neural-networks-with-local-error-signals-1&quot;&gt;Training Neural Networks with Local Error Signals&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;      개요      &lt;/th&gt;
      &lt;th&gt;내용&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;저자&lt;/td&gt;
      &lt;td&gt;&lt;em&gt;Arild Nøkland, Lars Hiller Eidnes&lt;/em&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;논문 링크&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1901.06656&quot;&gt;https://arxiv.org/abs/1901.06656&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;소스코드&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/anokland/local-loss&quot;&gt;https://github.com/anokland/local-loss&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;제출일&lt;/td&gt;
      &lt;td&gt;Submitted on 20 Jan 2019 (v1), last revised 7 May 2019 (this version, v2)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;최근 분류(classification)를 위한 신경망의 감독학습(supervised learning)은 보통 global loss function을 사용하여 이루어졌다. 즉, 모델을 학습시키는 데 있어서 하나의 loss function만을 설정해 두고, prediction 단계에서 계산한 loss로 backward pass 동안 gradient를 계산하며 weights를 업데이트하는 역전파(back-propagation) 과정을 거쳐왔다.&lt;/p&gt;

&lt;p&gt;그러나 이 논문에서는 하나의 loss function을 모델의 모든 레이어에 걸쳐 global하게 사용하는 대신 각 레이어별로 loss function을 설정하여 실험하였고, 이 방법은 생물학적으로 그럴듯하고(biologically plausible) 그러면서도 여전히 state-of-the-art 결과를 얻을 수 있음을 보여주었다.&lt;/p&gt;

&lt;p&gt;Global loss function의 사용은 다음과 같은 문제를 갖는다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Backward locking problem:&lt;/strong&gt; hidden layer의 weights들은 forward &amp;amp; backward pass가 끝날 때까지 업데이트되지 않는다. 따라서 weights update의 병렬화가 어렵다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Preventing reuse of the memory:&lt;/strong&gt; hidden layer의 activation들을 backward pass가 끝날 때까지 메모리에 상주시켜야 하기 때문에 메모리 사용량이 늘어난다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Biologically implausible:&lt;/strong&gt; global loss의 역전파는 신경망이라는 관점에서 생물학적으로 별로 타당하지 않다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이 논문에서, backward locking problem은 지역적으로(각 레이어별로) 측정된 error에 의해 각각 학습시킴으로써 해결될 수 있음을 보인다. Local loss function은 global error에 의존하지 않고, gradient는 해당 레이어를 제외한 그 이전 레이어에 전파되지 않으며, hidden layer는 forward pass 중간에도 업데이트될 수 있다.&lt;br /&gt;
추론(inference) 단계에서 네트워크는 global 역전파를 쓰는 것과 같이 움직인다. 그러나 hidden layer가 업데이트될 때, gradient와 activation은 더 이상 메모리에 남아 있을 필요가 없다.&lt;br /&gt;
따라서 모든 레이어를 동시에 학습시킴에도, 지역적으로 측정된 error는 각 레이어를 학습시키며 이것을 메모리 사용량과 학습 시간을 줄여줄 수 있게 된다.&lt;/p&gt;

&lt;p&gt;관련 연구는 &lt;strong&gt;Local Loss Functions, Similarity Measures in Neuroscience/Machine Learning&lt;/strong&gt; 등이 있다(논문 참조).&lt;/p&gt;

&lt;p&gt;표준 &lt;strong&gt;convolutional &amp;amp; fully connected&lt;/strong&gt; 네트워크 구조를 사용하여, global loss 대신 각 레이어별로 (이전 레이어로 전파되지 않는) local learning signal을 설정했다. 이 signal은 2개의 single-layer sub-networks로 분리되어, 각각은 서로 다른 loss function을 갖는다. 하나는 표준 &lt;strong&gt;cross-entropy loss&lt;/strong&gt;이고, 다른 하나는 &lt;strong&gt;similarity matching loss&lt;/strong&gt;이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-07-11-2019-ICML-Papers/01.png&quot; width=&quot;100%&quot; alt=&quot;activation and gradient flow&quot; /&gt;&lt;/center&gt;

&lt;p&gt;논문에서는 여러 loss를 정의하는데,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;sim loss:&lt;/strong&gt; mini-batch의 example들 간 pair-wise 유사도를 담고 있는 두 행렬간 L2 거리를 측정하는 similarity matching loss이다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;pred loss:&lt;/strong&gt; target과 local classifier의 prediction 간 cosss-entropy loss를 측정한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;sim-bpf loss &amp;amp; pred-bpf loss:&lt;/strong&gt; Backprop free version을 만들기 위해, global target이 각 hidden layer로 전파되는 것을 막는다. &lt;strong&gt;sim loss&lt;/strong&gt;에서는 one-hot encoded target vector 대신 random transformation target vector를, &lt;strong&gt;pred loss&lt;/strong&gt;에서는 binarized random transformation target vector를 사용한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;predsim &amp;amp; predsim-bpf loss:&lt;/strong&gt; sim과 pred를 조합해서 전체 loss를 만들었다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{predsim} = (1-\beta)L_{pred} + \beta L_{sim}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{predsim-bpf} = (1-\beta)L_{pred-bpf} + \beta L_{sim-bpf}&lt;/script&gt;

&lt;p&gt;실험은 MNIST, Fashion-MNIST, Kuzushiji-MNIST, CIFAR-10, CIFAR-100, STL_10, SVHN에 대해서 각각 진행하였다.&lt;/p&gt;

&lt;p&gt;결과를 요약하자면 단지 local &lt;strong&gt;pred&lt;/strong&gt; loss만으로도 global 역전파를 사용한 것과 거의 같은 성능을 보였고, &lt;strong&gt;predsim&lt;/strong&gt;이나 &lt;strong&gt;predsim-bpf&lt;/strong&gt;를 사용한 경우 state-of-the-art 결과를 얻을 수 있었다고 한다.&lt;/p&gt;

&lt;p&gt;따라서 이 논문의 contribution은 loss function을 굳이 global하게 만들지 말고 각 레이어별로 local loss function을 만들어서 backward locking problem과 parallelization을 해결하는 것이 &lt;strong&gt;학습속도, 생물학적 타당성, 분류 성능&lt;/strong&gt;을 다 잡을 수 있다는 가능성을 보여준 것이 되겠다.&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>PyTorch 사용법 - 04. Recurrent Neural Network(RNN) Model</title>
   <link href="http://localhost:4000/pytorch-usage-04-RNN-Model/"/>
   <updated>2019-06-12T00:00:00+09:00</updated>
   <id>http://localhost:4000/pytorch-usage-04-RNN-Model</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-00-references/&quot;&gt;PyTorch 사용법 - 00. References&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-01-introduction/&quot;&gt;PyTorch 사용법 - 01. 소개 및 설치&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-02-Linear-Regression-Model/&quot;&gt;PyTorch 사용법 - 02. Linear Regression Model&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/&quot;&gt;PyTorch 사용법 - 03. How to Use PyTorch&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2019/06/12/pytorch-usage-04-RNN-Model/&quot;&gt;PyTorch 사용법 - 04. Recurrent Neural Network Model&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이 글에서는 RNN(Recurrent Neural Network) 기본 모델의 Pytorch 프로젝트를 살펴본다.&lt;/p&gt;

&lt;p&gt;사용되는 torch 함수들의 사용법은 &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-00-references/&quot;&gt;여기&lt;/a&gt;에서 확인할 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;프로젝트-구조&quot;&gt;프로젝트 구조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;02_Linear_Regression_Model/
    &lt;ul&gt;
      &lt;li&gt;main.py&lt;/li&gt;
      &lt;li&gt;data/
        &lt;ul&gt;
          &lt;li&gt;02_Linear_Regression_Model_Data.csv&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;results/&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;일반적으로 데이터는 &lt;code class=&quot;highlighter-rouge&quot;&gt;data/&lt;/code&gt; 디렉토리에 넣는다.&lt;/li&gt;
  &lt;li&gt;코드는 git에 두고, &lt;code class=&quot;highlighter-rouge&quot;&gt;data/&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일에 추가하여 데이터는 git에 올리지 않는다. 파일은 다른 서버에 두고 필요할 때 다운로드한다. 일반적으로 dataset은 그 크기가 수 GB 혹은 그 이상도 될 수 있기 때문에 upload/download 시간이 굉장히 길어지기도 하고, &lt;a href=&quot;https://github.com/&quot;&gt;Git&lt;/a&gt;이 100MB 이상의 큰 파일은 업로드를 지원하지 않기 때문이기도 하다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;물론 이 예제 프로젝트는 너무 간단하여 그냥 &lt;code class=&quot;highlighter-rouge&quot;&gt;data/&lt;/code&gt; 디렉토리 없이 해도 상관없다.&lt;br /&gt;
그리고 &lt;code class=&quot;highlighter-rouge&quot;&gt;output/&lt;/code&gt; 또는 &lt;code class=&quot;highlighter-rouge&quot;&gt;results/&lt;/code&gt; 디렉토리를 만들도록 한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;import&quot;&gt;Import&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음 파일을 다운로드하여 &lt;code class=&quot;highlighter-rouge&quot;&gt;data/&lt;/code&gt; 디렉토리에 넣는다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/greeksharifa/Tutorial.code/blob/master/Python/PyTorch_Usage/02_Linear_Regression_Model/data/02_Linear_Regression_Model_Data.csv&quot;&gt;02_Linear_Regression_Model_Data.csv&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://pytorch.org/&quot;&gt;torch&lt;/a&gt;: 설명이 필요없다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/nn.html&quot;&gt;from torch import nn&lt;/a&gt;: nn은 Neural Network의 약자이다. torch의 nn 라이브러리는 Neural Network의 모든 것을 포괄하며, Deep-Learning의 가장 기본이 되는 1-Layer Linear Model도 &lt;code class=&quot;highlighter-rouge&quot;&gt;nn.Linear&lt;/code&gt; 클래스를 사용한다. 이 예제에서도 &lt;strong&gt;nn.Linear&lt;/strong&gt;를 쓴다.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;nn.Module&lt;/strong&gt;은 모든 Neural Network Model의 Base Class이다. 모든 Neural Network Model(흔히 Net이라고 쓴다)은 &lt;strong&gt;nn.Module&lt;/strong&gt;의 subclass이다. nn.Module을 상속한 어떤 subclass가 Neural Network Model로 사용되려면 다음 두 메서드를 override해야 한다.
        &lt;ul&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;__init__(self)&lt;/code&gt;: &lt;strong&gt;&lt;em&gt;Initialize.&lt;/em&gt;&lt;/strong&gt; 여러분이 사용하고 싶은, Model에 사용될 구성 요소들을 정의 및 초기화한다. 대개 다음과 같이 사용된다.
            &lt;ul&gt;
              &lt;li&gt;self.conv1 = nn.Conv2d(1, 20, 5)&lt;/li&gt;
              &lt;li&gt;self.conv2 = nn.Conv2d(20, 20, 5)&lt;/li&gt;
              &lt;li&gt;self.linear1 = nn.Linear(1, 20, bias=True)&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;forward(self, x)&lt;/code&gt;: &lt;strong&gt;&lt;em&gt;Specify the connections.&lt;/em&gt;&lt;/strong&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;__init__&lt;/code&gt;에서 정의된 요소들을 잘 연결하여 모델을 구성한다. Nested Tree Structure가 될 수도 있다. 주로 다음처럼 사용된다.
            &lt;ul&gt;
              &lt;li&gt;x = F.relu(self.conv1(x))&lt;/li&gt;
              &lt;li&gt;return F.relu(self.conv2(x))&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;다른 말로는 위의 두 메서드를 override하기만 하면 손쉽게 Custom net을 구현할 수 있다는 뜻이기도 하다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;참고: &lt;strong&gt;torch.autograd.Variable&lt;/strong&gt;은 이전에는 auto gradient 계산을 위해 tensor에 필수적으로 씌워 주어야 했으나, PyTorch 0.4.0 버전 이후로 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.Tensor&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.autograd.Variable&lt;/code&gt; 클래스가 통합되었다. 따라서 PyTorch 구버전을 사용할 예정이 아니라면 Variable은 쓸 필요가 전혀 없다.
    &lt;ul&gt;
      &lt;li&gt;인터넷에 돌아다니는 수많은 코드의 Variable Class는 0.4.0 버전 이전에 PyTorch를 시작한 사람들이 쓴 것이다.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/autograd.html#variable-deprecated/&quot;&gt;https://pytorch.org/docs/stable/autograd.html#variable-deprecated/&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://pytorch.org/blog/pytorch-0_4_0-migration-guide/&quot;&gt;https://pytorch.org/blog/pytorch-0_4_0-migration-guide/&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;load-data&quot;&gt;Load Data&lt;/h2&gt;

&lt;h3 id=&quot;데이터-준비&quot;&gt;데이터 준비&lt;/h3&gt;

&lt;p&gt;지금의 경우는 전처리할 필요가 없으므로 그냥 데이터를 불러오기만 하면 된다. 데이터가 어떻게 생겼는지도 확인해 보자.&lt;br /&gt;
데이터가 어떤지 살펴보는 것은 모델을 결정하는 데 있어 매우 중요하다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/02_Linear_Regression_Model_Data.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Avoid copy data, just refer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'y'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'02_Linear_Regression_Model_Data'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/PyTorch/2018-11-02-pytorch-usage-02-Linear-Regression-Model/02_Linear_Regression_Model_Data.png&quot; alt=&quot;02_Linear_Regression_Model_Data&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;from_numpy&lt;/strong&gt;로 불러오는 이유는 데이터를 복사하여 새로 텐서를 생성하는 대신 원 데이터와 메모리를 공유하는 텐서를 쓰기 위함이다. 지금은 상관없지만 대용량의 데이터를 다룰 때에는 어떤 함수가 데이터를 복사하는지 아닌지를 확실하게 알아둘 필요가 있다.&lt;br /&gt;
물론, 정말 대용량의 데이터의 경우는 read_csv로 한번에 불러오지 못한다. 이는 데이터를 &lt;em&gt;batch&lt;/em&gt;로 조금씩 가져오는 것으로 해결하는데, 이에 대해서는 나중에 살펴보자.&lt;/p&gt;

&lt;p&gt;참고: 이 데이터는 다음 코드를 통해 생성되었다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/02_Linear_Regression_Model_Data.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'y'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;define-and-load-model&quot;&gt;Define and Load Model&lt;/h2&gt;

&lt;p&gt;매우 간단한 모델이므로 코드도 짧다.&lt;br /&gt;
여기서는 여러분의 편의를 위해 함수들의 parameter 이름을 명시하도록 한다.&lt;/p&gt;

&lt;p&gt;PyTorch에서 Linear 모델은 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.nn.Linear&lt;/code&gt; 클래스를 사용한다. 여기서는 단지 x를 y로 mapping하는 일차원 직선($ y = wx + b $)을 찾고 싶은 것이므로, &lt;code class=&quot;highlighter-rouge&quot;&gt;in_features&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;out_features&lt;/code&gt;는 모두 1이다.&lt;br /&gt;
&lt;strong&gt;nn.Linear&lt;/strong&gt;은 &lt;strong&gt;nn.Module&lt;/strong&gt;의 subclass로 in_features개의 input을 선형변환을 거쳐 out_features개의 output으로 변환한다. parameter 개수는 $ (in_features \times out_features [ + out_features]) $ 개이다. 마지막 항은 &lt;strong&gt;bias&lt;/strong&gt;이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
Linear(in_features=1, out_features=1, bias=True)
Parameter containing:
tensor([[-0.9360]], requires_grad=True)
Parameter containing:
tensor([0.7960], requires_grad=True)
&quot;&quot;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;별다른 utility 함수가 필요 없으므로 따로 &lt;code class=&quot;highlighter-rouge&quot;&gt;utils.py&lt;/code&gt;는 만들지 않는다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;set-loss-functioncreterion-and-optimizer&quot;&gt;Set Loss function(creterion) and Optimizer&lt;/h2&gt;

&lt;p&gt;적절한 모델을 선정할 때와 마찬가지로 loss function과 optimizer를 결정하는 것은 학습 속도와 성능을 결정짓는 중요한 부분이다.&lt;br /&gt;
지금과 같이 간단한 Linear Regression Model에서는 어느 것을 사용해도 학습이 잘 된다. 하지만, 일반적으로 성능이 좋은 &lt;code class=&quot;highlighter-rouge&quot;&gt;AdamOptimizer&lt;/code&gt;를 사용하도록 하겠다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MSELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
tensor([[-0.1399],
        [-1.0759],
        [-2.0119],
        [-2.9478],
        [-3.8838],
        [-4.8197],
        [-5.7557],
        [-6.6917],
        [-7.6276],
        [-8.5636]], grad_fn=&amp;lt;ThAddmmBackward&amp;gt;)
&quot;&quot;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고: 보통 변수명은 criterion 혹은 loss_function 등을 이용한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;train-model&quot;&gt;Train Model&lt;/h2&gt;

&lt;p&gt;Train은 다음과 같이 이루어진다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;모델에 데이터를 통과시켜 예측값(현재 모델의 weights로 prediction)을 얻은 뒤&lt;/li&gt;
  &lt;li&gt;실제 정답과 loss를 비교하고&lt;/li&gt;
  &lt;li&gt;gradient를 계산한다.&lt;/li&gt;
  &lt;li&gt;이 값을 통해 weights를 업데이트한다(backpropagation).&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        Show your intermediate results
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;코드의 각 라인을 설명하면 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;prediction&lt;/code&gt;: 모델에 데이터(x)를 집어넣었을 때 예측값(y). 여기서는 $ y = wx + b $의 결과들이다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;loss&lt;/code&gt;: criterion이 MSELoss로 설정되어 있으므로, prediction과 y의 평균제곱오차를 계산한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;optimizer.zero_grad()&lt;/code&gt;: optimizer의 grad를 0으로 설정한다. PyTorch는 parameter들의 gradient를 계산해줄 때 grad는 계속 누적되도록 되어 있다. 따라서 gradient를 다시 계산할 때에는 0으로 세팅해주어야 한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;loss.backward()&lt;/code&gt;: gradient 계산을 역전파(backpropagation)한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;optimizer.step()&lt;/code&gt;: 계산한 gradient를 토대로 parameter를 업데이트한다($ w \leftarrow w - \alpha \Delta w, b \leftarrow b - \alpha \Delta b $)&lt;/li&gt;
  &lt;li&gt;학습 결과를 중도에 확인하고 싶으면 그래프를 중간에 계속 그려주는 것도 한 방법이다.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;visualize-and-save-results&quot;&gt;Visualize and save results&lt;/h2&gt;

&lt;p&gt;결과를 그래프로 보여주는 부분은 &lt;code class=&quot;highlighter-rouge&quot;&gt;matplotlib.pyplot&lt;/code&gt;에 대한 내용이므로 여기서는 넘어가도록 하겠다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;display_results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'b--'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'loss={:.4}, w={:.4}, b={:.4}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# plt.savefig('results/02_Linear_Regression_Model_trained.png')
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;display_results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/PyTorch/2018-11-02-pytorch-usage-02-Linear-Regression-Model/02_Linear_Regression_Model_trained.png&quot; alt=&quot;02_Linear_Regression_Model_Trained&quot; /&gt;&lt;/p&gt;

&lt;p&gt;모델을 저장하려면 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.save&lt;/code&gt; 함수를 이용한다. 저장할 모델은 대개 &lt;code class=&quot;highlighter-rouge&quot;&gt;.pt&lt;/code&gt; 확장자를 사용한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obj&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'02_Linear_Regression_Model.pt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고: &lt;code class=&quot;highlighter-rouge&quot;&gt;.pt&lt;/code&gt; 파일로 저장한 PyTorch 모델을 load해서 사용하려면 다음과 같이 한다. 이는 나중에 &lt;strong&gt;Transfer Learning&lt;/strong&gt;과 함께 자세히 다루도록 하겠다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;loaded_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'02_Linear_Regression_Model.pt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;display_results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loaded_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;정확히 같은 결과를 볼 수 있을 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;전체 코드는 &lt;a href=&quot;https://github.com/greeksharifa/Tutorial.code/blob/master/Python/PyTorch_Usage/02_Linear_Regression_Model/main.py&quot;&gt;여기&lt;/a&gt;에서 살펴볼 수 있다.&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>Deep Learning Tutorial(딥러닝 튜토리얼) 01. 소개</title>
   <link href="http://localhost:4000/Deep-Learning-01/"/>
   <updated>2019-06-10T00:00:00+09:00</updated>
   <id>http://localhost:4000/Deep-Learning-01</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://greeksharifa.github.io/&quot;&gt;Deep Learning Tutorial(딥러닝 튜토리얼) 01. 소개&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이 글에서는 Deep Learning(딥러닝)을 소개하고 그 기초를 다룬다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;deep-learning딥러닝이란&quot;&gt;Deep Learning(딥러닝)이란?&lt;/h2&gt;

&lt;h3 id=&quot;직관적인-이해&quot;&gt;직관적인 이해&lt;/h3&gt;

&lt;p&gt;여러분은 A 회사의 주식 가격을 예측하고자 한다. 그러기 위해서 A 회사에 대한 정보를 수집하였다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A의 설립일자&lt;/li&gt;
  &lt;li&gt;A의 재작년 수익&lt;/li&gt;
  &lt;li&gt;A의 작년 수익&lt;/li&gt;
  &lt;li&gt;A의 대표의 나이&lt;/li&gt;
  &lt;li&gt;A의 본사가 위치한 국가의 소득수준&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그리고 여러분은 수학에서 $x$를 입력하면 $y$가 나오는 함수처럼, 이 정보들을 가지고 주식 가격을 추정해보려고 한다. 위 5개의 요인 중 어떤 것이 중요할 지는 모르지만 대충 다음과 같이 그래프를 그렸다고 하자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-06-10-Deep-Learning-01/01.png&quot; width=&quot;100%&quot; alt=&quot;A의 주가를 예측하라!&quot; /&gt;&lt;/center&gt;

&lt;p&gt;(저 그래프가 정말 맞는지는 우선 논외로 한다. 이걸 잘 설계하는 것이 딥러닝에서는 &lt;strong&gt;매우&lt;/strong&gt; 중요하다)&lt;/p&gt;

&lt;p&gt;모든 딥러닝이 이렇게 흘러가지는 않지만, 딥러닝은 대충 이런 것이다. 약간 더 자세히 설명하면,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;입력($\mathbf{X} = $ &lt;em&gt;{A의 설립일자, A의 재작년 수익, A의 작년 수익, A의 대표의 나이, A의 본사가 위치한 국가의 소득수준}&lt;/em&gt; )을 받아서&lt;/li&gt;
  &lt;li&gt;학습을 시켜놓은 &lt;strong&gt;네트워크(심층신경망, DNN, Deep Neural Network)&lt;/strong&gt; 에 집어넣으면&lt;/li&gt;
  &lt;li&gt;출력($\mathbf{\hat{Y}} = $ &lt;em&gt;{A의 주식 가격}&lt;/em&gt;)을 내놓는&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이런 네트워크를 설계하고, 학습시키고, 테스트하는 그런 과정을 포함한다.&lt;/p&gt;

&lt;h3 id=&quot;그래서-deep-learning이-뭔데&quot;&gt;그래서 Deep Learning이 뭔데?&lt;/h3&gt;

&lt;p&gt;간단히 얘기하자면 Deep Neural Network(심층신경망)을 설계하고 학습시켜 다음 출력을 생성하는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/%EB%94%A5_%EB%9F%AC%EB%8B%9D#cite_ref-1&quot;&gt;국문 위키피디아&lt;/a&gt;를 인용해보자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;딥 러닝(영어: deep learning), 심층학습(深層學習)은 여러 비선형 변환기법의 조합을 통해 높은 수준의 추상화(abstractions, 다량의 데이터나 복잡한 자료들 속에서 핵심적인 내용 또는 기능을 요약하는 작업)를 시도하는 기계학습(machine learning) 알고리즘의 집합[1] 으로 정의되며, 큰 틀에서 사람의 사고방식을 컴퓨터에게 가르치는 기계학습의 한 분야&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Deep_learning&quot;&gt;영문 위키피디아&lt;/a&gt;도 인용해보자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Deep learning (also known as deep structured learning or hierarchical learning) is part of a broader family of machine learning methods based on artificial neural networks. Learning can be supervised, semi-supervised or unsupervised.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;해석하면,&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;딥러닝(심층구조학습 또는 구조적학습)은 인공신경망에 근거한 넓은 범위의 기계학습방법의 한 부분이다. 학습 방식에는 지도(감독)을 받거나, 지도을 일부만 받거나, 받지 않는 방법이 있다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;기계학습(Machine Learning)&lt;/strong&gt;은 컴퓨터가 스스로 학습하여 예측모형을 개발하는 인공지능의 한 분야이다.&lt;/p&gt;

&lt;p&gt;하나의 용어를 설명하려면 더 많은 용어들을 설명해야 한다. 바로 지도학습으로 넘어가자.&lt;/p&gt;

&lt;h4 id=&quot;지도학습supervised-learning은-또-무엇인가&quot;&gt;지도학습(Supervised Learning)은 또 무엇인가?&lt;/h4&gt;

&lt;p&gt;다른 이름으로는 감독학습, 교사학습으로도 불린다.&lt;/p&gt;

&lt;p&gt;이번엔 A의 주가 말고 그냥 아라비아 숫자를 생각해보자. 여러분은 다음과 같은 과제를 받았다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;손으로 쓴 숫자 이미지가 주어지면, 해당 이미지에는 0~9 중 어떤 숫자가 쓰여 있는지 판별하라.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-06-10-Deep-Learning-01/02.png&quot; width=&quot;100%&quot; alt=&quot;각 숫자 이미지에는 레이블이 있다.&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위의 각 숫자 이미지에는 &lt;strong&gt;Label&lt;/strong&gt;이 달려 있는 것을 확인할 수 있다. 지도학습은 이와 같이 각 데이터에 레이블이 있는 상태에서 학습을 시작하는 방법이다. 즉 모든 데이터($X$, 여기서는 숫자 이미지)에 레이블($Y$, 여기서는 0 ~ 9 중 하나의 숫자)이 주어져 있는 경우이다.&lt;/p&gt;

&lt;h4 id=&quot;그럼-비지도-학습unsupervised-learning은&quot;&gt;그럼 비지도 학습(Unsupervised Learning)은?&lt;/h4&gt;

&lt;p&gt;무감독 학습, 비교사 학습이라고도 한다.&lt;/p&gt;

&lt;p&gt;간단하다. 위의 데이터에서 이미지만 주어지고 레이블은 주어지지 않는 경우이다. 이런 경우에는 보통 clustering(군집화) 등 비슷한 이미지끼리 그룹화하는 등의 task를 수행하게 된다. 위의 숫자 이미지라면 0은 0끼리, 1은 1끼리 그롭화하는 것을 생각할 수 있겠다.&lt;br /&gt;
물론 이것말고 비지도 학습의 종류는 많다.&lt;/p&gt;

&lt;h4 id=&quot;그럼-준지도-학습semi-supervised-learning이란&quot;&gt;그럼 준지도 학습(Semi-supervised Learning)이란?&lt;/h4&gt;

&lt;p&gt;일부의 데이터에만 레이블 $Y$가 주어져 있는 경우이다.&lt;/p&gt;

&lt;h4 id=&quot;왜-비지도-학습같이-어려운-것을-하는가&quot;&gt;왜 비지도 학습같이 어려운 것을 하는가?&lt;/h4&gt;

&lt;p&gt;네트워크의 학습 관점에서, 정답(레이블)이 주어져 있는 경우가 대개 학습이 훨씬 쉽다. 보통 쉬운 순서대로 지도학습, 준지도학습, 비지도학습 순이다.&lt;br /&gt;
그런데 왜 비지도 학습 같은 것을 하는가?&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-06-10-Deep-Learning-01/03.png&quot; width=&quot;80%&quot; alt=&quot;각 숫자 이미지에는 레이블이 없다.&quot; /&gt;&lt;/center&gt;

&lt;p&gt;현실에서 데이터는 엄청나게 많지만 그것에 레이블을 다는 작업은 보통 수동으로 한다(…). 그래서 레이블이 없는 경우가 거의 대부분이며, 많은 연구자들이 기를 쓰고 semi-supervised learning이라도 할 수 있도록 소수의 데이터에라도 레이블을 추가하거나 아니면 아예 컴퓨터가 알아서 레이블링을 하도록 학습을 시키는 이유이기도 하다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;deep-learning의-역사&quot;&gt;Deep Learning의 역사&lt;/h2&gt;

&lt;h3 id=&quot;perceptron퍼셉트론&quot;&gt;Perceptron(퍼셉트론)&lt;/h3&gt;

&lt;p&gt;딥러닝의 근간인 인공신경망(ANN, Artificial Neural Network)의 시초는 &lt;a href=&quot;https://psycnet.apa.org/record/1959-09865-001&quot;&gt;F. Rosenblatt 가 1958년 발표&lt;/a&gt;한 퍼셉트론(perceptron)이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-06-10-Deep-Learning-01/04.png&quot; width=&quot;80%&quot; alt=&quot;Perceptron&quot; /&gt;&lt;/center&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{y} = g(\sum_{i=1}^n{w_i x_i + b})&lt;/script&gt;

&lt;p&gt;웬만한 식에서 $\ \hat{}$ 이 붙은 것($\hat{y}$ 등)은 네트워크 또는 모델이 내놓은 예측치를 의미한다. 이와 대비되는 것으로 실제 정답($y$)이 있다.&lt;/p&gt;

&lt;p&gt;수학 시간에서 봤을 함수 $y = ax + b$와 비슷한 상태이다. 다른 점이 있다면&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$x$가 하나가 아닌 여러 개($x_1, x_2, …, x_n$)이며&lt;/li&gt;
  &lt;li&gt;가중치는 $a$가 아닌 $w_1, w_2, …, w_n$)으로 표시되고&lt;/li&gt;
  &lt;li&gt;Activation function($g$)가 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Activation function에 대해서는 나중에 설명하도록 한다.&lt;/p&gt;

&lt;p&gt;즉 $n$개의 입력값들의 선형 결합에 어떤 특정 함수를 적용하여 $y$라는 값을 예측하겠다는 것인데, 이 모형은 XOR같이 간단한 것조차 구분하지 못했기 때문에 거의 30년간 인공신경망 연구는 묻히게 된다.&lt;/p&gt;

&lt;p&gt;Perceptron은 선형 결합(Linear combination)으로 계산되기 때문에, $x$의 개수가 많아져 다차원의 공간에서 Perceptron이 어느 값 이상이냐 미만이냐로 나누는 것은 곧 다차원의 공간에서 hyperplane으로 나눈다는 것을 의미한다. XOR을 표현하기 위한 2차원 공간($x_1, x_2$만 사용)에서는 hyperplane이 직선으로 나타나기 때문에 우리가 보기가 쉬워진다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-06-10-Deep-Learning-01/05.png&quot; width=&quot;100%&quot; alt=&quot;XOR&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-06-10-Deep-Learning-01/06.png&quot; width=&quot;100%&quot; alt=&quot;XOR&quot; /&gt;&lt;/center&gt;

&lt;blockquote&gt;
  &lt;p&gt;출처: http://www.cs.stir.ac.uk/courses/ITNP4B/lectures/kms/2-Perceptrons.pdf&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;위 그림과 같이 XOR은 한 직선으로 구분해내는 것이 불가능하다.&lt;/p&gt;

&lt;h3 id=&quot;mlpmulti-layer-perceptron-다층-퍼셉트론&quot;&gt;MLP(Multi-Layer Perceptron, 다층 퍼셉트론)&lt;/h3&gt;

&lt;p&gt;위에서 설명한 것은 Sinle-Layer Perceptron이다. 즉, 퍼셉트론이 한 층으로만 되어 있다는 것인데, 이를 여러 층으로 쌓으면 위에서 본 XOR을 퍼셉트론이로 구분해내는 것이 가능해진다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-06-10-Deep-Learning-01/08.png&quot; width=&quot;100%&quot; alt=&quot;Multi-Layer Perceptron&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-06-10-Deep-Learning-01/07.png&quot; width=&quot;100%&quot; alt=&quot;Multi-Layer Perceptron&quot; /&gt;&lt;/center&gt;

&lt;blockquote&gt;
  &lt;p&gt;출처: https://gomguard.tistory.com/178&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;자세한 것은 &lt;a href=&quot;https://gomguard.tistory.com/178&quot;&gt;여기&lt;/a&gt;를 참조하면 될 것 같다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/&quot;&gt;다음 글&lt;/a&gt;에서는 더 살펴보도록 한다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>MovieQA(Movie Question Answering)</title>
   <link href="http://localhost:4000/Movie-Question-Answering/"/>
   <updated>2019-05-29T00:00:00+09:00</updated>
   <id>http://localhost:4000/Movie-Question-Answering</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 MovieQA: Understanding Stories in Movies through Question-Answering에 대해 알아보고자 한다.&lt;/p&gt;

&lt;p&gt;VQA task는 이미지(Visual, 영상으로도 확장 가능)와 그 이미지에 대한 질문(Question)이 주어졌을 때, 해당 질문에 맞는 올바른 답변(Answer)을 만들어내는 task이다.&lt;/p&gt;

&lt;p&gt;MovieQA는 Vision QA의 확장판과 비슷한 것이라고 보면 된다. 그러나 크게 다른 점은 사진 한 장과 QA셋이 아닌 Movie Clip과 QA셋으로 학습 및 테스트를 진행한다는 것이다. 사진이 영상으로 바뀐 만큼 당연히 난이도 역시 증가하였다.&lt;/p&gt;

&lt;p&gt;MovieQA 홈페이지는 http://movieqa.cs.toronto.edu/home/ 이다.&lt;/p&gt;

&lt;p&gt;중요한 부분만 적을 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;movieqa-understanding-stories-in-movies-through-question-answering&quot;&gt;MovieQA: Understanding Stories in Movies through Question-Answering&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.02902&quot;&gt;MovieQA: Understanding Stories in Movies through Question-Answering&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;초록abstract&quot;&gt;초록(Abstract)&lt;/h2&gt;

&lt;p&gt;우리는 video와 text 모두를 통해 자동적 스토리 이해를 평하가는 MovieQA 데이터셋을 소개할 것이다. 이 데이터셋은 408개의 영화(movie)에 대한 아주 다양한 의미의 14,944개의 질문으로 이루어져 있다. 이 질문들은 ‘누가’ ‘누구에게’ ‘무엇을’ ‘어떻게’ ‘왜’ 했는지까지의 범위를 포함한다. 각 질문에는 5개의 답이 있는데 1개만 맞는 답이며 4개는 사람이 직접 만든 가짜 답이다. 우리의 데이터셋은 영상클립, 줄거리, 제목, 자막, DVS 등 많은 소스들을 포함한다는 점에서 유일하다. 우리는 이 데이터셋을 다양한 통계적 방법으로 분석했으며 존재하는 QA 기술들을 확장하여 열린 의미의 QA로 하는 것은 어렵다는 것을 보일 것이다. 우리는 이 데이터셋을 평가방법과 함께 일반에 공개하여 도전을 장려할 것이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-05-29-Movie-Question-Answering/01.png&quot; width=&quot;100%&quot; alt=&quot;ovieQA Dataset&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;서론introduction&quot;&gt;서론(Introduction)&lt;/h2&gt;

&lt;p&gt;이미지 태깅, 물체인식 및 분할, 액션 인식, 이미지/비디오 캡셔닝 등 많은 시각적 task에서 레이블링된 많은 양의 데이터가 사용 가능해진 것과 함께 딥러닝에서 빠른 발전이 있었다. 우리는 시각장애가 있는 사람들을 위한 보조적인 해결책이나, 일반적인 framework에서 이런 모든 task들을 추론에 의해 실제 세계를 전체적으로 인식하는 인지로봇과 같은 application에 한 걸음 더 다가갔다. 그러나 정말 ‘지능적인’ 기계는 동기, 의도, 감정, 의사소통 등 높은 수준의 것을 포함한다. 이러한 주제들은 문학에서나 겨우 탐험이 시작되었다.&lt;/p&gt;

&lt;p&gt;(눈에 보이는) 장면을 이해하는 것을 보여주는 훌륭한 방법은 그것에 대한 질문-답변을 하는 것이다. 이러한 생각은 각 이미지에 대해 여러 질문들과 다지선다형 답변을 포함한 질문-답변 데이터셋을 만드는 것으로 이어졌다.&lt;br /&gt;
이러한 데이터셋은 RGB-D 이미지 또는 Microsoft COCO와 같은 정지 이미지의 거대한 모음집에 기반한다. 전형적인 질문으로는 ‘무엇이(what)’ 거기에 있고 ‘어디에(where)’ 그것이 있는지와 같은 것, 물체가 어떤 성질을 갖는지, 얼마나 많은 ‘특정 종류의 물건’이 있는지 등이 있다.&lt;br /&gt;
이러한 질문들은 전체적인 자연에 대한 우리의 시각적 알고리즘을 확인시켜주기는 하지만, 정지 이미지에 대해 물어볼 수 있는 태생적인 한계가 존재한다. 행동과 그 의도에 대한 높은 수준의 의미 이해는 오직 순간적, 또는 일생에 걸친 시각적 관찰에 의한 추론에 의해서만 가능하다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-05-29-Movie-Question-Answering/02.png&quot; width=&quot;100%&quot; alt=&quot;MovieQA Dataset&quot; /&gt;&lt;/center&gt;

&lt;p&gt;영화(Movies)는 사람들의 삶과 이야기, 성격에 대한 높은 수준의 이해, 행동과 그 이면에 숨겨진 동기와 같은 것들을 이해할 수 있도록 하는 짤막한 정보를 우리에게 제공한다. 우리의 목표는 ‘복잡한 영상과 그에 맞는 텍스트(자막) 모두를 포함한 것을 이해하는 기계’를 측정하는 질문-답변 데이터셋을 만드는 것이다. 우리는 이 데이터셋이 다음 수준의 자동적인 ‘정말로’ 이해를 하는 기계를 만드는 것을 촉진하는 것이 되었으면 한다.&lt;/p&gt;

&lt;p&gt;이 논문은 영화에 대한 거대한 질문-답변 데이터셋, MovieQA를 소개한다. 이는 408개의 영화와 14,944개의 5지선다형 질문을 포함한다. 이 중 140개의 영화(6,462개의 질답)에는 영화의 질문-답변 부분에 해당하는 time stamp가 붙어 있다.&lt;br /&gt;
이 질문들은 ‘누가’ ‘무엇을’ ‘누구에게’ 같이 시각적으로만 풀 수 있는 것과 ‘왜’ ‘어떻게’ 무슨 일이 일어났냐는 시각정보와 대사(텍스트)를 모두 사용해야만 답을 추론할 수 있는 질문들을 포함한다.&lt;br /&gt;
우리의 데이터셋은 영상클립, 제목, 자막, 줄거리, DVS를 포함하는 다양한 출처의 정보를 포함하는 유일한 데이터셋이다. 우리는 이를 통계적으로 분석할 것이며 또한 존재하는 질답 기술을 우리의 데이터에 적용하고 이러한 open-ended 질답이 어려운 것을 보일 것이다.&lt;br /&gt;
우리는 leaderboard를 포함한 &lt;a href=&quot;http://movieqa.cs.toronto.edu/leaderboard&quot;&gt;온라인 벤치마크 사이트&lt;/a&gt;를 만들어 두었다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;관련-연구related-works&quot;&gt;관련 연구(Related Works)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Video understanding via language:&lt;/strong&gt; 영상 범위에서 시각 및 언어정보를 통합시킨 연구는 더 적은 연구만이 존재한다. LSTM을 사용한 영상클립에 캡션을 다는 것 등이 있었다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Question-answering:&lt;/strong&gt; 자연언어처리에서 인기 있는 task이다. Memory network나 deep LSTM, Bayesian approach 등이 사용되고 있다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;QA Datasets:&lt;/strong&gt; NYUv2 RGB-D와 같은 데이터셋이나, 100만 단위의 MS-COCO 데이터셋 등이 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;movieqa-데이터셋movieqa-dataset&quot;&gt;MovieQA 데이터셋(MovieQA Dataset)&lt;/h2&gt;

&lt;p&gt;앞서 언급했듯이 408개의 영화와, 위키피디아에서 가져온 줄거리(시놉시스)를 포함한다. 또한 영상, 제목, DVS, 대사 스크립트를 포함한다.&lt;/p&gt;

&lt;p&gt;이 부분의 주된 내용은 영화, 질문, 답변에는 어떤 종류가 있고, 어느 비율만큼 어떤 것이 있는지에 대한 통계 자료들이다. 자세한 내용은 궁금하면 논문을 직접 읽어보는 것이 빠르다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-05-29-Movie-Question-Answering/03.png&quot; width=&quot;70%&quot; alt=&quot;MovieQA Dataset Statistics&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-05-29-Movie-Question-Answering/04.png&quot; width=&quot;100%&quot; alt=&quot;MovieQA Dataset Statistics&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-05-29-Movie-Question-Answering/05.png&quot; width=&quot;70%&quot; alt=&quot;MovieQA Dataset Statistics&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-05-29-Movie-Question-Answering/06.png&quot; width=&quot;70%&quot; alt=&quot;MovieQA Dataset Statistics&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;다지선다형-질문-답변multi-choice-question-answering&quot;&gt;다지선다형 질문-답변(Multi-choice Question-Answering)&lt;/h2&gt;

&lt;p&gt;여기서는 질답을 위한 여러 지능적인 기준선(intelligent baselines)를 조사하려 한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$S$를 이야기(줄거리, 제목, 비디오 샷을 포함한 어떤 정보든 포함)라 한다.&lt;/li&gt;
  &lt;li&gt;$q^S$는 하나의 질문이다.&lt;/li&gt;
  &lt;li&gt;${a^S_j}^M_{j=1}$은 질문 $q^S$에 대한 여러 답변이다. 여기서 $M=5$이다(5지선다형이므로).&lt;/li&gt;
  &lt;li&gt;그러면 다지선다형 질답의 일반적인 문제느 3방향 득점 점수 $f(S, q^S, a^S)$로 나타낼 수 있다.
    &lt;ul&gt;
      &lt;li&gt;이 함수는 이야기와 질문이 주어졌을 때 답변의 “Quality”를 평가한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;우리의 목표는 이제 $f$를 최대화하는 질문 $q^S$에 대한 답변 $a^S$를 선택하는 것이다:&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;j^\ast = \text{argmax}_{j=1 ... M} \ f(S, q^S, a^S_j)&lt;/script&gt;

&lt;p&gt;아래는 모델의 한 예시이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-05-29-Movie-Question-Answering/07.png&quot; width=&quot;100%&quot; alt=&quot;MovieQA Dataset Statistics&quot; /&gt;&lt;/center&gt;

&lt;p&gt;모델은 ‘The Hasty Student’, ‘Searching Student’, ‘Memory Network’, ‘Video baselines’ 등을 포함한다.&lt;/p&gt;

&lt;h2 id=&quot;결론conclusion&quot;&gt;결론(Conclusion)&lt;/h2&gt;

&lt;p&gt;이 논문에서는 영상과 텍스트 모두를 아우르는 자동적 이야기 이해 평가를 목표로 하는 MovieQA 데이터셋을 소개하였다.
우리의 데이터셋은 영상클립, 제목, 대사 스크립트, 줄거리, DVS 등 다양한 출처의 정보를 포함한다는 점에서 유일하다. 우리는 여러 지능적인 기준선과 우리의 task의 난이도를 분석하는 원래 존재하던 질답 기술을 연장시키기도 했다. 평가 서버를 포함한 우리의 벤치마크는 &lt;a href=&quot;http://movieqa.cs.toronto.edu&quot;&gt;온라인&lt;/a&gt;에서 확인할 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;참고문헌references&quot;&gt;참고문헌(References)&lt;/h2&gt;

&lt;p&gt;논문 참조!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;모델들에 대한 자세한 설명들은 생략하였다. Student 모델같은 경우에는 이름부터 꽤 흥미롭기 때문에 한번쯤 찾아보는 것을 추천한다.&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>VQA(Visual Question Answering)</title>
   <link href="http://localhost:4000/Visual-Question-Answering/"/>
   <updated>2019-04-17T00:00:00+09:00</updated>
   <id>http://localhost:4000/Visual-Question-Answering</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 VQA: Visual Question Answering에 대해 알아보고자 한다.&lt;/p&gt;

&lt;p&gt;VQA task는 이미지(Visual, 영상으로도 확장 가능)와 그 이미지에 대한 질문(Question)이 주어졌을 때, 해당 질문에 맞는 올바른 답변(Answer)을 만들어내는 task이다.&lt;/p&gt;

&lt;p&gt;아래는 &lt;a href=&quot;https://eng.snu.ac.kr/node/16080&quot;&gt;서울대학교 공대뉴스광장&lt;/a&gt;을 인용하였다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;VQA Challenge는 2016년 CVPR을 시작으로 매년 개최되며, 1년마다 발전된 기술을 평가하고 시상하고 있다. 2017년부터는 같은 질문에 비슷한 이미지를 보여주고 다른 답변을 하는 데이터를 VQA 2.0 데이터셋 통해 수집한 후 인공지능의 유효성을 엄밀히 평가한다.&lt;br /&gt;
예를 들어 ‘누가 안경을 쓰고 있나?’라는 질문에 비슷한 이미지가 주어지면 ‘남자’ 또는 ‘여자’의 답을 가질 수 있도록 데이터의 분포를 고려하는 것. VQA 2.0 데이터셋은 20만 개의 이미지에 대해 110만 개의 질문과 1100만 이상의 답을 가지며, VQA 1.0보다 1.8배의 데이터를 가지고 있다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;VQA Challenge는 컴퓨터비전패턴인식학회(IEEE Computer Vision and Pattern Recognition, CVPR) 워크샵 중 하나이며, &lt;a href=&quot;https://visualqa.org/&quot;&gt;VQA Homepage&lt;/a&gt;에서 매년 열린다. 관심 있으면 클릭해 보자.&lt;/p&gt;

&lt;p&gt;국내 연구팀의 대표적인 성과로는 2016년 네이버랩스 2위, 2018년 서울대 장병탁교수팀 2위가 있겠다.&lt;/p&gt;

&lt;p&gt;VQA Challenge라고 하는 것은 Aishwarya Agrawal, Jiasen Lu, Stanislaw Antol, Margaret Mitchell, C. Lawrence Zitnick, Dhruv Batra, Devi Parikh 등의 연구자가 일종의 Challenge로서 제안한 것이기 때문에, 이를 중심으로 설명한다. 그렇기 때문에 논문이기도 하면서 동시에 새로운 task를 제안하겠다는 느낌이 강하다.&lt;/p&gt;

&lt;p&gt;중요한 부분만 적을 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;vqa-visual-question-answering&quot;&gt;VQA: Visual Question Answering&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1505.00468&quot;&gt;VQA: Visual Question Answering)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;초록abstract&quot;&gt;초록(Abstract)&lt;/h2&gt;

&lt;p&gt;이 논문에서는 VQA task를 제안한다. VQA task는 이미지(Visual, 영상으로도 확장 가능)와 그 이미지에 대한 질문(Question)이 주어졌을 때, 해당 질문에 맞는 올바른 답변(Answer)을 만들어내는 task이다.&lt;br /&gt;
VQA를 성공적으로 수행하기 위한 시스템은 이미지 captioning을 하는 시스템보다 더 높은 수준의 이미지 이해도와 복잡한 추론능력을 가져야 한다. 또한 (간단한 수준의 답변만 하는 것은 좋지 않기 때문에 이를) 자동으로 평가하는 것도 가능해야 한다. 우리는 25만 장의 이미지와, 76만 개의 질문, 1000만 개의 답과 그에 대한 정보를 제공한다. 많은 기준과 방법들은 사람의 수행능력과 비교한다. VQA Demo는 CloudCV에서 볼 수 있다.&lt;/p&gt;

&lt;p&gt;참고) 2019.04.17 현재 논문에 링크된 CloudCV Demo는 404 error가 뜨는 중이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;서론introduction&quot;&gt;서론(Introduction)&lt;/h2&gt;

&lt;p&gt;Computer Vision(CV), Natural Language Processing (NLP), Knowledge Representation &amp;amp; Reasoning (KR)를 결합한 이미지 캡셔닝(captioning)은 지난 몇 년간 급격히 발전해 왔다. 그러나 이 task는 별로 “AI-complete”하지 못하다(그다지 인공”지능”스럽지 않다).&lt;br /&gt;
그러면 “AI-complete”하지 못하다는 것은 무엇인가? 이 논문에서는 좀 더 자유로운 형식에 열린 형태인 VQA(Visual Question Answering)을 제안하고자 한다. 이러한 답변을 제대로 하기 위해서는 다양한 AI 능력들이 필요하다:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;세밀한 인식(“이 피자엔 어떤 종류의 치즈가 있는가?”)&lt;/li&gt;
  &lt;li&gt;물체 감지(“얼마나 많은 자전거가 있는가?”)&lt;/li&gt;
  &lt;li&gt;행동인식(“남자는 울고 있는가?”)&lt;/li&gt;
  &lt;li&gt;지식기반 추론(“이것은 채식주의자를 위한 피자인가?”)&lt;/li&gt;
  &lt;li&gt;상식 추론(“이 사람은 20/20 시력을 갖고 있는가?”, “이 사람은 회사를 원하는가?” 참고: 20/20은 1.0/1.0과 같음)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;또한 VQA 시스템은 자동으로 평가가 가능해야 한다. 이 논문에서는 열린 문제(open-ended, 답변의 가능성이 다양함)와 다지선다형(multiple-choice) task를 둘 다 본다. 다지선다형 문제는 열린 문제와는 다르게 단지 정해진 답변 중 옳은 것을 고르기만 하면 된다.&lt;/p&gt;

&lt;p&gt;데이터셋은 COCO 데이터셋에 5만 개를 더 추가했다. 데이터 수는 초록에도 나와 있다. 또한 이미지 캡셔닝이랑 무엇이 다른지에 대한 설명도 나와 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;관련-연구related-works&quot;&gt;관련 연구(Related Works)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;VQA Efforts:&lt;/strong&gt; Visual Question Answering은 이전에도 다뤄진 적이 있긴 한데, 여기서 제안하는 것보다 훨씬 제한된 환경과 제한된 데이터셋 안에서 다룬다. 물체의 종류도 적고, 답변의 단어 등도 제한적이다. 이 VQA task는 그렇지 않다. free-form, open-ended이다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Text-based Q&amp;amp;A:&lt;/strong&gt; 이 문제는 NLP와 텍스트 처리 분야에서 잘 연구되었다. VQA 기술에 도움이 될 몇 가지 접근법이 있다. 이 경우 질문은 텍스트를 기반으로 이루어진다. VQA는 text와 vision 모두에 의존한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Describing Visual Content:&lt;/strong&gt; 이미지 태깅, 이미지 캡셔닝, 비디오 캡셔닝 등이 VQA와 관련이 있다. 그러나 그 캡션은 vision에 특화된 것이 아닌 지나치게 일반적인(많은 이미지에 대해 동일한 캡션을 써도 말이 됨) 경우가 있다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Other Vision+Language Tasks:&lt;/strong&gt; 이미지 캡셔닝보다 평가가 쉬운 coreference resolution, generating referring expressions 등의 task가 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;vqa-데이터셋vqa-dataset-collection&quot;&gt;VQA 데이터셋(VQA Dataset Collection)&lt;/h2&gt;

&lt;p&gt;사실 이미지 한장이면 충분할 듯 하다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-17-Visual-Question-Answering/01.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;잘 안 보이니까 일부만 확대하겠다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-17-Visual-Question-Answering/02.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;약 20만 장의 현실 이미지와 약 5만 장의 추상적인 이미지가 있다.&lt;/li&gt;
  &lt;li&gt;Training / Validation / Test 셋이 나누어져 있다. 그 나누는 비율도 정해져 있다(추상 이미지의 경우 20K/10K/20K). subsplit은 없다.&lt;/li&gt;
  &lt;li&gt;이미 MS COCO 데이터셋은 이미지당 5개의 한 문장짜리 캡션이 있으므로, 추상 이미지에도 그만큼 붙여서 만들었다.&lt;/li&gt;
  &lt;li&gt;흥미롭고, 다양하고, 잘 만들어진 질문을 모으는 것은 매우 중요한 문제이다.
    &lt;ul&gt;
      &lt;li&gt;“저 고양이의 색깔은 무엇인가?”, “지금 몇 개의 의자가 이미지에 있는가?” 같은 질문은 너무 단순하다.&lt;/li&gt;
      &lt;li&gt;그러나 우리는 “상식”을 필요로 하는 질문을 원한다. 또, 상식”만”으로 대답할 수 있는 질문은 안 된다.
        &lt;ul&gt;
          &lt;li&gt;예를 들면 “사진의 저 동물은 어떤 소리를 낼 것 같은가?” 같은 질문이다.&lt;/li&gt;
          &lt;li&gt;“콧수염은 무엇으로 만들어지는가?” 같은 질문은 의미 없다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;그래서 총 76만 개 정도의 질문을 확보하였다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;많은 질문들에 대해서는 yes/no만 해도 충분하다. 그러나 그렇지 않은 것들도 있다.&lt;/li&gt;
  &lt;li&gt;열린 형태(open-ended) 질문들은 다음 metric에 의해 평가된다.
    &lt;ul&gt;
      &lt;li&gt;$ \text{accuracy} = min({\text{그 답변을 한 사람의 수} \over 3}, 1) $&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;다지선다형(객관식) 문제는 18개의 선택지가 있다.
    &lt;ul&gt;
      &lt;li&gt;이외에도 다양한 형태의 문제가 존재한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;vqa-데이터셋-분석vqa-dataset-analysis&quot;&gt;VQA 데이터셋 분석(VQA Dataset Analysis)&lt;/h2&gt;

&lt;p&gt;데이터의 정확한 수, 질문의 종류 및 수, 답변의 종류 및 수, 질답의 길이 등에 대한 분포 등이 수록되어 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;질문에는 “What is…”, “Is there…”, “How many…”, “Does the…” 같은 질문들이 있다. 질문의 길이는 4~8단어가 대부분이다.&lt;/li&gt;
  &lt;li&gt;답변에는 yes/no, 색깔, left/right 등의 답변이 많다. 1 / 2 / 3단어인 경우가 대략 90%, 6%, 2.5% 정도씩 있다.&lt;/li&gt;
  &lt;li&gt;상식을 필요로 하는 질문은 위에서 설명한 대로 당연이 이미지에서도 정보를 얻어야 답변이 가능하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;task를 제안하는 것인만큼 데이터에 대한 정보가 매우 자세하다. 아래 그림 같은 정보도 있다. 여러 종류의 질문에 대해 답변이 어떤 단어가 어떤 비율로 있는지 등을 나타낸다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-17-Visual-Question-Answering/03.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;vqa-기준선과-방법vqa-baselines-and-methods&quot;&gt;VQA 기준선과 방법(VQA Baselines and Methods)&lt;/h2&gt;

&lt;h3 id=&quot;baselines&quot;&gt;Baselines&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;random:&lt;/strong&gt; 무작위로 답변을 선택한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;prior(“yes”):&lt;/strong&gt; “yes” 답변이 가장 많기 때문에 항상 yes를 답으로 내놓는다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;per Q-type prior:&lt;/strong&gt; 각 질문 종류별로 답변 중 최빈값을 답으로 내놓는다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;nearest neighbor:&lt;/strong&gt; 가장 유사한 K개의 질문을 뽑아 그 답변들 중 최빈값을 답으로 내놓는다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;methods&quot;&gt;Methods&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Image Channel:&lt;/strong&gt; 이미지를 위한 embedding을 제공한다.
    &lt;ul&gt;
      &lt;li&gt;I: VGGNet의 마지막 hidden 레이어가 4096차원의 embedding으로 사용된다.&lt;/li&gt;
      &lt;li&gt;norm I: 위와 비슷하나 $l_2$ 정규화된 활성함수를 사용&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Question Channel:&lt;/strong&gt; 질문을 위한 embedding을 제공한다.
    &lt;ul&gt;
      &lt;li&gt;Bag-of-Words Question(BoW Q): 질문의 최빈 1000개의 단어와 30차원의 BoW를 사용하여 1030차원의 질문 embedding을 만든다.&lt;/li&gt;
      &lt;li&gt;LSTM Q: 1024차원이다.&lt;/li&gt;
      &lt;li&gt;deeper LSTM Q: 2048차원이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Multi-Layer Perceptron(MLP):&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;BoW Q + I에 대해서는 단지 concatenate한다.&lt;/li&gt;
      &lt;li&gt;LSTM Q + I, deeper LSTM Q + norm I에 대해서는 이미지 embedding은 차원을 맞추기 위해 1024차원으로 변환된 후 LSTM embedding과 element-wise하게 곱해진다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;

&lt;p&gt;방법에 따라서는 28.13%/30.53%(각각 open-ended와 multiple-choice)를 나타낸 것부터 58.16%/63.09%를 나타낸 모델(deeper LSTM Q + norm I)까지 결과는 다양하다.&lt;br /&gt;
따라서 적어도 60%는 넘어야 의미 있는 VQA 시스템이라고 할 수 있을 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;vqa-challenge-and-workshop&quot;&gt;VQA Challenge and Workshop&lt;/h2&gt;

&lt;p&gt;CVPR 2016에서부터 1년 간격으로 열린다. 테스트 서버도 준비되어 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;결론-및-토의conclusion-and-discussion&quot;&gt;결론 및 토의(Conclusion and Discussion)&lt;/h2&gt;

&lt;p&gt;이 논문에서는 VQA task를 제안하였고, 그에 맞는 데이터를 제공하였다.&lt;br /&gt;
우리는 VQA가 자동평가가 가능한 “AI-complete” 문제를 풀기 위한 한계를 끌어올리기에 적합하다고 생각한다. 이를 위한 노력에 드는 시간도 가치가 있다고 여겨진다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;참고문헌references&quot;&gt;참고문헌(References)&lt;/h2&gt;

&lt;p&gt;논문 참조!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;결론 이후에도 많은 정보가 있으니 참조하면 좋다. 매우 흥미로운 것들이 많다.&lt;br /&gt;
대부분은 데이터의 분포에 관한 설명 및 시각화한 그림들이다.&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>DANs(Dual Attention Networks for Multimodal Reasoning and Matching)</title>
   <link href="http://localhost:4000/Dual-Attention-Networks/"/>
   <updated>2019-04-17T00:00:00+09:00</updated>
   <id>http://localhost:4000/Dual-Attention-Networks</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 네이버랩스(Naver Corp.)에서 2017년 발표한 논문인 Dual Attention Networks for Multimodal Reasoning and Matching에 대해 알아보고자 한다.&lt;br /&gt;
네이버랩스는 인공지능 국제대회 ‘CVPR 2016: VQA Challenge’에서 2위를 차지하였고, 해당 챌린지에서 DAN(Dual Attention Networks)라는 알고리즘을 개발하였다. 이어 이 알고리즘을 조금 더 일반화하여 2017년 발표한 논문이 이 논문이다.&lt;/p&gt;

&lt;p&gt;VQA가 무엇인지는 &lt;a href=&quot;https://greeksharifa.github.io/computer%20vision/2019/04/17/Visual-Question-Answering/&quot;&gt;여기&lt;/a&gt;를 참조하면 된다.&lt;/p&gt;

&lt;p&gt;간단히, DANs은 따로 존재하던 Visual 모델과 Textual 모델을 잘 합쳐 하나의 framework로 만든 모델이라고 할 수 있겠다.&lt;/p&gt;

&lt;p&gt;중요한 부분만 적을 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;dansdual-attention-networks-for-multimodal-reasoning-and-matching&quot;&gt;DANs(Dual Attention Networks for Multimodal Reasoning and Matching)&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1611.00471&quot;&gt;DANs(Dual Attention Networks for Multimodal Reasoning and Matching)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;초록abstract&quot;&gt;초록(Abstract)&lt;/h2&gt;

&lt;p&gt;vision과 language 사이의 세밀한 상호작용을 포착하기 위해 우리는 visual 및 textual attention을 잘 조정한 Dual Attention Networks(DANs)를 제안하고자 한다. DANs는 이미지와 텍스트 모두로부터 각각의 중요한 부분에 여러 단계에 걸쳐 집중(attend / attention)하고 중요한 정보를 모아 이미지/텍스트의 특정 부분에만 집중하고자 한다. 이 framework에 기반해서, 우리는 multimodal reasoning(추론)과 matching(매칭)을 위한 두 종류의 DANs를 소개한다. 각각의 모델은 VQA(Visual Question Answering), 이미지-텍스트 매칭에 특화된 것이고 state-of-the-art 성능을 얻을 수 있었다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;서론introduction&quot;&gt;서론(Introduction)&lt;/h2&gt;

&lt;p&gt;Vision과 language는 실제 세계를 이해하기 위한 인간 지능의 중요한 두 부분이다. 이는 AI에도 마찬가지이며, 최근 딥러닝의 발전으로 인해 이 두 분야의 경계조차 허물어지고 있다. VQA, Image Captioning, image-text matching, visual grounding 등등.&lt;/p&gt;

&lt;p&gt;최근 기술 발전 중 하나는 attention mechanism인데, 이는 이미지 등 전체 데이터 중에서 중요한 부분에만 ‘집중’한다는 것을 구현한 것으로 많은 신경망의 성능을 향상시키는 데 기여했다. &lt;br /&gt;
시각 데이터와 텍스트 데이터 각각에서는 attention이 많은 발전을 가져다 주었지만, 이 두 모델을 결합시키는 것은 연구가 별로 진행되지 못했다.&lt;/p&gt;

&lt;p&gt;VQA같은 경우 “(이미지 속) 저 우산의 색깔은 무엇인가?” 와 같은 질문에 대한 답은 ‘우산’과 ‘색깔’에 집중함으로써 얻을 수 있고, 이미지와 텍스트를 매칭하는 task에서는 이미지 속 ‘girl’과 ‘pool’에 집중함으로써 해답을 얻을 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-17-Dual-Attention-Networks/01.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;이 논문에서 우리는 vision과 language의 fine-grained 상호작용을 위한 visual 모델과 textual 모델 두 가지를 잘 결합한 Dual Attention Networks(DANs)를 소개한다. DANs의 두 가지 변형 버전이 있는데, reasoning-DAN(r-DAN, 추론용 모델)과 matching-DAN(m-DAN, 매칭용 모델)이다.&lt;/p&gt;

&lt;p&gt;r-DAN은 이전 attention 결과와 다음 attention을 모은 결합 메모리를 사용하여 시각적 그리고 언어적 attention을 협동 수행한다. 이는 VQA같은 multimodal 추론에 적합하다.&lt;br /&gt;
m-DAN은 시각 집중 모델과 언어 집중 모델을 분리하여 각각 다른 메모리에 넣지만 이미지와 문장 사이의 의미를 찾기 위해 학습은 동시에 진행하는 모델이다. 이 접근법은 최종적으로 효율적인 cross-modal 매칭을 용이하게 해 준다.&lt;br /&gt;
두 알고리즘 모두 시각적 그리고 언어적(문자적, textual) 집중 mechanism을 하나의 framework 안에 긴밀히 연결한 것이다.&lt;/p&gt;

&lt;p&gt;이제 우리가 기여한 바는 다음과 같다:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;시각적 그리고 언어적 attention을 위한 통합된 framework를 제안하였다. 이미지 내 중요한 부분과 단어들은 여러 단계에서 합쳐진 곳에 위치한다.&lt;/li&gt;
  &lt;li&gt;이 framework의 변형 버전 두 가지는 실제로 추론 및 매칭을 위한 모델로 구현되어 VQA와 image-text 매칭에 적용되었다.&lt;/li&gt;
  &lt;li&gt;attention 결과의 상세한 시각화는 우리의 모델이 task에 핵심적인 이미지 및 문장 부분에 잘 집중하고 있음을 보여주는 것을 가능하게 한다.&lt;/li&gt;
  &lt;li&gt;이 framework는 VQA와 Flickr30K 데이터셋에서 SOTA(state-of-the-art) 결과를 보여주었다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;관련-연구related-works&quot;&gt;관련 연구(Related Works)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Attention Mechanisms:&lt;/strong&gt; 간단히 말해 시각적 또는 언어적 입력에서 task를 해결하는 데 중요한 일부분에만 집중하도록 해 문제를 잘 풀 수 있게 하는 방법이다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Visual Question Answering(VQA):&lt;/strong&gt; 이미지와 그 이미지와 연관된 질문이 주어지면 적절한 답을 찾는 task이다. 자세한 내용은 &lt;a href=&quot;https://greeksharifa.github.io/computer%20vision/2019/04/17/Visual-Question-Answering/&quot;&gt;여기&lt;/a&gt;를 참조하라.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Image-Text Matching:&lt;/strong&gt; 시각자료(이미지)와 글자자료(=문장, 언어적 부분) 사이의 의미적 유사도를 찾는 것이 가장 중요하다. 많은 경우 이미지 특징벡터(feature vector)와 문장 특징벡터를 직접 비교할 수 있도록 변형해 비교하는 방법이 자주 쓰인다. 이 비교방법은 양방향 손실함수 또는 CNN으로 결합하는 방법 등이 쓰인다. 그러나 multimodal attention 모델을 개발하려는 시도는 없었다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;dual-attention-networksdans&quot;&gt;Dual Attention Networks(DANs)&lt;/h2&gt;

&lt;h3 id=&quot;input-representation&quot;&gt;Input Representation&lt;/h3&gt;

&lt;h4 id=&quot;image-representation&quot;&gt;Image representation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;이미지 특징은 19-layer VGGNet 또는 152-layer ResNet으로 추출했다.&lt;/li&gt;
  &lt;li&gt;448 $\times$ 448 으로 바꿔 CNN에 집어넣는다.&lt;/li&gt;
  &lt;li&gt;다른 ‘지역’(region)으로부터 특징벡터를 얻기 위해 VGGNet 및 ResNet의 마지막 pooling layer를 취했다.&lt;/li&gt;
  &lt;li&gt;이제 이미지는 ${v_1, …, v_N}$으로 표현된다. $N$은 이미지 지역의 개수, $v_n$은 512(VGGNet) 또는 2048(ResNet)이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;text-representation&quot;&gt;Text representation&lt;/h4&gt;

&lt;p&gt;one-hot 인코딩으로 주어진 $T$개의 입력 단어들 ${w_1, …, w_T}$을 임베딩시킨 후 양방향 LSTM에 집어넣는다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-17-Dual-Attention-Networks/02.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;임베딩 행렬(embedding matrix)와 LSTM은 end-to-end로 학습된다.&lt;/p&gt;

&lt;h3 id=&quot;attention-mechanisms&quot;&gt;Attention Mechanisms&lt;/h3&gt;

&lt;p&gt;bias $b$는 생략되어 있다.&lt;/p&gt;

&lt;h4 id=&quot;visual-attention&quot;&gt;Visual Attention&lt;/h4&gt;

&lt;p&gt;이미지의 특정 부분에 집중하게 하는 context vector를 생성하는 것을 주목적으로 한다.&lt;/p&gt;

&lt;p&gt;step $k$에서, 시각문맥벡터(visual context vector) $v^{(k)}$는&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;v^{(k)} = \text{V\_Att} (\{v_n\}^N_{n=1}, \ m_v^{(k-1)}&lt;/script&gt;

&lt;p&gt;$m_v^{(k-1)}$는 step $k-1$까지 집중했었던 정보를 인코딩하는 메모리 벡터이다.&lt;br /&gt;
여기에다가 soft attention mechanism을 적용하게 된다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-17-Dual-Attention-Networks/03.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;attention weights $\alpha$는 2-layer FNN과 softmax로 구해진다. $W$들은 네트워크 parameter이다.&lt;/p&gt;

&lt;h4 id=&quot;textual-attention&quot;&gt;Textual Attention&lt;/h4&gt;

&lt;p&gt;마찬가지로 문장의 특정 부분에 집중할 수 있도록 문맥벡터 $u^{(k)}$를 매 step마다 생성하는 것이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;u^{(k)} = \text{T\_Att} (\{u_t\}^T_{t=1}, \ m_u^{(k-1)}&lt;/script&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-17-Dual-Attention-Networks/04.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;r-dan-for-visual-question-answering&quot;&gt;r-DAN for Visual Question Answering&lt;/h3&gt;

&lt;p&gt;VQA는 multimodal 데이터를 결합 추론하는 것을 필요로 하는 문제이다. 이를 위해 r-DAN은 step $k$에서 시각 및 언어적 정보를 축적하는 메모리 벡터 $m^{(k)}$를 유지한다. 이는 재귀적으로 다음 식을 통해 업데이트된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;m^{(k)} = m^{(k-1)} + v^{(k)} \  (\cdot) \ u^{(k)}&lt;/script&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-17-Dual-Attention-Networks/05.png&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-17-Dual-Attention-Networks/06.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;최종 답은 다음과 같이 계산된다. $ \text{p}_{\text{ans}}$는 정답 후보들의 확률을 나타낸다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bold{\text{p}}_{\text{ans}} = \text{softmax} \bigr( W_{\text{ans}} \ m^{(K)} \bigl)&lt;/script&gt;

&lt;h3 id=&quot;m-dan-for-image-text-matching&quot;&gt;m-DAN for Image-Text Matching&lt;/h3&gt;

&lt;p&gt;수식의 형태는 꽤 비슷하다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;m_v^{(k)} = m_v^{(k-1)} + v^{(k)}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;m_u^{(k)} = m_u^{(k-1)} + u^{(k)}&lt;/script&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-17-Dual-Attention-Networks/07.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;s^{(k)} = v^{(k)} \cdot u^{(k)}, \ S = \sum_{k=0}^K s^{(k)}&lt;/script&gt;
Loss function은 다음과 같이 정의된다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-17-Dual-Attention-Networks/08.png&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;추론할 시점에는 어떤 이미지나 문장이든 결합공간 안에 임베딩된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;z_v = [v^{(0)}; ... ; v^{(K)}],&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;z_u = [u^{(0)}; ... ; u^{(K)}],&lt;/script&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;실험experiments&quot;&gt;실험(Experiments)&lt;/h2&gt;

&lt;h3 id=&quot;experimental-setup&quot;&gt;Experimental Setup&lt;/h3&gt;

&lt;p&gt;r-DAN과 m-DAN 모두에 대해 모든 hyper-parameters들은 전부 고정되었다.&lt;/p&gt;

&lt;p&gt;$K$=2, LSTM을 포함한 모든 네트워크의 hidden layer의 dimension=512,&lt;br /&gt;
lr=0.1, momentum=0.9, weight decay=0.0005, dropout rate=0.5, gradient clipping=0.1,&lt;br /&gt;
epochs=60, 30epoch 이후 lr=0.01,&lt;br /&gt;
minibatch=128 $\times$ 128 quadruplets(긍정 이미지, 긍정 문장, 부정 이미지, 부정 문장),&lt;br /&gt;
가능한 답변의 수 C=2000, margin $m$=100이다.&lt;/p&gt;

&lt;h3 id=&quot;evaluation-on-visual-question-answering&quot;&gt;Evaluation on Visual Question Answering&lt;/h3&gt;

&lt;h4 id=&quot;dataset-and-evaluation-metric&quot;&gt;Dataset and Evaluation Metric&lt;/h4&gt;

&lt;p&gt;VQA 데이터셋을 사용하였고, train(이미지 8만 장), val(이미지 4만 장), test-dev(이미지 2만 장), test-std(이미지 2만 장)이다. 측정방법은&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-17-Dual-Attention-Networks/09.png&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;$\hat{a}$는 예측된 답이다.&lt;/p&gt;

&lt;h4 id=&quot;results-and-analysis&quot;&gt;Results and Analysis&lt;/h4&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-17-Dual-Attention-Networks/10.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-17-Dual-Attention-Networks/11.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;결과를 보면 대부분의 상황에서 SOTA 결과를 얻었으며, 이미지와 문장에서 집중해야 할 부분을 잘 찾았음을 확인할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;evaluation-on-image-text-matching&quot;&gt;Evaluation on Image-Text Matching&lt;/h3&gt;

&lt;p&gt;분석결과는 비슷하므로 생략한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-17-Dual-Attention-Networks/12.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;결론conclusion&quot;&gt;결론(Conclusion)&lt;/h2&gt;

&lt;p&gt;우리는 시각 및 언어적 attention mechanism을 연결하기 위한 Dual Attention Networks (DANs)를 제안하였다. 추론과 매칭을 위한 모델을 하나씩 만들었고, 각각의 모델은 이미지와 문장으로부터 공통 의미를 찾아낸다.&lt;br /&gt;
이 모델들은 VQA와 image-text 매칭 task에서 SOTA 결과를 얻어냄으로써 DANs의 효과를 입증하였다. 제안된 이 framework는 image captioning, visual grounding, video question answering 등등 많은 시각 및 언어 task들로 확장될 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;참고문헌references&quot;&gt;참고문헌(References)&lt;/h2&gt;

&lt;p&gt;논문 참조! 부록은 없다. &lt;del&gt;읽기 편하다&lt;/del&gt;&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>Pix2Pix(Image-to-Image Translation with Conditional Adversarial Networks)</title>
   <link href="http://localhost:4000/Pix2Pix/"/>
   <updated>2019-04-07T00:00:00+09:00</updated>
   <id>http://localhost:4000/Pix2Pix</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 2016년 11월 &lt;em&gt;Phillip Isola&lt;/em&gt; 등이 발표한 Image-to-Image Translation with Conditional Adversarial Networks(Pix2Pix)를 살펴보도록 한다.&lt;/p&gt;

&lt;p&gt;Pix2Pix는 Berkeley AI Research(BAIR) Lab 소속 Phillip Isola 등이 2016 최초 발표(2018년까지 업데이트됨)한 논문이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-07-Pix2Pix/01.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;Pix2Pix는 Image to Image Translation을 다루는 논문이다. 이러한 변환은 Colorization(black &amp;amp; white $\rightarrow$ color image) 등을 포함하는데, Pix2Pix에서는 이미지 변환 문제를 colorization처럼 한 분야에만 국한되지 않고 좀 더 일반화한 문제를 풀고자 했다. 그리고 그 수단으로써 Conditional adversarial nets를 사용했다.&lt;/p&gt;

&lt;p&gt;중요한 부분만 적을 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;pix2piximage-to-image-translation-with-conditional-adversarial-networks&quot;&gt;Pix2Pix(Image-to-Image Translation with Conditional Adversarial Networks)&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1611.07004&quot;&gt;Pix2Pix(Image-to-Image Translation with Conditional Adversarial Networks)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;초록abstract&quot;&gt;초록(Abstract)&lt;/h2&gt;

&lt;p&gt;우리는 conditional adversarial networks를 일반화된 이미지 변환 문제에 테스트하였다. 이 네트워크는 단지 input-output mapping만 배우는 것이 아니라 이를 학습하기 위한 loss function까지 배운다. 따라서 전통적으로 매우 다른 loss function을 쓰던 문제에들도 이 접근법을 적용할 수 있다.&lt;br /&gt;
우리는 이 접근이 label과 동기화, 경계선만 있는 이미지를 복원, 흑백이미지에 색깔 입히기 등등의 문제에 효과적임을 보였다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;서론introduction&quot;&gt;서론(Introduction)&lt;/h2&gt;

&lt;p&gt;이미지를 이미지로 변환할 뿐인 수많은 문제들은 그 세팅이 똑같음에도 각각 따로 연구되어 왔다(위에서 말한 이미지 변환 문제들). 우리는 이러한 변환 문제를 위한 일반적인 framework를 개발하는 것이 목표이다.&lt;/p&gt;

&lt;p&gt;이쪽 방향으로는 이미 CNN이라는 좋은 기계가 있다. CNN은 결과의 품질을 알려주는 loss function을 최소화한다. 그러나 학습 과정 자체는 자동화되어 있지만 결과를 잘 나오게 하기 위해서는 여전히 수동으로 조절해야 할 것이 많다. 즉, 우리는 &lt;em&gt;무엇을 최소화해야하는지&lt;/em&gt; CNN에게 말해주어야 한다.&lt;br /&gt;
만약 우리가 단순히 결과와 정답 사이의 유클리드 거리를 최소화하라고만 하면 뿌연(blurry) 이미지를 생성하게 된다. 이는 유클리드 거리는 그럴듯한 결과를 평균했을 때 최소화되기 때문이고, 결과적으로 이미지가 흐려진다. 실제 같은(realistic) 이미지를 얻기 위해서는 더 전문 지식이 필요하다.&lt;/p&gt;

&lt;p&gt;만약 우리가 원하는 것을 고수준으로(high-level goal) 말할 수만 있다면, 네트워크는 스스로 그러한 목표에 맞게 loss를 줄여나갈 것이다. 운 좋게도, 최근에 정확히 이것을 해주는 GAN이 발표되었다. GAN은 실제와 가짜를 구분하지 못하도록 학습을 진행하며, 이는 흐린 이미지를 생성하지 않게 할 수 있다(뿌연 이미지는 실제 사진처럼 보일 리 없으므로).&lt;/p&gt;

&lt;p&gt;이 논문에서, 우리는 CGAN이라는 조건부 생성모델을 사용한다. 우리는 input image라는 조건을 줄 것이고 그에 맞는 output image를 생성할 것이기 때문에 이는 이미지 변환 문제에 잘 맞는다.&lt;/p&gt;

&lt;p&gt;이 논문이 기여하는 바는&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;conditional GAN이 넓은 범위의 문제에서 충분히 합리적인 결과를 가져다준다는 것을 밝혔고&lt;/li&gt;
  &lt;li&gt;좋은 결과를 얻기에 충분한 간단한 framework를 제안하고 여러 중요한 architecture의 효과를 분석하였다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;관련-연구related-works&quot;&gt;관련 연구(Related Works)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Structures losses for image modeling:&lt;/strong&gt; 이미지 변환 문제는 per-pixel 분류 또는 회귀 문제로 다뤄졌다. 이러한 공식화는 output space는 “unstructured”이며 각 결과 픽셀은 다른 픽셀에 독립적인 것처럼 다룬다. CGAN는 “structured loss”를 학습하며 많은 논문들이 이러한 loss를 다룬다. conditional random fields, SSIM metric, nonparametric losses 등등.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Conditional GANs:&lt;/strong&gt; 사실 이 논문에서 GAN을 처음 사용한 것은 아니다. 그러나 조건부 GAN을 이미지 변환 문제에 사용한 적은 없었다. CGAN에 대한 설명은 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/19/CGAN/&quot;&gt;여기&lt;/a&gt;를 참조하자.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;방법method&quot;&gt;방법(Method)&lt;/h2&gt;

&lt;p&gt;GAN은 random noise vector $z$로부터 output image $y$를 생성하는 $G: z \rightarrow y$를 학습하는 생성모델이다. 이에 비해 CGAN은 $z$와 observed image $x$로부터 $y$로의 mapping인 $G: {x, z} \rightarrow y$를 학습한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-07-Pix2Pix/02.png&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\\&lt;/script&gt;

&lt;h3 id=&quot;목적함수objective&quot;&gt;목적함수(Objective)&lt;/h3&gt;

&lt;p&gt;CGAN의 목적함수는 다음과 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_{\text{cGAN}}(G, D) = \mathbb{E}_{x , \ y}[log \ D(x,y)] + \mathbb{E}_{x , \ z}[log \ (1-D(G(x, z)))]&lt;/script&gt;

&lt;p&gt;D를 조건부로 학습시키는 것을 중요하게 여겨, D가 $x$를 관측하지 못하도록 unconditional variant를 비교하도록 했다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_{\text{GAN}}(G, D) = \mathbb{E}_{ y}[log \ D(y)] + \mathbb{E}_{x , \ z}[log \ (1-D(G(x, z)))]&lt;/script&gt;

&lt;p&gt;D의 할일은 그대로이지만, G는 단지 D를 속이는 것뿐만 아니라 L2 distance에서의 ground truth에도 가깝도록 만들어야 한다.&lt;br /&gt;
사실 L2보다는 L1을 사용하는 것이 덜 흐린 이미지를 생성하는 데 도움이 되었다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_{L1}(G) = \mathbb{E}_{x, \ y, \ z }[ \Vert y - G(x, z) \Vert_1 ]&lt;/script&gt;

&lt;p&gt;그래서 최종 목적함수는&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;G^\ast = arg \ min_G \ max_D \ \mathcal{L}_{\text{cGAN}}(G, D) + \lambda \mathcal{L}_{L1}(G)&lt;/script&gt;

&lt;p&gt;이다.&lt;/p&gt;

&lt;p&gt;$z$가 없이도 네트워크는 $x \rightarrow y$ mapping을 학습할 수 있지만, 결정론적인 결과를 생성할 수 있고, 따라서 delta function 이외의 어떤 분포와도 맞지 않을 수 있다. 과거의 conditional GAN은 이를 인정하여 $x$에 더해 Gaussian noise $z$를 입력으로 주었다.&lt;br /&gt;
초기 실험에서 우리는 noise를 단순히 무시하도록 했지만, 최종 모델에서는 dropout 시에만 noise를 제공하여 학습과 테스트 시 모두에 G의 여러 레이어에 적용되도록 만들었다. dropout noise에도 불구하고 우리는 매우 조금의 stochasiticity만을 관측하였다. 아주 stochastic한 결과를 생성하는 conditional GAN을 설계하는 것은 아주 중요한 문제이다.&lt;/p&gt;

&lt;h3 id=&quot;네트워크-구조network-architectures&quot;&gt;네트워크 구조(Network architectures)&lt;/h3&gt;

&lt;p&gt;우리는 DCGAN을 G와 D의 기본 모델로 하였고 둘 다 convolution-BatchNorm-ReLU 구조를 따른다.&lt;/p&gt;

&lt;h4 id=&quot;generator-with-skips&quot;&gt;Generator with skips&lt;/h4&gt;

&lt;p&gt;이미지 변환(image-to-image translation) 문제에서 어려운 점은 고해상도 input grid를 고해상도 output grid로 mapping하는 것이다. 심지어 표면의 외관은 다른데 각각 같은 근본적인 구조를 가진다는 것이다.&lt;br /&gt;
많은 이전 연구들은 encoder-decoder 네트워크를 사용한다. 이러한 네트워크에서는 bottleneck 레이어를 통과하기 때문에 정보의 손실이 필연적으로 발생할 수밖에 없다. 그래서, skip-connection을 추가한 &lt;strong&gt;U-Net&lt;/strong&gt;이라는 구조를 사용했다.&lt;br /&gt;
정확히는, 전체 레이어 개수를 $n$이라 할 때 모든 $i$번째 레이어와 $n-i$번째 레이어를 연결했다. 각 연결은 단순히 concatenate한 것이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-07-Pix2Pix/03.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;h4 id=&quot;markovian-discriminatorpatchgan&quot;&gt;Markovian discriminator(PatchGAN)&lt;/h4&gt;

&lt;p&gt;high-frequency 모델링을 위해, 집중할 부분(attention)을 local image patch 단위로만 제한하는 것으로 충분하다. 그래서, 우리는 D를 PatchGAN(일반 GAN인데 단지 Patch 단위로만 보는 것) 구조로 만들었다.&lt;br /&gt;
그래서 우리의 D는 $N \times N$개의 각 Patch별로 이 부분이 진짜인지 가짜인지를 판별한다.&lt;/p&gt;

&lt;p&gt;실험 단계에서 우리는 $N$이 작아도 전체 이미지를 한번에 보는 것보다는 더 좋은 결과를 얻을 수 있음을 보였다. 이는 더 작은 PatchGAN은 더 적은 parameter를 가지고, 더 빠르며, 더 큰 이미지에 적용하는 데에서도 이점이 있음을 보여준다.&lt;/p&gt;

&lt;p&gt;D가 이미지를 Markov random field처럼 보는 것이 효과적인 모델링 방법이므로, patch의 지름보다 더 먼 pixel들은 독립적이라고 보았다. 이러한 접근은 이미 연구된 바 있고, texture/style 모델에서 꽤 흔하며 적절한 가정이다. 따라서 PatchGAN은 texture/style loss면에서 충분히 이해가능한 모델이다.&lt;/p&gt;

&lt;h3 id=&quot;최적화-및-추론optimization-and-inference&quot;&gt;최적화 및 추론(Optimization and inference)&lt;/h3&gt;

&lt;p&gt;일반적인 GAN 접근법을 따랐다. original GAN에서는 $log \ (1-D(x, G(x,z)))$를 최소화하는 대신 $log \ D(x, G(x,z))$를 최대화하는 것이 낫다고 했다.&lt;br /&gt;
그러나 우리는 D를 최적화하는 목적함수를 2로 나누어 D가 G보다 상대적으로 더 빠르게 학습되지 않도록 하였다.&lt;br /&gt;
또한 minibatch SGD와 Adam을 사용하였다($lr=0.0002, \beta_1 = 0.5, \beta_2 = 0.999$).  또한 batch size는 실험에 따라 1~10으로 조정하였다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;실험experiments&quot;&gt;실험(Experiments)&lt;/h2&gt;

&lt;p&gt;conditional GAN의 보편성을 테스트하기 위해, 다양하게 진행하였다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Problem&lt;/th&gt;
      &lt;th&gt;Dataset&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Semantic labels $\leftrightarrow$ photo&lt;/td&gt;
      &lt;td&gt;Cityspaces dataset&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Architectural labels $\leftrightarrow$ photo&lt;/td&gt;
      &lt;td&gt;CMP Facades&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Map $\leftrightarrow$ aerial photo&lt;/td&gt;
      &lt;td&gt;Google Maps&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;BW $\rightarrow$ color photos&lt;/td&gt;
      &lt;td&gt;ImageNet&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Edges $\rightarrow$ photo&lt;/td&gt;
      &lt;td&gt;Natural Image manifold&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Sketch $\rightarrow$ photo&lt;/td&gt;
      &lt;td&gt;human sketches&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Day $\rightarrow$ night&lt;/td&gt;
      &lt;td&gt;ACM Transactions on Graphics&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Thermal $\rightarrow$ color photos&lt;/td&gt;
      &lt;td&gt;Benchmark dataset and baseline&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Photo with missing pixels $\rightarrow$ inpainted photo&lt;/td&gt;
      &lt;td&gt;Paris StreetView&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;다른 네트워크보다 더 좋은 결과:&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-07-Pix2Pix/04.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;encoder-decoder보다 더 효과적인 U-Net:&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-07-Pix2Pix/05.png&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;Patch의 개수를 늘렸을 때의 선명도 상승:&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-07-Pix2Pix/06.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;구글맵 사진과 도식화한 그림 간 변환 결과:&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-07-Pix2Pix/07.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;Colorization과 이미지 도식화:&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-07-Pix2Pix/08.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;등등 많은 결과가 논문에 나타나 있다.&lt;/p&gt;

&lt;p&gt;사실 colorization 문제와 같은 것에서는 colorization에 특화된 네트워크가 더 좋은 결과를 내기는 한다.&lt;br /&gt;
그러나 이 Pix2Pix는 훨씬 더 넓은 범위의 문제를 커버할 수 있다는 점에서 의의가 있다.&lt;/p&gt;

&lt;p&gt;더 많은 결과에 대해서는 &lt;a href=&quot;https://phillipi.github.io/pix2pix/&quot;&gt;여기&lt;/a&gt;를 참조하라.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;결론conclusion&quot;&gt;결론(Conclusion)&lt;/h2&gt;

&lt;p&gt;이 논문에서는 image-to-image translation 문제에 대해, 특히 고도로 구조화된 그래픽 결과에 대해 conditional adversarial networks가 괜찮은 접근법이라는 것을 보여주었다. 이 네트워크는 문제와 데이터에 대한 loss를 학습함으로써 넓은 범위의 문제에 대해 적합함을 보여주었다.&lt;/p&gt;

&lt;h3 id=&quot;acknowledgments&quot;&gt;Acknowledgments&lt;/h3&gt;

&lt;p&gt;&lt;del&gt;매우 많다 ㅎㅎ&lt;/del&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;참고문헌references&quot;&gt;참고문헌(References)&lt;/h2&gt;

&lt;p&gt;논문 참조!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;결론 이후에도 많은 실험 결과가 있으니 참조하시라. 매우 흥미로운 것들이 많다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-07-Pix2Pix/09.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-07-Pix2Pix/10.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-07-Pix2Pix/11.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-04-07-Pix2Pix/12.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;부록&quot;&gt;부록&lt;/h2&gt;

&lt;h3 id=&quot;generator-architectures&quot;&gt;Generator architectures&lt;/h3&gt;

&lt;p&gt;코드는 &lt;a href=&quot;https://github.com/phillipi/pix2pix&quot;&gt;여기&lt;/a&gt;에 있다.&lt;/p&gt;

&lt;p&gt;encoder는 C64-C128-C256-C512-C512-C512-C512-C512 구조이다(convolution layer).&lt;br /&gt;
decoder는 CD512-CD512-CD512-C512-C256-C128-C64  구조이다.&lt;/p&gt;

&lt;p&gt;decoder의 마지막 레이어 이후 output 채널에 맞게 mapping되고(3, colorization에서는 2), Tanh 함수가 그 뒤를 따른다.&lt;br /&gt;
또한 encoder의 C64에서는 BatchNorm이 없다.&lt;br /&gt;
encoder의 모든 ReLU는 기울기 0.2의 Leaky ReLU이며, decoder는 그냥 ReLU이다.&lt;/p&gt;

&lt;p&gt;U-Net decoder는 다음과 같이 생겼다. 앞서 언급했든 $i$와 $n-i$번째 레이어 사이에 skip-connection이 존재한다.  이는 decoder의 채널의 수를 변화시킨다.&lt;/p&gt;

&lt;p&gt;CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128&lt;/p&gt;

&lt;h3 id=&quot;discriminator-architectures&quot;&gt;Discriminator architectures&lt;/h3&gt;

&lt;p&gt;$ 70 \times 70 $ discriminator의 구조는:&lt;/p&gt;

&lt;p&gt;C64-C128-C256-C512&lt;/p&gt;

&lt;p&gt;단 C64에는 BatchNorm이 적용되지 않는다.&lt;br /&gt;
마지막 레이어 이후 convolution을 통해 1차원으로 mapping하며 마지막에 sigmoid 함수가 적용된다.&lt;br /&gt;
0.2짜리 Leaky ReLU가 적용되었다.&lt;/p&gt;

&lt;p&gt;다른 크기의(patch) D들은 조금씩 깊이가 다르다.&lt;/p&gt;

&lt;p&gt;$ 1 \times 1 $ discriminator: C64-C128(convolution들은 $ 1 \times 1 $ spatial 필터를 사용)&lt;/p&gt;

&lt;p&gt;$ 16 \times 16 $ discriminator: C64-C128&lt;/p&gt;

&lt;p&gt;$ 286 \times 286 $ discriminator: C64-C128-C256-C512-C512-C512&lt;/p&gt;

&lt;h3 id=&quot;학습-상세&quot;&gt;학습 상세&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;$ 256 \times 256 $ 이미지는 $ 286 \times 286 $ 크기로 resize되었다가 random cropping을 통해 다시 $ 256 \times 256 $가 되었다.&lt;/li&gt;
  &lt;li&gt;모든 네트워크는 scratch로부터 학습되었다.&lt;/li&gt;
  &lt;li&gt;weights는 (0, 0.02) 가우시안 분포를 따르는 랜덤 초기값을 가진다.&lt;/li&gt;
  &lt;li&gt;데이터셋마다 조금씩 다른 기타 설정은 논문을 참조하자.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>GAN의 개선 모델들(catGAN, Semi-supervised GAN, LSGAN, WGAN, WGAN_GP, DRAGAN, EBGAN, BEGAN, ACGAN, infoGAN)</title>
   <link href="http://localhost:4000/advanced-GANs/"/>
   <updated>2019-03-20T00:00:00+09:00</updated>
   <id>http://localhost:4000/advanced-GANs</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 catGAN, Semi-supervised GAN, LSGAN, WGAN, WGAN_GP, DRAGAN, EBGAN, BEGAN, ACGAN, infoGAN 등에 대해 알아보도록 하겠다.&lt;/p&gt;

&lt;p&gt;아래쪽의 ACGAN, infoGAN은 발표 시기가 아주 최신은 아니지만 conditional GAN(CGAN)의 연장선상에 있다고 할 수 있기 때문에 따로 빼 놓았다.&lt;/p&gt;

&lt;p&gt;각각에 대해 간단히 설명하면,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;catGAN(Categorical GAN):&lt;/strong&gt; D가 real/fake만 판별하는 대신 class label/fake class을 출력하도록 바꿔서 unsupervised 또는 semi-supervised learning이 가능하도록 하였고 또한 더 높은 품질의 sample을 생성할 수 있게 되었다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Semi-supervised GAN:&lt;/strong&gt; catGAN과 거의 비슷하다. original GAN과는 달리 DCGAN을 기반으로 만들어졌다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;LSGAN:&lt;/strong&gt; 진짜 분포 $ p_{data} $와 가짜 데이터 분포 $p_g$를 비슷하게 만들기 위해, decision boundary에서 멀리 떨어진 sample에게 penalty를 주어 진짜 데이터에 근접하게 만드는 아이디어를 사용했다. 이름답게 loss function에는 Least Square가 사용되었고, 이를 통해 더 선명한 출력 이미지와 학습 과정의 높은 안정성을 얻었다. 또한, 이 최적화 과정이 $\chi^2$ divergence 최소화와 같음을 보였다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;WGAN:&lt;/strong&gt; 실제 데이터의 분포와 가짜 데이터의 분포의 거리를 측정하는 방법으로 &lt;em&gt;Wasserstein Distance&lt;/em&gt;를 정의하여 가짜 데이터를 실제 데이터에 근접하도록 하는 방법을 제시하였는데, 기존의 GAN들이 최적 값으로 잘 수렴하지 않던 문제를 해결, 거의 대부분의 데이터셋에서 학습이 잘 되는 GAN을 만들어냈다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;WGAN_GP:&lt;/strong&gt; Improved WGAN이다. WGAN이 &lt;em&gt;k&lt;/em&gt;-Lipschitz constraints를 만족시키기 위해 단순히 clipping을 수행하는데, 이것이 학습을 방해하는 요인으로 작용할 수 있다. WGAN_GP에서는 gradient penalty라는 것을 목적함수에 추가하여 이를 해결하였고, 학습 안정성을 데이터셋뿐만 아니라 모델 architecture에 대해서도 얻어냈다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;DRAGAN:&lt;/strong&gt; Deep Regret Analytic GAN이다. WGAN에 더불어 gradient penalty를 정규화하고 더 다듬어 gradient penalty schemes(또는 heuristics)를 만들었고, 이를 저자들은 DRAGAN algorithm이라 하였다. 결과적으로 여전히 남아 있던 mode collapse 문제를 더 완화하였다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;EBGAN:&lt;/strong&gt; Energy-Based GAN. 지금까지 대부분의 GAN이 D가 real일 확률을 0/1로 나타냈었다면, 이 모델은 그 구조를 깨고 에너지 기반 모델로 바꿨다는 데 의의가 있다. 그래서 D는 단지 real/fake를 구분하는 것이 아닌 G에 대한 일종의 loss function처럼 동작하며, 실제 구현은 Auto-Encoder으로 이루어졌다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;BEGAN:&lt;/strong&gt; Boundary Equilibrium GAN으로, EBGAN을 베이스로 하고 Watterstein distance를 사용하였으며, 모델 구조를 단순화하고 이미지 다양성과 품질 간 trade-off를 조절할 수 있는 방법 또한 알아냈다고 한다. 이 논문에서는 스스로 &lt;strong&gt;&lt;em&gt;milestone&lt;/em&gt;&lt;/strong&gt;한 품질을 얻었다고 한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ACGAN:&lt;/strong&gt; D를 2개의 분류기로 구성하고 목적함수도 두 개로 나눠서 real/fake, 데이터의 class를 구하는 과정을 분리하여 disentangled한 $z$를 만들었다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;infoGAN:&lt;/strong&gt; 많은 GAN들이 그 내부의 parameter가 심하게 꼬여(entangled) 있고 이는 parameter의 어떤 부분이 어느 역할을 하는지 전혀 알 수 없게 만든다. infoGAN에서는 이를 잘 분리하여, semantic feature를 잘 조작하면 어떤 인자를 조작했느냐에 따라 생성되는 이미지의 각도, 밝기, 너비 등을 임의로 조작할 수 있게 하였다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 글에 소개된 대부분의 GAN은 다음 repository에 구현되어 있다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/znxlwm/pytorch-generative-model-collections&quot;&gt;Pytorch version&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://github.com/hwalsuklee/tensorflow-generative-model-collections?fbclid=IwAR1VSa7c9QOdVcrzuPX995FBwqI1WhOAl43jM2HSzp84sfMw2hMZwsB_KPQ&quot;&gt;Tensorflow version&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;catgan&quot;&gt;catGAN&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1511.06390&quot;&gt;catGAN&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;2015년 11월 처음 제안되었다.&lt;/p&gt;

&lt;p&gt;데이터의 전체 또는 일부가 unlabeled인 경우 clustering은 $p_x$를 직접 예측하는 generative model과 분포를 예측하는 대신 데이터를 직접 잘 구분된 카테고리로 묶는 discriminative model로 나누어지는데, 이 모델에서는 이 두 아이디어를 합치고자 했다.&lt;br /&gt;
논문에서 이 &lt;strong&gt;catGAN&lt;/strong&gt;은 original GAN이 $real, fake$만 구분하던 것을 real인 경우에는 그 class가 무엇인지까지 구분하게($C_1, C_2, …, C_N, C_{fake}$)했다는 점에서 original GAN의 일반화 버전이라고 하였으며, 또한 &lt;a href=&quot;https://papers.nips.cc/paper/4154-discriminative-clustering-by-regularized-information-maximization&quot;&gt;RIM(Regularized Information Maximization)&lt;/a&gt;에서 regularization이 추가가 되었듯 catGAN에선 G가 D에 대한 regularization을 하기 때문에 RIM의 확장판이라고도 하였다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/catGAN1.png&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;RIM에서 최적의 unsupervised classifier의 목적함수로 엔트로피를 사용하였듯 catGAN도 목적함수로 엔트로피 개념을 사용한다. 아래는 논문에 나온 그림이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/catGAN2.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;왼쪽에서 초록색은 G(generate라고 되어 있다), 보라색은 D를 의미한다. 여기서 H는 엔트로피이다.&lt;/p&gt;

&lt;p&gt;오른쪽 그림을 보면, D의 입장에서는:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;i) real data는 실제 class label을 딱 하나 갖고 있기 때문에 해당하는 label일 확률만 1에 가깝고 나머지는 0이어야 한다. 따라서 엔트로피( $ H[p(y \vert x, D)] $ )를 최소화한다.&lt;/li&gt;
  &lt;li&gt;ii) fake data의 경우 특정 class에 속하지 않기 때문에 class label별로 확률은 비슷해야 한다. 따라서 엔트로피$H[p(y \vert x, G(z))]$를 최대화한다.&lt;/li&gt;
  &lt;li&gt;iii) 학습 sample이 특정 class에 속할 확률이 비슷해야 한다는 가정을 했기 때문에, input data $x$에 대한 marginal distribution(주변확률분포)의 엔트로피($H[p(y \vert D)]$)가 최대가 되어야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;G의 입장에서는:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;D를 속여야 하기 때문에 G가 만든 가짜 데이터는 가짜임에도 특정 class에 속한 것처럼 해야 한다. 즉, D의 i) 경우처럼 엔트로피($H[p(y \vert x, G(z))]$)를 최소화한다.&lt;/li&gt;
  &lt;li&gt;생성된 sample은 특정 class에 속할 확률이 비슷해야 하기 때문에 marginal distribution의 엔트로피($H[p(y \vert D)]$)가 최대화되어야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;따라서 D와 G의 목적함수를 정리하면,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_D = max_D ~~~ H_{\chi}[p(y| D)] - \mathbb{E}_{x\sim \chi} [H[p(y|x, D)]] + \mathbb{E}_{z\sim P(z)}[H[p(y|G(z), D)]]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_G = min_G ~~~ H_G[p(y| D)] + \mathbb{E}_{z\sim P(z)}[H[p(y|G(z), D)]]&lt;/script&gt;

&lt;p&gt;다만 $L_D$의 마지막 항을 직접 구하는 것은 어렵기 때문에, $z \sim P(z) $를 $M$개 뽑아 평균을 계산하는 몬테카를로 방법을 쓴다.&lt;/p&gt;

&lt;p&gt;위 목적함수를 사용하여 실험한 결과는 다음과 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/catGAN3.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;Unsupervised catGAN은 9.7%의 error를 보이는 데 반해 $n=100$만의 labeled data가 있는 버전의 경우 error가 1.91%까지 떨어진다. $n=1000$, $n=전체$인 경우 error는 점점 떨어지는 것을 볼 수 있다. 즉, 아주 적은 labeled data를 가진 semi-supervised learning이라도 굉장히 쓸모있다는 뜻이다.&lt;/p&gt;

&lt;p&gt;또한 k-means나 RIM과 비교했을 때 두 원을 잘 분리해내는 것을 볼 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/catGAN4.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;MNIST나 CIFAR-10 데이터도 잘 생성해내는 것을 확인하였다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/catGAN5.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;semi-supervised-gan&quot;&gt;Semi-supervised GAN&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.01583&quot;&gt;Semi-supervised GAN&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;2016년 6월 처음 제안되었다.&lt;/p&gt;

&lt;p&gt;위의 catGAN과 거의 비슷한 역할을 한다. 전체적인 구조도 비슷하다.&lt;/p&gt;

&lt;p&gt;논문 자체가 짧고 목적함수에 대한 내용이 없어서 자세한 설명은 생략한다. 특징을 몇 개만 적자면,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;original GAN과는 달리 sigmoid 대신 softmax를 사용하였다. $N+1$개로 분류해야 하니 당연하다.&lt;/li&gt;
  &lt;li&gt;DCGAN을 기반으로 작성하였다.&lt;/li&gt;
  &lt;li&gt;D가 classifier의 역할을 한다. 그래서 논문에서는 D/C network라고 부른다(D이자 C).&lt;/li&gt;
  &lt;li&gt;classifier의 정확도는 sample의 수가 적을 때 CNN보다 더 높다는 것을 보여주었다. sample이 많을 때는 거의 같았다.&lt;/li&gt;
  &lt;li&gt;original GAN보다 생성하는 이미지의 품질이 좋다.&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/semiGAN.png&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;lsgan&quot;&gt;LSGAN&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1611.04076&quot;&gt;LSGAN&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;2016년 11월 처음 제안되었다.&lt;/p&gt;

&lt;p&gt;original GAN의 sigmoid cross entropy loss function은 vanishing gradients 문제가 있고, 따라서 출력 이미지는 실제 이미지에 비해선 분명히 품질이 떨어진다.&lt;/p&gt;

&lt;p&gt;아래 그림의 (b)에서, 오른쪽 아래의 가짜 데이터는 D를 잘 속이고 있지만 vanishing gradient(sigmoid 그래프의 양쪽 끝을 생각하라) 문제로 인해 거의 업데이트되지 않고, 따라서 가짜 이미지는 실제 이미지와는 동떨어진 결과를 갖는다.&lt;br /&gt;
그러나 (c)처럼 이렇게 경계로부터 멀리 떨어진 sample들을 거리에 penalty를 줘서 경계 근처로 끌어올 수 있다면 가짜 이미지는 실제에 거의 근접하게 될 것이다. LSGAN은 이 아이디어에서 출발한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/LSGAN1.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;그래서, D를 위한 loss function을 least squares로 대체하면, 경계(decision boundary)로부터 먼 sample들은 penalty를 받아 경계 근처로 끌려온다.&lt;/p&gt;

&lt;p&gt;original GAN의 목적함수는 다음과 같았다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_G max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[log D(x)] + \mathbb{E}_{x \sim p_{z}(z)}[log (1-D(G(z)))]&lt;/script&gt;

&lt;p&gt;LSGAN의 목적함수는 다음과 같다. $a$: fake data label , $b$: real data label.&lt;br /&gt;
$c$: G가 원하는 것은 이 $c$라는 값을 D가 fake data라고 믿는 것이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_D V_{\text{LSGAN}}(D) = \frac{1}{2} \mathbb{E}_{x \sim p_{data}(x)}[(D(x)-b)^2] + \frac{1}{2} \mathbb{E}_{x \sim p_{z}(z)}[(D(G(z)) - a)^2]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_G V_{\text{LSGAN}}(G) = \frac{1}{2} \mathbb{E}_{x \sim p_{z}(z)}[(D(G(z)) - c)^2]&lt;/script&gt;

&lt;p&gt;이렇게 목적함수를 바꿈으로써 얻는 이득은 두 가지다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;original GAN과는 달리 decision boundary에서 멀리 떨어진 sample을 오랫동안 가만히 두지 않고, 설령 맞는 영역에 위치한다고 해도 이에 penalty를 준다. 이는 결과적으로 G가 이미지를 생성할 때 decision boundary에 최대한 가까운, 즉 실제 이미지에 가깝게 생성하도록 한다.&lt;/li&gt;
  &lt;li&gt;멀리 떨어진 sample일수록 square 함수에 의해 penalty를 크게 받는다. 따라서 vanishing gradients 문제가 많이 해소되며, 따라서 학습이 안정적이게 된다. original GAN의 sigmoid는 $\vert x \vert$가 클 때 gradient가 매우 작다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;또 한 가지 더: LSGAN의 목적함수를 최적화하는 과정은 $\chi^2$ divergence를 최소화하는 것과 같다.&lt;br /&gt;
간략히 설명하면,&lt;/p&gt;

&lt;p&gt;original GAN에서는 최적화 과정이 Jensen-Shannon divergence를 최소화하는 것을 보였다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;C(G) = KL \biggl( p_{data} \Vert \frac{p_{data}+p_g}{2} \biggr) + KL \biggl( p_{g} \Vert \frac{p_{data}+p_g}{2} \biggr) - log(4)&lt;/script&gt;

&lt;p&gt;이제 LSGAN의 목적함수를 확장해 보면,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_D V_{\text{LSGAN}}(D) = \frac{1}{2} \mathbb{E}_{x \sim p_{data}(x)}[(D(x)-b)^2] + \frac{1}{2} \mathbb{E}_{x \sim p_{z}(z)}[(D(G(z)) - a)^2]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_G V_{\text{LSGAN}}(G) = \frac{1}{2} \mathbb{E}_{x \sim p_{data}(x)}[(D(x)-c)^2] +  \frac{1}{2} \mathbb{E}_{x \sim p_{z}(z)}[(D(G(z)) - c)^2]&lt;/script&gt;

&lt;p&gt;$ V_{\text{LSGAN}}(G) $의 추가된 항은 G의 parameter를 포함하지 않기 때문에 최적값에 영향을 주지 않는다.&lt;/p&gt;

&lt;p&gt;우선 G를 고정했을 때 D의 최적값은:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D^\ast(x) = {bp_{data}(x) + ap_g(x) \over p_{data}(x) + p_g(x)}&lt;/script&gt;

&lt;p&gt;중간 과정을 조금 생략하고 적으면,  $b-c=1, b-a=2$라 했을 때&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;2C(G) = \mathbb{E}_{x \sim p_{data}} [(D^\ast(x)-c)^2] + \mathbb{E}_{x \sim p_{g}} [(D^\ast(x)-c)^2]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= \int_\chi {((b-c)(p_d(x) + p_g(x)) - (b-a)p_g(x))^2 \over p_d(x) + p_g(x)} dx&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= \int_\chi {(2p_g(x) - (p_d(x) + p_g(x)))^2 \over p_d(x) + p_g(x)} dx&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= \chi^2_{Pearson} (p_d + p_g \Vert 2p_g)&lt;/script&gt;

&lt;p&gt;그러므로 LSGAN의 최적화 과정은 $b-c=1, b-a=2$일 때 $p_d + p_g$와 $2p_g$ 사이의 Pearson $\chi^2$ divergence를 최소화하는 과정과 같다.&lt;/p&gt;

&lt;p&gt;학습시킬 때 $a, b, c$ 값을 $a=-1, b=1, c=0$ 또는 $a=0, b=c=1$ 등을 쓸 수 있다. 둘 사이의 차이는 실험 결과 별로 없으므로,  논문에서는 후자를 택했다.&lt;/p&gt;

&lt;p&gt;LSGAN의 구조는 두 가지가 제안되어 있다. 하나는 112$ \times $112 size의 이미지를 출력하는 모델, 다른 하나는 class 개수가 3470개인 task를 위한 것(한자를 분류한다)인데, 충분히 읽기 쉬운 글자를 만들어내는 것을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;아래에 모델 구조를 나타내었다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/LSGAN2.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/LSGAN3.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;많은 class 수를 가진 경우 생성된 이미지 품질이 좋지 못한데, 이유는 입력 class 종류는 매우 많지만 출력은 하나뿐이기 때문이다. 이를 해결하는 방법은 conditional GAN을 쓰는 것이다.&lt;br /&gt;
그러나 one-hot encoding은 너무 비용이 크기 때문에 그 대신 각각의 class에 대응하는 작은 벡터를 linear mapping을 통해 하나 만들어서 모델의 레이어에 붙이는 방식을 썼다. 그 결과가 위 그림과 같으며, 목적함수는 다음과 같이 정의된다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_D V_{\text{LSGAN}}(D) = \frac{1}{2} \mathbb{E}_{x \sim p_{data}(x)}[(D(x \vert \Phi(y))-1)^2] + \frac{1}{2} \mathbb{E}_{x \sim p_{z}(z)}[(D(G(z) \vert \Phi(y)))^2]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_G V_{\text{LSGAN}}(G) = \frac{1}{2} \mathbb{E}_{x \sim p_{z}(z)}[(D(G(z \vert \Phi(y))) - 1)^2]&lt;/script&gt;

&lt;p&gt;$y$는 label vector, $ \Phi(\cdot) $은 linear mapping 함수이다.&lt;/p&gt;

&lt;p&gt;LSUN-bedroom 등 여러 데이터셋에 대한 실험 결과이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/LSGAN4.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/LSGAN5.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/LSGAN6.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/LSGAN7.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;마지막 그림의 경우 한자 글자를 꽤 잘 생성해내는 것을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;LSGAN도 GAN의 역사에서 꽤 중요한 논문 중 하나이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;wgan&quot;&gt;WGAN&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1701.07875&quot;&gt;WGAN&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;2017년 1월 처음 제안되었다.&lt;/p&gt;

&lt;p&gt;소스코드: &lt;a href=&quot;https://github.com/martinarjovsky/WassersteinGAN&quot;&gt;pytorch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;참고할 만한 사이트: &lt;a href=&quot;https://medium.com/@jonathan_hui/gan-wasserstein-gan-wgan-gp-6a1a2aa1b490&quot;&gt;링크&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;이 논문도 f-GAN처럼 수학으로 넘쳐흐른다. 다만 요약하지 않을 뿐&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이 논문의 수학을 이해하는 데 있어 매우 좋은 참고자료가 있다: &lt;a href=&quot;https://www.slideshare.net/ssuser7e10e4/wasserstein-gan-i&quot;&gt;링크&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;이 논문은 실제 데이터 분포와 가짜 데이터 분포 사이의 거리를 측정하는 방법을 바꿈으로써 GAN이 &lt;em&gt;매우&lt;/em&gt; 안정적인 학습을 할 수 있도록 만들었다는 것에 의의가 있다.&lt;br /&gt;
기억할 것은 하나다: &lt;strong&gt;거의 대부분의 데이터셋에서 학습이 안정적으로 잘 진행된다&lt;/strong&gt;(다만 경우에 따라 약간 느리다고 한다).&lt;/p&gt;

&lt;p&gt;original GAN부터 시작해서 GAN의 기본 아이디어는 두 분포 사이의 거리를 최소화하도록 G(와 D)를 잘 학습시키는 것이다. original GAN의 경우 이 최적화 과정이 &lt;em&gt;Jenson-Shannon divergence&lt;/em&gt;(JSD)를 최소화하는 것과 같다는 것은 이미 증명되어있다.&lt;/p&gt;

&lt;p&gt;그러나 이 JSD는 모든 분포의 거리를 효과적으로 측정해주지 못한다. 예를 들어&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{P}_0(x=0, y&gt;0), \quad \mathbb{P}_\theta(x=\theta, y&gt;0)&lt;/script&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/WGAN1.png&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;두 (반직선 형태인) 분포 간의 거리를 JSD로 측정하면,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;JS ( \mathbb{P}_{0}, \mathbb{P}_\theta ) = 0 \ \ if \ \theta=0, \quad log \ 2 \quad otherwise&lt;/script&gt;

&lt;p&gt;즉, $ \theta $가 1이든 0.0001이든 상관없이 두 분포가 얼마나 가까운지에 대한 정보를 JSD는 전혀 제공해주지 못한다. 이는 KL divergence도 마찬가지이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;KL ( \mathbb{P}_{0}, \mathbb{P}_{\theta}) = 0 \ \ if \ \theta=0, \quad \infty  \quad otherwise&lt;/script&gt;

&lt;p&gt;참고로 논문에 나온 다른 측정방식으로 &lt;em&gt;Total Variation&lt;/em&gt;(TV)이 있는데 별반 다를 것은 없다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lambda( \mathbb{P}_{0}, \mathbb{P}_{\theta}) = 0 \ \ if \ \theta=0, \quad 1 \quad otherwise&lt;/script&gt;

&lt;p&gt;참고로 TV는 이렇게 정의된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\delta(\mathbb{P}_r, \mathbb{P}_g) = sup_{A \in \Sigma} \vert \mathbb{P}_r(A) - \mathbb{P}_g(A) \vert&lt;/script&gt;

&lt;p&gt;그래서 WGAN의 저자들은 이와 비슷한 분포를 가진 경우 등은 GAN이 수렴을 잘 하지 못할 것이라고 하며 분포 간 거리를 측정하는 새로운 &lt;em&gt;Earth-Mover&lt;/em&gt;(EM) distance 또는 &lt;em&gt;Wasserstein-1&lt;/em&gt; distance라고 부르는 것을 제안했다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;W(\mathbb{P}_r, \mathbb{P}_g) = \text{inf}_{\gamma \in \Pi(\mathbb{P}_r, \mathbb{P}_g)} \int d(x, y) \gamma (dxdy)  \\ \qquad = \text{inf}_{\gamma \in \Pi(\mathbb{P}_r, \mathbb{P}_g)} \ \mathbb{E}_{(x, y) \sim \gamma} [ \Vert x - y \Vert ]&lt;/script&gt;

&lt;p&gt;$\Pi(\mathbb{P}, \mathbb{Q})$는 두 확률분포 $\mathbb{P}, \mathbb{Q}$의 결합확률분포들의 집합이고, $\gamma$는 그 중 하나이다.&lt;br /&gt;
즉 위 식은 모든 결합확률분포 $\Pi(\mathbb{P}, \mathbb{Q})$ 중 $d(x,y)$의 기댓값을 가장 작게 추정한 값이다.&lt;/p&gt;

&lt;p&gt;이제 이 식을 위 그림의 두 분포에 적용하면 거리는&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;W(\mathbb{P}_0, \mathbb{P}_\theta) = \vert \theta \vert&lt;/script&gt;

&lt;p&gt;로 아주 적절하게 나온다.&lt;/p&gt;

&lt;p&gt;그래서 이렇게 나온 Wasserstein distance는 &lt;span&gt;$\mathbb{P}_r$&lt;/span&gt;과 &lt;span&gt;$\mathbb{P}_\theta$&lt;/span&gt; 사이의 거리를 &lt;span&gt;$\mathbb{P}_r$&lt;/span&gt;를 &lt;span&gt;$\mathbb{P}_\theta$&lt;/span&gt;로 옮길 때 필요한 양과 거리의 곱으로 측정한다.&lt;br /&gt;
이를 어떤 산(분포) 전체를 옮기는 것과 같다고 해서 &lt;em&gt;Earth Mover&lt;/em&gt; 또는 EM distance라고 불린다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Cost = mass \times distance&lt;/script&gt;

&lt;p&gt;original GAN과 목적함수의 차이를 비교하면,&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;Discriminator&lt;/th&gt;
      &lt;th&gt;Generator&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;GAN&lt;/td&gt;
      &lt;td&gt;$\nabla_{\theta_d} \frac{1}{m} \sum^m_{i=1} \ [log D(x^{(i)}) + log (1-D(G(z^{(i)})))] $&lt;/td&gt;
      &lt;td&gt;$\nabla_{\theta_g} \ \frac{1}{m} \sum^m_{i=1} log (D(G(z^{(i)}))) $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;WGAN&lt;/td&gt;
      &lt;td&gt;$\nabla_w \frac{1}{m} \ \sum^m_{i=1} \ [f(x^{(i)}) + f(G(z^{(i)}))] $&lt;/td&gt;
      &lt;td&gt;$\nabla_{\theta} \frac{1}{m} \ \sum^m_{i=1} \ f(G(z^{(i)})) $&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;차이점이 더 있는데,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$f$는 &lt;em&gt;k&lt;/em&gt;-Lipschitz function이어야 한다. 이를 위해 WGAN에서는 단순히 $[c, -c]$로 clipping한다.&lt;/li&gt;
  &lt;li&gt;log_sigmoid를 사용하지 않는다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제 WGAN 논문에 제시된 알고리즘을 보자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/WGAN2.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;알고리즘에 굉장히 특별하진 않다. optimizer로 &lt;em&gt;RMSProp&lt;/em&gt;을 사용한 것이 약간의 차이점이다.&lt;/p&gt;

&lt;p&gt;학습 과정에서의 장점을 보여주는 그림이 논문에 제시되어 있다. 두 Gaussian 분포를 볼 때 GAN의 수렴이 훨씬 잘 된다는 말이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/WGAN3.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;WGAN 실험 결과를 보면 다음과 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/WGAN4.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\\&lt;/script&gt;
사실 이 논문은 부록을 포함해 32page짜리 논문으로 수학이 넘쳐흐르지만, 필자의 논문 리뷰는 이 논문이 무슨 내용인지 정도만 전달하려는, 내용을 적당히 요약하여 보여주는 것이 목적이므로 자세한 수식 및 증명 과정은 따로 적지 않는다.&lt;/p&gt;

&lt;p&gt;&lt;del&gt;궁금하면 직접 읽으면 된다&lt;/del&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;improved-wgan&quot;&gt;Improved WGAN&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.00028&quot;&gt;WGAN_GP&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;2017년 3월 처음 제안되었다.&lt;/p&gt;

&lt;p&gt;소스코드: &lt;a href=&quot;https://github.com/caogang/wgan-gp&quot;&gt;pytorch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;참고할 만한 사이트: &lt;a href=&quot;https://medium.com/@jonathan_hui/gan-wasserstein-gan-wgan-gp-6a1a2aa1b490&quot;&gt;링크&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WGAN은 clipping을 통해 Lipschitz 함수 제약을 해결하긴 했지만, 이는 예상치 못한 결과를 초래할 수 있다:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;(WGAN 논문에서 인용)&lt;br /&gt;
만약 clipping parameter($c$)가 너무 크다면, 어떤 weights든 그 한계에 다다르기까지 오랜 시간이 걸릴 것이며, 따라서 D가 최적화되기까지 오랜 시간이 걸린다.&lt;br /&gt;
반대로 $c$가 너무 작다면, 레이어가 크거나 BatchNorm을 쓰지 않는다면 쉽게 vanishing gradients 문제가 생길 수 있다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;clipping은 단순하지만 문제를 발생시킬 수 있다. 특히 $c$가 잘 정해지지 않았다면 품질이 낮은 이미지를 생성하고 수렴하지 않을 수 있다. 모델의 성능은 이 $c$에 매우 민감하다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/WGAN_GP1.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;가중치 clipping은 가중치를 정규화하는 효과를 갖는다. 이는 모델 $f$의 어떤 한계치를 설정하는 것과 같다.&lt;/p&gt;

&lt;p&gt;그래서 이 논문에서는 &lt;em&gt;gradient penalty&lt;/em&gt;라는 것을 D의 목적함수에 추가해 이 한계를 극복하고자 한다(G의 목적함수는 건드리지 않은 듯 하다).&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L = \mathbb{E}_{\hat{x} \sim \mathbb{P}_g} \ [D(\hat{x})] - \mathbb{E}_{x \sim \mathbb{P}_r} \ [D(x)] + \lambda \ \mathbb{E}_{\hat{x} \sim \mathbb{P}_{\hat{x}}} \ [(\Vert \nabla_{\hat{x}}D(\hat{x}) \Vert_2 - 1)^2 ]&lt;/script&gt;

&lt;p&gt;즉 clipping을 적용하는 대신 WGAN_GP는 gradient norm이 목표인 $1$에서 멀어지면 penalty를 주는 방식을 택했다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Sampling Distribution:&lt;/strong&gt; $\mathbb{P}_{\hat{x}}$는 실제 데이터 분포 $\mathbb{P}_r$과 G가 생성한 데이터 분포 $\mathbb{P}_g$로부터 추출한 point 쌍들 사이에 직선을 하나 그어서 얻은 것이다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Penalty coefficient:&lt;/strong&gt; $\lambda$가 붙은 마지막 항(이 논문에서는 $\lambda=10$으로 고정됨)이 gradient penalty이다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;No critic batch normalization:&lt;/strong&gt; BN은 D의 문제의 형식을 1-1 매칭 문제에서 전체 batch input-batch output으로 바꿔버린다. 이 논문에서 새로 만든 gradient penalty 목적함수는 이 조건에 맞지 않기 때문에 BN을 쓰지 않았다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Two-sided penalty:&lt;/strong&gt; gradient가 단지 $1$ 아래로 내려가는 것을 막는(one-sided) 대신 $1$ 근처에 머무르도록 했다(two-sided).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그래서 발전시킨 알고리즘은 다음과 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/WGAN_GP2.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;좀 특이하게도 이 논문에는 모델 구조(architecture)를 바꿔가면서 한 실험 결과가 있다. 확실히 WGAN_GP 버전이 뛰어남을 볼 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/WGAN_GP3.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;WGAN_GP만이 (이 논문에서 실험한) 모든 architecture에 대해서 제대로 된 학습에 성공하였다고 한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/WGAN_GP4.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;여러 실험 결과들이 더 있지만 하나만 더 소개하면,&lt;br /&gt;
논문에서는 아래 이미지(LSUN-bedroom)가 지금까지의 연구에 의해 나온 것 중 제일 잘 나온 것이라고 믿는다고 한다. 각각의 이미지가 $128 \times 128 $ 크기라 그다지 고해상도는 아니긴 하지만 어쨌든 실제로 꽤 깨끗한 이미지로 보인다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/WGAN_GP5.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\\&lt;/script&gt;

&lt;p&gt;종합하면 이 개선된 버전은 데이터셋뿐만 아니라(WGAN) 모델 구조에 대해서도(architecture) 학습 안정성을 얻었다고 할 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;dragan&quot;&gt;DRAGAN&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1705.07215&quot;&gt;DRAGAN&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;2017년 5월 처음 제안되었다.&lt;/p&gt;

&lt;p&gt;소스코드: &lt;a href=&quot;https://github.com/kodalinaveen3/DRAGAN?fbclid=IwAR3mPLo134C3xx4QerWUCCTWqCVfH7seDkPK5Rlkr_trAjxwYfCHWvcs1dk&quot;&gt;tensorflow&lt;/a&gt;, &lt;a href=&quot;https://github.com/jfsantos/dragan-pytorch&quot;&gt;pytorch&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;참고할 만한 사이트: &lt;a href=&quot;https://lernapparat.de/more-improved-wgan/&quot;&gt;링크&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WGAN_GP 논문과 차이점은 D(critic network)에 의해 계산되는 식별함수 $f$가 gradient에 있어 어떤 제한을 받는가이다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;WGAN_GP에서는 gradient가 실제 데이터와 가짜 데이터 사이의 직선 위 랜덤한 곳으로 설정되기 때문에 모든 곳에서 $ \vert \nabla f \vert = 1 $를 향한다.&lt;/li&gt;
  &lt;li&gt;DRAGAN에서는 gradient가 실제에 “가깝게” sampling된다. 이는  실제 데이터 근처에 있을 때만 $ \vert \nabla f \vert = 1 $를 향한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;아래 그림은 위 차이를 보여준다. &lt;a href=&quot;(https://lernapparat.de/more-improved-wgan/)&quot;&gt;참고 사이트&lt;/a&gt;에서 가져왔다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/DRAGAN1.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;간단히 DRAGAN은 실제 데이터 분포(manifold)에 가까울 때만 gradient penalizing을 시켜 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/03/GAN/#mode-collapsing&quot;&gt;mode collapsing&lt;/a&gt;을 막을 수 있다.&lt;/p&gt;

&lt;p&gt;$ \lambda $가 penalty hyperparameter로 사용되는데, 작은 $\lambda$는 toy tasks에 있어 특히 잘 학습됨을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;이 논문이 기여한 바는 다음과 같다:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;AGD를 regret minimization으로 봄으로써 GAN 학습에 대한 추론을 제안하였다.&lt;/li&gt;
  &lt;li&gt;nonparametric 한계 안에서 GAN 학습의 점근적 수렴과 매 단계마다 D가 최적이어야 할 필요가 없다는 것을 증명하였다.&lt;/li&gt;
  &lt;li&gt;AGD가 비 볼록(non-convex) 게임에서 잠재적으로 어떻게 나쁜 국소평형 지점(local minima)으로 수렴하는지와 이것이 GAN의 학습에 있어 mode collapsing에 얼마나 큰 책임이 있는지를 논했다.&lt;/li&gt;
  &lt;li&gt;실제 데이터에 근접한 경우에 D의 $f$의 gradient가 큰 값을 가질 때 어떻게 mode collapse 상황이 생기는지를 특징지었다.&lt;/li&gt;
  &lt;li&gt;이러한 관찰에 의해 DRAGAN(a novel gradient penalty scheme)을 소개하였고 이것이 mode collapsing 문제를 완화해준다는 것을 보였다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;원래의 GAN들은, sample이 real data에 가까움에도 sharp gradient를 갖기 떄문에 mode collapse의 정의에 의해 이것이 나타난다. 이러한 sharp gradient는 G가 많은 $z$ 벡터들을 하나의 출력값 $x$로 가게끔 하고 따라서 형평성(equilibrium, mode collapse의 정의를 생각하라)을 약화시키도록 한다.&lt;br /&gt;
그래서 이러한 실패를 막으려면 D에게 다음과 같은 penalty를 줘서 gradient를 정규화시키는 것이다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lambda \ \cdot \ \mathbb{E}_{x \sim P_{real}, \ \delta \sim N_d (0, \ cI)} [\Vert \nabla_X D_\theta(x+\delta) \Vert^2 ]&lt;/script&gt;

&lt;p&gt;이 전략은 GAN 학습의 안정성을 증가시킨다. 이 논문에는 그 결과와 그렇게 되는 이유가 설명되어 있으니 자세한 부분은 이를 참고하자.&lt;/p&gt;

&lt;p&gt;그러나, 이 논문에서는 위의 penalty 식이 여전히 불안정하며 지나치게 penalty를 주는(over-penalized) 경우가 있을 수 있고, 따라서 D는 real point $x$와 noise인 $x+\lambda$에게 동일한 “실제 데이터일” 확률을 부여할 수 있다는 것을 발견하였다. 따라서 더 나은 gradient penalty 식은&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lambda \ \cdot \ \mathbb{E}_{x \sim P_{real}, \ \delta \sim N_d (0, \ cI)} [ \ max(0, \ \Vert \nabla_X D_\theta(x+\delta) \Vert^2 - k )\ ]&lt;/script&gt;

&lt;p&gt;그리고, 실험적인 최적화를 적용한 최종 penalty 식은&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lambda \ \cdot \ \mathbb{E}_{x \sim P_{real}, \ \delta \sim N_d (0, \ cI)} [ \ \Vert \nabla_X D_\theta(x+\delta) \Vert - k \ ]^2&lt;/script&gt;

&lt;p&gt;결과적으로 real data의 작은 동요(변화, perturbations)에도 잘 작동하였다.&lt;/p&gt;

&lt;p&gt;이 논문에서 사용한 gradient penalty schemes 또는 heuristics는 DRAGAN algorithm으로 부르기로 하였다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;ebgan&quot;&gt;EBGAN&lt;/h1&gt;

&lt;p&gt;2016년 9월 처음 제안되었다.&lt;/p&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1609.03126&quot;&gt;EBGAN&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;이 논문에서는 D를 data manifold에 가까운 지점에서는 낮은 에너지를, 그렇지 않은 지점에서는 높은 에너지를 갖도록 하는 일종의 energy function으로 보는 Energy-Based GAN을 소개한다. 일반 GAN과 비슷하게 G는 최대한 낮은 에너지를 갖는(즉, 실제 데이터와 비슷한) sample을 생성하고, D는 G가 생성한 이미지들에는 높은 에너지를 부여하도록 한다.&lt;br /&gt;
D를 energy function으로 봄으로써 다양한 architecture과 loss function에 사용할 수 있게 되었다.  이 논문에서는 D를 auto-encoder로 구현하였다.&lt;br /&gt;
결과적으로 EBGAN은 학습이 더 안정적이며 또한 고해상도 이미지를 생성하는 데에도 능하다는 것을 보여주었다.&lt;/p&gt;

&lt;p&gt;우선 Energy Based Model은,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;LeCun이 2006년 제안하였으며&lt;/li&gt;
  &lt;li&gt;input space를 하나의 scalar(energy로 지칭된다)로 mapping하는 모델이다.&lt;/li&gt;
  &lt;li&gt;학습이 제대로 된 경우 낮은 에너지를, 아니면 높은 에너지를 생성하며&lt;/li&gt;
  &lt;li&gt;CNN등의 학습에서 cross entropy loss를 사용하여 loss를 낮춰가는 것과 비슷하다. 여기선 loss랑 energy랑 비슷하게 사용된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;간단히 이 Energy Based Model을 GAN에 적용시킨 것이 EBGAN이다.&lt;/p&gt;

&lt;p&gt;이 논문의 contribution은,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;GAN 학습에 energy-based를 적용시켰고&lt;/li&gt;
  &lt;li&gt;simple hinge loss에 대해, 시스템이 수렴했을 때 G는 데이터 분포를 따르는 point를 생성하게 된다는 증명과&lt;/li&gt;
  &lt;li&gt;energy를 reconstruction error로 본 auto-encoder architecture로 EBGAN framework를 만들었고&lt;/li&gt;
  &lt;li&gt;EBGAN과 확률적 GAN 모두에게 좋은 결과를 얻을 수 있는 시스템적 실험셋(hyperparameter 등)&lt;/li&gt;
  &lt;li&gt;ImageNet 데이터셋에 대해 256$\times$256 고해상도 이미질르 생성할 수 있음을 보여주었다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;목적함수는 다음과 같이 정의된다. $[\cdot]^+ = max(0,\  \cdot)$이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_D(x, z) = D(x) + [m - D(G(z))]^{+}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_G(z) = D(G(z))&lt;/script&gt;

&lt;p&gt;EBGAN은 per-pixel Euclidean distance를 사용한다.&lt;/p&gt;

&lt;p&gt;찾아낸 해가 optimum인지에 대한 증명은 Theorem 1과 2로 나누어져 증명이 논문에 수록되어 있다. 간략히 소개하기엔 꽤 복잡하므로 넘어간다.&lt;/p&gt;

&lt;p&gt;D의 구조를 나타내면 다음과 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/EBGAN1.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;왜 auto-encoder를 썼냐 하면:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;D가 오직 0과 1 두 값만 낸다면 한 minibatch 안에서 많은 다른 sample들이 orthogonal에서 멀어질 것임을 뜻한다. 이는 비효율적인 학습을 초래하며, minibatch size를 줄이는 것은 현재 하드웨어 상으로 별로 좋은 옵션이 아니다. 그래서 이 대신 reconstruction-based output을 씀으로써 D에게 좀 더 다양한 target을 제공한다.&lt;/li&gt;
  &lt;li&gt;Auto-encoder는 전통적으로 energy-based model을 표현하는 좋은 모델이다. auto-encoder는 supervision이나 negative sample 같은 것 없이도 energy manifold를 잘 학습할 수 있다. 이는 EBGAN auto-encoding model이 &lt;em&gt;실제&lt;/em&gt; 데이터를 복원하도록 학습했을 때, D는 그 data manifold를 스스로 찾아낼 수 있다는 뜻이다. 반대로 G로부터의 negative sample이 없다면 binary logistic loss로 학습된 D는 무의미하다는 뜻이기도 하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 논문에서는 &lt;strong&gt;repelling regularizer&lt;/strong&gt;라는 것을 제안하는데, 이는 모델이 겨우 몇 개의 $p_{data}$로 뭉쳐 있는 sample들을 생성하는 것을 고의로 막기 위한 것으로 EBGAN auto-encoder model에 최적화된 것이다. &lt;br /&gt;
Pulling-away Term, PT는 다음과 같이 정의된다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f_{PT}(S) = \frac{1}{N(N-1)} \sum_i \sum_{j \ne i} \Bigl( \frac{S_i S_j}{\Vert S_i \Vert \Vert S_j \Vert } \Bigr)^2&lt;/script&gt;

&lt;p&gt;PT는 minibatch 상에서 동작하고 쌍으로 sample representation을 orthogonalize하려고 한다. 논문에서는 PT로 학습된 EBGAN auto-encoder model을 &lt;strong&gt;EBGAN-PT&lt;/strong&gt;라고 부르기로 하였다.&lt;/p&gt;

&lt;p&gt;이 논문의 실험결과는 다른 GAN과는 약간 다르다. &lt;em&gt;Inception score&lt;/em&gt;를 생성 품질을 측정하는 척도로 사용하여 GAN과 EBGAN의 생성 품질을 비교한 것이다. 점수가 높을수록 품질이 좋은 것이도, 각 막대그래프는 해당 점수를 가진 sample의 비율이 얼마나 되는지를 나타낸 것이다. 따라서 각 막대가 오른쪽에 많이 분포할수록 생성 품질이 좋다고 할 수 있다.&lt;br /&gt;
아래 그림은 일부만 가져온 것이다. 논문에서도 그림이 너무 작으니 pdf에서 확대해서 보라는 것을 추천하고 있다. 그림이 15개 정도 있는데, 실험 조건만 다를 뿐 대부분 비슷한 분포를 보이고 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/EBGAN2.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;일반 GAN과 비교하면 MNIST 생성 품질도 확실히 좋은 것을 볼 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/EBGAN3.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;또 LSUN, CELEBA, ImageNet 데이터셋에 대해서도 실험한 결과들이 논문에 실려 있다. 대부분의 이미지는 품질이 훨씬 좋고 선명한 이미지 품질을 볼 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;began&quot;&gt;BEGAN&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.10717&quot;&gt;BEGAN&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;2017년 3월 처음 제안되었다.&lt;/p&gt;

&lt;p&gt;구글이 내놓은 GAN 논문이다. 이 논문에서 중요한 특징 및 개선점은,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모델 구조는 더 단순해졌고, 여전히 빠르고 안정적인 학습이 가능하다.&lt;/li&gt;
  &lt;li&gt;EBGAN을 바탕으로 해 energy와 auto-encoder를 사용한다. 다만 loss는 WGAN의 Wasserstein distance를 사용한다.&lt;/li&gt;
  &lt;li&gt;대부분의 GAN이 ‘실제 데이터 분포’와 ‘가짜 데이터 분포’ 사이의 거리를 좁히기 위해 노력해왔다면, BEGAN은 ‘진짜 데이터에 대한 auto-encoder 데이터 분포’와 ‘가짜 데이터에 대한 auto-encoder 데이터 분포’ 사이의 거리를 계산한다.&lt;/li&gt;
  &lt;li&gt;D가 G를 압도하는 상황이 발생하는 것을 막기 위해 D와 G의 equilibrium을 조절하는 hyperparameter $\gamma$를 도입하였다. &lt;em&gt;diversity ratio&lt;/em&gt;라고 부른다는데, 이것으로
    &lt;ul&gt;
      &lt;li&gt;auto-encoder가 데이터를 복원하는 것과 진짜/가짜를 구별하는 것 사이의 균형을 맞추고&lt;/li&gt;
      &lt;li&gt;$\gamma$가 낮으면 auto-encoder가 새 이미지를 생성하는 것에 집중한다는 것이므로 이미지 다양성이 떨어진다. 반대는 당연히 반대의 효과를 가진다.&lt;/li&gt;
      &lt;li&gt;이 equilibrium 개념을 가져와서 수렴(즉, 학습)이 잘 되었는지를 판별하는 데 쓸 수도 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 논문은 결과에 비해 수식이 꽤 단순한 편이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;auto-encoder의 Wasserstein distance 하한&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;우선 pixel-wise auto-encoder를 학습할 때 $ \mathcal{L}: \mathbb{R}^{N_x} \mapsto \mathbb{R}^+$ 를 정의하면,&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/BEGAN1.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;$\mu_{1, 2}$를 auto-encoder loss의 두 분포라 하고, $\Gamma(\mu_1, \mu_2)$를 모든 $\mu_1$과 $\mu_2$의 결합들의 집합이라 하고, $m_{1, 2} \in \mathbb{R}$을 각 평균이라 하면, Wasserstein distance는&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;W_1(\mu_1, \mu_2) = inf_{\gamma \in \Gamma(\mu_1, \mu_2)} \ \mathbb{E}_{(x_1, x_2) \sim \gamma} [\vert x_1 - x_2 \vert ]&lt;/script&gt;

&lt;p&gt;Jensen’s inequality를 써서&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;inf \mathbb{E}[ \vert x_1 - x_2 \vert ] \geqslant inf \vert \mathbb{E}[x_1 - x_2] \vert = \vert m_1 - m_2 \vert&lt;/script&gt;

&lt;p&gt;데이터 분포 간 사이의 거리를 구하려는 것이 아니라 auto-encoder loss distribution의 Wasserstein distance를 구하려고 하는 것이라는 것을 알아둘 필요가 있다.&lt;/p&gt;

&lt;p&gt;GAN의 목적함수에서, $\vert m_1 - m_2 \vert $를 최대화하는 것은 딱 두 가지인데, $m_1$이 0으로 가는 것이 auto-encoder가 실제 이미지를 생성하는 것으로 자연스럽기 때문에 선택한 것은 다음 중 (b)이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/BEGAN2.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;GAN의 목적함수를 정리하면,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_D = \mathcal{L}(x;\theta_D) - \mathcal{L}(G(z_D;\theta_G);\theta_D) \qquad \text{for} \ \ \theta_D&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{L}_G = -\mathcal{L}_D \qquad \qquad \qquad \qquad \qquad \qquad \text{for} \ \ \theta_G&lt;/script&gt;

&lt;p&gt;참고: $ G(\cdot) = G(\cdot, \ \theta_G), \mathcal{L}(\cdot) = \mathcal{L}(\cdot ; \ \theta_D)$이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;D와 G의 평형(equilibrium)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;만약 평헝이 이루어졌다면 다음은 당연하다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{E} [ \mathcal{L}(x)] = \mathbb{E}[\mathcal{L}(G(z))]&lt;/script&gt;

&lt;p&gt;한쪽이 지나치게 강해지는 것을 막기 위해, diversity ratio $\gamma$를 정의하였다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\gamma = \frac{\mathbb{E}[\mathcal{L}(G(z))]}{ \mathbb{E}[\mathcal{L}(x)] } \in [0, 1]&lt;/script&gt;

&lt;p&gt;이것으로 조금 위에서 말한 이미지의 다양성과 품질 간 trade-off, D와 G의 평형 등을 모두 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;BEGAN의 목적함수&lt;/strong&gt;&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/BEGAN3.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;$ \mathbb{E}[\mathcal{L}(G(z))]  = \gamma \mathbb{E}[ \mathcal{L}(x)] $를 유지하기 위해 Proportional Control Theory를 사용하였다.
    &lt;ul&gt;
      &lt;li&gt;$k_t \in [0, 1]$를 사용하여 얼마나 경사하강법 중 $\mathcal{L}(G(z))$를 강조할 것인지를 조절한다.&lt;/li&gt;
      &lt;li&gt;$k_0 = 0$&lt;/li&gt;
      &lt;li&gt;t가 지날수록 값이 커진다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;$\lambda_k$는 learning rate와 비슷하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;수렴 판별 방법&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;조금 전의 equilibrium 컨셉을 생각해서, 수렴과정을 가장 가까운 복원 $\mathcal{L}(x)$를 찾는 것으로 생각할 수 있다.&lt;/p&gt;

&lt;p&gt;수렴 측정방법은 다음과 같이 표현 가능하다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{M}_{global} = \mathcal{L}(x) + \vert \gamma \mathcal{L}(x) - \mathcal{L}(G(z_G)) \vert&lt;/script&gt;

&lt;p&gt;이는 모델이 잘 학습되어 최종 상태에 도달했는지, 아니면 mode collapsing했는지를 판별할 때 쓸 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Model architecture&lt;/strong&gt;&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/BEGAN4.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;DCGAN과는 달리&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;batch norm&lt;/li&gt;
  &lt;li&gt;dropout&lt;/li&gt;
  &lt;li&gt;transpose convolution&lt;/li&gt;
  &lt;li&gt;exponential growth for convolution filters&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;등이 다 없다. 모델 구조가 상당히 단순함을 알 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;실험 결과&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;간단히 말하면..좋다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/BEGAN5.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;예전에 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/17/DCGAN/&quot;&gt;DCGAN&lt;/a&gt;에서 봤던 interpolating도 잘 됨을 확인할 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/BEGAN6.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;acgan&quot;&gt;ACGAN&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.09585&quot;&gt;ACGAN&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;2016년 10월 처음 제안되었다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/17/DCGAN/&quot;&gt;DCGAN&lt;/a&gt;에서는 $z$가 속한 벡터공간의 각 차원별 특징은 사람이 해석할 수 없는 수준이다. 즉 $z$의 요소를 변화시킬 때 사진이 변화하는 형상은 알 수 있지만, 각각의 차원이 정확히 무슨 역할을 하고 어떤 특징을 갖는지는 알 수가 없다.&lt;br /&gt;
그러나 해석하기 쉬운 특징량(disentangled latend code)에 의존하는 모델들이 여럿 제안되었는데, 그것은 앞에서 설명했던 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/19/CGAN/&quot;&gt;CGAN&lt;/a&gt;, ACGAN, &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/20/advanced-GANs/#infogan&quot;&gt;infoGAN&lt;/a&gt; 등이 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/ACGAN1.png&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;ACGAN이 original GAN 및 CGAN과 다른 점은,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;D는 2개의 분류기로 구성되는데
    &lt;ul&gt;
      &lt;li&gt;하나는 original GAN과 같은 real/fake 판별&lt;/li&gt;
      &lt;li&gt;다른 하나는 데이터의 class 판별&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;목적함수: 맞는 &lt;strong&gt;S&lt;/strong&gt;ource의 log-likelihood $L_S$, 맞는 &lt;strong&gt;C&lt;/strong&gt;lass의 log-likelihood $L_C$ 두 개로 나누어
    &lt;ul&gt;
      &lt;li&gt;$L_S$는 기존 GAN의 목적함수와 같다. 즉 real/fake를 판별하는 것과 관련이 있다.&lt;/li&gt;
      &lt;li&gt;$L_C$는 그 데이터의 class를 판별하는 것과 관련이 있다. CGAN에서 본 것과 약간 비슷하다.&lt;/li&gt;
      &lt;li&gt;D는 $L_S+L_C$를 최대화하고&lt;/li&gt;
      &lt;li&gt;G는 $L_C-L_S$를 최대화하도록 학습된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_S = E[log \ p(S=real \vert X_{real})] +  E[log \ p(S=fake \vert X_{fake})]&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_C = E[log \ p(C=c \quad \ \vert X_{real})] + E[log \ p(C=c \ \ \quad  \vert X_{fake})]&lt;/script&gt;

&lt;p&gt;실험은 ImageNet과 CIFAR-10에 대해 진행하였다고 한다. 결과는 (위의 BEGAN에 비해) 아주 놀랍지는 않아서(물론 예전 논문이다) 생략한다.&lt;/p&gt;

&lt;p&gt;대신 실험 시 사용한 모델 구조를 가져왔다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/ACGAN2.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/ACGAN3.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;infogan&quot;&gt;infoGAN&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.03657&quot;&gt;infoGAN&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;2016년 6월 처음 제안되었다.&lt;/p&gt;

&lt;p&gt;original GAN은 input vector $z$에 어떠한 제한도 없이 단순히 무작위 값을 집어넣었기 때문에, 이러한 $z$의 각 차원은 역할이 분리되지 않고 심하게 꼬여(entangled) 있다.&lt;br /&gt;
그러나 이 domain들은 서로 다른 역할을 하는 여러 부분으로 분리될 수 있다.&lt;/p&gt;

&lt;p&gt;그래서 이 논문에서는 noise 부분 $z$와, 데이터 분포의 가장 중요한 의미를 가지는 특징량(latent code) $c$ 두 부분으로 나누었다(CGAN과 비슷). 특징량은 설명 가능한 부분(semantic features), $z$는 원래의 것처럼 데이터를 생성하기 위한 incompressible noise이다.&lt;/p&gt;

&lt;p&gt;G에 들어가는 input은 따라서 $G(z, c)$로 표시된다. 그러나 기존 GAN은 단지 $P_G(x \vert c) = P_G(x)$로 처리함으로써 특징량 $c$를 무시해버릴 수 있다. 따라서 정보이론적 정규화를 시행하도록 한다: $c$와 $G(z, c)$ 사이에는 아주 높은 상호정보량이 있기 때문에, $I(c;\ G(z,c))$ 역시 높을 것이다.&lt;/p&gt;

&lt;p&gt;참고: 상호정보량은 다음과 같이 KLD로 측정한다. 서로 독립인 경우 0이 되는 것은 상호정보량의 이름에서 봤을 때 직관적이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I(X;Y) = D_{KL}(p(x,y) \Vert p(x)p(y))&lt;/script&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/infoGAN1.png&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;그래서 목적함수는 다음과 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_G max_D V_I(D, G) = V(D, G) - \lambda I(c; G(z, c))&lt;/script&gt;

&lt;p&gt;$V(D, G)$는 기존 GAN의 목적함수이다.&lt;/p&gt;

&lt;p&gt;상호정보량은 쉽게 구하긴 어렵기 때문에, 논문에서는 이를 직접적으로 구하는 대신 하한을 구해 이를 최대화하는 방식을 썼다. 수식을 중간과정을 일부 생략하고 적으면&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;I(c; G(z, c)) = H(c) - H(c \vert G(z, c)) = \mathbb{E}_{x \sim G(z,c)} [ \mathbb{E}_{c' \sim P(c \vert x)}[log \ P(c' \vert x)]] + H(c)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\qquad \qquad \qquad \qquad \qquad \qquad \qquad \quad \ \  \ge \mathbb{E}_{x \sim G(z,c)} [ \mathbb{E}_{c' \sim P(c \vert x)}[log \ Q(c' \vert x)]] + H(c)&lt;/script&gt;

&lt;p&gt;상호정보량 I(c; G(z, c))의  variational lower bound $L_I(G, Q)$를 정의할 수 있는데,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_I(G, Q) = E_{c \sim P(c), x \sim G(z, c)}[log \ Q(c \vert x)] + H(c)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\qquad \qquad \qquad \ = E_{x \sim G(z,c)} [ \mathbb{E}_{c' \sim P(c \vert x)}[log \ Q(c' \vert x)]] + H(c)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\le  I(c; G(z, c)) \ \qquad \qquad \quad&lt;/script&gt;

&lt;p&gt;그래서 infoGAN은 아래 minimax game을 하는 것이 된다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_{G, Q} max_D V_{\text{infoGAN}}(D, G, Q) = V(D, G) - \lambda L_I(G,Q)&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;실험 결과&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;semantic features $c$를 적절히 조작하면 생성될 이미지에 어떤 변화를 줄 수 있는지를 중점적으로 보여주었다.&lt;br /&gt;
MNIST의 경우 숫자의 종류(digit), 회전, 너비 등을 조작할 수 있고, 사람 얼굴의 경우 얼굴의 각도, 밝기, 너비 등을 바꿀 수 있음을 보여주었다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/infoGAN2.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-20-advanced-GANs/infoGAN3.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;더 많은 결과는 논문을 참조하자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;이후-연구들&quot;&gt;이후 연구들&lt;/h1&gt;

&lt;p&gt;GAN 이후로 수많은 발전된 GAN이 연구되어 발표되었다.&lt;br /&gt;
GAN 학습에 관한 내용을 정리한 것으로는 다음 논문이 있다. &lt;a href=&quot;https://arxiv.org/abs/1606.03498&quot;&gt;Improved Techniques for Training GANs&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;또 다른 것으로는 PROGDAN, SLOGAN 등이 있다.&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>f-GAN</title>
   <link href="http://localhost:4000/f-GAN/"/>
   <updated>2019-03-19T00:00:00+09:00</updated>
   <id>http://localhost:4000/f-GAN</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 2016년 6월 &lt;em&gt;Sebastian Nowozin&lt;/em&gt; 등이 발표한 &lt;em&gt;f&lt;/em&gt;-GAN - Training Generative Neural Samplers using Variational Divergence Minimization를 살펴보도록 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;f&lt;/em&gt;-GAN은 특정한 구조를 제안했다기보다는 약간 divergence에 대한 내용을 일반적으로 증명한 수학 논문에 가깝다.&lt;/p&gt;

&lt;p&gt;중요한 부분만 적을 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;이 논문은 수학이 넘쳐흐르는 논문이다.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;f-gan&quot;&gt;&lt;em&gt;f&lt;/em&gt;-GAN&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.00709&quot;&gt;&lt;em&gt;f&lt;/em&gt;-GAN&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;초록abstract&quot;&gt;초록(Abstract)&lt;/h2&gt;

&lt;p&gt;2016년에 나온 논문임을 생각하라.&lt;/p&gt;

&lt;p&gt;Generative neural sampler는 random input vector를 입력으로 받아 network weights에 정의된 확률분포로부터 sample을 만들어내는 확률적 모델이다. 이 모델들은 sample과 도함수 계산이 효율적이지만 우도(likelihood)나 주변화(marginalization)을 계산하진 못한다. 적대생성적 학습방법은 이런 모델이 추가 신경망을 통해 이를 학습할 수 있게 해준다.&lt;br /&gt;
우리는 이 적대생성적 접근법이 더 일반적인 변분 발산(variational divergence) 추정 접근의 특별한 경우임을 보일 것이다. 우리는 임의의 &lt;em&gt;f-divergence&lt;/em&gt;가 Generative neural sampler에 쓰일 수 있음을 보일 것이다. 우리는 이렇게 다양한 divergence 함수를 쓸 수 있는 것이 학습 복잡도와 생성모델의 품질 면에서 이득임을 논할 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;서론introduction&quot;&gt;서론(Introduction)&lt;/h2&gt;

&lt;p&gt;확률적 생성모델은 주어진 domain $\chi$ 상의 확률분포를 서술한다. 예를 들면 자연언어 문장, 자연 이미지, 녹음된 파형 등의 분포가 있다.&lt;/p&gt;

&lt;p&gt;가능한 모델 집합 $Q$에서 생성모델 Q가 주어졌을 때 우리는 일반적으로 다음에 관심이 있다:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sampling. Q로부터 sample을 생성한다. sample을 살펴보거나 어떤 함숫값을 계산해봄으로써 우리는 분포에 대한 통찰을 얻거나 결정문제를 풀 수 있다.&lt;/li&gt;
  &lt;li&gt;Estimation. 알려지지 않은 진짜 분포 P로부터 iid sample ${x_1, x_2, …, x_n}$이 주어졌을 때, 이 진짜 분포를 가장 잘 설명하는 Q $\in Q$를 찾는다.&lt;/li&gt;
  &lt;li&gt;Point-wise 우도 측정. sample $x$가 주어지면, 우도 Q($x$)를 계산한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GAN은 정확한 sampling과 근사추정이 가능한 인상적인 모델이다. 여기서 사용된 모델은 균등분포 같은 random input vector를 받는 feedforward 신경망이다. 최종적으로 모델을 통과하여 나오는 것은 예를 들면 이미지이다. GAN에서 sampling하는 것은 딱 1개의 input이 신경망을 통과하면 정확히 하나의 sample이 나온다는 점에서 효율적이다.&lt;/p&gt;

&lt;p&gt;이런 확률적 feedforward 신경망을 &lt;strong&gt;generative neural samplers&lt;/strong&gt;라고 부를 것이다. GAN도 여기에 포함되며, 또한 variational autoencoder의 decoder 모델이기도 하다.&lt;/p&gt;

&lt;p&gt;original GAN에서, neural sample를 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/03/GAN/#%EB%AA%A9%EC%A0%81%ED%95%A8%EC%88%98-%EC%B5%9C%EC%A0%81%ED%99%94%EC%9D%98-%EC%9D%98%EB%AF%B8&quot;&gt;JSD&lt;/a&gt;의 근사적 최소화로 추정하는 것이 가능함이 증명되어 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_{JS}(P \| Q) = {1 \over 2} D_{KL}(P \| {1 \over 2}(P+Q)) + {1 \over 2} D_{KL}(Q \| {1 \over 2}(P+Q))&lt;/script&gt;

&lt;p&gt;$D_{KL}$은 &lt;a href=&quot;https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence&quot;&gt;Kullback–Leibler divergence&lt;/a&gt;이다.&lt;/p&gt;

&lt;p&gt;GAN 학습의 중요한 테크닉은 동시에 최적화된 &lt;strong&gt;Discriminator&lt;/strong&gt; 신경망을 만든 것에 있다. 왜냐하면 $D_{JS}$는 진짜 분포 $P$는 충분한 학습을 통해 Q가 $P$에 충분히 가까워졌을 때 분포 간 divergence를 측정하는 적정한 방법이기 때문이다.&lt;/p&gt;

&lt;p&gt;우리는 이 논문에서 GAN 학습목적(training objectives)과 이를 임의의 &lt;em&gt;f-divergence&lt;/em&gt;로 일반화하고자, GAN을 variational divergence 추정 framework로 확장할 것이다.&lt;/p&gt;

&lt;p&gt;구체적으로, 이 논문에서 보여주는 state-of-the-art한 것은:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GAN 학습목적을 모든 &lt;em&gt;f&lt;/em&gt;-divergence에 대해 유도하고 여러 divergence 함수를 소개할 것이다: Kullback-Leibler와 Pearson Divergence를 포함한다.&lt;/li&gt;
  &lt;li&gt;우리는 GAN의 saddle-point 최적화를 단순화할 것이고 또 이론적으로 증명할 것이다.&lt;/li&gt;
  &lt;li&gt;자연 이미지에 대한 generative neural sampler을 측정하는 데 어느 divergence 함수가 적당한지 실험적 결과를 제시하겠다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;방법method&quot;&gt;방법(Method)&lt;/h2&gt;

&lt;p&gt;먼저 divergence 추정 framework를 리뷰부터 하겠다. 이후 divergence 추정에서 model 추정으로 확장하겠다.&lt;/p&gt;

&lt;h3 id=&quot;the-f-divergence-family&quot;&gt;The &lt;em&gt;f&lt;/em&gt;-divergence Family&lt;/h3&gt;

&lt;p&gt;Kullback-Leibler divergence같이 잘 알려진 것은 두 확률분포 간 차이를 측정한다.&lt;/p&gt;

&lt;p&gt;두 분포 $P$와 $Q$가 있고, domain $\chi$에서 연속밀도함수 $p$와 $q$에 대해 &lt;em&gt;f-divergence&lt;/em&gt;는&lt;br /&gt;
$ f : \mathbb{R}_+ \rightarrow \mathbb{R} $이 $f(1)=0$인 볼록이고 하반연속인(convex, lower-semicontinuous) 함수 $f$에 대해&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_f(P \Vert Q) = \int_{\chi} q(x) f \Bigl( {p(x) \over q(x)} \Bigr) dx&lt;/script&gt;

&lt;p&gt;로 정의된다.&lt;/p&gt;

&lt;h3 id=&quot;variational-estimation-of-f-divergences&quot;&gt;Variational Estimation of &lt;em&gt;f&lt;/em&gt;-divergences&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Nyugen&lt;/em&gt; 등 연구자는 $P$와 $Q$로부터의 sample만 주어진 경우에서 &lt;em&gt;f&lt;/em&gt;-divergence를 측정하는 일반적인 변분법을 유도했다. 우리는 이를 고정된 모델에서 그 parameter를 측정하는 것으로까지 확장할 것이고, 이를 &lt;em&gt;variational divergence minimization&lt;/em&gt;(VDM)이라 부를 것이다. 또한 적대적 생성 학습법은 이 VDM의 특수한 경우임을 보인다.&lt;/p&gt;

&lt;p&gt;모든 볼록이고 &lt;a href=&quot;https://ko.wikipedia.org/wiki/%EB%B0%98%EC%97%B0%EC%86%8D%EC%84%B1&quot;&gt;하반연속&lt;/a&gt;인 볼록 켤레함수 $f^\ast$ (&lt;em&gt;Fenchel conjugate&lt;/em&gt;)를 갖는다. 이는&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f^\ast(t) = \quad sup \quad  \{ ut-f(u) \} \\ u \in dom_f \qquad&lt;/script&gt;

&lt;p&gt;로 정의된다.&lt;/p&gt;

&lt;p&gt;또한 $f^\ast$ 역시 볼록이며 하반연속이고 $f^{\ast\ast} = f$이므로 $ f(u) = sup_{t \in dom_{f^\ast}} { tu-f^\ast(t) } $로 쓸 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Nguyen&lt;/em&gt; 등 연구자는 lower bound를 구했다: $\tau$가 $T: \chi \rightarrow \mathbb{R} $인 함수들의 임의의 집합일 때,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D_f(P \Vert Q) \ge sup_{T \in \tau} (\mathbb{E}_{x \sim P} [T(x)] - \mathbb{E}_{x \sim Q} [f^\ast(T(x))])&lt;/script&gt;

&lt;p&gt;변분법을 취해서,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;T^\ast(x) = f^{'} \Bigl( {p(x) \over q(x)} \Bigr)&lt;/script&gt;

&lt;p&gt;아래는 여러 &lt;em&gt;f&lt;/em&gt;-divergence를 생성함수와 함께 나타낸 것이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-19-f-GAN/01.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;variational-divergence-minimizationvdm&quot;&gt;Variational Divergence Minimization(VDM)&lt;/h3&gt;

&lt;p&gt;이제 실제 분포 $P$가 주어졌을 때 생성모델 $Q$를 측정하기 위해 &lt;em&gt;f&lt;/em&gt;-divergence $D_f(P\Vert Q)$에 하한을 적용할 수 있다.&lt;/p&gt;

&lt;p&gt;벡터 $\theta$를 받는 모델 $Q$를 $Q_{\theta}$, $\omega$를 쓰는 $T$를 $T_{\omega}$로 썼을 때, 우리는 다음 &lt;em&gt;f&lt;/em&gt;-GAN 목적함수의 saddle-point를 찾는 것으로 $Q_{\theta}$를 학습시킬 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F(\theta, \omega) = \mathbb{E}_{x \sim P} [T_{\omega}(x)] - \mathbb{E}_{x \sim Q_{\theta}} [f^\ast({T_\omega}(x))]&lt;/script&gt;

&lt;p&gt;주어진 유한한 학습 데이터셋에 대해 위 식을 최적화하려면, minibatch를 통해 기댓값을 근사해야 한다. $\mathbb{E}&lt;em&gt;{x \sim P}[\cdot]$를 근사하기 위해 학습 셋으로부터 비복원추출하여 $B$개를 뽑고, $\mathbb{E}&lt;/em&gt;{x \sim Q_{\theta}}[\cdot]$를 근사하기 위해 현재 생성모델 $Q_{\theta}$로부터 $B$개를 뽑는다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-19-f-GAN/02.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;representation-for-the-variational-function&quot;&gt;Representation for the Variational Function&lt;/h3&gt;

&lt;p&gt;위의 식을 다른 &lt;em&gt;f&lt;/em&gt;-divergence에도 사용하려면 켤레함수 $f^\ast$의 도메인  $dom_{f^\ast}$를 생각해야 한다. $T_\omega (x) = g_f(V_\omega(x)) $로 바꿔 쓸 수 있다.&lt;/p&gt;

&lt;p&gt;이제 GAN 목적함수를 보면, divergence가 sigmoid이므로&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;F(\theta, \omega) = \mathbb{E}_{x \sim P} [log D_{\omega}(x)] - \mathbb{E}_{x \sim Q_{\theta}} [log(1-D_\omega(x))]&lt;/script&gt;

&lt;p&gt;출력 활성함수는 Table 6을 보라(부록).&lt;/p&gt;

&lt;h3 id=&quot;example-univariate-mixture-of-gaussians&quot;&gt;Example: Univariate Mixture of Gaussians&lt;/h3&gt;

&lt;p&gt;가우시안 sample에 대해 근사한 결과를 적어 놓았다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-19-f-GAN/03.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;vdm-알고리즘algorithms-for-variational-divergence-minimizationvdm&quot;&gt;VDM 알고리즘(Algorithms for Variational Divergence Minimization(VDM))&lt;/h2&gt;

&lt;p&gt;이제 우리는 목적함수의 saddle point를 찾기 위한 수치적 방법을 논할 것이다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Goodfellow가 제안한 교대(alternative) 학습 방법&lt;/li&gt;
  &lt;li&gt;더 직접적인 single-step 최적화 과정&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;두 가지를 쓴다.&lt;/p&gt;

&lt;h3 id=&quot;single-step-gradient-method&quot;&gt;Single-Step Gradient Method&lt;/h3&gt;

&lt;p&gt;원래 것과는 달리 inner loop가 없고, 단 하나의 back-propagation으로 $\omega$와 $\theta$의 gradient가 계산된다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-19-f-GAN/04.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;saddle point 근방에서 $\theta$에 대해 볼록하고 $\omega$ 에 대해  오목한 $F$에 대해 위 알고리즘 1은 saddle point $(\theta^\ast, \omega^\ast)$에서 수렴함을 보일 수 있다.&lt;/p&gt;

&lt;p&gt;이를 위해 다음 정리를 논문 부록에서 보이고 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem 1.&lt;/strong&gt; $\pi^t := (\theta^t, \omega^t) $ 라 하고, 조금 위의 근방 조건을 만족하는 saddle point $ \pi^\ast = (\theta^\ast, \omega^\ast) $ 가 존재한다고 가정하자. 더욱이 위 근방에 포함되는 $ J(\pi) = {1\over 2} \Vert \nabla F(\pi) \Vert_2^2 $ 를 정의할 수 있고, $F$는 $ \pi^\ast $ 근방 모든 $ \pi, \pi^{‘} $ 에 대해 $ \Vert \nabla J(\pi^{‘}) - \nabla J(\pi) \Vert_2 \le L \Vert \pi^{‘} - \pi \Vert_2 $ 를 만족하는 상수 $ L &amp;gt; 0 $ 가 존재할 수 있게 하는 $F$는 충분히 smooth하다.&lt;br /&gt;
알고리즘 1에서 step-size를 $ \eta=\delta / L$ 라 할 때,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;J(\pi^t) \le \Bigl( 1 - {\lambda^2 \over 2L} \Bigr)^t J(\pi^0)&lt;/script&gt;

&lt;p&gt;를 얻을 수 있다.&lt;br /&gt;
또 gradient $ \nabla F(x) $ 의 2차 norm은 기하적으로 감소한다.&lt;/p&gt;

&lt;h3 id=&quot;practical-considerations&quot;&gt;Practical Considerations&lt;/h3&gt;

&lt;p&gt;Goodfellow가 GAN 논문 당시 제안한 팁 중에&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\mathbb{E}_{x \sim Q_{\theta}} [log(1-D_\omega(x))]&lt;/script&gt; 
를 최소화하는 대신 
&lt;script type=&quot;math/tex&quot;&gt;\mathbb{E}_{x \sim Q_{\theta}} [log D_\omega(x)]&lt;/script&gt;
 를 최대화하는 것으로 속도를 빠르게 하는 것이 있었다.&lt;br /&gt;
이를 더 일반적인 &lt;em&gt;f&lt;/em&gt;-GAN에 적용하면&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta^{t+1} = \theta^t + \eta \nabla_\theta \mathbb{E}_{x \sim Q_{\theta^t}} [g_f(V_{\omega^t}(x))]&lt;/script&gt;

&lt;p&gt;그렇게 함으로써 generator 출력을 최대화할 수 있다.&lt;/p&gt;

&lt;p&gt;실험적으로, 우리는 Adam과 gradient clipping이 LSUN 데이터셋의 대규모 실험에서는 특히 유용함을 발견하였다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;실험experiments&quot;&gt;실험(Experiments)&lt;/h2&gt;

&lt;p&gt;이제 VDM에 기초하여 MNIST와 LSUN에 대해 학습시킨 결과는 다음과 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-19-f-GAN/05.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-19-f-GAN/06.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;결과 요약을 하면… 약간 예상 외로 divergence 함수가 달라져도 결과의 품질은 큰 차이가 없었다고 한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;관련-연구related-work&quot;&gt;관련 연구(Related Work)&lt;/h2&gt;

&lt;p&gt;오직 신경망에 적용할 수 있는 것에 대해서만 논하겠다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Mixture density networks: 유한한 mixture 모델의 parameter를 직접 회귀시키는 데 쓸 수 있다.&lt;/li&gt;
  &lt;li&gt;NADE and RNADE: 사전에 정의되었고 어느 정도 임의의 출력 차원을 가진 출력의 factorization을 수행한다.&lt;/li&gt;
  &lt;li&gt;Diffusion probabilistic models: 자명하고 알려진 분포에서 출발하는 학습된 발산과정의 결과로 목표 분포를 정의한다.&lt;/li&gt;
  &lt;li&gt;Noise contrasive estimation(NCE): 임의로 생성된 noise로부터 데이터를 식별하는 비선형 logistic 회귀를 수행하여 비정규화된 확률모델의 parameter를 추정하는 방법이다.&lt;/li&gt;
  &lt;li&gt;Variational auto-encoders(VAE): 변분법적 베이지안 학습 목표함수를 갖고 sample을 잠재표현식으로 매핑하는 확률적 encoder와 decoder 모델의 쌍이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;토의discussion&quot;&gt;토의(Discussion)&lt;/h2&gt;

&lt;p&gt;Generative neural samplers는 factorizing 가정 없이도 복잡한 분포를 표현하는 강력한 방법을 제공한다. 그러나 이 논문에서 사용된 순수 generative neural samplers는 관측된 데이터에 대한 조건부로 적용할 수 없고 따라서 그로부터 추론할 것이 없다는 한계를 갖고 있다.&lt;/p&gt;

&lt;p&gt;우리는 미래에는 표현의 불확실성을 위한 neural samplers의 진면목이 식별 모델에서 발견될 것이며 생성자와 조건부 GAN 모델에 추가적인 input을 넣음으로써 쉽게 이 경우에 대해 확장할 수 있을 것이라 믿는다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;참고문헌references&quot;&gt;참고문헌(References)&lt;/h2&gt;

&lt;p&gt;논문 참조!&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;부록&quot;&gt;부록&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Section A: 이 부분이다.&lt;/li&gt;
  &lt;li&gt;Section B: &lt;em&gt;f&lt;/em&gt;-divergence의 확장된 리스트(생성함수와 볼록 켤레함수)를 나열하였다.&lt;/li&gt;
  &lt;li&gt;Section C: Theorem 1를 증명한다. (논문에는 Theorem 2라 되어 있는데 같은 것이다)&lt;/li&gt;
  &lt;li&gt;Section D: 현재 GAN 최적화 알고리즘과 차이를 논한다.&lt;/li&gt;
  &lt;li&gt;Section E: 다양한 divergence 측정방법을 써서 Gaussian을 혼합 Gaussian 분포에 맞춤으로써 우리의 접근법을 증명한다.&lt;/li&gt;
  &lt;li&gt;Section F: 본문에서 사용한 모델의 세부 구조를 보여준다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;증명의 자세한 부분은 논문을 보는 것이 빠르므로 생략하겠다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-19-f-GAN/07.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-19-f-GAN/08.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-19-f-GAN/09.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;MNIST 생성자:&lt;br /&gt;
$z \rightarrow Linear(100, 1200) \rightarrow BN \rightarrow ReLU \rightarrow Linear(1200, 1200) \rightarrow BN \rightarrow ReLU \rightarrow Linear(1200, 784) \rightarrow Sigmoid $&lt;/p&gt;

&lt;p&gt;모든 weights는 0.05 scale로 초기화되었다.&lt;/p&gt;

&lt;p&gt;MNIST Variational Function:&lt;br /&gt;
$ x \rightarrow Linear(784, 240) \rightarrow ELU \rightarrow Linear(240, 240) \rightarrow ELU \rightarrow Linear(240, 1) $&lt;/p&gt;

&lt;p&gt;ELU는 exponential linear unit이다. 모든 weights는 0.005 scale로 초기화되었다.&lt;/p&gt;

&lt;p&gt;LSUN Natural Images:&lt;br /&gt;
$ z \rightarrow Linear(100, 6\ast6\ast512)  \rightarrow BN \rightarrow ReLU \rightarrow Reshape(512, 6, 6) \rightarrow Deconv(512, 256) \rightarrow BN \rightarrow ReLU \rightarrow Deconv(256, 128) \rightarrow BN \rightarrow ReLU \rightarrow Deconv(128, 64) \rightarrow BN \rightarrow ReLU \rightarrow Deconv(64, 3) $&lt;/p&gt;

&lt;p&gt;deconv는 kernel size 4, stride 2를 사용하였다.&lt;/p&gt;

&lt;p&gt;Deconv는 Deconvolution을 의미하는데, &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/17/DCGAN/&quot;&gt;DCGAN 글&lt;/a&gt;에서도 설명하였듯 잘못된 표현이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;이후-연구들&quot;&gt;이후 연구들&lt;/h1&gt;

&lt;p&gt;GAN 이후로 수많은 발전된 GAN이 연구되어 발표되었다.&lt;/p&gt;

&lt;p&gt;많은 GAN들(catGAN, Semi-supervised GAN, LSGAN, WGAN, WGAN_GP, DRAGAN, EBGAN, BEGAN, ACGAN, infoGAN 등)에 대한 설명은 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/20/advanced-GANs/&quot;&gt;다음 글&lt;/a&gt;에서 진행하도록 하겠다.&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>CGAN(Conditional GAN)</title>
   <link href="http://localhost:4000/CGAN/"/>
   <updated>2019-03-19T00:00:00+09:00</updated>
   <id>http://localhost:4000/CGAN</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 2014년 11월 &lt;em&gt;Mehdi Mirza&lt;/em&gt; 등이 발표한 Conditional Generative Adversarial Nets(CGAN)를 살펴보도록 한다.&lt;/p&gt;

&lt;p&gt;CGAN은 GAN의 변형 모델이다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;(즉 DCGAN보다는 먼저 나왔다. 하지만 DCGAN이 GAN의 역사에서 제일 중요한 것 중 하나이기 때문에 CGAN을 나중으로 미뤘다.)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;CGAN은 GAN과 학습 방법 자체는 별로 다를 것이 없다(D 학습 후 G 학습시키는 것).&lt;br /&gt;
GAN의 변형 모델들은 대부분 그 모델 구조를 바꾼 것이다.&lt;/p&gt;

&lt;p&gt;CGAN을 도식화한 구조는 다음과 같다. &lt;a href=&quot;https://github.com/hwalsuklee/tensorflow-generative-model-collections&quot;&gt;출처&lt;/a&gt;&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-19-CGAN/04.png&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;중요한 부분만 적을 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;conditional-gancgan&quot;&gt;Conditional GAN(CGAN)&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1411.1784&quot;&gt;Conditional GAN&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;초록abstract&quot;&gt;초록(Abstract)&lt;/h2&gt;

&lt;p&gt;2014년에 나온 논문임을 생각하라.&lt;/p&gt;

&lt;p&gt;최근 GAN이 생성모델을 학습시키는 근사한 방법으로 소개되었다. 우리는 이 GAN의 조건부(conditional) 버전, 간단히 $y$ 데이터를 추가하여 만든 적대적 망을 소개하려 한다. 이 CGAN이 class label(숫자 0~9)에 맞는 MNIST 이미지를 생성할 수 있음을 보일 것이다. 또한 이 모델이 multi-modal 모델에 어떻게 사용될지, 또 이미지 태깅에 어떻게 응용 가능할지도 또한 설명할 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;서론introduction&quot;&gt;서론(Introduction)&lt;/h2&gt;

&lt;p&gt;생성 모델을 학습하기 위해, 다루기 힘든 엄청난 확률적 계산의 어려움을 대체하는 GAN이 최근 소개되었다. 적대신경망은 Markov chain이 필요없이 오직 back-propagation만으로 학습이 가능하고, 별다른 추측도 할 필요가 없다.&lt;/p&gt;

&lt;p&gt;Unconditional 생성모델에서, 데이터가 생성되는 종류(mode)를 제어할 방법은 없다. 그러나, 추가 정보를 통해 데이터 생성 과정을 제어할 수 있다. 이러한 조건 설정(conditioning)은 class label 등에 기반할 수 있다.&lt;/p&gt;

&lt;p&gt;이 논문에서 우리는 conditional 적대신경망을 구현할 것이다. 또 이를 MNIST와 MIR Flickr 데이터셋에 대해 테스트한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;관련-연구related-works&quot;&gt;관련 연구(Related Works)&lt;/h2&gt;

&lt;p&gt;궁금하면 읽어보자.&lt;/p&gt;

&lt;h3 id=&quot;multi-modal-learning-for-image-labelling&quot;&gt;Multi-modal Learning for Image Labelling&lt;/h3&gt;

&lt;p&gt;굉장히 많은 카테고리를 다룰 수 있는 모델에 관한 문제는 추가 modality에 대한 정보를 다루는 것으로 일부 해결 가능하다. 단어를 vector representation으로 변형하는 것 등이 있다.&lt;/p&gt;

&lt;p&gt;input-output 1-1 매칭에만 치중한 문제는 conditional 확률적 생성모델을 사용하는 것이 한 방법이 될 수 있다.&lt;/p&gt;

&lt;p&gt;자세한 내용은 원문을 보고 각 논문을 찾아보라. 이미 요약된 부분이라 그냥 건너뛰거나 본문을 보는 것이 더 낫다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;조건부-적대신경망conditional-adversarial-nets&quot;&gt;조건부 적대신경망(Conditional Adversarial Nets)&lt;/h2&gt;

&lt;h3 id=&quot;gangenearative-adversarial-nets&quot;&gt;GAN(Genearative Adversarial Nets)&lt;/h3&gt;

&lt;p&gt;최근 소개된 GAN은 다음 두 부분으로 이루어졌다. 둘 다 non-linear하게 매핑하는 함수일 수 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;데이터분포를 입력받아 실제에 가깝게 데이터를 생성하는 생성모델 G&lt;/li&gt;
  &lt;li&gt;입력받은 데이터가 진짜 데이터인지 G가 만들어낸 것인지를 판별하는 D&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;다음 식으로 표현되는 minimax 게임을 G와 D가 진행하게 된다:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_G max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[log D(x)] + \mathbb{E}_{x \sim p_{z}(z)}[log (1-D(G(z)))]&lt;/script&gt;

&lt;p&gt;수식에 대한 자세한 설명은 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/03/GAN/#%EC%A0%81%EB%8C%80%EC%A0%81-%EB%A7%9Dadversarial-nets&quot;&gt;GAN&lt;/a&gt;을 참고하라.&lt;/p&gt;

&lt;h3 id=&quot;cganconditional-adversarial-nets&quot;&gt;CGAN(Conditional Adversarial Nets)&lt;/h3&gt;

&lt;p&gt;G와 D가 추가 정보 $y$라는 조건이 붙는다면 조건부 생성모델을 만들 수 있다. $y$는 어떤 보조 정보라도 될 수 있는데, class label이나 다른 modality의 데이터 등이다. 우리는 $y$를 G와 D의 input layer에 추가로 같이 집어넣음으로써 이를 수행할 수 있다.&lt;/p&gt;

&lt;p&gt;G에서는 input noise $p_z(z)$와 $y$가 합쳐진 형태가 된다. 이 적대적 학습 framework는 이 hidden representation이 어떻게 생겼는지에 별 영향을 받지 않는다.&lt;br /&gt;
D에서는 $x$와 $y$가 input으로써 들어가게 된다.&lt;/p&gt;

&lt;p&gt;좀 전 수식을 conditional 버전으로 바꿔보면,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_G max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[log D(x|y)] + \mathbb{E}_{x \sim p_{z}(z)}[log (1-D(G(z|y)))]&lt;/script&gt;

&lt;p&gt;&lt;em&gt;참고&lt;/em&gt;: D와 G에 들어가는 input이 단지 조건부로 바뀌었다. 실제 들어가는 형태는 합쳐진 형태이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-19-CGAN/01.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;실험-결과experimental-results&quot;&gt;실험 결과(Experimental Results)&lt;/h2&gt;

&lt;p&gt;이미 좋다는 게 알려진 논문의 경우에는 굳이 실험 조건 등을 자세히 볼 필요는 없다. 여기서는 결과만 소개한다.&lt;/p&gt;

&lt;h3 id=&quot;unimodal&quot;&gt;Unimodal&lt;/h3&gt;

&lt;p&gt;모델 구조는 다음과 갈다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;G
    &lt;ul&gt;
      &lt;li&gt;uniform distribution $z$. size=100&lt;/li&gt;
      &lt;li&gt;$z$와 $y$는 각각 size 200, 1000짜리 hidden layer(ReLU)로 매핑됨&lt;/li&gt;
      &lt;li&gt;1200짜리 hidden layer로 합쳐짐(ReLU)&lt;/li&gt;
      &lt;li&gt;마지막으로 784차원으로 변환됨(MNIST 이미지는 $28^2$이다)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;D
    &lt;ul&gt;
      &lt;li&gt;$x$는 240 unit과 5 piece짜리 maxout layer, $y$는 50 unit과 5 piece짜리 maxout layer로 매핑됨&lt;/li&gt;
      &lt;li&gt;240 unit, 5 piece짜리 maxout layer로 합쳐진 후 Sigmoid&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;MNIST로 실험한 결과이다. Log-likelihood 값이 잘 나왔음을 확인할 수 있다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th&gt;MNIST&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;DBN&lt;/td&gt;
      &lt;td&gt;138 $\pm $ 2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Stacked CAE&lt;/td&gt;
      &lt;td&gt;121 $\pm $ 1.6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Deep GSN&lt;/td&gt;
      &lt;td&gt;214 $\pm $ 1.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Adversarial nets&lt;/td&gt;
      &lt;td&gt;225 $\pm $ 2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Conditional adversarial nets&lt;/td&gt;
      &lt;td&gt;132 $\pm $ 1.8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;$y$ 데이터는 각 row별로 0~9까지 들어갔다. 아래는 CGAN을 통해 생성된 이미지이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-19-CGAN/02.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;주어지는 조건($y$)에 따라 class가 잘 나뉘는 것은 확인할 수 있다(이미지 품질은 original GAN과 비슷하다).&lt;/p&gt;

&lt;h3 id=&quot;multimodal&quot;&gt;Multimodal&lt;/h3&gt;

&lt;p&gt;여러 이미지들에 대해 사람이 직접 넣은 태그와 CGAN이 생성해낸 태그를 비교한 테이블을 가져왔다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-19-CGAN/03.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;가장 오른쪽 열이 생성된 태그 중 제일 나은 것 10개를 나열한 것인데, 꽤 잘 된 것으로 보인다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;추후-연구future-work&quot;&gt;추후 연구(Future work)&lt;/h2&gt;

&lt;p&gt;이 논문에서 소개된 결과는 서론 정도의 내용이지만, 각각은 조건부 생성모델의 잠재력과 다른 많은 분야로의 응용에 대한 가능성을 보여 준다.&lt;/p&gt;

&lt;p&gt;이번 실험에서는 태그를 독립적으로 사용했지만, 한번에 여러 태그를 사용한다면 더 나은 결과를 얻을 수 있을 것이다.&lt;/p&gt;

&lt;p&gt;추후 연구의 또 다른 방향은 언어 모델을 배우는 학습계획을 구현하는 것이 있겠다.&lt;/p&gt;

&lt;h3 id=&quot;acknowledgments&quot;&gt;Acknowledgments&lt;/h3&gt;

&lt;p&gt;이 프로젝트는 Pylearn2 framework로 개발되었다.&lt;/p&gt;

&lt;h2 id=&quot;참고문헌references&quot;&gt;참고문헌(References)&lt;/h2&gt;

&lt;p&gt;논문 참조!&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;튜토리얼&quot;&gt;튜토리얼&lt;/h1&gt;

&lt;p&gt;GAN의 핵심 부분을 제외한 부분은 &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/&quot;&gt;여기&lt;/a&gt;를 참고하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/znxlwm/pytorch-generative-model-collections/blob/master/CGAN.py&quot;&gt;여기&lt;/a&gt;에서 CGAN을 학습시켜볼 수 있다. 해당 repository에는 CGAN뿐 아니라 많은 종류의 GAN이 Pytorch로 구현되어 있으므로 참고하면 좋다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;이후-연구들&quot;&gt;이후 연구들&lt;/h1&gt;

&lt;p&gt;GAN 이후로 수많은 발전된 GAN이 연구되어 발표되었다.&lt;/p&gt;

&lt;p&gt;많은 GAN들(catGAN, Semi-supervised GAN, LSGAN, WGAN, WGAN_GP, DRAGAN, EBGAN, BEGAN, ACGAN, infoGAN 등)에 대한 설명은 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/20/advanced-GANs/&quot;&gt;여기&lt;/a&gt;, f-GAN에 대한 설명은 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/19/f-GAN/&quot;&gt;여기&lt;/a&gt;에서 진행하도록 하겠다.&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>DCGAN(Deep Convolutional GAN)</title>
   <link href="http://localhost:4000/DCGAN/"/>
   <updated>2019-03-17T00:00:00+09:00</updated>
   <id>http://localhost:4000/DCGAN</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 2015년 11월 &lt;em&gt;Alec Radford&lt;/em&gt; 등이 발표한 DCGAN(Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks)를 살펴보도록 한다.&lt;/p&gt;

&lt;p&gt;DCGAN은 GAN의 개선 모델로 GAN과 다른 점은 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;$D$&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Strided Convolution을 사용한다.&lt;/li&gt;
      &lt;li&gt;Batch Normalization을 사용한다. 입력 레이어(첫 번째)에는 사용하지 않는다.&lt;/li&gt;
      &lt;li&gt;activation function으로 Leaky ReLU를 사용한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;$G$&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Fractional Strided Convolution(Transposed Convolution)을 사용한다.&lt;/li&gt;
      &lt;li&gt;Batch Normalization을 사용한다. 출력 레이어(마지막)에는 사용하지 않는다.&lt;/li&gt;
      &lt;li&gt;activation function으로 ReLU를 사용하고 마지막 레이어에는 tanh를 사용한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;참고&lt;/em&gt;: 논문에서 deconvolution이라 되어 있는 것은 Transposed 또는 fractional strided convolution을 의미한다. 이 연산은 엄밀히 말해 convolution의 역연산이 아니기 때문에(그 비슷한 것을 의도하긴 했지만) deconvolution은 사실 틀린 표현이다.&lt;/p&gt;

&lt;p&gt;그래서 나아진 점, 혹은 알아낸 것은?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(흔히 생각하는 FHD를 넘는 고해상도랑은 거리가 멀지만) 고해상도 이미지를 생성할 수 있게 되었다.&lt;/li&gt;
  &lt;li&gt;거의 대부분의 상황에서 안정적인 학습이 가능하다.&lt;/li&gt;
  &lt;li&gt;단순히 이미지를 기억(overfitting)하는 것이 아님을 보였다.&lt;/li&gt;
  &lt;li&gt;convolution의 각 filter는 의미 있는 부분에 대한 정보를 갖고 있다. 논문에서는 침실 데이터를 사용하였는데, 어떤 필터는 창문에 대한 정보를 갖고 있는 식이다. 논문에서는 이를 시각화하여 보여주었다.&lt;/li&gt;
  &lt;li&gt;input인 noise($z$)는 별 의미 없는 값이 아니라, 이것이 생성될 이미지의 특징을 결정하는 벡터이다. 논문에서는,
    &lt;ul&gt;
      &lt;li&gt;웃는 여자를 생성한 noise $z_1$&lt;/li&gt;
      &lt;li&gt;무표정 여자를 생성한 noise $z_2$&lt;/li&gt;
      &lt;li&gt;무표정 남자를 생성한 noise $z_3$&lt;/li&gt;
      &lt;li&gt;$z_4 :=$ $z_1$ - $z_2$ + $z_3$이라 할 때&lt;/li&gt;
      &lt;li&gt;$z_4$를 noise로 쓰면 웃는 남자를 생성해낸다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;또 왼쪽을 보는 사람과 오른쪽을 보는 사람을 생성한 두 벡터를 interpolating하면 마치 얼굴을 회전시킨 듯한 중간 결과들이 얻어진다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;DCGAN은 GAN과 학습 방법 자체는 별로 다를 것이 없다(D 학습 후 G 학습시키는 것).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;참고&lt;/em&gt;: $G$로 들어가는 입력 벡터를 뜻하는 noise는 latent variable이라고도 하며, Auto-encoder에서 출력 영상을 만들기 위한 source와 비슷하기에 이 표현도 사용된다.&lt;/p&gt;

&lt;p&gt;중요한 부분만 적을 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;논문dcgan&quot;&gt;논문(DCGAN)&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1511.06434&quot;&gt;Deep Convolutional GAN&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;초록abstract&quot;&gt;초록(Abstract)&lt;/h2&gt;

&lt;p&gt;2015~2016년에 나온 논문임을 생각하라.&lt;/p&gt;

&lt;p&gt;최근에는 CNN을 통한 supervised learning 연구가 많이 이루어졌지만 unsupervised learning은 별 주목을 받지 못했다. 우리는 Deep Convolutional GANs를 소개하여 그 간극을 좁히고자 한다. 여러 이미지 데이터셋을 학습시키면서 우리는 DCGAN의 G와 D 모두가 object로부터 유의미한 표현 구조를 찾았음을 보였다. 또, 이를 일반적인(general) 이미지 표현에도 응용해 보았다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;서론introduction&quot;&gt;서론(Introduction)&lt;/h2&gt;

&lt;p&gt;GAN은 최대우도(maximum likelihood) 테크닉의 매력적인 대체재이다. 또한 그 학습 방법과 heuristic cost function가 적다는 것 때문에 representation learning에도 훌륭히 잘 쓸 수 있다. 다만 학습이 불안정하고 G가 터무니없는 output을 내뱉을 때가 있다. 그래서 상당히 제한적으로 쓰일 수밖에 없었다.&lt;/p&gt;

&lt;p&gt;이 논문에서는, 우리는 다음과 같은 것들을 보일 것이다:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;거의 대부분의 상황에서 학습이 안정적인 Convolutional GAN을 제안하고 평가한다. 이것이 DCGAN이다.&lt;/li&gt;
  &lt;li&gt;D에게 image classification를 시켜봤는데, 거의 state-of-the-art한 결과를 보인다.&lt;/li&gt;
  &lt;li&gt;특정 필터가 특정 object를 그려낸다는 것을 시각화한다.&lt;/li&gt;
  &lt;li&gt;G에 들어가는 noise에 산술 연산을 한 결과로 많은 의미있는 이미지를 생성함을 보인다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;관련-연구related-works&quot;&gt;관련 연구(Related Works)&lt;/h2&gt;

&lt;p&gt;궁금하면 읽어보자.&lt;/p&gt;

&lt;h3 id=&quot;representation-learning-from-unlabeled-data&quot;&gt;Representation Learning from Unlabeled Data&lt;/h3&gt;

&lt;p&gt;Unsupervised representation learning은 꽤 잘 연구되었다. 전통적인 접근 방법으로는 clustering(K-means)이 있다.&lt;br /&gt;
이미지 쪽에서는 image representation을 학습하기 위한 구조적 clustering, auto-encoder를 학습시키는 것, what/where 분리 구조, image를 간략한 code로 encode하고 다시 이미지로 복원하는 decoder를 포함하는 사다리 구조 등등이 있었다.&lt;br /&gt;
Deep belief networks도 구조적 표현방식을 학습하는 데 좋은 성능을 보였다.&lt;/p&gt;

&lt;h3 id=&quot;generating-natural-images&quot;&gt;Generating Natural Images&lt;/h3&gt;

&lt;p&gt;이건 두 종류가 있다: parametric과 non-parametric.&lt;/p&gt;

&lt;p&gt;database에 존재하는 이미지 찾기 등을 수행하는 non-parametric 모델들은 texture synthesis, super-resolution, in-painting 등에 사용되었다.&lt;/p&gt;

&lt;p&gt;Parameteric 모델은 꽤 널리 알려졌지만(MNIST), 성공적인 것은 별로 없다. 대부분 흐린(blurry) 이미지만을 생성해냈다.&lt;br /&gt;
GAN이 생성한 것은 noise가 많고 이해하기 어려웠다. Laplcian pyramid extension, recurrent network, deconvolution network 등의 접근은 자연 이미지를 생성하는 데 성공적이었지만 supervised task에 generator를 활용하진 않았다.&lt;/p&gt;

&lt;h3 id=&quot;visualizing-the-internals-of-cnns&quot;&gt;Visualizing the Internals of CNNs&lt;/h3&gt;

&lt;p&gt;Neural Networks의 문제점은 너무 black-box같다는 것이다(&lt;em&gt;참고&lt;/em&gt;: 네트워크의 각 필터 등이 정확히 무엇을 의미하는지 사람이 이해할 수가 없다). 다만 각 필터의 의미를 찾으려는 시도는 있었다.&lt;/p&gt;

&lt;p&gt;자세한 내용은 원문을 보고 각 논문을 찾아보라.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;접근법과-모델-아키텍처approach-and-model-architecture&quot;&gt;접근법과 모델 아키텍처(Approach and Model Architecture)&lt;/h2&gt;

&lt;p&gt;GAN에 CNN을 써서 이미지 품질을 높이려는 시도는 지금까지 성공적이지 못했다.&lt;/p&gt;

&lt;p&gt;우리는 많은 시도 끝에 다양한 데이터셋에서 안정적인 그리고 더 높은 해상도의 이미지를 생성하는 모델 구조를 찾아내었다.&lt;br /&gt;
핵심은 다음 3가지를 CNN 구조에 적용시키는 것이다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;max-pooling과 같은 미분불가능한 레이어를 strided convolution으로 바꿔 spatial downsampling이 가능하게 한 것이다. 이는 G에 사용된 것이고, D에는 upsampling이 가능하게 바꿨다.&lt;/li&gt;
  &lt;li&gt;요즘 트렌드는 FC(Fully Connected) Layer를 없애고 convolution layer로 바꾸는 것이다.&lt;/li&gt;
  &lt;li&gt;Batch Normalization을 사용하여 학습을 안정화시킨다(&lt;em&gt;참고&lt;/em&gt;: 2019년 현재 BN은 거의 필수처럼 되어 있다). 이는 weight 초기화가 나쁘게 된 경우와 깊은 모델에서 gradient flow를 도우며, 이는 학습 초기에 잘못된 방향으로 학습이 진행되어 망하는 경우를 막아준다. 그러나 sample이 요동치는 것을 막기 위해 G의 출력 레이어와 D의 input layer에는 넣지 않았다(이건 많은 시도 끝에 알아낸 듯).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;G에서는 activation function으로 ReLU를 사용하고 마지막 레이어에는 tanh를 사용한다. Bounded activation(tanh)은 더 빠르게 수렴하고 학습샘플의 분포를 따라갔다. D에는 Leaky ReLU를 사용하여 높은 해상도를 만들 수 있게 하였다. 이는 GAN과 다른 부분이다.&lt;/p&gt;

&lt;h2 id=&quot;적대적-학습-상세details-of-adversarial-training&quot;&gt;적대적 학습 상세(Details of Adversarial Training)&lt;/h2&gt;

&lt;p&gt;우리는 Large-scale Scene Understanding(LSUN), Imagenet-1k, Faces 데이터셋으로 학습을 진행했다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;pre-processing은 쓰지 않았고&lt;/li&gt;
  &lt;li&gt;size 128인 mini-batch SGD&lt;/li&gt;
  &lt;li&gt;(0, 0.02) 정규분포를 따르는 초기화&lt;/li&gt;
  &lt;li&gt;Leaky ReLU의 기울기는 0.2&lt;/li&gt;
  &lt;li&gt;AdamOptimizer(0.0002, 0.9)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;로 했다. AdamOptimizer의 beta1을 0.5로 줄이는 것보다 학습 안정성이 좋았다.&lt;/p&gt;

&lt;p&gt;모델 구조는 아래와 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-18-DCGAN/01.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;단 1 epoch만 학습시켰을 때의 결과. minibatch SGD를 썼기 때문에 이미지를 기억한다고는 볼 수 없다. 따라서 overfitting 없이 잘 생성하고 있는 것이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-18-DCGAN/02.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;5 epoch만 학습시켰을 때의 결과. 침대 근처 noise로 볼 때 오히려 underfitting이 일어난 것 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-18-DCGAN/03.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;dcgan의-능력의-경험적-검증empirical-validation-of-dcgans-capabilities&quot;&gt;DCGAN의 능력의 경험적 검증(Empirical Validation of DCGANs Capabilities)&lt;/h2&gt;

&lt;p&gt;Unsupervised representation learning 알고리즘을 평가하는 일반적인 방법은 supervised 데이터셋에 대해 특징 추출을 시킨 뒤 performance를 측정하는 것이다.&lt;/p&gt;

&lt;p&gt;검증 요약:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;CIFAR-10 데이터셋에 대해 검증한 결과, 다른 방법들(K-means, Exemplar CNN 등)과 비교하여 정확도가 별 차이가 없었다!(80.6~84.3%, DCGAN은 82.8%)&lt;/li&gt;
  &lt;li&gt;StreetView House Numbers dataset(SVHN)은 state-of-the-art 결과를 얻었다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;네트워크-내부-조사-및-시각화investigating-and-visualizing-the-internals-of-the-networks&quot;&gt;네트워크 내부 조사 및 시각화(Investigating and Visualizing the Internals of the Networks)&lt;/h2&gt;

&lt;p&gt;우리는 가장 가까운 학습 데이터 이미지를 찾거나, 최근접 픽셀이나 특징 혹은 log-likelihood metric 같은 방법은 별로이기 때문에 사용하지 않았다.&lt;/p&gt;

&lt;p&gt;생성된 2개의 이미지에 사용된 noise인 $z$를 선형 보간하며 그 보간된 $z$로 이미지를 생성시켜본 결과 한 이미지에서 다른 이미지로 서서히 변해가는 결과를 얻었다(아래 그림). 이미지를 보면 창문 없는 방이 거대한 창문이 있는 방으로 변해 가거나(6th row), TV가 창문으로 변해가는 과정(10th row)을 볼 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-18-DCGAN/04.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;벡터 산술 연산을 통해, vec(웃는 여자) $-$ vec(무표정 여자) $+$ vec(무표정 남자) $=$ vec(웃는 남자) 같은 결과를 얻을 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-18-DCGAN/05.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-18-DCGAN/06.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;네트워크 내부의 각 필터는 이해할 수 없는 형식이 아닌 특정 object나 특징을 추출하였음을 알 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-18-DCGAN/07.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;결론-및-추후-연구conclusions-and-future-work&quot;&gt;결론 및 추후 연구(Conclusions and future work)&lt;/h2&gt;

&lt;p&gt;우리는 안정적인 생성모델을 제안하였고 이 적대정 생성모델은 image representation에 탁월함을 보여 주었다. 그러나 아직 오래 학습시킬 시 필터 일부가 요동치는 것 등 모델에 불안정성이 남아 있다.&lt;/p&gt;

&lt;p&gt;추후 연구는 이를 안정화하는 방법을 찾는 것이 될 것이다. 또한 이 framework를 영상 또는 음성 등의 다른 domain에도 확장시킬 수도 있다.&lt;/p&gt;

&lt;h3 id=&quot;acknowledgments&quot;&gt;Acknowledgments&lt;/h3&gt;

&lt;p&gt;Ian GoodFellow 등의 연구자와 Nvidia Titan-X GPU에 감사를 표한다.&lt;/p&gt;

&lt;p&gt;&lt;del&gt;(광고인줄)&lt;/del&gt;&lt;/p&gt;

&lt;h2 id=&quot;참고문헌references&quot;&gt;참고문헌(References)&lt;/h2&gt;

&lt;p&gt;논문 참조!&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;튜토리얼&quot;&gt;튜토리얼&lt;/h1&gt;

&lt;h2 id=&quot;공식-튜토리얼&quot;&gt;공식 튜토리얼&lt;/h2&gt;

&lt;p&gt;DCGAN이 특별히 중요하기 때문인지 Pytorch 공식 홈페이지에 튜토리얼이 있다.&lt;/p&gt;

&lt;p&gt;GAN의 핵심 부분을 제외한 부분은 &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/&quot;&gt;여기&lt;/a&gt;를 참고하면 된다.&lt;/p&gt;

&lt;p&gt;https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;이후-연구들&quot;&gt;이후 연구들&lt;/h1&gt;

&lt;p&gt;GAN 이후로 수많은 발전된 GAN이 연구되어 발표되었다. 가장 중요한 것 두 개는 GAN의 학습 불안정성을 많이 개선시킨 DCGAN(Deep Convolutional GAN), 단순 생성이 목적이 아닌 원하는 형태의 이미지를 생성시킬 수 있게 하는 CGAN(Conditional GAN)일 듯 하다.&lt;/p&gt;

&lt;p&gt;많은 GAN들(catGAN, Semi-supervised GAN, LSGAN, WGAN, WGAN_GP, DRAGAN, EBGAN, BEGAN, ACGAN, infoGAN 등)에 대한 설명은 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/20/advanced-GANs/&quot;&gt;여기&lt;/a&gt;에서, CGAN에 대한 설명은 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/19/CGAN/&quot;&gt;다음 글&lt;/a&gt;에서 진행하도록 하겠다.&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>GAN(Generative Adversarial Networks)</title>
   <link href="http://localhost:4000/GAN/"/>
   <updated>2019-03-03T00:00:00+09:00</updated>
   <id>http://localhost:4000/GAN</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;이 글에서는 2014년 6월 &lt;em&gt;Ian J. Goodfellow&lt;/em&gt; 등이 발표한 Generative Adversarial Networks(GAN, 생성적 적대신경망)를 살펴보도록 한다.&lt;/p&gt;

&lt;p&gt;간단히 GAN은 두 가지 모델을 동시에 학습시키는 구조이다. G(Generator, 생성자)라는 모델은 직접 볼 수 없는 진짜 데이터와 최대한 비슷하게 생긴 가짜 데이터를 만드려고 하고, D(Distriminator, 식별자 또는 감별자)라는 모델은 자신에게 주어진 데이터가 진짜 데이터인지 가짜 데이터인지 최대한 구분하려고 한다.&lt;/p&gt;

&lt;p&gt;GAN을 도식화한 구조는 다음과 같다. &lt;a href=&quot;https://github.com/hwalsuklee/tensorflow-generative-model-collections&quot;&gt;출처&lt;/a&gt;&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-03-GAN/04.PNG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;논문에서는 설명을 위한 예시로 화폐 위조범($G$)와 경찰($D$)을 제시하였다. 다만 차이가 있다면,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;위조범은 진짜를 볼 수 없다는 것(그래서 장님blind라 불린다)&lt;/li&gt;
  &lt;li&gt;경찰은 자신이 판별한 결과를 위조범에게 알려준다
는 것이 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;참고&lt;/em&gt;: $G$로 들어가는 입력 벡터를 뜻하는 noise는 latent variable이라고도 하며, Auto-encoder에서 출력 영상을 만들기 위한 source와 비슷하기에 이 표현도 사용된다.&lt;br /&gt;
또 GAN은 특정한 모델 구조를 가진 것이 아니므로 코드가 특별히 정해진 것은 아니다.&lt;/p&gt;

&lt;p&gt;논문을 적절히 번역 및 요약하는 것으로 시작한다. 많은 부분을 생략할 예정이므로 전체가 궁금하면 원 논문을 찾아 읽어보면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;generative-adversarial-networksgan&quot;&gt;Generative Adversarial Networks(GAN)&lt;/h1&gt;

&lt;p&gt;논문 링크: &lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1406.2661&quot;&gt;Generative Adversarial Networks&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;초록abstract&quot;&gt;초록(Abstract)&lt;/h2&gt;

&lt;p&gt;이 논문에서는 적대적으로 동작하는 두 생성 모델을 동시에 학습시키는 새 framework를 제안한다. 생성자 G는 원본 data distribution을 흉내내려 하고, D는 눈앞의 데이터가 G에게서 온 것인지를 판별한다. G의 목적은 D가 최대한 실수하게 만드는 것이고, D는 당연히 최대한 정확하게 진짜/가짜를 판별하는 것이다.&lt;br /&gt;
이는 2인 minimax 게임과 비슷하다. 어떤 유일한 해가 존재하여 최종적으로 D는 실수할 확률이 0.5가 된다(즉 찍는 수준).&lt;br /&gt;
G와 D가 multi-layer perceptron으로 구성되면 전체 시스템은 backpropagation으로 학습될 수 있다.&lt;br /&gt;
GAN에는 어느 과정에서든 마르코프 체인이나 기타 다른 네트워크가 필요가 전혀 없다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;서론introduction&quot;&gt;서론(Introduction)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;적대적&lt;/em&gt;&lt;/strong&gt;인 두 네트워크를 학습시킨다. D는 원본 data distribution인지 G에서 온 것인지를 판별하고, G는 D가 실수하도록 가짜 데이터를 잘 만들어내는 것이 목표이다.&lt;br /&gt;
이 framework는 많은 특별한 학습 알고리즘과 optimizer를 사용할 수 있다. 앞서 말한 대로 multi-layer perception을 쓰면 다른 복잡한 네트워크는 필요 없이 오직 forward/backpropagation만으로 (이 논문에서는 dropout을 또 쓴다) 학습이 가능하다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;관련-연구related-works&quot;&gt;관련 연구(Related Works)&lt;/h2&gt;

&lt;p&gt;궁금하면 읽어보자.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;RBMs: restricted Boltzmann machines, 잠재 변수를 가진 유향 그래프 모델에 대한 대안으로, 무향 그래프 모델&lt;/li&gt;
  &lt;li&gt;DBMs: deep Boltzmann machines, RBMs와 비슷함. 다양한 변형이 존재&lt;/li&gt;
  &lt;li&gt;MCMC: Markov chain Monte Carlo methods, 위 모델의 측정 방법&lt;/li&gt;
  &lt;li&gt;DBNs: Deep belief networks, 하나의 무향 레이어와 여러 유향 레이어의 hybrid 모델. 계삭적 문제가 있음&lt;/li&gt;
  &lt;li&gt;NCE: noise-contrasive estimation, log-likelihood를 근사하거나 경계값을 구하지 않는 방법&lt;/li&gt;
  &lt;li&gt;GSN: generative stochastic network, 확률분포를 명시적으로 정의하지 않고 분포 샘플을 생성하도록 학습시키는 방법을 사용&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;adversarial nets&lt;/strong&gt;: 적대적 망은 생성 중 feedback loop를 필요로 하지 않아 sampling에서 Markov chain이 필요가 없다. 이는 backpropagation 성능 향상으로 이어진다.&lt;/li&gt;
  &lt;li&gt;auto-encoding varitional Bayes와 stochastic backpropagation은 생성 머신을 학습시키는 방법들 중 하나이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;적대적-망adversarial-nets&quot;&gt;적대적 망(Adversarial nets)&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;기호&lt;/th&gt;
      &lt;th&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$x$&lt;/td&gt;
      &lt;td&gt;데이터&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$p_g$&lt;/td&gt;
      &lt;td&gt;$x$에 대한 생성자의 분포&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$p_z(z)$&lt;/td&gt;
      &lt;td&gt;input noise 변수&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$\theta_g$&lt;/td&gt;
      &lt;td&gt;multilayer perceptrions의 parameters&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$G$&lt;/td&gt;
      &lt;td&gt;$\theta_g$에 의해 표현되는 미분가능한 함수&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$G(z; \theta_g$)&lt;/td&gt;
      &lt;td&gt;data space에 대한 mapping&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$D(x)$&lt;/td&gt;
      &lt;td&gt;$x$가 $p_g$가 아니라 원본 데이터에서 나왔을 확률&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$D(x; \theta_d)$&lt;/td&gt;
      &lt;td&gt;두 번째 multilayer perceptron&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;D의 목적은 데이터가 ‘원본’인지 ‘G가 생성한 데이터’인지 판별하는 것이므로 어떤 데이터에 대해 정확한 label(‘원본’ 또는 ‘G로부터’)을 붙이는 것이다. G의 목적은 D가 실수하게 만드는 것, 즉 어떤 데이터가 주어졌을 때 D가 ‘원본’이라고 판별할 확률과 ‘G로부터 나온 데이터’라고 판별할 확률을 모두 높이는 것(정확히는 같게)이다.&lt;br /&gt;
즉 $log(1-D(G(z)))$를 최소화하도록 G를 훈련시킨다.&lt;/p&gt;

&lt;p&gt;D와 G 모두에 대해 value function $V(G, D)$를 정의하면,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_G max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[log D(x)] + \mathbb{E}_{x \sim p_{z}(z)}[log (1-D(G(z)))]&lt;/script&gt;

&lt;p&gt;위 식의 의미는,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$min_G$: G는 V를 최소화하려고 한다.&lt;/li&gt;
  &lt;li&gt;$max_D$: D는 V를 최대화하려고 한다. 2-player minimax 게임과 같으므로 당연하다.&lt;/li&gt;
  &lt;li&gt;$\mathbb{E}$: 기댓값&lt;/li&gt;
  &lt;li&gt;$x \sim p_{data}(x)$: $x$가 원본 데이터 분포에서 왔을 때&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;D가 &lt;em&gt;아주 똑똑한 경찰&lt;/em&gt;이라면, $x$가 실제로 원본에서 온 것이라면 $D(x)=1$이 될 것이고, $G(z)$에서 온 것이라면 $D(G(z))=0$이 된다. 만약 G가 &lt;em&gt;완벽한 위조범&lt;/em&gt;이 되었다면, $D(x) = {1 \over 2}$이다.&lt;br /&gt;
따라서 D의 입장에서 V의 최댓값은 0이 되며, G의 입장에서 V의 최솟값은 $-\infty$임을 알 수 있다.&lt;/p&gt;

&lt;p&gt;학습시킬 때, inner loop에서 D를 최적화하는 것은 매우 많은 계산을 필요로 하고 유한한 데이터셋에서는 overfitting을 초래하기 때문에, $k$ step만큼 D를 최적화하고 G는 1 step만 최적화하도록 한다.&lt;br /&gt;
학습 초반에는 G가 형편없기 때문에 D는 진짜인지 G가 생성한 것인지를 아주 잘 구분해 낸다.&lt;br /&gt;
또 G가 $log(1-D(G(z)))$를 최소화하도록 하는 것보다는 $log(D(G(z)))$를 최대화하도록 하는 것이 더 학습이 잘 된다. 이는 G가 형편없을 때는 $log(1-D(G(z)))$의 gradient를 계산했을 때 너무 작은 값이 나와 학습이 느리기 때문이라고 한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-03-GAN/01.PNG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;파란 점선은 disctiminative distribution(D), 검정색은 원본 데이터($p_x$), 초록색은 생성된 분포$p_g$(G), $x$는 원본 데이터 분포를, 화살표는 $x=G(z)$ mapping을 나타낸다. (a) 초기 상태. (b) D 학습 후, (c) G 학습 후, 분포가 비슷해지는 것을 볼 수 있다. (d) 여러 번의 학습 끝에 G가 완전히 원본을 흉내낼 수 있는 경지에 도달함. 즉 $p_g = p_{data}$. D는 이제 진짜인지 가짜인지 구분할 수 없다. 즉 $D(x) = {1 \over 2}$.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;이론적-결과theoretical-results&quot;&gt;이론적 결과(Theoretical Results)&lt;/h2&gt;

&lt;p&gt;수학을 좋아한다면 직접 읽어보자.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Algorithm 1
    &lt;ul&gt;
      &lt;li&gt;for epochs do
        &lt;ul&gt;
          &lt;li&gt;for k steps do
            &lt;ul&gt;
              &lt;li&gt;noise prior $p_g(z)$로부터 $m$개의 noise sample $z^{(1)}, …, z^{(m)}$을 뽑는다.&lt;/li&gt;
              &lt;li&gt;noise prior $p_{data}(x)$로부터 $m$개의 noise sample $x^{(1)}, …, x^{(m)}$을 뽑는다.&lt;/li&gt;
              &lt;li&gt;D를 다음 stochastic gradient로 update한다. (ascending)
                &lt;ul&gt;
                  &lt;li&gt;$ \nabla_{\theta_d} {1 \over m} \sum^m_{i=1} [log D(x^{(i)}) + log (1-D(G(z^{(i)})))] $&lt;/li&gt;
                &lt;/ul&gt;
              &lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;noise prior $p_g(z)$로부터 $m$개의 noise sample $z^{(1)}, …, z^{(m)}$을 뽑는다.&lt;/li&gt;
          &lt;li&gt;G를 다음 stochastic gradient로 update한다. (descending)
            &lt;ul&gt;
              &lt;li&gt;$ \nabla_{\theta_d} {1 \over m} \sum^m_{i=1} [log (1-D(G(z^{(i)})))] $&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;이 minimax 게임은 $p_g = p_{data}$에 대한 global optimum을 가진다.
    &lt;ul&gt;
      &lt;li&gt;G를 고정했을 때, optimal한 D는 $ D^*&lt;em&gt;G(x) = {p&lt;/em&gt;{data}(x) \over p_{data}(x) + p_g(x)} $&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Algorithm 1은 수렴한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;실험experiments&quot;&gt;실험(Experiments)&lt;/h2&gt;

&lt;p&gt;MNIST, Toronto Face Database(TFD), CIFAR-10에 대해 학습을 진행했다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;G는 rectifier linear activations와 sigmoid를 사용했고, D는 maxout activations를 사용했다.&lt;/li&gt;
  &lt;li&gt;Dropout은 D를 학습시킬 때 사용했다.&lt;/li&gt;
  &lt;li&gt;noise는 G에서 가장 밑의 레이어에만 input으로 넣었다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;자세한 실험 조건은 직접 읽어보자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-03-GAN/02.PNG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;가장 오른쪽 열은 바로 옆에 있는 생성된 이미지와 가장 비슷한 학습 샘플이다. a) MNIST b) TFD c) CIFAR-10(fully connected model) d) CIFAR-10(convolutional D와 “deconvolutional” G)&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-03-03-GAN/03.PNG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;숫자 간 보간을 했을 때는 위와 같이 된다. 물론 GAN을 통해 생성한 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;장단점advantages-and-disadvantages&quot;&gt;장단점(Advantages and disadvantages)&lt;/h2&gt;

&lt;h3 id=&quot;단점&quot;&gt;단점&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;$p_g(x)$가 명시적으로 존재하지 않는다.&lt;/li&gt;
  &lt;li&gt;D는 G와 균형을 잘 맞추어서 성능이 향상되어야 한다(G는 D가 발전하기 전 너무 발전하면 안 된다).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;장점&quot;&gt;장점&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;마르코프 체인이 전혀 필요 없이 backprop만으로 학습이 된다.&lt;/li&gt;
  &lt;li&gt;특별히 어떤 추론(inference)도 필요 없다.&lt;/li&gt;
  &lt;li&gt;다양한 함수들이 모델에 접목될 수 있다.&lt;/li&gt;
  &lt;li&gt;마르코프 체인을 썼을 때에 비해 훨씬 선명한(sharp) 이미지를 결과로 얻을 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;결론-및-추후-연구conclusions-and-future-work&quot;&gt;결론 및 추후 연구(Conclusions and future work)&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;conditional generative model로 발전시킬 수 있다(CGAN).&lt;/li&gt;
  &lt;li&gt;Learned approximate inference는 $x$가 주어졌을 때 $z$를 예측하는 보조 네트워크를 학습함으로써 수행될 수 있다.&lt;/li&gt;
  &lt;li&gt;parameters를 공유하는 조건부 모델을 학습함으로써 다른 조건부 모델을 대략 모델링 할 수 있다. 특히, deterministic MP-DBM의 stochastic extension의 구현에 대부분의 네트워크를 쓸 수 있다.&lt;/li&gt;
  &lt;li&gt;Semi-supervised learning에도 활용 가능하다. classifier의 성능 향상을 꾀할 수 있다.&lt;/li&gt;
  &lt;li&gt;효율성 개선: G와 D를 조정하는 더 나은 방법이나 학습하는 동안 sample $z$에 대한 더 나은 distributions을 결정하는 등의 방법으로 속도를 높일 수 있다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;참고문헌references&quot;&gt;참고문헌(References)&lt;/h2&gt;

&lt;p&gt;논문 참조!&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;보충-설명&quot;&gt;보충 설명&lt;/h1&gt;

&lt;h2 id=&quot;목적함수&quot;&gt;목적함수&lt;/h2&gt;

&lt;p&gt;D의 목적함수는 G를 고정한 채로 진짜 데이터 $m$개와 가짜 데이터 $m$개를 D에 넣고, G에 대한 V를 계산한 뒤 gradient를 구하고 V를 높여 D를 최종적으로 업데이트한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;max_D V(D) = {1 \over m } \sum^m_{i=1} log D(x^i) + {1 \over m } \sum^m_{i=1} log D(1 - D(G(z^i)))&lt;/script&gt;

&lt;p&gt;G의 목적함수는 D를 고정한 채로 가짜 데이터 $m$개를 생성해 V을 계산한 뒤, G에 대한 V의 gradient를 계산하고 V를 낮춰 G를 업데이트한다.&lt;br /&gt;
G의 목적함수는 gradient가 0에 가까워지는 것을 막기 위해 논문에서 언급된 팁을 반영한 것이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;min_G V(G) = {1 \over m} \sum^m_{j=1} log(D(G(z^j)))&lt;/script&gt;

&lt;h3 id=&quot;목적함수-최적화의-의미&quot;&gt;목적함수 최적화의 의미&lt;/h3&gt;

&lt;p&gt;Machine Learning 관점에서 보면 모델이 loss가 최소화되는 parameter를 찾아가는 과정이다.&lt;br /&gt;
또는 진짜 데이터의 분포와 G가 생성한 가짜 데이터 분포 사이의 차이를 줄이는 것과도 같다.&lt;/p&gt;

&lt;p&gt;수학적으로는 D가 이미 최적이라는 가정 하에, GAN이 목적함수를 최적화한다는 과정($p_{data}$와 $p_g$를 똑같이 만드려는 것)은 $p_{data}$와 $p_g$ 사이의 &lt;a href=&quot;https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence&quot;&gt;Jensen-Shannon divergence(JSD)&lt;/a&gt;를 최소화하는 것과 같다.&lt;br /&gt;
JSD는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence&quot;&gt;Kullback–Leibler divergence&lt;/a&gt;의 대칭(symmetrized and smoothed) 버전이다. 그래서 GAN은 KLD를 최소화하는 것이라고 말하기도 한다.&lt;/p&gt;

&lt;p&gt;분포 $P$와 $Q$에 대해, $KLD = D(P \Vert Q), M = {1 \over 2}(P+Q)$라 할 때, JSD는&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;JSD(P \Vert Q) = {1 \over 2} D(P \Vert M) + {1 \over 2} D(Q \Vert M)&lt;/script&gt;

&lt;p&gt;이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;학습-방법&quot;&gt;학습 방법&lt;/h2&gt;

&lt;p&gt;GAN은 서로 경쟁하는 두 가지 모델을 학습시킨다. GAN을 쓰려면 다음 방법을 따른다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;우선 다음을 정의한다.
    &lt;ol&gt;
      &lt;li&gt;R(Real): 실제 데이터. 논문에선 $x$로 표시&lt;/li&gt;
      &lt;li&gt;I(Input 또는 Imaginary): G가 가짜 데이터를 생성할 source. 논문에선 $z$로 표시.
        &lt;ul&gt;
          &lt;li&gt;$G(z)$는 $G$가 $z$를 입력으로 받아 생성한 가짜 데이터이다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;$G$(generator): 생성자, 위조범&lt;/li&gt;
      &lt;li&gt;$D$(Distriminator): 감별자 또는 식별자, 경찰&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;다음 전체 과정을 &lt;code class=&quot;highlighter-rouge&quot;&gt;num_epochs&lt;/code&gt; 동안 반복한다:
    &lt;ol&gt;
      &lt;li&gt;D를 training하는 과정(&lt;code class=&quot;highlighter-rouge&quot;&gt;d_steps&lt;/code&gt;만큼 반복): &lt;strong&gt;D와 G를 모두 사용은 하지만 D의 parameter만 업데이트한다.&lt;/strong&gt;
        &lt;ol&gt;
          &lt;li&gt;$D$에 실제 데이터($x$)와 정답(1)을 입력으로 주고 loss를 계산한다.&lt;/li&gt;
          &lt;li&gt;$D$에 가짜 데이터($G(z)$)와 정답(0)을 입력으로 주고 loss를 계산한다.&lt;/li&gt;
          &lt;li&gt;두 loss를 합친 후 $D$의 parameter를 업데이트한다.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;G를 training하는 과정(&lt;code class=&quot;highlighter-rouge&quot;&gt;g_steps&lt;/code&gt;만큼 반복): &lt;strong&gt;D와 G를 모두 사용은 하지만 G의 parameter만 업데이트한다.&lt;/strong&gt;
        &lt;ol&gt;
          &lt;li&gt;$D$에 가짜 데이터($G(z)$)와 정답(1)을 입력으로 주고 loss를 계산한다.&lt;/li&gt;
          &lt;li&gt;계산한 loss를 이용하여 $G$의 parameter를 업데이트한다.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;단점-및-극복방안&quot;&gt;단점 및 극복방안&lt;/h2&gt;

&lt;p&gt;GAN 논문에서는 수학적인 증명이 포함되어 있지만(최소 해를 가지며, 충분히 학습할 시 항상 그 해답을 찾는다), 여러 요인들로 인해 실제 학습시킬 때에는 학습이 좀 불안정하다는 단점이 있다.&lt;/p&gt;

&lt;h3 id=&quot;mode-collapsing&quot;&gt;Mode Collapsing&lt;/h3&gt;

&lt;p&gt;간단히 이 현상은 학습 모델이 실제 데이터의 분포를 정확히 따라가지 못하고 그저 뭉뚱그리기만 하면서 다양성을 잃어버리는 것이다.&lt;br /&gt;
예를 들면 1~9까지의 숫자 9개를 만드는 대신 5만 9개 만드는 것과 비슷하며, MNIST의 경우 10종류의 모든 숫자가 아닌 특정 숫자들만 생성하는 경우이다.&lt;/p&gt;

&lt;p&gt;이는 GAN이 단순히 목적함수의 loss만을 줄이려는 방향으로 설정되어 있어 생기는 현상이다. 이 현상은 GAN의 개선 모델들에서 대부분 해결된다.&lt;/p&gt;

&lt;h3 id=&quot;oscillation&quot;&gt;Oscillation&lt;/h3&gt;

&lt;p&gt;G와 D가 수렴하지 않고 진동하는 모양새를 보일 때가 있다. 이 역시 비슷한 이유로 발생하며, 나중 모델들에서 해결된다.&lt;/p&gt;

&lt;h3 id=&quot;g와-d-사이의-imbalance&quot;&gt;G와 D 사이의 Imbalance&lt;/h3&gt;

&lt;p&gt;학습을 진행하면 처음에는 D가 발전하고 나중에 G가 급격히 학습되는 형상을 보이는데, 처음부터 D가 너무 성능이 좋아져버리면 오히려 G가 학습이 잘 되지 않는 문제가 발생한다(D가 시작부터 G의 기를 죽이는 셈).&lt;/p&gt;

&lt;h3 id=&quot;해결방안&quot;&gt;해결방안&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;진짜 데이터와 가짜 데이터 간 Least Square Error를 목적함수에 추가한다(LSGAN).&lt;/li&gt;
  &lt;li&gt;모델의 구조를 convolution으로 바꾼다(DCGAN)&lt;/li&gt;
  &lt;li&gt;mini-batch별로 학습을 진행할 경우 이전 학습이 잘 잊혀지는 것을 막기 위해 이를 기억하는 방향으로 학습시킨다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;튜토리얼&quot;&gt;튜토리얼&lt;/h1&gt;

&lt;h2 id=&quot;50줄로-짜보는-튜토리얼&quot;&gt;50줄로 짜보는 튜토리얼&lt;/h2&gt;

&lt;p&gt;원문 링크는 &lt;a href=&quot;https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f&quot;&gt;여기&lt;/a&gt;, 번역본은 &lt;a href=&quot;http://ddanggle.github.io/GANinTorch&quot;&gt;여기&lt;/a&gt;에서 볼 수 있다.&lt;br /&gt;
해당 튜토리얼에서는&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;이 전체 과정을 &lt;code class=&quot;highlighter-rouge&quot;&gt;num_epochs&lt;/code&gt;(여기서는 5000)만큼 반복한다.
    &lt;ol&gt;
      &lt;li&gt;training D(&lt;code class=&quot;highlighter-rouge&quot;&gt;d_steps&lt;/code&gt;만큼 반복):
        &lt;ol&gt;
          &lt;li&gt;가우시안 분포를 따르는 데이터를 Real Data로 생성하고&lt;/li&gt;
          &lt;li&gt;그 momentum(mean, std, skews, kurtoses)를 계산하여 D에게 전달, error를 계산한다.&lt;/li&gt;
          &lt;li&gt;또 Fake data를 G가 생성하게 하고&lt;/li&gt;
          &lt;li&gt;D가 error를 계산하게 한다.&lt;/li&gt;
          &lt;li&gt;위 두 과정(1~2, 3~4)으로 D의 parameter를 업데이트한다.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;training G(&lt;code class=&quot;highlighter-rouge&quot;&gt;g_steps&lt;/code&gt;만큼 반복):
        &lt;ol&gt;
          &lt;li&gt;G로 Fake data를 생성한다.&lt;/li&gt;
          &lt;li&gt;D에게서 판별 결과를 받아온다.&lt;/li&gt;
          &lt;li&gt;G가 error를 계산하게 한다.&lt;/li&gt;
          &lt;li&gt;G의 parameter를 업데이트한다.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/devnag/pytorch-generative-adversarial-networks&quot;&gt;코드&lt;/a&gt;는 원문에도 소개되어 있지만 전체는 사실 186줄이다(…) 물론 GAN의 핵심 코드는 50줄 정도이다.&lt;/p&gt;

&lt;h2 id=&quot;mnist-튜토리얼&quot;&gt;MNIST 튜토리얼&lt;/h2&gt;

&lt;p&gt;GAN의 핵심 부분을 제외한 부분은 &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/&quot;&gt;여기&lt;/a&gt;를 참고하면 된다.&lt;/p&gt;

&lt;p&gt;우선 기본 설정부터 하자.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;argparse&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pickle&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;imageio&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;argparse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ArgumentParser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'GAN tutorial: MNIST'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'--epochs'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'number of epochs'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'--batch-size'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'size of mini-batch'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'--noise-size'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'size of random noise vector'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'--use-cuda'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'use cuda if available'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'--learning-rate'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'-lr'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0002&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'learning rate of AdamOptimizer'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'--beta1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'parameter beta1 of AdamOptimizer'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'--beta2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'parameter beta2 of AdamOptimizer'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'--output-dir'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'output/'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'directory path of output'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'--log-file'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'log.txt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'filename of logging'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parse_args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;makedirs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exist_ok&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;use_cuda&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;use_cuda&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_available&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;root&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mnist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Generator는 다음과 같이 선언한다. 레이어는 총 4개, activation function은 LeakyRELU와 Tanh를 사용하였다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        :param x: input tensor[batch_size * noise_size]
        :return: output tensor[batch_size * 1 * 28 * 28]
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Discriminator는 다음과 같다. Linear Layer는 G의 역방향으로 가는 것과 비슷하지만, activation function에는 차이가 있다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        :param x: input tensor[batch_size * 1 * 28 * 28]
        :return: possibility of that the image is real data
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;GAN의 핵심 부분은 다음과 같다. 위의 Gaussian 분포 예제와 크게 다르지 않아서 크게 설명은 필요없을 듯 하다. 차이점을 조금 적어보자면&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;분포의 momentum을 G의 데이터 생성 source로 사용하는 대신 길이 100(MNIST의 경우 보통)짜리 random vector를 사용한다. G는 이 길이 100짜리 벡터를 갖고 MNIST의 숫자 이미지와 비슷한 이미지를 생성하려고 하게 된다.&lt;/li&gt;
  &lt;li&gt;또 &lt;code class=&quot;highlighter-rouge&quot;&gt;.cuda()&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;DataLoader&lt;/code&gt;를 사용하는 것 정도가 있겠으나 GAN의 핵심 부분은 아니다.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_real_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_real_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Training D with real data
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;target_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;target_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;D_real_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; \
                &lt;span class=&quot;n&quot;&gt;D_real_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;D_real_decision&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_real_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;D_real_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_real_decision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Training D with fake data
&lt;/span&gt;            
            &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;noise_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;D_fake_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;D_fake_decision&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_fake_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;D_fake_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_fake_decision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;D_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_real_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D_fake_loss&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;D_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;D_optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Training G based on D's decision
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;noise_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;use_cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;D_fake_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;D_fake_decision&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_fake_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;G_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D_fake_decision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;G_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;G_optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;전체 코드는 &lt;a href=&quot;https://github.com/greeksharifa/Tutorial.code/blob/master/Python/GAN_tutorial/gan_tutorial.py&quot;&gt;여기&lt;/a&gt;를 참조하라.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;이후-연구들&quot;&gt;이후 연구들&lt;/h1&gt;

&lt;p&gt;사실 2014년 발표된 original GAN은&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;학습이 불안정하고&lt;/li&gt;
  &lt;li&gt;고해상도 이미지는 생성하지 못하는
한계를 갖고 있었다. 논문에서 optimal point가 있고 그쪽으로 수렴한다는 것을 보였지만, 실제로는 여러 변수 때문에 학습이 항상 잘 되는 것이 아니라는 현상을 보인다. 이러한 문제를 보완하기 위해 GAN 이후로 수많은 발전된 GAN이 연구되어 발표되었다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그 중에서 가장 중요한 것을 3가지 정도만 뽑자면&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Convolution을 사용하여 GAN의 학습 불안정성을 많이 개선시킨 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/17/DCGAN/&quot;&gt;DCGAN(Deep Convolutional GAN, 2015)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;단순 생성이 목적이 아닌 원하는 형태의 이미지를 생성시킬 수 있게 하는 시초인 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/19/CGAN/&quot;&gt;CGAN(Conditional GAN, 2014)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;GAN이 임의의 divergence를 사용하는 경우에 대해 local convergence함을 보여주고 그에 대해 실제 작동하는 GAN을 보여준 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/19/f-GAN/&quot;&gt;f-GAN(2016)&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;일 듯 하다.&lt;/p&gt;

&lt;p&gt;많은 GAN들(catGAN, Semi-supervised GAN, LSGAN, WGAN, WGAN_GP, DRAGAN, EBGAN, BEGAN, ACGAN, infoGAN 등)에 대한 설명은 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/20/advanced-GANs/&quot;&gt;여기&lt;/a&gt;에서, DCGAN에 대해서는 &lt;a href=&quot;https://greeksharifa.github.io/generative%20model/2019/03/17/DCGAN/&quot;&gt;다음 글&lt;/a&gt;에서 진행하도록 하겠다.&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>Python argparse 사용법</title>
   <link href="http://localhost:4000/argparse-usage/"/>
   <updated>2019-02-12T00:00:00+09:00</updated>
   <id>http://localhost:4000/argparse-usage</id>
   <content type="html">&lt;p&gt;이 글에서는 Python 패키지인 argparse에 대해 알아본다. Machine Learning 코드를 볼 때 꽤 자주 볼 수 있을 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;import&quot;&gt;Import&lt;/h1&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;argparse&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;argparse&quot;&gt;argparse&lt;/h1&gt;

&lt;script data-ad-client=&quot;ca-pub-9951774327887666&quot; async=&quot;&quot; src=&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python train.py --epochs 50 --batch-size 64 --save-dir weights
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Machine Learning을 포함해서, 위와 같은 실행 옵션은 많은 코드에서 볼 수 있었을 것이다. 학습 과정을 포함하여 대부분은 명령창 또는 콘솔에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;python 파일명 옵션들...&lt;/code&gt;으로 실행시키기 때문에, argparse에 대한 이해는 필요하다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;중요:&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;기본적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;argparse&lt;/code&gt; 라이브러리는 명령창(터미널)에서 실행하는 것을 원칙으로 한다. Jupyter notebook이나 (iPython) 대화형 실행 framework에서는 제대로 실행되지 않을 수 있다. 또한 이러한 대화형 framework에서는 코드 상에서 명시적으로 집어 넣는 게 아닌 이상 인자에 값을 바로 줄 수도 없다.&lt;/li&gt;
  &lt;li&gt;그래도 쓰고 싶다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;args = parser.parse_args()&lt;/code&gt;를 &lt;code class=&quot;highlighter-rouge&quot;&gt;args = parser.parse_args(args=[])&lt;/code&gt;로 바꾸고 사용할 수는 있다…하지만 위의 이유로 인해 별 의미는 없을 듯하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;필자는 이 글에서 위의 명령 중 &lt;code class=&quot;highlighter-rouge&quot;&gt;--epochs&lt;/code&gt;와 같은 것을 &lt;strong&gt;인자&lt;/strong&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;50&lt;/code&gt;과 같은 것을 (같이 준) &lt;strong&gt;값&lt;/strong&gt;으로 부르겠다.&lt;/p&gt;

&lt;p&gt;argparse는 python에 기본으로 내장되어 있다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;argparse&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;import os&lt;/code&gt;는 output directory를 만드는 등의 역할을 위해 필요하다.&lt;/p&gt;

&lt;p&gt;argparse를 쓰려면 기본적으로 다음 코드가 필요하다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;argparse&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;argparse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ArgumentParser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Argparse Tutorial'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# argument는 원하는 만큼 추가한다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'--print-number'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                    &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'an integer for printing repeatably'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parse_args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;print_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'print number {}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ol&gt;
  &lt;li&gt;일단 &lt;a href=&quot;https://docs.python.org/3/library/argparse.html?highlight=argparse#argparse.ArgumentParser&quot;&gt;ArgumentParser&lt;/a&gt;에 원하는 description을 입력하여 parser 객체를 생성한다. description 외에도 usage, default value 등을 지정할 수 있다.&lt;/li&gt;
  &lt;li&gt;그리고 &lt;code class=&quot;highlighter-rouge&quot;&gt;add_argument()&lt;/code&gt; method를 통해 원하는 만큼 인자 종류를 추가한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;parse_args()&lt;/code&gt; method로 명령창에서 주어진 인자를 파싱한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;args&lt;/code&gt;라는 이름으로 파싱을 성공했다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;args.parameter&lt;/code&gt; 형태로 주어진 인자 값을 받아 사용할 수 있다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;실행 결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; python argparseTest.py -h
usage: argparseTest.py [-h] [--print-number PRINT_NUMBER]

Argparse Tutorial

optional arguments:
  -h, --help            show this help message and exit
  --print-number PRINT_NUMBER
                        an integer for printing repeatably

&amp;gt; python argparseTest.py --print-number 5
print number 1
print number 2
print number 3
print number 4
print number 5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;argparse의 인자는 지정할 수 있는 종류가 상당히 많다.&lt;/p&gt;
&lt;h2 id=&quot;help--h&quot;&gt;–help, -h&lt;/h2&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--help&lt;/code&gt; 또는 &lt;code class=&quot;highlighter-rouge&quot;&gt;-h&lt;/code&gt;: 기본으로 내장되어 있는 옵션이다. 이 인자를 넣고 python으로 실행하면 인자 사용법에 대한 도움말이 출력된다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; python argparseTest.py -h
usage: argparseTest.py [-h] [--print-number PRINT_NUMBER]
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;argument-이름-정의&quot;&gt;argument 이름 정의&lt;/h2&gt;
&lt;p&gt;인자의 이름을 지정할 때 여러 이름을 짓는 것이 가능하다. 지정할 때 두 개를 연속해서 나열한다. 보통 1~2개를 지정하는데, &lt;code class=&quot;highlighter-rouge&quot;&gt;--help&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;-h&lt;/code&gt;같이 fullname과 약자를 하나씩 지정하는 편이다. 또 &lt;code class=&quot;highlighter-rouge&quot;&gt;help=&lt;/code&gt;에서 description을 써줄 수 있다.&lt;br /&gt;
참고로 help 메시지는 % formatting을 지원한다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'--print-number'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'-p'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;help&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'an integer for printing repeatably'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;type-지정&quot;&gt;type 지정&lt;/h2&gt;
&lt;p&gt;기본적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;parse_args()&lt;/code&gt;가 주어진 인자들을 파싱할 때는 모든 문자를 숫자 등이 아닌 문자열 취급한다. 따라서 데이터 타입을 지정하고 싶으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;add_argument()&lt;/code&gt;에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;type=&lt;/code&gt;을 지정해 주어야 한다. default는 말한 대로 &lt;code class=&quot;highlighter-rouge&quot;&gt;str&lt;/code&gt;이다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ex) &lt;code class=&quot;highlighter-rouge&quot;&gt;parser.add_argument('--print-number', '-p', type=int, ...)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;type으로 사용 가능한 것은 한 개의 문자열을 받아들여 return 문이 있는 모든 callable 객체이다.&lt;/li&gt;
  &lt;li&gt;Common built-in types과 functions이 사용 가능한데, &lt;code class=&quot;highlighter-rouge&quot;&gt;str&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;int&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;float&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;bool&lt;/code&gt;과 &lt;code class=&quot;highlighter-rouge&quot;&gt;open&lt;/code&gt; 등이 있다. &lt;code class=&quot;highlighter-rouge&quot;&gt;list&lt;/code&gt;와 같은 것은 불가능하다. list처럼 쓰고 싶으면 아래쪽에서 설명할 &lt;code class=&quot;highlighter-rouge&quot;&gt;action=append&lt;/code&gt;를 이용한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;argparse.FileType()&lt;/code&gt; 함수도 &lt;code class=&quot;highlighter-rouge&quot;&gt;type=&lt;/code&gt;에 사용 가능한데, &lt;code class=&quot;highlighter-rouge&quot;&gt;mode=&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;bufsize=&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;encoding=&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;errors=&lt;/code&gt; parameter를 취하는 함수로서 다양한 파일을 여러 옵션으로 지정할 수 있다. 예를 들어 &lt;code class=&quot;highlighter-rouge&quot;&gt;argparse.FileType('w')&lt;/code&gt;는 쓰기 가능한 파일을 만든다. 자세한 것은 &lt;a href=&quot;https://docs.python.org/3/library/argparse.html?highlight=argparse#type&quot;&gt;여기&lt;/a&gt;를 참조한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;positional--optional-인자&quot;&gt;positional / optional 인자&lt;/h2&gt;
&lt;p&gt;positional 인자와 optional 인자가 있다. 인자의 이름 앞에 &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;가 붙어 있으면 optional, 아니면 positional 인자로서 필수로 지정해야 한다.&lt;br /&gt;
단, positional 인자도 필수로 넣어야 하게끔 할 수 있다. &lt;code class=&quot;highlighter-rouge&quot;&gt;add_argument()&lt;/code&gt; 함수에 &lt;code class=&quot;highlighter-rouge&quot;&gt;required=True&lt;/code&gt;를 집어넣으면 된다. 그러나 C언어에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;#define true false&lt;/code&gt;같은 짓인 만큼 권장되지 않는다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# argparseTest.py
# ...
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'--foo'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'-f'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# optional
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bar'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;         &lt;span class=&quot;c1&quot;&gt;# positional
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parse_args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'args.foo:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'args.bar:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# optional 인자는 지정하지 않아도 되고, 그럴 경우 기본값이 저장된다.
&amp;gt; python argparseTest.py bar_value
args.foo: None
args.bar: bar_value

# positional 인자는 반드시 값을 정해 주어야 한다.
&amp;gt; python argparseTest.py --foo 1
usage: argparseTest.py [-h] [--foo FOO] bar
argparseTest.py: error: the following arguments are required: bar

# optional 인자 뒤에는 반드시 저장할 값을 지정해야 한다. 
# 이는 `action=store`인 optional 인자에 해당한다. 6번 항목에서 설명하겠다.
&amp;gt; python argparseTest.py bar_value --foo
usage: argparseTest.py [-h] [--foo FOO] bar
argparseTest.py: error: argument --foo/-f: expected one argument

# optional 인자는 `--foo 3`또는 `--foo=3` 두 가지 방식으로 지정할 수 있다.
# positional 인자는 그런 거 없다.
&amp;gt; python argparseTest.py --foo=5 bar=bar_value
args.foo: 5
args.bar: bar_value

# positional 인자가 여러 개라면 순서를 반드시 지켜야 한다.
# optional 인자는 값만 잘 지정한다면 어디에 끼워 넣어도 상관없다.
&amp;gt; python argparseTest.py bar_value --foo 7
args.foo: 7
args.bar: bar_value
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;default-값-지정&quot;&gt;default 값 지정&lt;/h2&gt;
&lt;p&gt;값을 저장할 때 명시적으로 지정하지 않았을 때 들어가는 기본값을 설정할 수 있다. &lt;code class=&quot;highlighter-rouge&quot;&gt;add_argument()&lt;/code&gt;에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;default=&lt;/code&gt; 옵션을 지정한다.
    - &lt;code class=&quot;highlighter-rouge&quot;&gt;argparse.SUPPRESS&lt;/code&gt;를 적을 경우, 인자를 적지 않았을 때 None이 들어가는 것이 아닌 아예 인자 자체가 생성되지 않는다. 또한 &lt;code class=&quot;highlighter-rouge&quot;&gt;--help&lt;/code&gt;에도 표시되지 않는다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'--foo'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'-f'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; python argparseTest.py
args.foo: 5

# 그러나 인자를 적어 놓고 값은 안 주면 에러가 난다. 
# 기본적으로 한 개의 값을 추가로 받아야 하기 때문이다.
# 이걸 바꾸려면 6번이나 7번 항목을 참조한다.
&amp;gt; python argparseTest.py --foo
usage: argparseTest.py [-h] [--foo FOO]
argparseTest.py: error: argument --foo/-f: expected one argument
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;action의-종류-지정&quot;&gt;action의 종류 지정&lt;/h2&gt;
&lt;p&gt;인자를 정의(&lt;code class=&quot;highlighter-rouge&quot;&gt;add_argument()&lt;/code&gt;에 의해)할 때 action을 지정할 수 있다. 액션에는 다음과 같은 것들이 있으며, 기본값은 &lt;code class=&quot;highlighter-rouge&quot;&gt;store&lt;/code&gt;이다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;store&lt;/code&gt;: action을 지정하지 않으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;store&lt;/code&gt;이 된다. 인자 이름 바로 뒤의 값을 해당 인자에 대입(저장)시킨다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;store_const&lt;/code&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;add_argument()&lt;/code&gt;에서 미리 지정되어 있는 &lt;code class=&quot;highlighter-rouge&quot;&gt;const=&lt;/code&gt;에 해당하는 값이 저장된다. &lt;code class=&quot;highlighter-rouge&quot;&gt;const=&lt;/code&gt;는 반드시 써 주어야 한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;store_true&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;store_false&lt;/code&gt;: 인자를 적으면(값은 주지 않는다) 해당 인자에 &lt;code class=&quot;highlighter-rouge&quot;&gt;True&lt;/code&gt;나 &lt;code class=&quot;highlighter-rouge&quot;&gt;False&lt;/code&gt;가 저장된다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;append&lt;/code&gt;: 값을 하나가 아닌 여러 개를 저장하고 싶을 때 쓴다. 인자를 여러 번 호출하면 같이 주는 값이 계속 append된다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;append_const&lt;/code&gt;: append와 비슷하지만 사전에 지정한 const 값이 저장된다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;count&lt;/code&gt;: 인자를 적은 횟수만큼 값이 올라간다. 보통 &lt;code class=&quot;highlighter-rouge&quot;&gt;verbose&lt;/code&gt; 옵션에 많이 쓴다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;help&lt;/code&gt;: 도움말 메시지를 출력하게 하고 종료하여 코드는 실행시키지 않는다. &lt;code class=&quot;highlighter-rouge&quot;&gt;--help&lt;/code&gt; 역할을 대신한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;version&lt;/code&gt;: &lt;code class=&quot;highlighter-rouge&quot;&gt;version&lt;/code&gt; 인자에 사용가능하다. 버전 정보를 출력하고 종료한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;parser.add_argument('--foo', action='store_const', const=10)
&amp;gt; python argparseTest.py --foo
args.foo: 10

# 인자를 적지 않으면 default 값(None)이 저장된다.
parser.add_argument('--foo', action='store_const', const=10)
&amp;gt; python argparseTest.py
args.foo: None

# default 값을 지정하면 당연히 바뀐다.
parser.add_argument('--foo', action='store_const', const=10, default=5)
&amp;gt; python argparseTest.py
args.foo: 5

# store_true의 경우 default 값은 false이며, 인자를 적어 주면 true가 저장된다.
# store_false의 경우 반대이다.
parser.add_argument('--foo1', action='store_true')
parser.add_argument('--foo2', action='store_true')
parser.add_argument('--foo3', action='store_false')
parser.add_argument('--foo4', action='store_false')
args = parser.parse_args()

print('args.foo1:', args.foo1)
print('args.foo2:', args.foo2)
print('args.foo3:', args.foo3)
print('args.foo4:', args.foo4)
&amp;gt; python argparseTest.py --foo1 --foo4
args.foo: True
args.foo: False
args.foo: True
args.foo: False

# 참고로 한 번만 호출해도 args.foo는 데이터 타입이 list가 된다. 안 하면 None이다.
parser.add_argument('--foo', action='append')
&amp;gt; python argparseTest.py --foo 1 --foo 123 --foo=xyz
args.foo: ['1', '123', 'xyz']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;attribute-name---_-구분&quot;&gt;attribute name: -, _ 구분&lt;/h2&gt;
&lt;p&gt;인자의 이름에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;_&lt;/code&gt;을 쓸 수 있다. 단, python 기본 문법은 변수명에 &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;를 허용하지 않기 때문에, 인자의 이름에 &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;가 들어갔다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;args.인자&lt;/code&gt;로 접근하려면 &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;를 &lt;code class=&quot;highlighter-rouge&quot;&gt;_&lt;/code&gt;로 바꿔 주어야 한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--print-number&lt;/code&gt;의 경우 &lt;code class=&quot;highlighter-rouge&quot;&gt;args.print_number&lt;/code&gt;로 접근할 수 있다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--print_number&lt;/code&gt;의 경우 &lt;code class=&quot;highlighter-rouge&quot;&gt;args.print_number&lt;/code&gt;로 동일하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;dest-적용-위치-지정&quot;&gt;dest: 적용 위치 지정&lt;/h2&gt;
&lt;p&gt;argument를 지정할 때 store나 action의 저장 또는 적용 위치를 바꿔서 지정할 수 있다. 예를 들어 &lt;code class=&quot;highlighter-rouge&quot;&gt;--foo&lt;/code&gt;의 &lt;code class=&quot;highlighter-rouge&quot;&gt;dest=&lt;/code&gt; 옵션을 &lt;code class=&quot;highlighter-rouge&quot;&gt;--foo-list&lt;/code&gt;로 지정하면, &lt;code class=&quot;highlighter-rouge&quot;&gt;args.foo_list&lt;/code&gt;에 값이 저장되는 식이다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'--foo'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'append'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'foo_list'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_argument&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'--bar'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bar_value'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parse_args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'args.foo_list:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foo_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'args.bar_value:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bar_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foo&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Hmm?'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;AttributeError&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Where are you gone?'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; python argparseTest.py --foo 1 --foo 123 --foo=xyz --bar ABC
args.foo_list: ['1', '123', 'xyz']
args.bar_value: ABC
Where are you gone? 'Namespace' object has no attribute 'foo'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;nargs-값-개수-지정&quot;&gt;nargs: 값 개수 지정&lt;/h2&gt;
&lt;p&gt;argparse는 일반적으로 1개의 값을 추가로 받거나, &lt;code class=&quot;highlighter-rouge&quot;&gt;action=store_true&lt;/code&gt;의 경우는 값을 추가로 받지 않는다. 이를 바꿔 주는 것이 &lt;code class=&quot;highlighter-rouge&quot;&gt;nargs=&lt;/code&gt; 이다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;N&lt;/code&gt;: N개의 값을 읽어들인다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt;: 0개 또는 1개의 값을 읽어들인다.
    &lt;ul&gt;
      &lt;li&gt;인자와 값을 모두 적은 경우 해당 값이 저장된다.&lt;/li&gt;
      &lt;li&gt;인자만 적은 경우 const 값이 저장된다.&lt;/li&gt;
      &lt;li&gt;아무것도 적지 않았으면 default 값이 저장된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;: 0개 이상의 값을 전부 읽어들인다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt;: 1개 이상의 값을 전부 읽어들인다. 정규표현식의 것과 매우 비슷하다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;argparse.REMAINDER&lt;/code&gt;: 남은 값을 개수 상관없이 전부 읽어들인다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;예제는 &lt;a href=&quot;https://docs.python.org/3/library/argparse.html?highlight=argparse#nargs&quot;&gt;원문&lt;/a&gt;이나 &lt;a href=&quot;https://docs.python.org/ko/3.7/library/argparse.html#nargs&quot;&gt;번역본&lt;/a&gt;을 참조한다.&lt;/p&gt;

&lt;h2 id=&quot;choices-값-범위-지정&quot;&gt;choices: 값 범위 지정&lt;/h2&gt;
&lt;p&gt;인자와 같이 주어지는 값의 범위를 제한하고 싶으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;choices=&lt;/code&gt; 옵션을 쓰면 된다. &lt;code class=&quot;highlighter-rouge&quot;&gt;choices=&lt;/code&gt;에 들어갈 수 있는 정의역은 list 등 iterable 객체이다(&lt;code class=&quot;highlighter-rouge&quot;&gt;in&lt;/code&gt; 조건검사를 할 수 있으면 된다).&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;parser.add_argument('--foo', choices=range(1, 5))
&amp;gt; python argparseTest.py --foo 5
usage: argparseTest.py [-h] [--foo {1,2,3,4}]
argparseTest.py: error: argument --foo: 
invalid choice: '5' (choose from 1, 2, 3, 4)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;metavar-이름-재지정&quot;&gt;metavar: 이름 재지정&lt;/h2&gt;
&lt;p&gt;metavar은 &lt;code class=&quot;highlighter-rouge&quot;&gt;help=&lt;/code&gt;에서 도움말 메시지를 생성할 때 표시되는 이름을 변경할 수 있다(직접 값을 참조하는  &lt;code class=&quot;highlighter-rouge&quot;&gt;args.foo&lt;/code&gt; 같은 경우 기본 이름 또는 &lt;code class=&quot;highlighter-rouge&quot;&gt;dest=&lt;/code&gt;에 의해 재지정된 이름을 써야 한다).&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.python.org/3/library/argparse.html&quot;&gt;원문&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.python.org/ko/3.7/library/argparse.html&quot;&gt;번역본&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>PyCharm 사용법</title>
   <link href="http://localhost:4000/PyCharm-usage/"/>
   <updated>2019-02-07T00:00:00+09:00</updated>
   <id>http://localhost:4000/PyCharm-usage</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;PyCharm(파이참)은 Jetbrains 사에서 제작 및 배포하는 &lt;strong&gt;유료&lt;/strong&gt;/무료 프로그램이다.&lt;br /&gt;
Professional 버전은 돈을 주고 구입하거나, 학생이라면 &lt;a href=&quot;https://www.jetbrains.com/student/&quot;&gt;학생 인증&lt;/a&gt;을 하고 무료로 사용할 수 있다.&lt;/p&gt;

&lt;p&gt;글이 길기 때문에 사용법을 검색하고 싶다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + F&lt;/code&gt; 키를 누른 다음 검색해 보자.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;2020.05.10 updated&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;설치&quot;&gt;설치&lt;/h2&gt;

&lt;p&gt;PyCharm 홈페이지에서 설치 파일을 다운받는다.&lt;/p&gt;

&lt;script data-ad-client=&quot;ca-pub-9951774327887666&quot; async=&quot;&quot; src=&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;a href=&quot;https://www.jetbrains.com/pycharm/download/#section=windows&quot;&gt;Windows&lt;/a&gt;, &lt;a href=&quot;https://www.jetbrains.com/pycharm/download/#section=mac&quot;&gt;Mac&lt;/a&gt;, &lt;a href=&quot;https://www.jetbrains.com/pycharm/download/#section=linux&quot;&gt;Linux&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;유료 버전을 구매했거나 &lt;a href=&quot;https://www.jetbrains.com/student/&quot;&gt;학생 인증&lt;/a&gt;이 가능하다면, Professional 버전을 다운받도록 한다.&lt;/p&gt;

&lt;h3 id=&quot;settings&quot;&gt;Settings&lt;/h3&gt;

&lt;p&gt;설치 시 다음 창을 볼 수 있다. 해당 컴퓨터에 설치한 적이 있으면 설정 파일 위치를 지정하고, 아니면 말도록 하자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/01.png&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;필자는 Darcula로 지정했고, 왼쪽 아래의 &lt;code class=&quot;highlighter-rouge&quot;&gt;Skip Remaining and Set Defaults&lt;/code&gt; 버튼을 누른다. 본인이 추가 설정하고 싶은 부분이 있으면 이후 설정에서 마음대로 바꾸면 된다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/02.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;설정을 완료하면 아래와 같은 화면을 볼 수 있다. 오른쪽 아래의 &lt;code class=&quot;highlighter-rouge&quot;&gt;Configure&lt;/code&gt; &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;Settings&lt;/code&gt; 를 클릭한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/03.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;정확히는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Settings for New Projects&lt;/code&gt;라는 대화창을 볼 수 있다. 이는 새 프로젝트를 만들 때 적용되는 &lt;strong&gt;기본 설정&lt;/strong&gt;이다. 새로운 설정을 만들고 싶다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Default&lt;/code&gt; 설정을 복제(Duplicate)한 뒤 새 설정에서 바꾸도록 한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/04.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;설정에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Appearance &amp;amp; Behavior&lt;/code&gt; &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;Appearance&lt;/code&gt;에서, &lt;code class=&quot;highlighter-rouge&quot;&gt;Theme&lt;/code&gt;를 &lt;code class=&quot;highlighter-rouge&quot;&gt;Darcula&lt;/code&gt; 또는 다른 것으로 지정할 수 있다. 아래의 &lt;code class=&quot;highlighter-rouge&quot;&gt;Use Custom Font&lt;/code&gt;는 메뉴 등의 폰트를 해당 폰트로 지정할 수 있다.&lt;br /&gt;
참고로, 코드의 폰트는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Editor&lt;/code&gt; &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;Font&lt;/code&gt;에서 지정한다. 이 두 가지 역시 구분하도록 한다. 기본값은 &lt;code class=&quot;highlighter-rouge&quot;&gt;Monospaced&lt;/code&gt;이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/05.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Keymap&lt;/code&gt;에서는 단축키를 지정할 수 있다. PyCharm의 기본 단축키는 타 프로그램과 좀 다른 부분이 많아 필자는 일부를 바꿨다.&lt;br /&gt;
변경하고 싶은 단축키를 찾아서 더블클릭 또는 우클릭하면 기존에 지정되어 있는 단축키를 삭제하고 새 단축키를 지정할 수 있다. 이때 겹친다면 기존 단축키를 남겨둘지 제거할지 선택할 수 있다. 또한 마우스와 조합한 단축키로 지정할 수도 있다.&lt;br /&gt;
그리고 검색창 옆에 &lt;code class=&quot;highlighter-rouge&quot;&gt;돋보기 + 네모 3개&lt;/code&gt;로 이루어진 아이콘을 클릭하면 명령의 이름이 아닌 현재 지정되어 있는 단축키로 검색할 수 있다(예: Ctrl + W).&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/06.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;추천하는 변경할 단축키는 다음과 같다.&lt;br /&gt;
아래쪽은 필자가 지정하여 사용하는 단축키이다. 이외에도 유용한 기능을 몇 개 적어 놓았다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Menu&lt;/th&gt;
      &lt;th&gt;변경 전&lt;/th&gt;
      &lt;th&gt;변경 후&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Execute selection in console&lt;/td&gt;
      &lt;td&gt;Alt + Shift + E&lt;/td&gt;
      &lt;td&gt;Ctrl + Enter&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Edit &amp;gt; Find &amp;gt; Replace&lt;/td&gt;
      &lt;td&gt;Ctrl + H&lt;/td&gt;
      &lt;td&gt;Ctrl + R&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Refactor &amp;gt; Rename&lt;/td&gt;
      &lt;td&gt;Shift + F6&lt;/td&gt;
      &lt;td&gt;F2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Other &amp;gt; Terminal&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Alt + T&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Other &amp;gt; Python Console&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Alt + 8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Other &amp;gt; SciView&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Alt + 0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Show in Explorer&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Ctrl + Alt + Shift + E&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Window &amp;gt; Editor Tabs &amp;gt; Close&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Ctrl + W&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Type Info&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Ctrl + Alt + Button1 Click&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Split and Move Right&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Ctrl + Alt + Shift + R&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Go to Declaration or Usages&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;Ctrl + Button1 Click&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;필자의 경우 나머지 설정은 그대로 두는 편이나, &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + Enter&lt;/code&gt;로 바꿀 때는 다른 곳에 할당된 것을 지운다(Already assigned 경고창에서 Leave 대신 Remove를 선택). 안 그러면 선택한 부분이 Python Console(대화형)에서 실행되지 않는다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/07.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 그림에서 기본 Python Interpreter 파일(python.exe)를 설정한다. 새 프로젝트를 생성 시 Configure Python Interpreter라는 경고가 보이면서 코드 실행이 안 되면 인터프리터가 설정되지 않은 것이다. 컴퓨터에 설치된 파이썬 파일을 찾아 설정하자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/08.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Show All...&lt;/code&gt;을 클릭하면 처음에는 빈 창이 보인다. &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt;를 눌러서 원하는 환경을 추가한다. 기존의 것을 추가하거나, 새로운 가상환경(virtualenv 또는 conda)를 즉석에서 생성 가능하다.&lt;br /&gt;
이렇게 만든 가상환경은 해당 프로젝트에서만 쓰거나(기본 설정), 아래쪽의 &lt;code class=&quot;highlighter-rouge&quot;&gt;Make available to all projects&lt;/code&gt;를 체크하여 다른 프로젝트에서도 해당 인터프리터를 택할 수 있도록 정할 수도 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/09.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;PyCharm에서 코드 실행을 대화형으로 하면 Python Console에 자꾸 &lt;code class=&quot;highlighter-rouge&quot;&gt;Special Variables&lt;/code&gt;라는 창이 뜨는 것을 볼 수 있다. 보통 쓸 일이 없는데 기본으로 표시되는 것이므로, &lt;code class=&quot;highlighter-rouge&quot;&gt;Build, Execution, Deployment&lt;/code&gt; &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;Console&lt;/code&gt;에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Show console variable by default&lt;/code&gt; 체크를 해제한다.&lt;/p&gt;

&lt;p&gt;해당 설정을 마쳤으면 첫 화면에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Create New Project&lt;/code&gt;를 클릭한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/10.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;프로젝트 이름은 기본적으로 Untitled 이므로 바꿔주고, 아래쪽의 Project Interpreter를 설정해 둔다. 미리 설정했다면 목록이 보일 것이고, 아니라면 새로 생성하거나 &lt;code class=&quot;highlighter-rouge&quot;&gt;python.exe&lt;/code&gt; 위치를 찾아 지정해준다.&lt;/p&gt;

&lt;h3 id=&quot;sync-settings&quot;&gt;Sync Settings&lt;/h3&gt;

&lt;p&gt;시작 화면에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Configure&lt;/code&gt; &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;Settings Repository...&lt;/code&gt;, 또는 프로젝트 생성 후 &lt;code class=&quot;highlighter-rouge&quot;&gt;File&lt;/code&gt; &amp;gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;Settings Repository...&lt;/code&gt; 를 클릭하면 지금까지 설정한 설정들을 git repository에 저장할 수 있다. git을 알고 있다면, Merge, Overwrite Local, Overwrite Remote의 뜻을 알 것이라 믿는다. git repository에 저장하면 컴퓨터를 옮겨도 동일한 설정을 쉽게 지정할 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/11.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;git repository는 그냥 여러분의 git 계정에서 빈 거 하나 만든 다음에 그 주소를 복사하면 된다. 그러면 PyCharm이 알아서 설정을 동기화시켜 줄 것이다.&lt;/p&gt;

&lt;p&gt;이를 지정하려면 Personal Access Token이 필요하다. &lt;a href=&quot;https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/&quot;&gt;여기&lt;/a&gt;를 참조한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/12.png&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;등록이 완료되면 Merge, Overwrite Local(git에 저장된 내용을 local로 덮어씀), Overwrite Remote(현재 local 설정을 인터넷에 덮어씀) 중 하나를 선택해 설정을 동기화할 수 있다.&lt;/p&gt;

&lt;p&gt;참고: 이렇게 동기화한 경우 일부 설정(예: &lt;code class=&quot;highlighter-rouge&quot;&gt;kepmap&lt;/code&gt; 등)이 바로 적용되지 않는 경우가 있다. 그런 경우는&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/48.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;여기에서 Keymap 설정을 변경해 주면 된다. 보통 처음 동기화를 시도하면 기본 설정이나 어떤 &lt;code class=&quot;highlighter-rouge&quot;&gt;Default Copy&lt;/code&gt; 버전으로 동작하고 있는 경우가 많다.&lt;/p&gt;

&lt;p&gt;여기까지 초기 설정이 끝났다(원하는 부분만 진행해도 좋다). 이제 PyCharm 프로젝트 화면을 살펴보도록 하자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;project-창alt--1&quot;&gt;Project 창(&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 1&lt;/code&gt;)&lt;/h2&gt;

&lt;p&gt;처음 프로젝트를 열면 다음과 같은 화면이 보일 것이다. (Show tips at startup은 무시한다)&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/13.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;맨 왼쪽에는 프로젝트 창이 있다. 맨 왼쪽 빨간 박스로 표시한 곳을 클릭하면 프로젝트 창을 접었다 폈다 할 수 있다. 단축키를 눌러도 된다(Alt + 1).&lt;/p&gt;

&lt;p&gt;필자는 현재 untitled라는 이름으로 프로젝트를 생성했기 때문에, 루트 폴더는 현재 untitled이다. 주황 박스를 오른쪽 클릭하면 꽤 많은 옵션이 있다. 참고로 프로젝트 내 모든 디렉토리 또는 파일에 오른쪽 클릭하여 기능을 쓸 수 있다. 디렉토리를 우클릭했을 때와 파일을 우클릭했을 때 옵션이 조금 다르다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/14.png&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;각 옵션을 대략 설명하면,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;New: File, Directory, Python File(&lt;code class=&quot;highlighter-rouge&quot;&gt;.py&lt;/code&gt;), Jupyter Notebook(&lt;code class=&quot;highlighter-rouge&quot;&gt;.ipynb&lt;/code&gt;) 등을 생성한다. 단축키 설정하는 방법은 다음과 같다.
    &lt;ul&gt;
      &lt;li&gt;새 Python 파일을 생성할 때는 &lt;code class=&quot;highlighter-rouge&quot;&gt;New &amp;gt; Python File&lt;/code&gt;을 선택하면 된다. 단축키를 설정하는 방법은 &lt;code class=&quot;highlighter-rouge&quot;&gt;Settings &amp;gt; Keymap&lt;/code&gt;의 검색창에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Python File&lt;/code&gt;을 검색하면 아무 단축키가 지정되어 있지 않은 것을 볼 수 있다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Add Keyboard Shortcut&lt;/code&gt;을 눌러 원하는 키를 설정해주자.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Cut, Copy, Paste 등은 설명하지 않겠다.&lt;/li&gt;
  &lt;li&gt;Copy Path, Copy Relative Path: 각각 해당 디렉토리 또는 파일의 절대/상대 경로를 복사한다. 이미지나 데이터 파일 등의 경로를 써야 할 때 유용하게 쓸 수 있다. 단, 사용 환경에 따라 디렉토리 구분자가 &lt;code class=&quot;highlighter-rouge&quot;&gt;/&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;//&lt;/code&gt; 등으로 달라지는 경우가 있으니 주의.&lt;/li&gt;
  &lt;li&gt;Refactor: 해당 디렉토리 또는 파일의 이름을 변경한다. 이때 이 파일명을 사용하는 코드(file open 등)이 있으면 그 코드를 자동으로 수정하게 할 수 있다.&lt;/li&gt;
  &lt;li&gt;Find Usages: 해당 파일을 참조하는 코드를 살펴볼 수 있다. Refactor와 같이 사용하면 좋다.&lt;/li&gt;
  &lt;li&gt;Show in Explorer: 해당 디렉토리나 파일이 있는 디렉토리를 탐색기나 Finder 등에서 열 수 있다.&lt;/li&gt;
  &lt;li&gt;Mark Directory as: 디렉토리의 속성을 설정한다. 세부 옵션이 4개 있다.
    &lt;ul&gt;
      &lt;li&gt;Sources Root: 프로젝트에서 코드의 최상위 폴더를 지정한다. 코드를 짜다 보면 프로젝트 루트 폴더에 직속된 파일이 아닌 경우 패키지나 파일 reference를 찾지 못하는 경우가 많은데, 그럴 때는 해당 코드를 포함하는 파일 바로 상위의 디렉토리를 Sources Root로 설정하면 빨간 줄이 사라지는 것을 볼 수 있다.&lt;/li&gt;
      &lt;li&gt;Excluded: PyCharm 색인(Index)에서 제외시킨다. PyCharm은 Find Usages와 같은 기능을 지원하기 위해 프로젝트 내 모든 파일과 코드에 대해 indexing을 수행하는데(목차를 생성하는 거랑 비슷함), 프로젝트 크기가 크면 굳이 필요 없는 수많은 파일들까지 indexing해야 한다. 이는 PyCharm 성능 저하와 함께 색인 파일의 크기가 매우 커지므로(임시 파일까지 포함하여 수 GB까지 되기도 함) 너무 많으면 적당히 제외시키도록 하자.&lt;/li&gt;
      &lt;li&gt;Resource Root: 말 그대로 Resource Root로 지정한다.&lt;/li&gt;
      &lt;li&gt;Template Folder: 템플릿이 있는 폴더에 지정하면 된다. Pure Python을 쓸 때에는 별 의미 없다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Add to Favorites: Favorites창에 해당 디렉토리나 파일을 추가한다. 즐겨찾기 기능이랑 같다. 프로젝트 창 아래에서 창을 찾을 수 있고, &lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 2&lt;/code&gt; 단축키로 토글할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/14_1.png&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;새-파일-생성&quot;&gt;새 파일 생성&lt;/h3&gt;

&lt;p&gt;이제 우클릭 &amp;gt; New &amp;gt; Python File로 새 파이썬 파일을 하나 생성하자. (현재 프로젝트 이름은 &lt;code class=&quot;highlighter-rouge&quot;&gt;PythonTutorial&lt;/code&gt;이다)&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/15.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;안타깝게도 새 Python 파일 생성을 위한 단축키는 지정할 수 없는 듯하다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;코드-실행전체-또는-선택&quot;&gt;코드 실행(전체 또는 선택)&lt;/h2&gt;

&lt;p&gt;그리고 원하는 파일명을 입력한다. 필자는 &lt;code class=&quot;highlighter-rouge&quot;&gt;tutorial&lt;/code&gt;이라고 입력하겠다. 그러면 파일명은 &lt;code class=&quot;highlighter-rouge&quot;&gt;tutorial.py&lt;/code&gt;가 될 것이다.&lt;/p&gt;

&lt;p&gt;이제 코딩할 수 있는 창이 열렸으니 코드를 입력하자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Hello Pycharm!'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;코드를 작성했으면 실행을 해 보아야 하지 않겠는가? 실행하는 방법은 여러 가지가 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;실행하고 싶은 코드 라인에 커서를 놓거나 실행할 만큼 드래그를 한 다음 &lt;a href=&quot;https://greeksharifa.github.io/references/2019/02/07/PyCharm-usage/#settings&quot;&gt;위&lt;/a&gt;에서 단축키를 바꿨다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + Enter&lt;/code&gt;, 바꾸지 않았다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + Shift + E&lt;/code&gt;를 누른다. 그러면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Python Console&lt;/code&gt;이라는 창이 아래쪽에 열리면서 실행한 코드와 실행 결과가 나타난다. 역시 단축키를 설정했다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 8&lt;/code&gt;로 열 수 있다. PyCharm Default settings에는 단축키가 할당되어 있지 않다.
    &lt;ul&gt;
      &lt;li&gt;이것은 정확히는 Interpreter라고 부르는 대화형 파이썬 창에서 실행시키는 것이다. 명령창(cmd, terminal)에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;python&lt;/code&gt;을 실행시키고 코드를 입력하는 것과 같은 형태이다. &lt;a href=&quot;https://greeksharifa.github.io/references/2019/01/26/Jupyter-usage/&quot;&gt;Jupyter notebook&lt;/a&gt;과도 비슷하다.&lt;/li&gt;
      &lt;li&gt;장점은 명령창에서 바로 입력하는 경우 오타가 나면 다시 입력해야 하는데 편집기에 코드를 써 놓고 필요한 만큼만 &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + Enter&lt;/code&gt;로 실행시키는 이 방식은 코드 수정과 재사용이 훨씬 편하다는 것이다.&lt;/li&gt;
      &lt;li&gt;콘솔에 문제가 있거나 해서 현재 실행창을 재시작하고 싶으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Python Console&lt;/code&gt; 왼쪽 &lt;code class=&quot;highlighter-rouge&quot;&gt;Rerun&lt;/code&gt; 버튼(화살표)을 누르거나 &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + F5&lt;/code&gt;를 입력한다.&lt;/li&gt;
      &lt;li&gt;참고로 PyCharm 아래쪽/왼쪽/오른쪽에 있는 창들 중에서 옆의 숫자는 단축키를 간략하게 나타낸 것이다. 예를 들어 필자는 좀 전 설정에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Python Console&lt;/code&gt; 창의 단축키를 &lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 8&lt;/code&gt;로 설정해 놨는데, 그래서 옆에 &lt;code class=&quot;highlighter-rouge&quot;&gt;8&lt;/code&gt; 이라는 숫자가 표시된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/16.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;Run &amp;gt; Run…을 누르면 실행시키고 싶은 파일 목록이 나타난다. 이 중 원하는 파일(현재는 &lt;code class=&quot;highlighter-rouge&quot;&gt;tutorial&lt;/code&gt;)을 선택하면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Terminal&lt;/code&gt;이라는 창에서 &lt;strong&gt;&lt;em&gt;해당 파일의 전체 코드&lt;/em&gt;&lt;/strong&gt;가 실행된다.
    &lt;ul&gt;
      &lt;li&gt;다시 실행할 때는 Run &amp;gt; Run을 선택하면 마지막으로 실행한 파일이 전체 실행된다.&lt;/li&gt;
      &lt;li&gt;아래 그림의 &lt;code class=&quot;highlighter-rouge&quot;&gt;Terminal&lt;/code&gt; 창 왼쪽의 &lt;code class=&quot;highlighter-rouge&quot;&gt;ReRun&lt;/code&gt; 버튼을 눌러도 마지막으로 실행한 파일이 다시 실행된다. 단축키는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + F5&lt;/code&gt;이다.&lt;/li&gt;
      &lt;li&gt;PyCharm 오른쪽 위에서도 실행할 파일을 선택 후 실행시킬 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/17.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/18.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/19.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;PyCharm 아래쪽의 &lt;code class=&quot;highlighter-rouge&quot;&gt;Terminal&lt;/code&gt; 창을 클릭하거나 &lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + T&lt;/code&gt; 단축키(바꾼 것이다)로 &lt;code class=&quot;highlighter-rouge&quot;&gt;Terminal&lt;/code&gt; 창을 열어서 &lt;code class=&quot;highlighter-rouge&quot;&gt;python tutorial.py&lt;/code&gt;를 입력한다.
    &lt;ul&gt;
      &lt;li&gt;그렇다. Python 파일 실행 방법과 똑같다. 이 &lt;code class=&quot;highlighter-rouge&quot;&gt;Terminal&lt;/code&gt; 창은 명령창(cmd 또는 터미널)과 똑같다.&lt;/li&gt;
      &lt;li&gt;대략 &lt;code class=&quot;highlighter-rouge&quot;&gt;tu&lt;/code&gt; 정도까지만 입력하고 &lt;code class=&quot;highlighter-rouge&quot;&gt;Tab&lt;/code&gt; 키를 누르면 파일명이 자동완성된다.&lt;/li&gt;
      &lt;li&gt;이 방법도 역시 해당 파일에 들어있는 모든 코드를 전체 실행시킨다.&lt;/li&gt;
      &lt;li&gt;터미널 창 답게 여러 개의 세션을 열어 놓을 수 있다. 기본적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;Local&lt;/code&gt;이라는 이름의 탭이 생성되며, 오른쪽의 &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt; 버튼을 클릭하라.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/20.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Project&lt;/code&gt; 창에서도 해당 파일을 &lt;code class=&quot;highlighter-rouge&quot;&gt;우클릭 &amp;gt; Run (파일명)&lt;/code&gt;을 클릭하면 해당 파일의 코드 전체가 실행된다.&lt;/li&gt;
  &lt;li&gt;편집 창에서도 파일명 탭을 &lt;code class=&quot;highlighter-rouge&quot;&gt;우클릭 &amp;gt; Run (파일명)&lt;/code&gt;해도 된다. 실행 방법은 많다.&lt;/li&gt;
  &lt;li&gt;Terminal에서 Local Environment에서 실행되는 대신, Remote SSH session에서 실행시키는 방법은 &lt;a href=&quot;https://greeksharifa.github.io/references/2019/02/07/PyCharm-usage/#terminal%EC%97%90%EC%84%9C-ssh-session%EC%9C%BC%EB%A1%9C-%EC%97%B4%EA%B8%B0&quot;&gt;여기&lt;/a&gt;를 참고하면 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;편집-창코드-편집기&quot;&gt;편집 창(코드 편집기)&lt;/h2&gt;

&lt;p&gt;코드를 편집하는 부분에도 여러 기능들이 숨어 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/27.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 그림의 오른쪽 부분을 보자. 경고인 듯한 느낌표와 함께 여러 색깔의 줄이 있다. 현재 커서는 9번째 라인의 &lt;code class=&quot;highlighter-rouge&quot;&gt;example&lt;/code&gt; 변수에 위치해 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;먼저 왼쪽에는 줄 번호(line number)라는 것을 다들 알 수 있을 것이다.
    &lt;ul&gt;
      &lt;li&gt;하지만 이 단축키는 모르는 사람이 많다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + G&lt;/code&gt;를 누르면 원하는 라인으로 이동할 수 있다. 줄의 어느 부분으로 이동할지도 &lt;code class=&quot;highlighter-rouge&quot;&gt;line:column&lt;/code&gt; 형식으로 정할 수 있다. 줄 번호만 지정하고 싶으면 그냥 숫자만 입력하면 된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;빨간 화살표가 가리키고 있는 경고 표시는 현재 이 파일에 &lt;strong&gt;syntax error&lt;/strong&gt;가 있다는 뜻이다. 메인 화면에도 해당 부분에는 빨간 줄이 그어진다(&lt;code class=&quot;highlighter-rouge&quot;&gt;printf&lt;/code&gt;). 그리고 오른쪽에도 빨간색 bar가 생긴다.
    &lt;ul&gt;
      &lt;li&gt;이 bar들은 현재 파일에서의 상대적 위치를 뜻한다. 즉, 예를 들어 맨 아래에 있는 오류 코드가 화면에 안 보이더라도 bar는 제일 아래쪽 근처에 표시된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;커서가 위치한 곳이 변수나 함수 등이라면 해당 파일의 모든 부분에서 같은 이름을 가진 변수(또는 함수)에는 옅은 초록색 배경색이 칠해진다. 그리고 해당 변수(함수)가 선언된 곳에는 옅은 주황색으로 배경색이 칠해진다(이 색깔은 &lt;code class=&quot;highlighter-rouge&quot;&gt;Settings&lt;/code&gt;에서 바꿀 수 있다). 어디서 사용되고 있는지 쉽게 알 수 있다. 그리고 그림에서 오른쪽에도 주황색 또는 초록색 짧은 bar가 생긴 것을 볼 수 있다.
    &lt;ul&gt;
      &lt;li&gt;옅어서 잘 안보인다면 색깔을 바꾸거나 아니면 Find and Replace(&lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + H&lt;/code&gt;)로 찾으면 더 선명하게 표시되기는 하는데, 해당 이름을 포함한 다른 변수 등도 같이 선택된다는 문제가 있다. 적당히 선택하자.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;특별히 &lt;strong&gt;&lt;em&gt;TODO&lt;/em&gt;&lt;/strong&gt; 주석문은 일반 회색 주석과는 다르게 연두색으로 눈에 띄게 칠해진다. 또한 오른쪽에 파란색 bar가 생긴다. 이 주석은 참고로 &lt;code class=&quot;highlighter-rouge&quot;&gt;TODO&lt;/code&gt; 창(&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 6&lt;/code&gt;)에서도 확인 가능하다. 못다한 코딩이 있을 때 쓸 수 있는 좋은 습관이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;편집 창의 아무 부분을 우클릭하여 &lt;code class=&quot;highlighter-rouge&quot;&gt;Local History &amp;gt; Show History&lt;/code&gt;를 클릭하면 해당 파일이 어떻게 수정되어 왔었는지가 저장된다. 잘 안 쓸 수도 있지만 잘못 지운 상태로 코딩을 좀 진행했다거나 하는 상황에서 쓸모 있는 기능이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;ipynb-파일-사용&quot;&gt;.ipynb 파일 사용&lt;/h3&gt;

&lt;p&gt;PyCharm에서도 &lt;code class=&quot;highlighter-rouge&quot;&gt;.ipynb&lt;/code&gt;파일을 사용할 수 있다. 웹브라우저에서 보는 jupyter notebook과 모양이 매우 흡사하다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/36.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위쪽의 셀 실행 버튼을 누르면(초록색 삼각형) jupyter 서버 주소 토큰을 입력하라고 나온다. 본인이 jupyter 서버를 실행시켰다면 &lt;a href=&quot;https://greeksharifa.github.io/references/2019/01/26/Jupyter-usage/#%EC%8B%A4%ED%96%89-%EB%B0%8F-%EC%A2%85%EB%A3%8C&quot;&gt;jupyter notebook 서버를 켠 상태&lt;/a&gt;에서 해당 주소를 입력해주고 실행하면 .ipynb 파일을 브라우저에서 쓰는 것처럼 사용할 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;자동완성-기능&quot;&gt;자동완성 기능&lt;/h3&gt;

&lt;p&gt;일반적인 편집기에는 다 들어있는, 변수나 함수 등의 이름을 일부만 입력하고 &lt;code class=&quot;highlighter-rouge&quot;&gt;Tab&lt;/code&gt; 키를 누르면 자동완성이 된다는 것은 알고 있을 것이다.&lt;/p&gt;

&lt;p&gt;아래는 일부 코드 블록을 간편하게 입력할 수 있는 방법을 소개한 것이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;클래스 내부의 함수를 작성할 때는 &lt;code class=&quot;highlighter-rouge&quot;&gt;(&lt;/code&gt;를 입력하는 순간 &lt;code class=&quot;highlighter-rouge&quot;&gt;self&lt;/code&gt; 인자가 자동으로 추가된다. 기본적으로 써야 하는 인자이기 때문에 자동 추가되며, 이를 비활성화하고 싶으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;File &amp;gt; Settings &amp;gt; Editor &amp;gt; General &amp;gt; Smart Keys&lt;/code&gt;에서 바꿀 수 있다.&lt;/li&gt;
  &lt;li&gt;함수나 클래스를 작성할 때, 삼중따옴표를 함수 prototype 정의 바로 밑에 써 주면 깔끔하게 함수 사용법을 정리할 수 있는 주석이 나타난다.
    &lt;ul&gt;
      &lt;li&gt;빈 줄에 함수 설명을, &lt;code class=&quot;highlighter-rouge&quot;&gt;param&lt;/code&gt;에는 각 인자의 설명을, &lt;code class=&quot;highlighter-rouge&quot;&gt;return&lt;/code&gt;에는 이 함수의 반환값에 대한 설명을 써 주자.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/34.png&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;빠른-선택-코드-정리-편집-등등-단축키&quot;&gt;빠른 선택, 코드 정리, 편집 등등 단축키&lt;/h3&gt;

&lt;p&gt;원하는 부분을 빠르게 선택할 수 있는 단축키는 많다. 이를 다 알고 빠르게 할 수 있다면 코딩 속도는 아주 빨라진다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;변수/함수 더블클릭: 해당 변수 이름 선택&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + Z&lt;/code&gt;: 실행 취소(Undo)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + Shift + Z&lt;/code&gt;: 재실행(Redo)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + D&lt;/code&gt;(Duplicate): 현재 커서가 있는 한 줄(또는 드래그한 선택 범위)을 복사해 아래에 붙여 넣는다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + X&lt;/code&gt; / &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + C&lt;/code&gt;: 현재 커서가 있는 한 줄(또는 드래그한 선택 범위)을 잘라내기/복사한다. 한 줄도 된다는 것을 기억하라.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + W&lt;/code&gt;: 현재 선택 범위의 한 단계 위 범위를 전체 선택한다. 무슨 말인지 모르겠다면 직접 해 보면 된다. 범위는 블록이나 괄호 등을 포함한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Tab&lt;/code&gt;: 현재 커서가 있는 한 줄(또는 드래그한 선택 범위)를 한 단계(오른쪽으로 이동) indent한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Shift + Tab&lt;/code&gt;: 현재 커서가 있는 한 줄(또는 드래그한 선택 범위)를 반대 방향으로(왼쪽으로 이동) 한 단계 indent한다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + A&lt;/code&gt;: 현재 파일의 코드를 전체선택한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + Shift + O&lt;/code&gt;(Import Optimization): 코드 내에 어지럽게 널려 있는 import들을 파일 맨 위로 모아 잘 정리한다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + Shift + L&lt;/code&gt;: 코드의 빈 줄, indentation 등을 한 번에 정리한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + 좌클릭&lt;/code&gt;: 해당 변수/함수가 선언된 위치로 화면/커서가 이동한다. 변수가 어떻게 정의됐는지 또는 함수가 어떻게 생겼는지 보기 유용하다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 좌클릭&lt;/code&gt;: 커서를 원하는 곳에 일단 놓고, 또 같은 것을 입력하고 싶은 곳에 &lt;code class=&quot;highlighter-rouge&quot;&gt;Alt&lt;/code&gt;를 누른 채로 새로 클릭하면, 커서가 여러 개가 되는 것을 확인할 수 있다. 이 상태에서 키보드로 입력을 시작하면 여러 곳에서 한번에 입력이 가능하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이외에도 기능은 정말 많다(Toggle Case, Convert indents to space/tab, Copy as Plain Text, Paste without Formatting, …). 한번 잘 찾아보자.&lt;/p&gt;

&lt;p&gt;각각의 기능들은 Edit 탭이나 Navigate, Code, Refactor 탭 등에 잘 분류되어 있다. 한번쯤 살펴보고 본인에게 필요한 기능들은 기억해두면 좋다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;찾기및-바꾸기-ctrl--f--ctrl--h&quot;&gt;찾기(및 바꾸기), (&lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + F | Ctrl + H&lt;/code&gt;)&lt;/h3&gt;

&lt;p&gt;찾기 및 바꾸기의 기본 단축키는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + R&lt;/code&gt;이다(&lt;strong&gt;R&lt;/strong&gt;eplace). 많은 다른 프로그램들은 &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + H&lt;/code&gt;를 쓰기 때문에 바꾸는 것도 좋다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/28.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;여기도 여러 기능들이 있다. 찾기 설명은 찾기 및 바꾸기의 설명 안에 포함되므로 생략하겠다.&lt;br /&gt;
아래에서 설명할 기능들은 모두 그림에 나온 버튼이나 체크박스 등에 대한 것이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;왼쪽 검색창에 찾고자 하는(또는 대체될) 문자열 또는 정규식을 입력한다. 아래쪽 창에는 대체할 문자열을 입력한다.
    &lt;ul&gt;
      &lt;li&gt;왼쪽 돋보기를 클릭하면 이전에 검색했던 문자열들을 재검색할 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;F3&lt;/code&gt;: 다음 것 찾기&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Shift + F3&lt;/code&gt;: 이전 것 찾기&lt;/li&gt;
  &lt;li&gt;Find All: 전부 다 찾아서 보여준다.&lt;/li&gt;
  &lt;li&gt;Select All Occurrences: 매칭되는 결과를 전부 선택한다.&lt;/li&gt;
  &lt;li&gt;Show Filter Popup: 찾을 범위를 지정할 수 있다. 전부(Anywhere), 주석에서만(In comments), 문자열에서만(In String Literals), 둘 다에서만, 혹은 제외하고 등의 필터를 설정 가능하다.&lt;/li&gt;
  &lt;li&gt;Match Case: 체크하면 대소문자를 구분한다.&lt;/li&gt;
  &lt;li&gt;Words: 정확히 단어로 맞아야 할 때(해당 문자열을 포함하는 단어를 제외하는 등) 체크한다.&lt;/li&gt;
  &lt;li&gt;Regex: &lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/20/regex-usage-01-basic/&quot;&gt;정규표현식&lt;/a&gt;을 사용하여 찾는다. 잘 쓸 줄 안다면 아주 좋다.&lt;/li&gt;
  &lt;li&gt;오른쪽에는 몇 개나 매칭되는 문자열을 찾았는지 보여준다(3 matches). 만약 하나도 없으면 문자 입력 창이 빨갛게 되면서 No matches라고 뜬다.&lt;/li&gt;
  &lt;li&gt;Replace(&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + p&lt;/code&gt;): 현재 선택된 부분을 대체한다..&lt;/li&gt;
  &lt;li&gt;Replace all(&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + a&lt;/code&gt;): 매칭되는 모든 문자열을 찾아 대체한다.&lt;/li&gt;
  &lt;li&gt;Exclude: 해당 매칭된 부분은 대체할 부분에서 제외한다.&lt;/li&gt;
  &lt;li&gt;Preserve Case: 대체 시 대소문자 형식을 보존한다.&lt;/li&gt;
  &lt;li&gt;In Selection: 파일 전체가 아닌 선택한 부분에서만 찾는다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;더-넓은-범위에서-찾기&quot;&gt;더 넓은 범위에서 찾기&lt;/h3&gt;

&lt;p&gt;선택한 파일 말고 더 넓은 범위에서 찾으려면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + Shift + F&lt;/code&gt;를 누르거나 다음 그림을 참고한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/29.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/30.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위의 Match Case등은 사용법이 똑같지만, 여기서는 파일뿐 아니라 프로젝트 전체, 모듈, 디렉토리, 또는 특정 범위(scope)에서 찾을 수 있다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Edit &amp;gt; Find &amp;gt; &lt;/code&gt;안의 다른 선택지들 역시 사용법은 크게 다르지 않으니 참고하자.&lt;/p&gt;

&lt;p&gt;다른 (범용) 찾기 단축키로 &lt;code class=&quot;highlighter-rouge&quot;&gt;Shift + Shift&lt;/code&gt;(Shift 키를 두번 누름)이 있다. 한번 해 보자.&lt;/p&gt;

&lt;h3 id=&quot;변수함수-등이-사용된-위치-찾기&quot;&gt;변수/함수 등이 사용된 위치 찾기&lt;/h3&gt;

&lt;p&gt;찾고자 하는 변수/함수를 우클릭하여 &lt;code class=&quot;highlighter-rouge&quot;&gt;Find Usages&lt;/code&gt;를 클릭하거나 &lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + F7&lt;/code&gt;을 누른다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/31.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;그러면 해당 변수/함수가 어디서 사용되었는지 정보가 전부 나온다. 왼쪽에 있는 많은 버튼들로 적절한 그룹별로 묶거나 하는 등의 작업을 할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;refactor이름-재지정&quot;&gt;Refactor(이름 재지정)&lt;/h3&gt;

&lt;p&gt;변수명을 바꾸고 싶어졌을 때가 있다. 무식하게 일일이 바꾸거나, 아니면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Find and Replace&lt;/code&gt;로 선택적으로 할 수도 있다.&lt;/p&gt;

&lt;p&gt;하지만 매우 쉽고 편리한 방법이 있다. 해당 변수를 선택하고 &lt;code class=&quot;highlighter-rouge&quot;&gt;Shift + F6&lt;/code&gt;을 누른다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/32.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;원하는 이름으로 바꾸고 &lt;code class=&quot;highlighter-rouge&quot;&gt;Refactor&lt;/code&gt;을 누르면 해당 변수만 정확하게 원하는 이름으로 바뀐다. 심지어 import해서 사용한 다른 파일에서도 바뀐다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/33.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;em&gt;아주 편리하다.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;창-위치-및-크기-변경&quot;&gt;창 위치 및 크기 변경&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Python Console&lt;/code&gt; 등의 창은 위치나 크기가 변경 가능하다. 크기는 창의 경계에 마우스 커서를 갖다대는 방식이니 굳이 설명하지 않겠다.&lt;br /&gt;
위치는 탭을 끌어서 이동시키거나 아니면 &lt;code class=&quot;highlighter-rouge&quot;&gt;우클릭 &amp;gt; Move to &amp;gt; 원하는 곳&lt;/code&gt;을 선택하면 된다.&lt;/p&gt;

&lt;p&gt;또 모니터를 2개 이상 쓴다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;View Mode&lt;/code&gt;에서 해당 설정을 변경할 수 있다. 기본은 PyCharm 내부에 위치 고정된 &lt;code class=&quot;highlighter-rouge&quot;&gt;Dock Pinned&lt;/code&gt; 모드이다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Float&lt;/code&gt;이나 &lt;code class=&quot;highlighter-rouge&quot;&gt;Window&lt;/code&gt;를 선택하면 위치를 자유롭게 이동할 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/21.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;모니터 크기는 충분한데 코드는 위아래로만 길게 보여서 공간이 아까웠다면, PyCharm에서는 굳이 그럴 필요 없다. Vim의 Split View와 비슷한 기능이 있다.&lt;/p&gt;

&lt;p&gt;편집 창(메인 화면)의 탭을 우클릭한 다음 &lt;code class=&quot;highlighter-rouge&quot;&gt;Split Vertically&lt;/code&gt;를 클릭해 보라. &lt;code class=&quot;highlighter-rouge&quot;&gt;Split Horizontally&lt;/code&gt;도 괜찮다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/23.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/24.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;동일한 파일을 여러 번 열고 다른 부분을 보는 것도 가능하다. 꽤 유용한 기능이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;favorites-창alt--2&quot;&gt;Favorites 창(&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 2&lt;/code&gt;)&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 2&lt;/code&gt;를 눌러 &lt;code class=&quot;highlighter-rouge&quot;&gt;Favorites&lt;/code&gt; 창을 연다.&lt;/p&gt;

&lt;p&gt;말 그대로 즐겨찾기이다. 자주 사용하는 파일을 &lt;code class=&quot;highlighter-rouge&quot;&gt;Favorites&lt;/code&gt;에 등록할 수 있다. 기본적으로 현재 프로젝트 이름으로 리스트가 하나 생성되어 있다.&lt;br /&gt;
이게 싫거나 새로운 리스트를 추가하고 싶으면 아래 그림의 오른쪽에 보이는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Add to New Favorites List&lt;/code&gt;를 클릭하라.&lt;/p&gt;

&lt;p&gt;그러면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Favorites&lt;/code&gt; 창에 해당 리스트에 추가한 파일이 등록된다. 이제 프로젝트 창에서 찾을 필요 없이 바로 파일을 열어볼 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/25.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;run-창alt--4&quot;&gt;Run 창(&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 4&lt;/code&gt;)&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 3&lt;/code&gt;은 기본적으로 할당되어 있지 않다. 추가하고 싶으면 추가하라.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Run&lt;/code&gt; 창은 조금 전 코드를 실행할 때 본 것이다. 여기서는 왼쪽에 몇 가지 버튼이 있는데, 각각&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Rerun(마지막 실행 파일 재실행)&lt;/li&gt;
  &lt;li&gt;Stop(현재 실행 중인 파일 실행 중단)&lt;/li&gt;
  &lt;li&gt;Restore Layout(레이아웃 초기화)&lt;/li&gt;
  &lt;li&gt;Pin Tab(현재 실행 탭 고정)&lt;/li&gt;
  &lt;li&gt;Up/Down to Stack Trace(trace 상에서 상위 또는 하위 단계로 이동)&lt;/li&gt;
  &lt;li&gt;Soft-Wrap(토글 키. 활성화 시 출력 내용이 한 줄을 넘기면 아래 줄에 출력됨. 비활성화 시 스크롤해야 나머지 내용이 보인다)&lt;/li&gt;
  &lt;li&gt;Scroll to the end(제일 아래쪽으로 스크롤)&lt;/li&gt;
  &lt;li&gt;Print(출력 결과를 정말 프린터에서 뽑는 거다)&lt;/li&gt;
  &lt;li&gt;Clear All(현재 출력 결과를 모두 지우기)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Soft-wrap 등은 꽤 유용하므로 잘 사용하자.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Run&lt;/code&gt; 창을 우클릭 시 &lt;code class=&quot;highlighter-rouge&quot;&gt;Compare with Clipboard&lt;/code&gt; 항목이 있는데, 현재 클립보드에 있는(즉, &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + C&lt;/code&gt; 등으로 복사한) 내용과 출력 결과를 비교하는 창을 띄운다. 정답 출력 결과를 복사해 놨다면 유용하게 쓸 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;todo-창alt--6&quot;&gt;TODO 창(&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 6&lt;/code&gt;)&lt;/h2&gt;

&lt;p&gt;PyCharm에서는 주석(&lt;code class=&quot;highlighter-rouge&quot;&gt;#&lt;/code&gt;)을 달면서 앞에 &lt;code class=&quot;highlighter-rouge&quot;&gt;TODO:&lt;/code&gt;라는 문구를 적으면 해당 주석은 특별히 눈에 띄는 연두색으로 바뀐다.&lt;/p&gt;

&lt;p&gt;이 &lt;strong&gt;TODO&lt;/strong&gt;들은 앞으로 해야 할 것을 모아 놓은 것이다. 이를 나중에 찾아보려면 PyCharm 아래쪽의 &lt;code class=&quot;highlighter-rouge&quot;&gt;TODO&lt;/code&gt; 창을 클릭하거나 &lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 6&lt;/code&gt;으로 열자.&lt;br /&gt;
그럼 현재 프로젝트의 어느 부분이 미완성인 채로 남아 있는지 한번에 볼 수 있다. 기본적으로 파일별로 정렬되어 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/35.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;structure-창alt--7&quot;&gt;Structure 창(&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 7&lt;/code&gt;)&lt;/h2&gt;

&lt;p&gt;현재 파일이 어떤 구조로(클래스는 무엇을 포함하고, 함수는 어떤 statement들을 포함하는지 등) 되어 있는지 살펴보려면 코드를 한줄한줄 다 뜯어보는 대신 Structure 창에서 볼 수 있다.&lt;br /&gt;
어떤 변수가 어디에 정의되었는지까지도 볼 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;python-console-창alt--8&quot;&gt;Python Console 창(&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 8&lt;/code&gt;)&lt;/h2&gt;

&lt;p&gt;단축키는 필자가 지정한 것이다.&lt;/p&gt;

&lt;p&gt;이는 명령창에서 Python을 실행했을 때 나타나는 것과 같다고 말했었다. 어려울 것 없이 똑같이 사용할 수 있다.&lt;/p&gt;

&lt;p&gt;단, 사용 환경에 따라 이런 대화형 창에서는 가용 메모리를 다 쓰지 못하는 경우가 있다. 예를 들어 GPU 메모리를 수 GB씩 쓰는 학습 알고리즘 등의 경우 터미널에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;python 파일명&lt;/code&gt;으로 실행하면 잘 작동하는데 대화형 창에서 실행하면 작동이 중지되는 것을 종종 볼 수 있다. 참고하자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;version-control-창alt--9&quot;&gt;Version Control 창(&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 9&lt;/code&gt;)&lt;/h2&gt;

&lt;p&gt;이건 Git 기능을 PyCharm에 옮겨놓은 것과 같다. git 사용법을 안다면 쉽게 이용 가능하다. 하지만 git을 잘 알고 있다면 그냥 Python의 &lt;code class=&quot;highlighter-rouge&quot;&gt;terminal&lt;/code&gt; 창을 열어서 git 명령어를 치는 것이 편할 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;sciview-창alt--0&quot;&gt;SciView 창(&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + 0&lt;/code&gt;)&lt;/h2&gt;

&lt;p&gt;PyCharm에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;matplotlib&lt;/code&gt; 등으로 그래프를 그린다면 바로 이 창에 표시가 된다.&lt;/p&gt;

&lt;p&gt;여기서 한 장씩 보기 또는 grid 모드로 보기 등을 선택할 수 있고, 확대 및 축소, 1:1, 창 크기에 맞추기 등의 옵션도 가능하다.&lt;/p&gt;

&lt;p&gt;그림 오른쪽 위에 작게 표시되는 x 표시를 누르면 그림을 지울 수 있다. 또한 우클릭을 통해 저장하거나 전체 삭제 등의 작업을 할 수 있다. 배경화면 사진으로도 지정할 수 있다(!).&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/37.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;참고로 pycharm에서는 일반적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;plt.show()&lt;/code&gt;를 그냥 하면 그림이 표시되지 않는 경우가 있다. 이에 대한 해결법은 &lt;a href=&quot;https://stackoverflow.com/questions/24886625/pycharm-does-not-show-plot&quot;&gt;링크&lt;/a&gt;를 참고하자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interactive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# plt.show(block=True)
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;디버깅debugging&quot;&gt;디버깅(Debugging)&lt;/h2&gt;

&lt;p&gt;PyCharm의 훌륭한 기능 중 하나이다. 사실 웬만한 코드 편집기에 있기는 한데, python을 쓰는 사람들 중에 이를 활용할 줄 알아서 쓰는 경우는 생각보다 많지 않은 것 같다.&lt;br /&gt;
&lt;em&gt;(물론 알아서 코드를 수정해 주는 것은 아니다…)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;예를 들어 다음과 같은 프로그램을 짰다고 생각해 보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;example&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;example&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'fibonacci({})&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: {:8d}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과는 다음과 갈다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;fibonacci(0)	:        2
fibonacci(1)	:        3
fibonacci(2)	:        5
fibonacci(3)	:        8
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;피보나치 수열은 2부터 시작하지 않으므로 잘못되었다. 그러면? 디버깅을 시작한다(물론 간단한 예시라서 바로 고칠 수 있지만 우선 넘어간다).&lt;/p&gt;

&lt;p&gt;디버깅을 시작하는 방법은 여러 가지가 있다. 이는 코드를 실행할 때와 매우 비슷한데, 초록색 삼각형 대신 벌레 모양의 아이콘을 클릭하면 된다. 그게 다이다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Run&lt;/code&gt; 대신에 &lt;code class=&quot;highlighter-rouge&quot;&gt;Debug&lt;/code&gt;를 누를 뿐이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/38.png&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;그러나 시작하기 전 &lt;strong&gt;Breakpoint&lt;/strong&gt;를 하나 설정한다. 버그가 있다고 생각하는 시점 직전에 설정하면 된다. 우선 이번 예시에서는 example을 선언한 라인에 설정하겠다. 코드 왼쪽, 라인 번호 바로 오른쪽 빈 공간을 클릭하자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/39.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;그러면 빨간 점과 함께 해당 라인의 배경이 빨간색으로 칠해진다.&lt;/p&gt;

&lt;p&gt;그리고 &lt;code class=&quot;highlighter-rouge&quot;&gt;Run &amp;gt; Debug&lt;/code&gt;를 클릭한다. 벌레를 클릭해도 좋다.&lt;br /&gt;
뭔가 다른 프로그램이 실행되고 있는 것 같으면, 실행하려는 파일명을 다시 확인하라.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/40.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;디버깅할 때는 코드를 그냥 실행할 때와는 동작이 많이 다르다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;실행 시에는 코드가 처음부터 끝까지 멈춤 없이 진행된다.
    &lt;ul&gt;
      &lt;li&gt;물론 사용자의 입력을 기다리거나, 계산이 오래 걸리거나, &lt;code class=&quot;highlighter-rouge&quot;&gt;sleep()&lt;/code&gt;등으로 지연시키는 경우는 예외이다. 그러나 이 경우에도 입력/계산/시간이 완료되면 자동으로 다음 코드를 지체 없이 빠르게 실행한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;디버깅 시, 처음에는 &lt;strong&gt;Breakpoints&lt;/strong&gt; 까지는 실행 시와 똑같이 순식간에 진행된다. 그러나 &lt;strong&gt;Breakpoints&lt;/strong&gt;에 도달하면 그 라인의 실행 직전까지만 코드가 실행된 후 대기 상태로 전환한다(이름이 왜 breakpoint이겠는가?).&lt;/li&gt;
  &lt;li&gt;그리고 이후 진행은 사용자가 무엇을 클릭했느냐에 따라 달라진다. 디버깅 모드에서는
    &lt;ul&gt;
      &lt;li&gt;한 줄 실행(딱 한줄만 실행),&lt;/li&gt;
      &lt;li&gt;지정 위치까지 실행(해당 지점을 &lt;strong&gt;Breakpoints&lt;/strong&gt; 삼아 그 라인 직전까지 실행),&lt;/li&gt;
      &lt;li&gt;어떤 함수 내부로 들어가 한 줄씩 실행,&lt;/li&gt;
      &lt;li&gt;현재 실행 중인 함수 밖으로 나오는 데까지 실행&lt;/li&gt;
      &lt;li&gt;등등의 옵션이 있는데, 각각의 옵션에 따라 딱 필요한 만큼까지만 코드가 실행된 후 대기 상태로 멈춰 있는다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;우선 &lt;code class=&quot;highlighter-rouge&quot;&gt;F8&lt;/code&gt;을 눌러보자. &lt;code class=&quot;highlighter-rouge&quot;&gt;Step Over&lt;/code&gt;이라고 되어 있다. 위 그림에서 빨간 박스 안의 첫 번째 아이콘을 클릭해도 된다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/41.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;그럼 한 줄을 실행하고 다음 statement로 넘어가 있다. 빈 줄은 건너뛴다.&lt;/li&gt;
  &lt;li&gt;실행한 줄 옆에 그 줄의 변수에 들어 있는 값이 업데이트된다. &lt;code class=&quot;highlighter-rouge&quot;&gt;example&lt;/code&gt; 변수는 &lt;code class=&quot;highlighter-rouge&quot;&gt;list&lt;/code&gt; 타입이며, 값 1을 20개 갖고 있는 리스트이다.&lt;/li&gt;
  &lt;li&gt;왼쪽 아래 untitled.py: 7로 값이 바뀌었다. 현재 &lt;code class=&quot;highlighter-rouge&quot;&gt;untitled.py&lt;/code&gt;의 7번째 줄을 실행하기 직전이란 뜻이다.&lt;/li&gt;
  &lt;li&gt;아래쪽 &lt;code class=&quot;highlighter-rouge&quot;&gt;Variables&lt;/code&gt; 창에서 접근할 수 있는 변수 목록이 업데이트되었다. 현재는 &lt;code class=&quot;highlighter-rouge&quot;&gt;example&lt;/code&gt; 하나뿐이므로 그 값을 볼 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Variables&lt;/code&gt; 창에서는 현재 scope에서 접근가능한 변수 목록이 자동으로 업데이트되지만, 미리 보고 싶거나 혹은 계산 결과 등을 보고 싶다면 새로운 &lt;em&gt;Watch&lt;/em&gt;를 추가할 수 있다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Variables&lt;/code&gt; 창 아무 곳이나 우클릭하면 새로 보고 싶은 변수 혹은 수식 결과값 등을 추가할 수 있다. 예시로 &lt;code class=&quot;highlighter-rouge&quot;&gt;example * 2&lt;/code&gt;를 추가해 보았다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/42.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Step Over&lt;/code&gt; 외에 다른 버튼들은 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Step Into&lt;/code&gt;(&lt;code class=&quot;highlighter-rouge&quot;&gt;F7&lt;/code&gt;): 코드가 어떤 함수를 실행하는 경우(예: 예시의 &lt;code class=&quot;highlighter-rouge&quot;&gt;func&lt;/code&gt;, 내장 함수인 &lt;code class=&quot;highlighter-rouge&quot;&gt;print&lt;/code&gt; 등), 해당 함수의 내부로 들어가서 실행할 수 있게 해 준다.
    &lt;ul&gt;
      &lt;li&gt;아래 예시는 &lt;code class=&quot;highlighter-rouge&quot;&gt;func()&lt;/code&gt; 내부로 들어간 모습을 보여준다.&lt;/li&gt;
      &lt;li&gt;참고로 argument로 무엇이 전달되었는지 등도 표시된다(아래 그림의 경우 &lt;code class=&quot;highlighter-rouge&quot;&gt;idx: 5&lt;/code&gt;라고 되어 있는 것을 볼 수 있다). argument뿐 아니라 업데이트되고 있는 변수들 모두 값을 보여주며, 방금 업데이트된(조금 전 실행한 라인의 결과) 값은 회색이 아닌 주황색으로 표시된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/43.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Step Into My Code&lt;/code&gt;: 위의 &lt;code class=&quot;highlighter-rouge&quot;&gt;Step Into&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;print&lt;/code&gt; 같은 내장 함수들 안으로까지 파고들어 코드를 실행한다. 내장 함수가 오작동하는 것은 아니기 때문에 자신의 코드만 검사하고 싶다면 이쪽을 택하자.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Force Step Into&lt;/code&gt;: 말 그대로 강제로 함수 안으로 들어가 실행시킨다. 비활성화된 경우가 많을 것이다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Step Out&lt;/code&gt;(&lt;code class=&quot;highlighter-rouge&quot;&gt;Shift + F8&lt;/code&gt;): 실행되고 있는 함수 밖으로 나오는 데까지 실행시킨다. &lt;code class=&quot;highlighter-rouge&quot;&gt;func&lt;/code&gt;  또는 &lt;code class=&quot;highlighter-rouge&quot;&gt;print&lt;/code&gt; 끝난 다음 줄로 이동한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Run to Cursor&lt;/code&gt;(&lt;code class=&quot;highlighter-rouge&quot;&gt;Alt + F9&lt;/code&gt;): 커서가 있는 곳으로까지 코드를 실행시킨다. 반복문 내부인 경우 가장 가까운 반복 단계에서 멈춘다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위의 모든 명령은 &lt;strong&gt;Breakpoint&lt;/strong&gt;에서 걸린다. 즉, &lt;code class=&quot;highlighter-rouge&quot;&gt;Run to Cursor&lt;/code&gt; 등으로 많이 이동하려 해도 그 사이에 &lt;strong&gt;Breakpoint&lt;/strong&gt;가 있으면 그 직전까지만 실행된 상태로 멈춘다.&lt;/p&gt;

&lt;p&gt;이런 기능들을 활용하면서 디버깅하면 어느 단계에서 코드가 잘못 되었는지 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Breakpoint&lt;/strong&gt;에는 한 가지 중요한 기능이 있다. 지금까지 설정한 것은 코드가 설정된 라인에 가면 무조건 멈추는데, 이 조건을 바꿀 수 있다. 8번째 줄에 &lt;strong&gt;Breakpoint&lt;/strong&gt;를 설정하고, &lt;strong&gt;Breakpoint&lt;/strong&gt;를 나타내는 빨간 원을 우클릭하자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/44.png&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;조건을 설정할 수 있는 창이 나온다.&lt;/p&gt;

&lt;p&gt;아래의 &lt;code class=&quot;highlighter-rouge&quot;&gt;More...&lt;/code&gt;를 클릭하면,&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/45.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;더 자세한 조건을 설정할 수 있다.&lt;/p&gt;

&lt;p&gt;예시를 한 개만 들어보겠다. 8번째 줄의 &lt;strong&gt;Breakpoint&lt;/strong&gt;를 아래처럼 설정한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;i == 5&lt;/code&gt; 일 때만 Breakpoint가 작동할 것이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/46.png&quot; width=&quot;85%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;조건을 설정하면 빨간 원 옆에 &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt;가 생기면서 condition이 설정되었음을 나타낸다.&lt;br /&gt;
디버깅 모드를 종료했다가 다시 시작한 다음, 프로그램 끝에 커서를 놓고 &lt;code class=&quot;highlighter-rouge&quot;&gt;Run to Cursor&lt;/code&gt;를 실행해 보자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/47.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;그러면 &lt;code class=&quot;highlighter-rouge&quot;&gt;i == 5&lt;/code&gt;일 때 &lt;code class=&quot;highlighter-rouge&quot;&gt;func&lt;/code&gt; 함수 내부에 멈춰 있음을 볼 수 있다. 한 번 더 &lt;code class=&quot;highlighter-rouge&quot;&gt;Run to Cursor&lt;/code&gt;로 이동하면 그때서야 끝부분으로 이동한다. 즉 &lt;code class=&quot;highlighter-rouge&quot;&gt;i == 5&lt;/code&gt;인 조건을 지났기 때문에 다시 발동하지 않는 것이다.&lt;/p&gt;

&lt;p&gt;이 기능은 반복문이 여러 차례 반복된 뒤에야(예: 1000번쯤, &lt;code class=&quot;highlighter-rouge&quot;&gt;Step Over&lt;/code&gt;를 1000번씩 누르긴 싫을 것이다) 버그가 나타나는 경우 해당 지점 직전에까지 가도록 Breakpoint를 설정하는 방법으로 쉽게 탐색할 수 있다.&lt;/p&gt;

&lt;p&gt;잘 쓰면 꽤 유용하니 이것도 익혀 두도록 하자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;profilers코드-실행시간-측정&quot;&gt;Profilers(코드 실행시간 측정)&lt;/h2&gt;

&lt;p&gt;코드 실행시간을 측정할 때 매번 코드 시작과 끝 지점에 &lt;code class=&quot;highlighter-rouge&quot;&gt;start_time&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;end_time&lt;/code&gt; 같은 코드를 삽입하지 않고도 특정 함수나 코드 일부분 등의 실행 시간을 측정하는 기능을 PyCharm에서 제공한다. 이는 Terminal이나 IPython 등으로 실행한 것이 아닌 PyCharm의 &lt;code class=&quot;highlighter-rouge&quot;&gt;Run&lt;/code&gt; 과 같은 방식으로 파일을 실행시켰을 때(&lt;a href=&quot;https://greeksharifa.github.io/references/2019/02/07/PyCharm-usage/#configurations%EC%8B%A4%ED%96%89-%EC%8B%9C-parameter-%EC%84%A4%EC%A0%95&quot;&gt;Configurations&lt;/a&gt;에서 설정 가능) 설정 가능하며, Professional 버전에서만 이용 가능하다.&lt;/p&gt;

&lt;p&gt;정확히는, &lt;code class=&quot;highlighter-rouge&quot;&gt;Configurations&lt;/code&gt;에서 실행할 파일을 지정한 다음, &lt;code class=&quot;highlighter-rouge&quot;&gt;Run&lt;/code&gt; 버튼이 아닌 &lt;code class=&quot;highlighter-rouge&quot;&gt;Profile&lt;/code&gt; 버튼을 클릭한다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;temp.py&lt;/code&gt; 파일을 다음과 같이 작성했다고 하자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/69.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;이제 이 코드에서 어느 부분이 실행시간의 많은 부분을 차지하는지 알아보자. PyCharm의 우상단에 있는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Profile&lt;/code&gt; 버튼을 클릭한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/70.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;그러면 실행창에는 다음과 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;Starting cProfile profiler&lt;/code&gt;라는 문구가 출력되면서 실행이 된다. &lt;code class=&quot;highlighter-rouge&quot;&gt;done&lt;/code&gt; 출력 이후에 한 줄이 더 출력되어 있는데, Snapshot(pstat 파일)이 지정된 경로에 저장되었다는 뜻이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/71.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;그리고 실행이 끝나면 확장자가 pstat인 파일이 열린다. 실행이 너무 오래 걸린다면, 위 그림의 빨간 박스(&lt;code class=&quot;highlighter-rouge&quot;&gt;Capture Snapshot&lt;/code&gt;, 실행이 끝난 상태에서는 비활성화됨)를 클릭하면 snapshot이 바로 저장되면서 중간 결과를 볼 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/74.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;pstat 파일에는 2개의 탭이 있다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Statistics&lt;/code&gt; 탭에는 각 함수별로&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;실행 수&lt;/li&gt;
  &lt;li&gt;해당 함수에 포함된 모든 함수의 실행 시간을 모두 더한 값&lt;/li&gt;
  &lt;li&gt;해당 함수 자체만의 실행 시간의 총합(해당 함수가 여러 번 실행되었을 수 있으므로)
이 나열되어 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;정확히는 사용자 정의 함수와 같은 일반 함수 외에도 Python 내장 함수(&lt;code class=&quot;highlighter-rouge&quot;&gt;print&lt;/code&gt; 등) 및 기본(&lt;code class=&quot;highlighter-rouge&quot;&gt;__init__&lt;/code&gt; 등) 함수, class, 실행 파일 등이 포함된다.&lt;/p&gt;

&lt;p&gt;원하는 함수명을 오른쪽 클릭하면 해당 함수가 위치한 곳으로 이동하거나, 아래의 &lt;code class=&quot;highlighter-rouge&quot;&gt;Call Graph&lt;/code&gt;에서 찾아볼 수도 있다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Call Graph&lt;/code&gt; 탭에서는 어떤 파일/함수에서 어떤 함수가 실행(call)되었고, 각 함수의 실행 시간을 전부 볼 수 있다.&lt;br /&gt;
이 기능은 복잡한 코드가 어떤 과정으로 실행되는지를 대략 알아보는 데도 쓸 수도 있다(순서는 Traceback을 보는 것이 낫다).&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/73.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;왼쪽 위에 있는 &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt; 등의 메뉴에서는 그림 확대/축소, 화면 맞추기, 이미지로 저장 등을 수행할 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;configurations실행-시-parameter-설정&quot;&gt;Configurations(실행 시 parameter 설정)&lt;/h2&gt;

&lt;p&gt;실행(Run)이나, 디버깅(Debugging) 버튼을 통해서 실행하고자 할 때, 엉뚱한 파일이 실행되는 경우가 있다. 이는 실행 버튼 바로 옆의 실행 파일명 또는 configuration 이름을 살펴보고 원하는 부분이 아니라면 바꿔주도록 하자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/49.png&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;참고로, &lt;code class=&quot;highlighter-rouge&quot;&gt;Run/Debug configuration&lt;/code&gt; 설정 창에서는 실행 파일뿐 아니라 인자(argparse 등에서 사용하는 argument)를 설정해 줄 수도 있다. Python에서는 기본적으로 실행 시 인자를 주기 위해서는 명령창에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;python &amp;lt;실행할 파일.py&amp;gt; --option1 &amp;lt;option1&amp;gt;&lt;/code&gt; 형식으로 실행시켜야 하는데, PyCharm에서는 이 설정을 저장해두고 바로바로 쓸 수 있다. 위의 그림에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Edit Configurations&lt;/code&gt;를 눌러보자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/50.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;순서대로 설명하면,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;(빨간색) configuration의 이름을 설정할 수 있다. 기본적으로 실행하고자 하는 파일명으로 설정되며, 파일명으로 뿐만 아니라 원하는 이름으로 변경할 수 있다.&lt;/li&gt;
  &lt;li&gt;(주황색) 실행하고자 하는 python 파일을 설정할 수 있다. 여기서 직접 추가하거나, 상단 메뉴 바의 &lt;code class=&quot;highlighter-rouge&quot;&gt;Run&lt;/code&gt;에서 새로 파일을 설정하면 추가된다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;(노란색) 딥러닝 등에서 보통 많이 쓰는 &lt;code class=&quot;highlighter-rouge&quot;&gt;argparse&lt;/code&gt;에서 인자를 받곤 하는데 이를 여기서 추가할 수 있다. 물론 argparse 뿐만 아니라 &lt;code class=&quot;highlighter-rouge&quot;&gt;sys.argv[]&lt;/code&gt;가 받는 것도 동일하다.&lt;/strong&gt; &lt;em&gt;사실 이게 제일 중요한 듯&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;(초록색) 원하는 실행 환경을 바꿔줄 수 있다.&lt;/li&gt;
  &lt;li&gt;(파란색) 실행 폴더의 위치를 지정한다. 기본적으로 실행 파일과 같은 위치로 지정되며, Python 코드 내의 상대 경로는 이 경로의 영향을 받는다.&lt;/li&gt;
  &lt;li&gt;(남색) 콘솔에서 실행시킬지 등을 결정할 수 있다. 기본적으로는 해제되어 있다.&lt;/li&gt;
  &lt;li&gt;(보라색) 실행시키기 전에 tool window 등을 미리 활성화 할 수 있다. 가능한 메뉴는 다음과 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/51.png&quot; width=&quot;40%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ssh를-통한-외부-서버-원격-접속&quot;&gt;SSH를 통한 외부 서버 원격 접속&lt;/h2&gt;

&lt;p&gt;보통 ssh를 통해서 외부 서버에 진입할 때는 명령창에서 vim이나, 혹은 기타 조잡한(?) 편집기를 통해서 코드 수정을 하게 된다. 그러나, PyCharm Pro 버전은 SSH로 접속할 수 있는 외부 서버를 연결하여 코드를 편집하면서, 서버에 변경사항을 실시간으로 업데이트할 수 있다.&lt;/p&gt;

&lt;p&gt;이 강력한 기능은 아쉽게도 community 버전에서는 지원하지 않는다.&lt;/p&gt;

&lt;p&gt;먼저 새 프로젝트 또는 로컬에 존재하는 기존 프로젝트를 연다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;Settings &amp;gt; Project: name  &amp;gt; Project Interpreter&lt;/code&gt; 로 이동한 뒤, 오른쪽 위의 톱니바퀴를 누르면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Add&lt;/code&gt; 또는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Show All&lt;/code&gt;이 뜬다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Add&lt;/code&gt;를 누르자. &lt;code class=&quot;highlighter-rouge&quot;&gt;Show All&lt;/code&gt;을 누른 다음 &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt; 버튼을 눌러도 좋다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/57.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;새 Interpreter를 만드는 과정에서, Virtualenv나 conda 등이 아닌 SSH Interpreter를 선택해준다. 그리고 서버 설정을 똑같이 입력해준다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/58.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;다음 화면에서 비밀번호도 잘 입력해준다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/59.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;그러면 이제 서버에 저장되어 있을 Interpreter를 설정하는 단계이다. 여러분이 그냥 Python 하나만 깔아놓고 쓰거나, Conda를 쓰거나, Virtualenv를 쓰거나 하는 경우마다 Python Interpreter의 위치는 전부 다르다.&lt;br /&gt;
아무튼 어딘가에 있을 &lt;code class=&quot;highlighter-rouge&quot;&gt;python.exe&lt;/code&gt;를 잘 찾아서 경로를 지정해 주어야 한다. Ubuntu 환경에서 Miniconda를 쓰는 필자는 대략 다음과 같은 interpreter 경로를 갖는다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/60.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;Interpreter 경로 지정은 오른쪽의 디렉토리 아이콘을 누르면 서버에 존재하는 파일과 디렉토리를 볼 수 있다.&lt;br /&gt;
그리고 관리자 권한으로 실행해야 하는 경우가 있다면, 위 그림에서 파란색으로 표시한 &lt;code class=&quot;highlighter-rouge&quot;&gt;Execute code using this interprete with root privileges via sudo&lt;/code&gt; 옵션을 체크한다. (보안 상 문제가 없으면 하는 거 추천)&lt;/p&gt;

&lt;p&gt;다음으로는 아래쪽에 있는, 원격 서버의 파일과 로컬 파일을 동기화시키는 항목이 나온다. 이 부분의 의미는,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;PyCharm의 기능은
    &lt;ul&gt;
      &lt;li&gt;원격 서버를 ssh를 통해 vim 등의 편집기로 수정만 하는 방식이 아니라,&lt;/li&gt;
      &lt;li&gt;로컬에 같은 파일을 복사한 채로 진행되며,&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;로컬 파일을 수정하면 자동으로 원격 서버의 파일도 동기화가 되며(옵션을 체크했을 경우)&lt;/li&gt;
  &lt;li&gt;로컬에서 실행 명령을 내리면 로컬에서 실행되는 것이 아닌 원격 서버에서 실행이 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/61.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;이를 위해서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Sync folders&lt;/code&gt; 옵션의 오른쪽에 있는 디렉토리 아이콘(위쪽 빨간 박스)을 클릭한다. 그리고 &lt;code class=&quot;highlighter-rouge&quot;&gt;Edit Sync Folders&lt;/code&gt; 대화창이 뜨면 동기화를 시킬 노란 박스로 표시한 &lt;code class=&quot;highlighter-rouge&quot;&gt;Local Path&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;Remote Path&lt;/code&gt;를 잘 지정한다(아래쪽 빨간 박스를 누르면 수정 가능). 클라우드 드라이브 서비스처럼 알아서 동기화가 된다.&lt;/p&gt;

&lt;p&gt;초록 박스로 표시한 &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt; 버튼을 누르면 동기화할 Path를 추가 지정할 수 있다. 이는 같은 Interpreter를 사용하는 여러 프로젝트가 있을 때 사용하면 된다.&lt;/p&gt;

&lt;p&gt;원격 서버에 이미 파일이 존재하는 경우, 위 그림에서 파란 박스로 표시한 부분을 체크 해제한다. 반대로 로컬에서 처음 시작하는 경우, 체크해도 좋다. 만약 서버에 파일이 있는데 로컬 파일을 원격으로 자동 업데이트하는 옵션을 체크하면 원격 서버의 파일이 지워진다는 경고창을 보게 된다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;OK&lt;/code&gt;를 누른 뒤 &lt;code class=&quot;highlighter-rouge&quot;&gt;Finish&lt;/code&gt; 버튼을 누르면 한번 더 비밀번호를 입력하는 창이 뜬다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/62.png&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;그러면 Interpreter 목록에서 원격 Interpreter를 확인할 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/63.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&amp;lt;/br&amp;gt;&lt;/p&gt;

&lt;p&gt;다음으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;Settings &amp;gt; Build, Execution, Deployment &amp;gt; Deployment&lt;/code&gt;으로 이동한다. 그러면 Deployment에 조금 전 추가한 정보가 들어가 있을 것이다. 만약 없으면 아래 그림처럼 새 SFTP 서버를 추가한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/52.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;그러면 서버 이름을 입력하는 대화창이 나온다. 입력해주자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/53.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;다음 그림을 보자.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/54.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;Host에는 서버의 IP 주소(ex. 123.124.125.126),&lt;/li&gt;
  &lt;li&gt;포트 번호는 원격 서버에서 허용한 번호,&lt;/li&gt;
  &lt;li&gt;User name은 서버의 사용자 이름,&lt;/li&gt;
  &lt;li&gt;인증 방식은 보통 비밀번호를 많이 쓸 테니 사용자 이름에 맞는 비밀번호를 입력해준다. 비밀번호는 저장해도 좋다.&lt;/li&gt;
  &lt;li&gt;그리고 아래쪽 Test Connection을 누르면 연결이 정상적인지 확인한다. 안 된다면 잘못 입력했거나, 외부 접속 또는 포트 등이 차단되어 있을 가능성이 높다. 테스트를 해보면 아래와 같은 창이 뜨는데, Yes를 눌러준다.&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/55.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;정상적이면 연결이 성공했다는 메시지가 뜬다.&lt;/li&gt;
&lt;/ul&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/56.png&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;Root Path는 기본값으로 두어도 되고, 인증이 잘 되었다면 AutoDetect를 사용해도 된다. 특정 directory에서 시작하고 싶으면 오른쪽 디렉토리 아이콘을 눌러 직접 지정해준다.&lt;/li&gt;
  &lt;li&gt;Web Server URL와 그 아래 고급 옵션은 필수는 아니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그리고 Mappings 탭을 클릭하면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Local Path&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;Deployment Path&lt;/code&gt;(Remote Path)를 mapping할 수 있는 탭이 나온다. 역시 디렉토리 아이콘을 눌러 경로를 지정해 준다. 이때 경로는 위에서 기억한 &lt;code class=&quot;highlighter-rouge&quot;&gt;Root path&lt;/code&gt;에 더한 상대 경로임을 유의한다. 즉 mapping되는 Remote Path는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Root path&lt;/code&gt; + &lt;code class=&quot;highlighter-rouge&quot;&gt;Deployment Path&lt;/code&gt;이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/67.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;이제 &lt;code class=&quot;highlighter-rouge&quot;&gt;Project: name &amp;gt; Project Interpreter&lt;/code&gt;에서 조금 전에 만든 Interpreter를 선택하고 설정을 마치면 파일 전송이 이루어진다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/64.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;코드 수정을 하면 자동 업로드가 된다(옵션을 체크했다면). 또한, 실행을 시키면 원격 서버에서 실행되게 된다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;참고.&lt;/em&gt; 원격 서버에서 실행을 하긴 하지만 linux 시스템에서 사용하는 bash 파일을 윈도우에서 실행시킬 수는 없다. 이 부분은 조금 아쉬운 부분이다.&lt;/p&gt;

&lt;p&gt;로컬 -&amp;gt; 원격 또는 원격 -&amp;gt; 로컬 간 파일 전송을 수동/자동으로 할 수도 있다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Tools &amp;gt; Deployment&lt;/code&gt;를 누른다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/65.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Upload to&lt;/code&gt;를 눌러 서버를 선택하면 현재 로컬 프로젝트 파일들을 저장된 원격 서버에 업로드할 수 있다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Download from&lt;/code&gt;을 눌러 서버를 선택하면 마찬가지로 원격 서버의 파일을 로컬에 내려받을 수 있다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Configuration&lt;/code&gt;을 누르면 조금 전 보았던 &lt;code class=&quot;highlighter-rouge&quot;&gt;Mappings&lt;/code&gt; 탭을 포함해 설정을 다시 할 수 있다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Automatic Upload&lt;/code&gt;를 누르면 토글이 되며, 로컬 파일을 원격 서버에 자동으로 업데이트할지를 결정할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;terminal에서-ssh-session으로-열기&quot;&gt;Terminal에서 SSH session으로 열기&lt;/h3&gt;

&lt;p&gt;메뉴 바에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Tools &amp;gt; Start SSH session...&lt;/code&gt;을 클릭하면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Select host to connect&lt;/code&gt; 창이 뜬다. 이때 아래쪽 목록에는 현재 프로젝트에 설정되어 있는 python environment들이 뜬다. SSH 연결을 추가하고 싶으면, &lt;code class=&quot;highlighter-rouge&quot;&gt;Edit credentials...&lt;/code&gt;를 클릭한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/2019-02-07-PyCharm-usage/68.png&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;그러면 위 그림과 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;SSH Session&lt;/code&gt; 대화창이 뜬다. 여기서 보통 ssh 연결할 때처럼 서버 주소, 사용자명, 비밀번호 등을 입력하고 &lt;code class=&quot;highlighter-rouge&quot;&gt;OK&lt;/code&gt;를 누르면 Terminal 창에서 로컬 환경 대신 SSH 환경에서 열리게 된다. 파일 접속은 물론이고 실행까지 원격 ssh 서버 상에서 이루어지게 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.jetbrains.com/pycharm/&quot;&gt;공식 홈페이지&lt;/a&gt;에서 더 자세한 사용법을 찾아볼 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Miniconda(Anaconda) 사용법</title>
   <link href="http://localhost:4000/Miniconda-usage/"/>
   <updated>2019-02-01T00:00:00+09:00</updated>
   <id>http://localhost:4000/Miniconda-usage</id>
   <content type="html">&lt;p&gt;Anaconda는 Continuum Analytics라는 곳에서 만든 파이썬 배포판으로 수백 개의 파이썬 패키지를 포함하는 환경을 구성한다. Anaconda로는 virtualenv와 같은 여러 개의 가상환경을 만들어 각각의 환경을 따로 관리할 수 있다.&lt;br /&gt;
그 중 Miniconda는 이것저것 설치할 것이 많은 Anaconda에서 패키지를 다르게 설치할 여러 환경들을 관리한다는 최소한의 기능만 가진 부분만 포함하는 mini 버전이다. 따라서 이 글에서는 Miniconda를 설치하여 가상환경을 관리하는 법을 알아보겠다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;설치&quot;&gt;설치&lt;/h2&gt;

&lt;script data-ad-client=&quot;ca-pub-9951774327887666&quot; async=&quot;&quot; src=&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;a href=&quot;https://www.anaconda.com/distribution/#download-section&quot;&gt;Anaconda&lt;/a&gt;를 설치하거나, &lt;a href=&quot;https://conda.io/en/latest/miniconda.html&quot;&gt;Miniconda&lt;/a&gt;를 설치한다. 설치하고 싶을 운영체제와 버전에 맞는 것을 골라 설치한다. 설치 방법은 공식 홈페이지에 따로 설명되어 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/conda/2019-02-01-Miniconda-usage/01.PNG&quot; alt=&quot;01_install&quot; /&gt;
Not recommended라고 되어 있는 옵션이지만 체크하면 PATH에 등록하지 않아도 된다(이건 환경마다 조금 다르다).
&lt;img src=&quot;/public/img/conda/2019-02-01-Miniconda-usage/02.PNG&quot; alt=&quot;02_install&quot; /&gt;&lt;/p&gt;

&lt;p&gt;설치 후 다음 명령을 명령창(cmd / 터미널)에 입력해본다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;만약 다음과 같이 오류가 뜬다면 conda가 System PATH에 등록되지 않은 것이므로 등록을 해 준다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/conda/2019-02-01-Miniconda-usage/03.PNG&quot; alt=&quot;03_install&quot; /&gt;
&lt;img src=&quot;/public/img/conda/2019-02-01-Miniconda-usage/04.PNG&quot; alt=&quot;04_install&quot; /&gt;&lt;/p&gt;

&lt;p&gt;윈도우10, Miniconda3인 경우 &lt;code class=&quot;highlighter-rouge&quot;&gt;C:\ProgramData\Miniconda3\Scripts&lt;/code&gt;를 PATH에 등록해 준다.&lt;/p&gt;

&lt;p&gt;설치 패키지 목록은 다를 것이지만 다음과 같이 뜬다. &lt;code class=&quot;highlighter-rouge&quot;&gt;conda list&lt;/code&gt;는 현재 환경(기본 환경의 이름은 base이다)에서 설치된 패키지 목록을 나타내는 명령이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/conda/2019-02-01-Miniconda-usage/05.PNG&quot; alt=&quot;05_conda_list&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;가상환경-목록-확인-생성-및-삭제&quot;&gt;가상환경 목록 확인, 생성 및 삭제&lt;/h2&gt;

&lt;p&gt;다음을 명령창에 입력한다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 또는,
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;info&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;envs&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;현재 활성화된 가상환경 옆에는 * 가 추가된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/conda/2019-02-01-Miniconda-usage/06.PNG&quot; alt=&quot;06_env_list&quot; /&gt;&lt;/p&gt;

&lt;p&gt;처음 설치했을 때는 기본값인 base 하나만 있을 것이다.&lt;/p&gt;

&lt;p&gt;다음 명령을 통해 새 가상환경을 하나 생성한다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# -n 옵션은 --name과 같은 것으로, 가상환경 이름을 myenv로 지정한다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myenv&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# python=3.6 옵션은 가상환경 생성 시 파이썬 버전을 지정한다.
# 지정하지 않으면 conda에 기본 포함된 파이썬 버전으로 생성된다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condatorch&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3.6&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 특정 패키지 버전을 지정하면서, 그리고 패키지를 설치하면서 생성하는 것도 가능하다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myenv&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3.4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;astroid&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;babel&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 가상환경 생성 시 이것저것 깔리는 것이 싫다면 다음 옵션을 주면 된다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;packages&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myenv&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;python&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 새 가상환경을 만들 때 특정 가상환경 안에 설치된 패키지 전부를 설치하면서 생성할 수 있다.
# base 가상환경에 있는 패키지를 전부 설치하면서 생성한다면, 
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myenv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clone&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# environment.yml 파일이 있다면 다음과 같이 생성할 수 있다.
# 생성 방법은 이후에 설명한다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;계속 진행하겠냐는 물음이 보이면 &lt;code class=&quot;highlighter-rouge&quot;&gt;y&lt;/code&gt;를 입력한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/conda/2019-02-01-Miniconda-usage/07.PNG&quot; alt=&quot;07_env_create&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다시 &lt;code class=&quot;highlighter-rouge&quot;&gt;conda env list&lt;/code&gt;로 목록을 확인해보면 지정한 이름으로 가상환경이 생성되었음을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/conda/2019-02-01-Miniconda-usage/08.PNG&quot; alt=&quot;08_env_create&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림에서 activate condatorch, deactivate 등의 명령이 쓰여 있는 것을 확인할 수 있는데, 이는 특정 가상환경을 활성화 또는 비활성화할때 사용하는 명령이다(가상환경이 무엇에 쓰는 것인지 알면 무슨 말뜻인지 알 수 있을 것이다). 이는 다음 절에서 설명한다.&lt;/p&gt;

&lt;p&gt;가상환경 삭제는 다음 명령을 통해 수행할 수 있다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 생성할 때와는 다르게 env를 앞에 적어주어야 한다.
# 생성 시에는 env를 앞에 적으면 실행이 되지 않는다.
# remove 앞에 env를 써 주지 않으면 가상환경 삭제가 아닌 패키지 삭제가 이루어진다.
# conda env remove -n &amp;lt;environment_name&amp;gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;remove&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condatorch&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 다음도 가능하다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;remove&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myenv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;all&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/conda/2019-02-01-Miniconda-usage/09.PNG&quot; alt=&quot;09_env_remove&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;requirementstxt로-가상환경-생성하기&quot;&gt;Requirements.txt로 가상환경 생성하기&lt;/h3&gt;

&lt;p&gt;아래 명령들은 가독성을 위해 두 줄로 펼쳐 놓았다.&lt;/p&gt;

&lt;p&gt;Windows 환경이라면 명령창에 다음과 같이 쓰는 것이 가능하다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;FOR /F &quot;delims=~&quot; %f in (requirements.txt) 
DO conda install --yes &quot;%f&quot; || pip install &quot;%f&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Unix 환경이라면 다음과 같이 쓸 수 있다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;while read requirement; do conda install --yes $requirement; 
done &amp;lt; requirements.txt 2&amp;gt;error.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;conda로는 설치가 안 되고 pip으로는 설치가 되는 패키지가 있다면 다음과 같이 쓸 수 있다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;while read requirement; do conda install --yes $requirement 
|| pip install $requirement; done &amp;lt; requirements.txt 2&amp;gt;error.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음을 참조하였다: &lt;a href=&quot;https://gist.github.com/luiscape/19d2d73a8c7b59411a2fb73a697f5ed4&quot;&gt;github 글&lt;/a&gt;, &lt;a href=&quot;https://stackoverflow.com/questions/35802939/install-only-available-packages-using-conda-install-yes-file-requirements-t&quot;&gt;stackoverflow 글&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;가상환경-활성화-비활성화&quot;&gt;가상환경 활성화, 비활성화&lt;/h2&gt;

&lt;p&gt;가상환경 활성화는 위에서도 설명했듯 다음과 같이 쓰면 된다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;activate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environment_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;activate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;condatorch&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Unix 등의 환경에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;activate&lt;/code&gt;가 아닌 &lt;code class=&quot;highlighter-rouge&quot;&gt;source activate&lt;/code&gt;를 써야 한다.&lt;/p&gt;

&lt;p&gt;그러면 명령창의 맨 앞에 (condatorch)와 같이 활성화된 가상환경 이름이 뜬다.&lt;/p&gt;

&lt;p&gt;비활성화는 다음 명령으로 할 수 있다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;deactivate&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 설치한 버전에 따라 deactivate는 deprecated되었다는 경고를 볼 수도 있다. 이 경우 conda deactivate이다.
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/conda/2019-02-01-Miniconda-usage/10.PNG&quot; alt=&quot;10_activate&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림이 잘 이해가 되지 않는다면, &lt;code class=&quot;highlighter-rouge&quot;&gt;activate&lt;/code&gt;를 여러 번 쓰지 않을 것을 권장한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;가상환경-안에-패키지-설치&quot;&gt;가상환경 안에 패키지 설치&lt;/h2&gt;

&lt;p&gt;버전에 따라 조금씩 다른 경우도 있으나, 최신 버전(2019-02-01 기준)의 Miniconda3에서는 pip, whl, conda를 통한 설치 모두 현재 활성화된(없다면 base 또는 컴퓨터에 깔려 있는 다른 버전의 파이썬에) 가상환경에만 설치된다. 따라서 각 환경 간 거의 완전한 분리가 가능하다.&lt;/p&gt;

&lt;p&gt;패키지 설치는 다음과 같다. &lt;code class=&quot;highlighter-rouge&quot;&gt;pip&lt;/code&gt;과 거의 비슷하다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seaborn&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 여러 개를 동시에 설치할 경우 comma 없이 그냥 나열한다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pandas&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;설치된 패키지 목록을 보고 싶으면 다음을 입력한다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고로 conda 환경에서도 pip 등을 통한 설치가 가능하다.&lt;/p&gt;

&lt;h3 id=&quot;environmentyml-파일-생성-및-가상환경-생성&quot;&gt;environment.yml 파일 생성 및 가상환경 생성&lt;/h3&gt;

&lt;p&gt;설치된 패키지 목록을 &lt;code class=&quot;highlighter-rouge&quot;&gt;.yml&lt;/code&gt; 파일로 저장하는 명령이다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;pip freeze &amp;gt; requirements.txt&lt;/code&gt;와 같은 역할이다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yml&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;만들어진 파일은 다음과 비슷하게 생겼다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;name: condatorch
channels:
  - pytorch
  - defaults
dependencies:
  - blas=1.0=mkl
  - certifi=2018.11.29=py36_0
  ...
  - zstd=1.3.7=h508b16e_0
  - pip:
    - cycler==0.10.0
    ...
    - six==1.12.0
prefix: C:\ProgramData\Miniconda3\envs\condatorch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;만들어진 파일로 가상환경을 생성하는 방법은 위에서도 설명했지만 다음과 같다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 이 경우에는 env를 앞에 써 주어야 한다.
# -f는 --file을 의미한다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yml&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myenv&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;패키지-업데이트&quot;&gt;패키지 업데이트&lt;/h3&gt;

&lt;p&gt;특정 환경 안의 특정 패키지를 업데이트하려면 다음과 같이 하면 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environment_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spacy&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;특정 환경 안의 모든 패키지를 업데이트하려면 다음과 같이 하면 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;environment_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;all&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 현재 환경 업데이트
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;all&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;conda-버전-확인-및-update&quot;&gt;Conda 버전 확인 및 update&lt;/h2&gt;

&lt;p&gt;명령창에서 Conda의 버전을 확인하는 방법은 다음과 같다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda -V
conda --version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Conda 자체를 업데이트하는 방법은 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;conda update conda
conda update anaconda
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html&quot;&gt;공식 홈페이지&lt;/a&gt;에서 더 자세한 사용법을 찾아볼 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Jupyter Notebook 사용법</title>
   <link href="http://localhost:4000/Jupyter-usage/"/>
   <updated>2019-01-26T00:00:00+09:00</updated>
   <id>http://localhost:4000/Jupyter-usage</id>
   <content type="html">&lt;p&gt;Jupyter notebook은 대화형 파이썬 인터프리터(Interpreter)로서 웹 브라우저 환경에서 파이썬 코드를 작성 및 실행할 수 있는 툴이다.&lt;br /&gt;
서버에 Jupyter notebook을 설치하여 포트를 개방한 후 해당 url에 접속하여 원격으로 사용하거나, 로컬 환경에서 브라우저를 띄워 대화형 환경에서 코드를 작성 및 실행할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;설치-및-실행&quot;&gt;설치 및 실행&lt;/h2&gt;

&lt;h3 id=&quot;설치&quot;&gt;설치&lt;/h3&gt;

&lt;p&gt;설치는 두 가지 방법이 있는데, 첫 번째는 &lt;a href=&quot;https://www.anaconda.com/distribution/&quot;&gt;Anaconda&lt;/a&gt;와 함께 설치하는 방법이 있다. Anaconda를 설치할 때 Jupyter Notebook도 같이 설치하면 된다.&lt;br /&gt;
Anaconda와 같은 역할을 하는 Miniconda 사용법은 &lt;a href=&quot;https://greeksharifa.github.io/references/2019/02/01/Miniconda-usage/&quot;&gt;여기&lt;/a&gt;를 참조하도록 한다.&lt;/p&gt;

&lt;p&gt;Anadonda를 설치하는 방법 외에 기본적으로 pip은 Jupyter 패키지 설치를 지원한다. 설치 방법은 다른 패키지 설치 방법과 똑같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install jupyter
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;파이썬3과 2를 구분지어야 한다면 pip 대신 pip3를 사용한다.&lt;/p&gt;

&lt;h3 id=&quot;실행-및-종료&quot;&gt;실행 및 종료&lt;/h3&gt;

&lt;script data-ad-client=&quot;ca-pub-9951774327887666&quot; async=&quot;&quot; src=&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jupyter notebook
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/public/img/Jupyter/2019-01-26-Jupyter-usage/01.PNG&quot; alt=&quot;01_jupyter_notebook&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 명령을 입력하면 자동으로 어떤 html 파일을 열면서 브라우저가 실행된다. 만약 실행되지 않는다면 http://localhost:8888 으로 접속하거나 위 그림의 맨 마지막 줄에 있는 url을 복사하여 브라우저에서 접속한다.&lt;/p&gt;

&lt;p&gt;그러면 위 명령을 실행한 디렉토리 위치(위 그림에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;jupyter notebook&lt;/code&gt;을 실행한 줄에서 볼 수 있다. 필자의 경우 &lt;code class=&quot;highlighter-rouge&quot;&gt;C:\JupyterTest&lt;/code&gt;)의 파일들이 브라우저에 보이게 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Jupyter/2019-01-26-Jupyter-usage/02.PNG&quot; alt=&quot;02_broswer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Jupyter의 실행을 종료하려면 명령창에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + C&lt;/code&gt;를 입력한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Jupyter/2019-01-26-Jupyter-usage/03.PNG&quot; alt=&quot;03_terminate&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;고급-실행-옵션&quot;&gt;고급: 실행 옵션&lt;/h3&gt;

&lt;p&gt;명령 옵션의 도움말을 표시한다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jupyter notebook --help
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;실행 속도 상승을 위해 MathJax를 무효화할 수 있다. MathJax는 수식 입력을 위해 필요한 JavaScript 라이브러리이다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jupyter notebook --no-mathjax
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;웹 브라우저를 지정하거나 실행시키지 않을 수 있다. 포트 번호 지정도 가능하다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jupyter notebook --browser=&quot;safari&quot;
jupyter notebook --no-browser
jupyter notebook --port=8889
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;노트북 실행 시 실행 디렉토리를 지정할 수 있다. 기본값은 현재 밍령창에서의 실행 위치이다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jupyter notebook --notebook-dir=/user/define/directory
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;고급-설정-파일-수정&quot;&gt;고급: 설정 파일 수정&lt;/h3&gt;

&lt;p&gt;매번 옵션을 지정해서 실행하기가 귀찮다면, Jupyter Notebook의 기본 설정을 변경하기 위해 다음 명령을 입력한다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jupyter notebook --generate-config
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;그러면 Jupyter가 실행되는 대신 설정 파일이 열린다.&lt;br /&gt;
Linux에서는 기본적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;/home/&amp;lt;username&amp;gt;/.jupyter/jupyter_notebook_config.py&lt;/code&gt; 파일로 생성되며, 윈도우에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;C:\Users\&amp;lt;username&amp;gt;\.jupyter\jupyter_notebook_config.py&lt;/code&gt;로 생성된다.&lt;/p&gt;

&lt;p&gt;설정 파일에서 필요한 옵션을 변경하여 사용하면 된다. 기본적으로 사용하지 않는 옵션은 모두 주석 처리되어 있다.&lt;/p&gt;

&lt;p&gt;기본 설정 파일을 재지정하고 싶으면 다음과 같이 입력한다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jupyter notebook --config=custom_config.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;임시로 설정 파일을 변경해서 실행하고 싶다면 일반 옵션 주듯이 하면 된다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;jupyter notebook --config custom_config.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Jupyter notebook을 단순히 로컬 환경에서 실행하는 것이 아니라 서버로 띄워 놓고 원격 접속을 하려면, 위 방법으로 허용 포트나 접속 주소 등 설정 파일을 수정해야 한다.&lt;/p&gt;

&lt;h3 id=&quot;고급-원격-접속-설정&quot;&gt;고급: 원격 접속 설정&lt;/h3&gt;

&lt;p&gt;localhost(127.0.0.1) 말고 다른 컴퓨터에서 (서버로) 원격접속하고 싶을 때가 있다. 그럴 때는 다음 과정을 따른다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;명령창(cmd or terminal)에 python 또는 ipython을 입력하여 대화창을 연다.
    &lt;ul&gt;
      &lt;li&gt;다음을 입력한다:
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &amp;gt;&amp;gt;&amp;gt; from notebook.auth import passwd
  &amp;gt;&amp;gt;&amp;gt; passwd()
  Enter password: 
  Verity password: 
  'sha1:c5b493745105:0d26dcd6e9cf868d3b49f43d'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;출력으로 나온 암호화된 비밀번호를 기억해 둔다.&lt;/li&gt;
      &lt;li&gt;참고로 linux에서나 윈도우에서나 passwd() 등으로 비밀번호를 입력할 때에는 명령창에 입력하고 있는 문자가 전혀 표시되지 않는다. 별표(&lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;)로도 표시되지 않으니 참고.&lt;/li&gt;
      &lt;li&gt;대화창을 종료한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;이제 조금 전에 생성한 &lt;code class=&quot;highlighter-rouge&quot;&gt;jupyter_notebook_config.py&lt;/code&gt;를 편집기로 연다.
    &lt;ul&gt;
      &lt;li&gt;아래처럼 주석처리된 부분을 다음과 같이 바꾼다. 물론 비밀번호는 조금 전 여러분이 생성한 문자열로 입력해야 한다.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  #c.NotebookApp.password = '' 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  c = get_config()
  c.NotebookApp.password = 'sha1:c5b493745105:0d26dcd6e9cf868d3b49f43d'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;필수:&lt;/strong&gt; 비슷하게 다음 설정들을 바꿔주어야 한다. 모든 설정을 변경할 때에는 앞의 주석(&lt;code class=&quot;highlighter-rouge&quot;&gt;#&lt;/code&gt;)을 지우도록 한다.
        &lt;ul&gt;
          &lt;li&gt;외부접속 허용: &lt;code class=&quot;highlighter-rouge&quot;&gt;c.NotebookApp.allow_origin = '*'&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;IP 설정: &lt;code class=&quot;highlighter-rouge&quot;&gt;c.NotebookApp.ip = &amp;lt;여러분의 IP&amp;gt;&lt;/code&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;옵션:&lt;/strong&gt; 다음은 하고 싶으면 하도록 한다.
        &lt;ul&gt;
          &lt;li&gt;작업경로 설정: &lt;code class=&quot;highlighter-rouge&quot;&gt;c.NotebookApp.notebook_dir = &amp;lt;원하는 경로&amp;gt;&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;포트 설정: &lt;code class=&quot;highlighter-rouge&quot;&gt;c.NotebookApp.port = &amp;lt;원하는 port&amp;gt;&lt;/code&gt;&lt;/li&gt;
          &lt;li&gt;jupyter notebook으로 실행 시 브라우저 실행 여부: &lt;code class=&quot;highlighter-rouge&quot;&gt;c.NotebookApp.open_browser = False&lt;/code&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이제 외부접속을 할 때는 서버에서&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;jupyter notebook을 실행시킨 다음&lt;/li&gt;
  &lt;li&gt;
    &lt;여러분의 IP=&quot;&quot;&gt;:&lt;원하는 port=&quot;&quot;&gt; 형식을 브라우저의 주소창에 입력하면 된다.
&lt;/원하는&gt;&lt;/여러분의&gt;
    &lt;ul&gt;
      &lt;li&gt;예시: &lt;code class=&quot;highlighter-rouge&quot;&gt;123.212.321.14:8888&lt;/code&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;여러분이 설정한 비밀번호를 입력한다. 암호화된 문자열이 아니라 &lt;code class=&quot;highlighter-rouge&quot;&gt;passwd()&lt;/code&gt; 에서 입력한 비밀번호면 된다.&lt;/li&gt;
  &lt;li&gt;물론 일반 가정집에서는 그냥 ip를 할당할 수 없기 때문에 공유기 설정을 해주거나, 회사 컴퓨터 등이라면 따로 접속 허용하는 절차를 거쳐야 한다. 이 부분은 여기서는 ~pass~
    &lt;ul&gt;
      &lt;li&gt;그냥 되는 경우도 있다. 안 되는 경우에만 검색해서 해 보기 바람.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;jupyter의-기본-사용법&quot;&gt;Jupyter의 기본 사용법&lt;/h2&gt;

&lt;h3 id=&quot;새-파일-생성&quot;&gt;새 파일 생성&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Jupyter/2019-01-26-Jupyter-usage/04.PNG&quot; alt=&quot;04_new&quot; /&gt;&lt;/p&gt;

&lt;p&gt;오른쪽 부분의 &lt;code class=&quot;highlighter-rouge&quot;&gt;New&lt;/code&gt; 버튼을 클릭하면 Python 3, Text File, Folder, Terminal 등의 옵션이 있다(파이썬 버전에 따라 Python 2가 있을 수 있다). 우선 Python 3을 클릭하여 Python 3 코드를 입력할 수 있는 창을 열도록 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Jupyter/2019-01-26-Jupyter-usage/05.PNG&quot; alt=&quot;05_python3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;생성하면 맨 위에 기본적으로 Untitled라는 제목으로 생성이 된다. 파일 탐색기나 Finder 등에서도 &lt;code class=&quot;highlighter-rouge&quot;&gt;Untitled.ipynb&lt;/code&gt;라는 파일을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Jupyter/2019-01-26-Jupyter-usage/06.PNG&quot; alt=&quot;06_ipynb&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 checkpoints 디렉토리는 자동으로 생성된다. Jupyter는 자동저장이 되고(맨 위의 autosaved), 체크포인트를 따로 설정할 수 있다.&lt;/p&gt;

&lt;p&gt;제목은 Untitled 부분을 클릭하면 수정할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;편집--명령-모드&quot;&gt;편집 / 명령 모드&lt;/h3&gt;

&lt;p&gt;편집 모드에서는 셀의 내용을 편집할 수 있고(셀의 테두리가 초록색), 명령 모드는 편집중이 아닌 상태 또는 셀 자체에 조작을 가하는 상태(셀의 테두리가 파란색)이다.&lt;br /&gt;
명령 모드에서 편집 모드로 들어가려면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Enter&lt;/code&gt;키를, 반대로는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Esc&lt;/code&gt; 키를 누르면 된다.&lt;/p&gt;

&lt;h3 id=&quot;셀의-타입&quot;&gt;셀의 타입&lt;/h3&gt;

&lt;p&gt;Code 타입, Markdown 타입이 있다.&lt;br /&gt;
Code 타입은 일반 코드를 실행할 수 있는 셀이다. 기본적으로 셀을 생성하면 Code 타입으로 생성된다.&lt;br /&gt;
Markdown 타입은 &lt;a href=&quot;https://greeksharifa.github.io/references/2018/06/29/markdown-usage/&quot;&gt;Markdown&lt;/a&gt;으로 셀의 내용을 작성할 수 있다. 코드로 실행되지는 않으며, 수식을 작성할 수 있다. 수식은 MathJax에 의해 지원된다. 수식 작성 방법은 &lt;a href=&quot;https://greeksharifa.github.io/references/2018/06/29/equation-usage/&quot;&gt;여기&lt;/a&gt;를 참고한다.&lt;/p&gt;

&lt;p&gt;Markdown 타입으로 변경하면 Markdown 코드를 작성할 수 있다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Shift + Enter&lt;/code&gt; 키를 누르면 마크다운이 실제 보여지는 방식으로 변경되며, 다시 수정하려면 &lt;code class=&quot;highlighter-rouge&quot;&gt;Enter&lt;/code&gt; 또는 &lt;code class=&quot;highlighter-rouge&quot;&gt;더블 클릭&lt;/code&gt;하면 편집 가능하다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Jupyter/2019-01-26-Jupyter-usage/07.PNG&quot; alt=&quot;07_markdown&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;셀-실행&quot;&gt;셀 실행&lt;/h3&gt;

&lt;p&gt;실행하고 싶은 셀의 아무 곳에나 커서를 위치시킨 후 &lt;code class=&quot;highlighter-rouge&quot;&gt;Shift + Enter&lt;/code&gt; 키를 누른다.&lt;br /&gt;
실행하면 셀 아래쪽에는 실행 결과가 표시되고, 셀 옆의 ‘In [ ]’과 ‘Out [ ]’에 몇 번째로 실행시켰는지를 나타내는 숫자가 표시된다. 여러 번 실행하면 계속 숫자가 올라간다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Jupyter/2019-01-26-Jupyter-usage/08.PNG&quot; alt=&quot;08_run&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;강제-중단--재실행&quot;&gt;강제 중단 / 재실행&lt;/h3&gt;

&lt;p&gt;제목 아래 줄의 탭에 Kernel 탭이 있다. 커널은 IPython 대화창 아래에서 백그라운드 비슷하게 실행되는 일종의 운영체제 같은 개념이다. IPython 대화창을 관리한다고 보면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Jupyter/2019-01-26-Jupyter-usage/09.PNG&quot; alt=&quot;09_interrupt&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Kernel 탭의 모든 버튼은 코드를 삭제하지는 않는다. 각 버튼의 기능을 설명하면,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Interrupt: 실행 중인 코드를 강제 중지한다. 중지하면 위 그림과 같은 에러가 뜨며 실행이 중지된다.&lt;/li&gt;
  &lt;li&gt;Restart: 실행 중인 코드가 중지되며 재시작된다. 코드나 실행 결과는 삭제되지 않는다.&lt;/li&gt;
  &lt;li&gt;Restart &amp;amp; Clear Output: 코드는 중지되며 실행 결과도 삭제한다.&lt;/li&gt;
  &lt;li&gt;Restart &amp;amp; Run All: 재시작 후 모든 셀의 코드를 위에서부터 순차적으로 한 번씩 실행한다.&lt;/li&gt;
  &lt;li&gt;Reconnect: 인터넷 연결이 끊어졌을 때 연결을 재시도한다.&lt;/li&gt;
  &lt;li&gt;Shutdown: 커널을 종료한다. 이 버튼을 누르면 실행 결과는 삭제되지 않으나 완전 종료된 상태로 더 이상 메모리를 잡아먹지 않는다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Shutdown되었거나, 인터넷 연결이 끊어졌거나, 기타 문제가 있으면 아래와 같이 탭 옆에 알림이 표시된다. Shutdown 된 경우 No kernel이라고 뜬다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Jupyter/2019-01-26-Jupyter-usage/10.PNG&quot; alt=&quot;10_shutdowned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;현재 실행중인 커널이 있는지 확인하는 방법은 두 가지다. 첫 번째는 Home 화면에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;ipynb&lt;/code&gt; 파일의 아이콘이 초록색이면 실행중, 회색이면 중단된 또는 시작되지 않은 상태이다. 여기서는 해당 디렉토리에서 실행중인 것만 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Jupyter/2019-01-26-Jupyter-usage/11_shutdowned.PNG&quot; alt=&quot;11_shutdowned&quot; /&gt;&lt;/p&gt;

&lt;p&gt;또 하나는 Home 화면에서 Files 탭 대신 Running 탭을 클릭하면 실행 중인 IPython과 터미널의 목록을 확인할 수 있다. 이 탭에서는 전체 디렉토리에서 실행중인 파일 또는 터미널을 전부 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Jupyter/2019-01-26-Jupyter-usage/12.PNG&quot; alt=&quot;12_list&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;text-file-생성&quot;&gt;Text File 생성&lt;/h3&gt;

&lt;p&gt;New 버튼에서 Text File을 생성하면 &lt;code class=&quot;highlighter-rouge&quot;&gt;.txt&lt;/code&gt; 파일이나 &lt;code class=&quot;highlighter-rouge&quot;&gt;.py&lt;/code&gt; 파일 등을 만들 수 있다. 이렇게 만든 파일은 대화 형식으로 실행되지 않고, 터미널에서 실행시켜야 한다. 읽는 것은 IPython 창에서도 가능하다.&lt;/p&gt;

&lt;h3 id=&quot;folder-생성&quot;&gt;Folder 생성&lt;/h3&gt;

&lt;p&gt;디렉토리를 생성할 때 사용한다. 폴더랑 같은 것이다.&lt;/p&gt;

&lt;h3 id=&quot;터미널&quot;&gt;터미널&lt;/h3&gt;

&lt;p&gt;New 버튼으로 Terminal을 클릭하면, 터미널을 하나 새로 연다. 이것은 윈도우나 맥 등의 명령창(cmd 또는 terminal)과 같다. 여기서 .py 파일을 실행시킬 수 있고, 파일의 목록을 보거나 삭제하는 등의 명령이 모두 가능하다. Running 탭에서 중지시킬 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Jupyter/2019-01-26-Jupyter-usage/13.PNG&quot; alt=&quot;13_terminal&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;파일-이름-변경-또는-삭제&quot;&gt;파일 이름 변경 또는 삭제&lt;/h3&gt;

&lt;p&gt;파일 맨 왼쪽의 체크박스를 클릭하면 복제, 수정, 삭제 등이 가능하다. 물론 로컬 파일 탐색기에서 수정이나 삭제를 해도 되며, 서버가 연결에 문제가 없으면 바로 반영된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Jupyter/2019-01-26-Jupyter-usage/14.PNG&quot; alt=&quot;14_name&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;자동완성&quot;&gt;자동완성&lt;/h3&gt;

&lt;p&gt;웬만한 IDE에는 다 있는 자동완성 기능이다. 변수나 함수 등을 일부만 입력하고 &lt;code class=&quot;highlighter-rouge&quot;&gt;Tab&lt;/code&gt; 키를 누르면 된다. 따로 설명할 필요는 없을 듯 하다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;단축키&quot;&gt;단축키&lt;/h2&gt;

&lt;p&gt;단축키 정보는 [Help] - [Keyboard Shortcuts] 또는 명령 모드에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;H&lt;/code&gt;를 눌러서 표시할 수 있다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;공용 단축키&lt;/th&gt;
      &lt;th&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Shift + Enter&lt;/td&gt;
      &lt;td&gt;액티브 셀을 실행하고 아래 셀을 선택한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ctrl + Enter&lt;/td&gt;
      &lt;td&gt;액티브 셀을 실행한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Alt + Enter&lt;/td&gt;
      &lt;td&gt;액티브 셀을 실행하고 아래에 셀을 하나 생성한다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;편집 모드 단축키&lt;/th&gt;
      &lt;th&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Ctrl + Z&lt;/td&gt;
      &lt;td&gt;Undo 명령이다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ctrl + Shift + Z&lt;/td&gt;
      &lt;td&gt;Redo 명령이다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Tab&lt;/td&gt;
      &lt;td&gt;자동완성 또는 Indent를 추가한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Shift + Tab&lt;/td&gt;
      &lt;td&gt;툴팁 또는 변수의 상태를 표시한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ctrl + Shift + -&lt;/td&gt;
      &lt;td&gt;커서의 위치에서 셀을 잘라 두 개로 만든다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;참고로 명령 모드 단축키 중 콤마(&lt;code class=&quot;highlighter-rouge&quot;&gt;,&lt;/code&gt;)로 되어 있는 것은 연속해서 누르라는 의미이다. 예로 &lt;code class=&quot;highlighter-rouge&quot;&gt;D&lt;/code&gt;를 두 번 누르면 액티브 코드 셀을 삭제한다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;명령 모드 단축키&lt;/th&gt;
      &lt;th&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;↑, ↓&lt;/td&gt;
      &lt;td&gt;셀 선택&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;A&lt;/td&gt;
      &lt;td&gt;액티브 코드 셀의 위(Above)에 셀을 하나 생성한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;B&lt;/td&gt;
      &lt;td&gt;액티브 코드 셀의 위(Below)에 셀을 하나 생성한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ctrl + S&lt;/td&gt;
      &lt;td&gt;Notebook 파일을 저장한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Shift + L&lt;/td&gt;
      &lt;td&gt;줄 번호 표시를 토글한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;D, D&lt;/td&gt;
      &lt;td&gt;(D 두번 연속으로 타이핑)액티브 코드 셀을 삭제한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Z&lt;/td&gt;
      &lt;td&gt;삭제한 셀을 하나 복원한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Y&lt;/td&gt;
      &lt;td&gt;액티브 코드 셀을 Code 타입(코드를 기술하는 타입)으로 한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;M&lt;/td&gt;
      &lt;td&gt;액티브 코드 셀을 Markdown 타입으로 한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;O, O&lt;/td&gt;
      &lt;td&gt;커널을 재시작한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;P&lt;/td&gt;
      &lt;td&gt;명령 팔레트를 연다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;H&lt;/td&gt;
      &lt;td&gt;단축키 목록을 표시한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Enter&lt;/code&gt; 키로 숨긴다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;jupyter의-기능&quot;&gt;Jupyter의 기능&lt;/h2&gt;

&lt;h3 id=&quot;docstring의-표시&quot;&gt;DocString의 표시&lt;/h3&gt;

&lt;p&gt;선언한 변수 뒤에 &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt;를 붙여서 셀을 실행하는 것으로 해당 변수의 상태를 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;약간 다른 방법으로 변수를 타이핑한 후 &lt;code class=&quot;highlighter-rouge&quot;&gt;Shift + Tab&lt;/code&gt;을 누르면 툴팁이 표시된다.&lt;br /&gt;
툴팁에는 DocString의 일부 내용이 표시된다.&lt;/p&gt;

&lt;h3 id=&quot;이미지-첨부하기&quot;&gt;이미지 첨부하기&lt;/h3&gt;

&lt;p&gt;Drag &amp;amp; Drop으로 첨부할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;shell명령-프롬프트의-이용&quot;&gt;shell(명령 프롬프트)의 이용&lt;/h3&gt;

&lt;p&gt;명령창에서 쓰는 명령을 그대로 쓰되, 맨 앞에 &lt;code class=&quot;highlighter-rouge&quot;&gt;!&lt;/code&gt;를 입력하여 사용 가능하다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;!cd Documents
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;매직-명령어-이용&quot;&gt;매직 명령어 이용&lt;/h3&gt;

&lt;p&gt;맨 앞에 &lt;code class=&quot;highlighter-rouge&quot;&gt;%&lt;/code&gt;를 붙이고 특정 명령을 수행할 수 있다. 이는 파이썬 문법에는 포함되지 않은, Jupyter notebook만의 기능이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Jupyter/2019-01-26-Jupyter-usage/15.PNG&quot; alt=&quot;15_magic&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;매직 명령어&lt;/th&gt;
      &lt;th&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;%pwd&lt;/td&gt;
      &lt;td&gt;현재 디렉토리 경로 출력&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;%time &lt;code class=&quot;highlighter-rouge&quot;&gt;코드&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;코드&lt;/code&gt;의 실행 시간을 측정하여 표시&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;%timeit &lt;code class=&quot;highlighter-rouge&quot;&gt;코드&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;코드&lt;/code&gt;를 여러 번 실행한 결과를 요약하여 표시&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;%history -l 3&lt;/td&gt;
      &lt;td&gt;최근 3개의 코드 실행 이력 취득&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;%ls&lt;/td&gt;
      &lt;td&gt;윈도우의 dir, Linux의 ls 명령과 같음&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;%autosave &lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;자동저장 주기를 설정한다. 초 단위이며, 0이면 무효로 한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;%matplotlib&lt;/td&gt;
      &lt;td&gt;그래프를 그리는 코드 위에 따로 설정한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;%matplotlib inline&lt;/code&gt;으로 설정하면 코드 셀의 바로 아래에, &lt;code class=&quot;highlighter-rouge&quot;&gt;%matplotlib tk&lt;/code&gt;로 설정하면 별도 창에 그래프가 출력된다. &lt;code class=&quot;highlighter-rouge&quot;&gt;%matplotlib notebook&lt;/code&gt;으로 하면 코드 셀 바로 아래에 동적으로 그래프를 조작할 수 있는 그래프가 생성된다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 코드 실행 시간 측정
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 결과:
# CPU times: user 225 us, sys: 0 ns, total: 225 us
# Wall time: 228 us
# 499950000
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 1000회 반복, 3회 실행
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeit&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 결과: 
# 1000 loops, best of 3: 238 us for loop
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 옵션 지정하기
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 셀 전체의 시간 측정
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</content>
 </entry>
 
 <entry>
   <title>PyTorch 사용법 - 03. How to Use PyTorch</title>
   <link href="http://localhost:4000/pytorch-usage-03-How-to-Use-PyTorch/"/>
   <updated>2018-11-10T00:00:00+09:00</updated>
   <id>http://localhost:4000/pytorch-usage-03-How-to-Use-PyTorch</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-00-references/&quot;&gt;PyTorch 사용법 - 00. References&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-01-introduction/&quot;&gt;PyTorch 사용법 - 01. 소개 및 설치&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-02-Linear-Regression-Model/&quot;&gt;PyTorch 사용법 - 02. Linear Regression Model&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/&quot;&gt;PyTorch 사용법 - 03. How to Use PyTorch&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2019/06/12/pytorch-usage-04-RNN-Model/&quot;&gt;PyTorch 사용법 - 04. Recurrent Neural Network Model&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;2020.02.04 Updated&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;이 글에서는 PyTorch 프로젝트를 만드는 방법에 대해서 알아본다.&lt;/p&gt;

&lt;p&gt;사용되는 torch 함수들의 사용법은 &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-00-references/&quot;&gt;여기&lt;/a&gt;에서 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;Pytorch의 학습 방법(loss function, optimizer, autograd, backward 등이 어떻게 돌아가는지)을 알고 싶다면 &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/#train-model&quot;&gt;여기&lt;/a&gt;로 바로 넘어가면 된다.&lt;/p&gt;

&lt;p&gt;Pytorch 사용법이 헷갈리는 부분이 있으면 &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/#q--a&quot;&gt;Q&amp;amp;A 절&lt;/a&gt;을 참고하면 된다.&lt;/p&gt;

&lt;p&gt;예시 코드의 많은 부분은 링크와 함께 공식 Pytorch 홈페이지(pytorch.org/docs)에서 가져왔음을 밝힌다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;주의: 이 글은 좀 길다. ㅎ&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;import&quot;&gt;Import&lt;/h1&gt;

&lt;script data-ad-client=&quot;ca-pub-9951774327887666&quot; async=&quot;&quot; src=&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# preprocess, set hyperparameter
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;argparse&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# load data
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# train
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# visualization
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;argparse&quot;&gt;argparse&lt;/h1&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python train.py --epochs 50 --batch-size 64 --save-dir weights
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Machine Learning을 포함해서, 위와 같은 실행 옵션은 많은 코드에서 볼 수 있었을 것이다. 학습 과정을 포함하여 대부분은 명령창 또는 콘솔에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;python 파일 옵션들...&lt;/code&gt;으로 실행시키기 때문에, argparse에 대한 이해는 필요하다.&lt;/p&gt;

&lt;p&gt;argparse에 대한 내용은 &lt;a href=&quot;https://greeksharifa.github.io/references/2019/02/12/argparse-usage/&quot;&gt;여기&lt;/a&gt;를 참조하도록 한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;load-data&quot;&gt;Load Data&lt;/h1&gt;

&lt;p&gt;전처리하는 과정을 설명할 수는 없다. 데이터가 어떻게 생겼는지는 직접 봐야 알 수 있다.&lt;br /&gt;
다만 한 번 쓰고 말 것이 아니라면, 데이터가 추가되거나 변경점이 있더라도 전처리 코드의 대대적인 수정이 발생하도록 짜는 것은 본인 손해이다.&lt;/p&gt;

&lt;h2 id=&quot;단순한-방법&quot;&gt;단순한 방법&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/02_Linear_Regression_Model_Data.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Avoid copy data, just refer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'y'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pandas&lt;/code&gt;나 &lt;code class=&quot;highlighter-rouge&quot;&gt;csv&lt;/code&gt; 패키지 등으로 그냥 불러오는 방법이다. 데이터가 복잡하지 않은 형태라면 단순하고 유용하게 쓸 수 있다. 그러나 이 글에서 중요한 부분은 아니다.&lt;/p&gt;

&lt;h2 id=&quot;torchutilsdatadataloader&quot;&gt;torch.utils.data.DataLoader&lt;/h2&gt;

&lt;p&gt;참조: &lt;a href=&quot;https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader&quot;&gt;torch.utils.data.DataLoader&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Pytorch는 &lt;code class=&quot;highlighter-rouge&quot;&gt;DataLoader&lt;/code&gt;라고 하는 괜찮은 utility를 제공한다. 간단하게 생각하면 DataLoader 객체는 학습에 쓰일 데이터 전체를 보관했다가, train 함수가 batch 하나를 요구하면 batch size 개수만큼 데이터를 꺼내서 준다고 보면 된다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;실제로 &lt;code class=&quot;highlighter-rouge&quot;&gt;[batch size, num]&lt;/code&gt;처럼 미리 잘라놓는 것은 아니고, 내부적으로 Iterator에 포함된 Index가 존재한다. train() 함수가 데이터를 요구하면 사전에 저장된 batch size만큼 return하는 형태이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;사용할 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.utils.data.Dataset&lt;/code&gt;에 따라 반환하는 데이터(자연어, 이미지, 정답 label 등)는 조금씩 다르지만, 일반적으로 실제 DataLoader를 쓸 때는 다음과 같이 쓰기만 하면 된다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;DataLoader 안에 데이터가 어떻게 들어있는지 확인하기 위해, MNIST 데이터를 가져와 보자. DataLoader는 &lt;code class=&quot;highlighter-rouge&quot;&gt;torchvision.datasets&lt;/code&gt; 및 &lt;code class=&quot;highlighter-rouge&quot;&gt;torchvision.transforms&lt;/code&gt;와 함께 자주 쓰이는데, 각각 Pytorch가 공식적으로 지원하는 &lt;a href=&quot;https://pytorch.org/docs/stable/torchvision/datasets.html&quot;&gt;dataset&lt;/a&gt;, &lt;a href=&quot;https://pytorch.org/docs/stable/torchvision/transforms.html?highlight=torchvision%20transforms&quot;&gt;데이터 transformation 및 augmentation 함수들&lt;/a&gt;(주로 이미지 데이터에 사용)를 포함한다.&lt;br /&gt;
각각의 사용법은 아래 절을 참조한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/mnist'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'type:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;first_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__iter__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__next__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'{:15s} | {:&amp;lt;25s} | {}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'name'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'type'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'size'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'{:15s} | {:&amp;lt;25s} | {}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Num of Batch'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'{:15s} | {:&amp;lt;25s} | {}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'first_batch'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'{:15s} | {:&amp;lt;25s} | {}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'first_batch[0]'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;first_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'{:15s} | {:&amp;lt;25s} | {}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'first_batch[1]'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;first_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;type: &amp;lt;class 'torch.utils.data.dataloader.DataLoader'&amp;gt; 

name            | type                      | size
Num of Batch    |                           | 938
first_batch     | &amp;lt;class 'list'&amp;gt;            | 2
first_batch[0]  | &amp;lt;class 'torch.Tensor'&amp;gt;    | torch.Size([64, 1, 28, 28])
first_batch[1]  | &amp;lt;class 'torch.Tensor'&amp;gt;    | torch.Size([64])
# 총 데이터의 개수는 938 * 28 ~= 60000(마지막 batch는 32)이다.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;custom-dataset-만들기&quot;&gt;Custom Dataset 만들기&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;nn.Module&lt;/strong&gt;을 상속하는 Custom Model처럼, Custom DataSet은 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.utils.data.Dataset&lt;/code&gt;를 상속해야 한다. 또한 override해야 하는 것은 다음 두 가지다. &lt;code class=&quot;highlighter-rouge&quot;&gt;python dunder&lt;/code&gt;를 모른다면 먼저 구글링해보도록 한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;__len__(self)&lt;/code&gt;: dataset의 전체 개수를 알려준다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;__getitem__(self, idx)&lt;/code&gt;: parameter로 idx를 넘겨주면 idx번째의 데이터를 반환한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;위의 두 가지만 기억하면 된다. 전체 데이터 개수와, i번째 데이터를 반환하는 함수만 구현하면 Custom DataSet이 완성된다.&lt;br /&gt;
다음에는 완성된 DataSet을 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.utils.data.DataLoader&lt;/code&gt;에 인자로 전달해주면 끝이다.&lt;/p&gt;

&lt;p&gt;완전 필수는 아니지만 &lt;code class=&quot;highlighter-rouge&quot;&gt;__init__()&lt;/code&gt;도 구현하는 것이 좋다.&lt;/p&gt;

&lt;p&gt;1차함수 선형회귀(Linear Regression)의 &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-02-Linear-Regression-Model/#load-data&quot;&gt;예&lt;/a&gt;를 들면 다음과 같다.&lt;br /&gt;
데이터는 &lt;a href=&quot;https://drive.google.com/file/d/1gVxV5eD5NfyEO4aHSyAGmsDgUco8FQPb/view?usp=sharing&quot;&gt;여기&lt;/a&gt;에서 받을 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LinearRegressionDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;csv_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        Args:
            csv_file (string): Path to the csv file. 
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;csv_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'y'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__len__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__getitem__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LinearRegressionDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'02_Linear_Regression_Model_Data.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;torchvisiondatasets&quot;&gt;torchvision.datasets&lt;/h2&gt;

&lt;p&gt;참조: &lt;a href=&quot;https://pytorch.org/docs/stable/torchvision/datasets.html&quot;&gt;torchvision.datasets&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Pytorch가 공식적으로 다운로드 및 사용을 지원하는 datasets이다. 2020.02.04 기준 dataset 목록은 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MNIST
    &lt;ul&gt;
      &lt;li&gt;MNIST(숫자 0~9에 해당하는 손글씨 이미지 6만(train) + 1만(test))&lt;/li&gt;
      &lt;li&gt;Fashion-MNIST(간소화된 의류 이미지),&lt;/li&gt;
      &lt;li&gt;KMNIST(일본어=히라가나, 간지 손글씨),&lt;/li&gt;
      &lt;li&gt;EMNIST(영문자 손글씨),&lt;/li&gt;
      &lt;li&gt;QMNIST(MNIST를 재구성한 것)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;MS COCO
    &lt;ul&gt;
      &lt;li&gt;Captions(이미지 한 장과 이를 설명하는 한 영문장),&lt;/li&gt;
      &lt;li&gt;Detection(이미지 한 장과 여기에 있는 object들을 segmantation한 정보)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;LSUN(https://www.yf.io/p/lsun),&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;ImageFolder&lt;/em&gt;, &lt;em&gt;DatasetFolder&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;Image:
    &lt;ul&gt;
      &lt;li&gt;ImageNet 2012,&lt;/li&gt;
      &lt;li&gt;CIFAR10 &amp;amp; CIFAR100,&lt;/li&gt;
      &lt;li&gt;STL10, SVHN, PhotoTour, SBU&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Flickr8k &amp;amp; Flickr30k, VOC Segmantation &amp;amp; Detection,&lt;/li&gt;
  &lt;li&gt;Cityscapes, SBD, USPS, Kinetics-400, HMDB51, UCF101&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;각각의 dataset마다 필요한 parameter가 조금씩 다르기 때문에, &lt;a href=&quot;https://pytorch.org/docs/stable/torchvision/datasets.html#mnist&quot;&gt;MNIST&lt;/a&gt;만 간단히 설명하도록 하겠다. 사실 공식 홈페이지를 참조하면 어렵지 않게 사용 가능하다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/PyTorch/2018-11-10-pytorch-usage-03-How-to-Use-PyTorch/01.PNG&quot; alt=&quot;01_MNIST&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;root: 데이터를 저장할 루트 폴더이다. 보통 &lt;code class=&quot;highlighter-rouge&quot;&gt;data/&lt;/code&gt;나 &lt;code class=&quot;highlighter-rouge&quot;&gt;data/mnist/&lt;/code&gt;를 많이 쓰는 것 같지만, 상관없다.&lt;/li&gt;
  &lt;li&gt;train: 학습 데이터를 받을지, 테스트 데이터를 받을지를 결정한다.&lt;/li&gt;
  &lt;li&gt;download: true로 지정하면 알아서 다운로드해 준다. 이미 다운로드했다면 재실행해도 다시 받지 않는다.&lt;/li&gt;
  &lt;li&gt;transform: 지정하면 이미지 데이터에 어떤 변형을 가할지를 transform function의 묶음(Compose)로 전달한다.&lt;/li&gt;
  &lt;li&gt;target_transform: 보통 위의 transform까지만 쓰는 것 같다. 쓰고 싶다면 이것도 쓰자.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;torchvisiontransforms&quot;&gt;torchvision.transforms&lt;/h2&gt;

&lt;p&gt;참조: &lt;a href=&quot;https://pytorch.org/docs/stable/torchvision/transforms.html?highlight=torchvision%20transforms&quot;&gt;torchvision.transforms&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;이미지 변환 함수들을 포함한다. 상대적으로 자주 쓰이는 함수는 다음과 같은 것들이 있다. 더 많은 목록은 홈페이지를 참조하면 된다. 참고로 parameter 중 &lt;code class=&quot;highlighter-rouge&quot;&gt;transforms&lt;/code&gt;는 변환 함수들의 list 또는 tuple이다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;transforms.CenterCrop(size): 이미지의 중앙 부분을 크롭하여 [size, size] 크기로 만든다.&lt;/li&gt;
      &lt;li&gt;transforms.Resize(size, interpolation=2): 이미지를 지정한 크기로 변환한다. 직사각형으로 자를 수 있다.
        &lt;ul&gt;
          &lt;li&gt;참고: transforms.Scale는 Resize에 의해 deprecated되었다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;transforms.RandomCrop(size, padding=None, pad_if_needed=False, fill=0, padding_mode=’constant’): 이미지의 랜덤한 부분을 [size, size] 크기로 잘라낸다. input 이미지가 output 크기보다 작으면 padding을 추가할 수 있다.&lt;/li&gt;
      &lt;li&gt;transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 3/4), interpolation=2): 이미지를 랜덤한 크기 및 비율로 자른다.
        &lt;ul&gt;
          &lt;li&gt;참고: transforms.RandomSizedCrop는 RandomResizedCrop에 의해 deprecated되었다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;transforms.RandomRotation(degrees, resample=False, expand=False, center=None): 이미지를 랜덤한 각도로 회전시킨다.&lt;/li&gt;
      &lt;li&gt;transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0): brightness, contrast 등을 변화시킨다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;이미지를 torch.Tensor 또는 PILImage로 변환시킬 수 있다. 사용자 정의 변환도 가능하다.
    &lt;ul&gt;
      &lt;li&gt;transforms.ToPILImage(mode=None): PILImage로 변환시킨다.&lt;/li&gt;
      &lt;li&gt;transforms.ToTensor(): torch.Tensor로 변환시킨다.&lt;/li&gt;
      &lt;li&gt;transforms.Lambda(lambd): 사용자 정의 lambda function을 적용시킨다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;torch.Tensor에 적용해야 하는 변환 함수들도 있다.
    &lt;ul&gt;
      &lt;li&gt;transforms.LinearTransformation(transformation_matrix): tensor로 표현된 이미지에 선형 변환을 시킨다.&lt;/li&gt;
      &lt;li&gt;transforms.Normalize(mean, std, inplace=False): tensor의 데이터 수치(또는 범위)를 정규화한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;brightness나 contrast 등을 바꿀 수도 있다.
    &lt;ul&gt;
      &lt;li&gt;transforms.functional.adjust_contrast(img, contrast_factor) 등&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;위의 변환 함수들을 랜덤으로 적용할지 말지 결정할 수도 있다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;transforms.RandomChoice(transforms): &lt;code class=&quot;highlighter-rouge&quot;&gt;transforms&lt;/code&gt; 리스트에 포함된 변환 함수 중 랜덤으로 1개 적용한다.&lt;/li&gt;
      &lt;li&gt;transforms.RandomApply(transforms, p=0.5): &lt;code class=&quot;highlighter-rouge&quot;&gt;transforms&lt;/code&gt; 리스트에 포함된 변환 함수들을 p의 확률로 적용한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;위의 모든 변환 함수들을 하나로 조합하는 함수는 다음과 같다. 이 함수를 &lt;code class=&quot;highlighter-rouge&quot;&gt;dataloader&lt;/code&gt;에 넘기면 이미지 변환 작업이 간단하게 완료된다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;transforms.Compose(transforms)
        &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CenterCrop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;변환 순서는 보통 resize/crop, toTensor, Normalize 순서를 거친다. Normalize는 tensor에만 사용 가능하므로 이 부분은 순서를 지켜야 한다.&lt;/p&gt;

&lt;h2 id=&quot;torchtext&quot;&gt;torchtext&lt;/h2&gt;

&lt;p&gt;자연어처리(NLP)를 다룰 때 쓸 수 있는 좋은 라이브러리가 있다. 이는 자연어처리 데이터셋을 다루는 데 있어서 매우 편리한 기능을 제공한다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;데이터셋 로드&lt;/li&gt;
  &lt;li&gt;토큰화(Tokenization)&lt;/li&gt;
  &lt;li&gt;단어장(Vocabulary) 생성&lt;/li&gt;
  &lt;li&gt;Index mapping: 각 단어를 해당하는 인덱스로 매핑&lt;/li&gt;
  &lt;li&gt;단어 벡터(Word Vector): word embedding을 만들어준다. 0이나 랜덤 값 및 사전학습된 값으로 초기화할 수 있다.&lt;/li&gt;
  &lt;li&gt;Batch 생성 및 (자동) padding 수행&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;설치는 다음과 같다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip install torchtext
# conda 환경에선 다음과 같다.
conda install -c pytorch torchtext
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;define-and-load-model&quot;&gt;Define and Load Model&lt;/h1&gt;

&lt;h2 id=&quot;pytorch-model&quot;&gt;Pytorch Model&lt;/h2&gt;

&lt;p&gt;gradient 계산 방식 등 Pytorch model의 작동 방식은 &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/#set-loss-functioncreterion-and-optimizer&quot;&gt;Set Loss function(creterion) and Optimizer 절&lt;/a&gt;을 보면 된다.&lt;/p&gt;

&lt;p&gt;Pytorch에서 쓰는 용어는 Module 하나에 가깝지만, 많은 경우 layer나 model 등의 용어도 같이 사용되므로 굳이 구분하여 적어 보았다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Layer&lt;/strong&gt; : Model 또는 Module을 구성하는 한 개의 층, Convolutional Layer, Linear Layer 등이 있다.&lt;br /&gt;
&lt;strong&gt;Module&lt;/strong&gt; : 1개 이상의 Layer가 모여서 구성된 것. Module이 모여 새로운 Module을 만들 수도 있다.&lt;br /&gt;
&lt;strong&gt;Model&lt;/strong&gt; : 여러분이 최종적으로 원하는 것. 당연히 한 개의 Module일 수도 있다.&lt;/p&gt;

&lt;p&gt;예를 들어 &lt;strong&gt;nn.Linear&lt;/strong&gt;는 한 개의 layer이기도 하며, 이것 하나만으로도 module이나 Model을 구성할 수 있다. 단순 Linear Model이 필요하다면, &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;처럼 사용해도 무방하다.&lt;/p&gt;

&lt;p&gt;PyTorch의 모든 모델은 기본적으로 다음 구조를 갖는다. PyTorch 내장 모델뿐 아니라 사용자 정의 모델도 반드시 이 정의를 따라야 한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Model_Name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Model_Name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        ex)
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)
        &quot;&quot;&quot;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;some_function1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;some_function2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        ex)
        x = F.relu(self.conv1(x))
        x = F.relu(self.conv2(x))
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;PyTorch 모델로 쓰기 위해서는 다음 조건을 따라야 한다. 내장된 모델들(&lt;strong&gt;nn.Linear&lt;/strong&gt; 등)은 당연히 이 조건들을 만족한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;torch.nn.Module&lt;/strong&gt;을 상속해야 한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;__init__()&lt;/code&gt;과 &lt;code class=&quot;highlighter-rouge&quot;&gt;forward()&lt;/code&gt;를 override해야 한다.
    &lt;ul&gt;
      &lt;li&gt;사용자 정의 모델의 경우 init과 forward의 인자는 자유롭게 바꿀 수 있다. 이름이 x일 필요도 없으며, 인자의 개수 또한 달라질 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이 두 가지 조건은 PyTorch의 기능들을 이용하기 위해 필수적이다.&lt;/p&gt;

&lt;p&gt;따르지 않는다고 해서 에러를 내뱉진 않지만, 다음 규칙들은 따르는 것이 좋다:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;__init__()&lt;/code&gt;에서는 모델에서 사용될 module을 정의한다. module만 정의할 수도, activation function 등을 전부 정의할 수도 있다.
    &lt;ul&gt;
      &lt;li&gt;아래에서 설명하겠지만 module은 &lt;strong&gt;nn.Linear&lt;/strong&gt;, &lt;strong&gt;nn.Conv2d&lt;/strong&gt; 등을 포함한다.&lt;/li&gt;
      &lt;li&gt;activation function은 &lt;strong&gt;nn.functional.relu&lt;/strong&gt;, &lt;strong&gt;nn.functional.sigmoid&lt;/strong&gt; 등을 포함한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;forward()&lt;/code&gt;에서는 모델에서 행해져야 하는 계산을 정의한다(대개 train할 때). 모델에서 forward 계산과 backward gradient 계산이 있는데, 그 중 forward 부분을 정의한다. input을 네트워크에 통과시켜 어떤 output이 나오는지를 정의한다고 보면 된다.
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;__init__()&lt;/code&gt;에서 정의한 module들을 그대로 갖다 쓴다.&lt;/li&gt;
      &lt;li&gt;위의 예시에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;__init__()&lt;/code&gt;에서 정의한 &lt;code class=&quot;highlighter-rouge&quot;&gt;self.conv1&lt;/code&gt;과 &lt;code class=&quot;highlighter-rouge&quot;&gt;self.conv2&lt;/code&gt;를 가져다 썼고, activation은 미리 정의한 것을 쓰지 않고 즉석에서 불러와 사용했다.&lt;/li&gt;
      &lt;li&gt;backward 계산은 PyTorch가 알아서 해 준다. &lt;code class=&quot;highlighter-rouge&quot;&gt;backward()&lt;/code&gt; 함수를 호출하기만 한다면.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;nnmodule&quot;&gt;nn.Module&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-02-Linear-Regression-Model/#import&quot;&gt;여기&lt;/a&gt;를 참고한다. 요약하면 &lt;strong&gt;nn.Module&lt;/strong&gt;은 모든 PyTorch 모델의 base class이다.&lt;/p&gt;

&lt;h3 id=&quot;nnmodule-내장-함수&quot;&gt;nn.Module 내장 함수&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#module&quot;&gt;nn.Module&lt;/a&gt;에 내장된 method들은 모델을 추가 구성/설정하거나, train/eval(test) 모드 변경, cpu/gpu 변경, 포함된 module 목록을 얻는 등의 활동에 초점이 맞춰져 있다.&lt;/p&gt;

&lt;p&gt;모델을 추가로 구성하려면,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;add_module(name, module)&lt;/code&gt;: 현재 module에 새로운 module을 추가한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;apply(fn)&lt;/code&gt;: 현재 module의 모든 submodule에 해당 함수(fn)을 적용한다. 주로 model parameter를 초기화할 때 자주 쓴다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;모델이 어떻게 생겼는지 보려면,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;children()&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;modules()&lt;/code&gt;: 자식 또는 모델 전체의 모든 module에 대한 iterator를 반환한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;named_buffers(), named_children(), named_modules(), named_parameters()&lt;/code&gt;: 위 함수와 비슷하지만 이름도 같이 반환한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;모델을 통째로 저장 혹은 불러오려면,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;state_dict(destination=None, prefix='', keep_vars=False)&lt;/code&gt;: 모델의 모든 상태(parameter, running averages 등 buffer)를 딕셔너리 형태로 반환한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;load_state_dict(state_dict, strict=True)&lt;/code&gt;: parameter와 buffer 등 모델의 상태를 현 모델로 복사한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;strict=True&lt;/code&gt;이면 모든 module의 이름이 &lt;em&gt;정확히&lt;/em&gt; 같아야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;학습 시에 필요한 함수들을 살펴보면,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cuda(device=None)&lt;/code&gt;: 모든 model parameter를 GPU 버퍼에 옮기는 것으로 GPU를 쓰고 싶다면 이를 활성화해주어야 한다.
    &lt;ul&gt;
      &lt;li&gt;GPU를 쓰려면 두 가지에 대해서만 &lt;code class=&quot;highlighter-rouge&quot;&gt;.cuda()&lt;/code&gt;를 call하면 된다. 그 두 개는 모든 input batch 또는 tensor, 그리고 모델이다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.cuda()&lt;/code&gt;는 optimizer를 설정하기 전에 실행되어야 한다. 잊어버리지 않으려면 모델을 생성하자마자 쓰는 것이 좋다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;eval()&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;train()&lt;/code&gt;: 모델을 train mode 또는 eval(test) mode로 변경한다. Dropout이나 BatchNormalization을 쓰는 모델은 학습시킬 때와 평가할 때 구조/역할이 다르기 때문에 반드시 이를 명시하도록 한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;parameters(recurse=True)&lt;/code&gt;: module parameter에 대한 iterator를 반환한다. 보통 optimizer에 넘겨줄 때 말고는 쓰지 않는다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;zero_grad()&lt;/code&gt;: 모든 model parameter의 gradient를 0으로 설정한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;사용하는 법은 매우 간단히 나타내었다. Optimizer에 대한 설명은 &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/#set-loss-functioncreterion-and-optimizer&quot;&gt;여기&lt;/a&gt;를 참조하면 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;user_defined_initialize_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vgg16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 예시는 예시일 뿐
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last_module&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add_module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'last_module'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last_module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;last_module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;user_defined_initialize_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# set optimizer. model.parameter를 넘겨준다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;betas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# train
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# test
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'test'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;pytorch-layer의-종류&quot;&gt;Pytorch Layer의 종류&lt;/h2&gt;

&lt;p&gt;참조: &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#module&quot;&gt;nn.module&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;참고만 하도록 한다. 좀 많다. 쓰고자 하는 것과 이름이 비슷하다 싶으면 홈페이지를 참조해서 쓰면 된다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Linear layers
    &lt;ul&gt;
      &lt;li&gt;nn.Linear&lt;/li&gt;
      &lt;li&gt;nn.Bilinear&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Convolution layers
    &lt;ul&gt;
      &lt;li&gt;nn.Conv1d, nn.Conv2d, nn.Conv3d&lt;/li&gt;
      &lt;li&gt;nn.ConvTranspose1d, nn.ConvTranspose2d, nn.ConvTranspose3d&lt;/li&gt;
      &lt;li&gt;nn.Unfold, nn.Fold&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Pooling layers
    &lt;ul&gt;
      &lt;li&gt;nn.MaxPool1d, nn.MaxPool2d, nn.MaxPool3d&lt;/li&gt;
      &lt;li&gt;nn.MaxUnpool1d, nn.MaxUnpool2d, nn.MaxUnpool3d&lt;/li&gt;
      &lt;li&gt;nn.AvgPool1d, nn.AvgPool2d, nn.AvgPool3d&lt;/li&gt;
      &lt;li&gt;nn.FractionalMaxPool2d&lt;/li&gt;
      &lt;li&gt;nn.LPPool1d, nn.LPPool2d&lt;/li&gt;
      &lt;li&gt;nn.AdaptiveMaxPool1d, nn.AdaptiveMaxPool2d, nn.AdaptiveMaxPool3d&lt;/li&gt;
      &lt;li&gt;nn.AdaptiveAvgPool1d, nn.AdaptiveAvgPool2d, nn.AdaptiveAvgPool3d&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Padding layers
    &lt;ul&gt;
      &lt;li&gt;nn.ReflectionPad1d, nn.ReflectionPad2d&lt;/li&gt;
      &lt;li&gt;nn.ReplicationPad1d, nn.ReplicationPad2d, nn.ReplicationPad3d&lt;/li&gt;
      &lt;li&gt;nn.ZeroPad2d&lt;/li&gt;
      &lt;li&gt;nn.ConstantPad1d, nn.ConstantPad2d, nn.ConstantPad3d&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Normalization layers
    &lt;ul&gt;
      &lt;li&gt;nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d&lt;/li&gt;
      &lt;li&gt;nn.GroupNorm&lt;/li&gt;
      &lt;li&gt;nn.InstanceNorm1d, nn.InstanceNorm2d, nn.InstanceNorm3d&lt;/li&gt;
      &lt;li&gt;nn.LayerNorm&lt;/li&gt;
      &lt;li&gt;nn.LocalResponseNorm&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Recurrent layers
    &lt;ul&gt;
      &lt;li&gt;nn.RNN, nn.RNNCell&lt;/li&gt;
      &lt;li&gt;nn.LSTM, nn.LSTMCell&lt;/li&gt;
      &lt;li&gt;nn.GRU, nn.GRUCell&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Dropout layers
    &lt;ul&gt;
      &lt;li&gt;nn.Dropout, nn.Dropout2d, nn.Dropout3d&lt;/li&gt;
      &lt;li&gt;nn.AlphaDropout&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Sparse layers
    &lt;ul&gt;
      &lt;li&gt;nn.Embedding&lt;/li&gt;
      &lt;li&gt;nn.EmbeddingBag&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;pytorch-activation-function의-종류&quot;&gt;Pytorch Activation function의 종류&lt;/h2&gt;

&lt;p&gt;참조: &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity&quot;&gt;Activation functions&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Non-linear activations
    &lt;ul&gt;
      &lt;li&gt;nn.ELU, nn.SELU&lt;/li&gt;
      &lt;li&gt;nn.Hardshrink, nn.Hardtanh&lt;/li&gt;
      &lt;li&gt;nn.LeakyReLU, nn.PReLU, nn.ReLU, nn.ReLU6, nn.RReLU&lt;/li&gt;
      &lt;li&gt;nn.Sigmoid, nn.LogSigmoid&lt;/li&gt;
      &lt;li&gt;nn.Softplus, nn.Softshrink, nn.Softsign&lt;/li&gt;
      &lt;li&gt;nn.Tanh, nn.Tanhshrink&lt;/li&gt;
      &lt;li&gt;nn.Threshold&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Non-linear activations (other)
    &lt;ul&gt;
      &lt;li&gt;nn.Softmin&lt;/li&gt;
      &lt;li&gt;nn.Softmax, nn.Softmax2d, nn.LogSoftmax&lt;/li&gt;
      &lt;li&gt;nn.AdaptiveLogSoftmaxWithLoss&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;containers&quot;&gt;Containers&lt;/h2&gt;

&lt;p&gt;참조: &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#containers&quot;&gt;Containers&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;여러 layer들을 하나로 묶는 데 쓰인다.&lt;br /&gt;
종류는 다음과 같은 것들이 있는데, Module 설계 시 자주 쓰는 것으로 &lt;strong&gt;nn.Sequential&lt;/strong&gt;이 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;nn.Module&lt;/li&gt;
  &lt;li&gt;nn.Sequential&lt;/li&gt;
  &lt;li&gt;nn.ModuleList&lt;/li&gt;
  &lt;li&gt;nn.ModuleDict&lt;/li&gt;
  &lt;li&gt;nn.ParameterList&lt;/li&gt;
  &lt;li&gt;nn.ParameterDict&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;nnsequential&quot;&gt;nn.Sequential&lt;/h3&gt;

&lt;p&gt;참조: &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#sequential&quot;&gt;nn.Sequential&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;이름에서 알 수 있듯 여러 module들을 연속적으로 연결하는 모델이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Example of using Sequential
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
이 경우 model(x)는 nn.ReLU(nn.Conv2d(20,64,5)(nn.ReLU(nn.Conv2d(1,20,5)(x))))와 같음.
&quot;&quot;&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example of using Sequential with OrderedDict
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;OrderedDict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'conv1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()),&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'conv2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;조금 다르지만 비슷한 역할을 할 수 있는 것으로는 nn.ModuleList, nn.ModuleDict가 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;모델-구성-방법&quot;&gt;모델 구성 방법&lt;/h2&gt;

&lt;p&gt;크게 6가지 정도의 방법이 있다. &lt;strong&gt;nn&lt;/strong&gt; 라이브러리를 잘 써서 직접 만들거나, 함수 또는 클래스로 정의, cfg파일 정의 또는 &lt;a href=&quot;https://pytorch.org/docs/stable/torchvision/models.html&quot;&gt;torchvision.models&lt;/a&gt;에 미리 정의된 모델을 쓰는 방법이 있다.&lt;/p&gt;

&lt;h3 id=&quot;단순한-방법-1&quot;&gt;단순한 방법&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-02-Linear-Regression-Model/#define-and-load-model&quot;&gt;이전 글&lt;/a&gt;에서 썼던 방식이다. &lt;em&gt;매우&lt;/em&gt; 단순한 모델을 만들 때는 굳이 nn.Module을 상속하는 클래스를 만들 필요 없이 바로 사용 가능하며, 단순하다는 장점이 있다.&lt;/p&gt;

&lt;h3 id=&quot;nnsequential을-사용하는-방법&quot;&gt;nn.Sequential을 사용하는 방법&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sequential_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여러 &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/#pytorch-layer%EC%9D%98-%EC%A2%85%EB%A5%98&quot;&gt;Layer&lt;/a&gt;와 &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/#pytorch-activation-function%EC%9D%98-%EC%A2%85%EB%A5%98&quot;&gt;Activation function&lt;/a&gt;들을 조합하여 하나의 sequential model을 만들 수 있다. 역시 상대적으로 복잡하지 않은 모델 중 모델의 구조가 sequential한 모델에만 사용할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;함수로-정의하는-방법&quot;&gt;함수로 정의하는 방법&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;TwoLayerNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;net&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TwoLayerNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;바로 위의 모델과 완전히 동일한 모델이다. 함수로 선언할 경우 변수에 저장해 놓은 layer들을 재사용하거나, skip-connection을 구현할 수도 있다. 하지만 그 정도로 복잡한 모델은 아래 방법을 쓰는 것이 낫다.&lt;/p&gt;

&lt;h3 id=&quot;nnmodule을-상속한-클래스를-정의하는-방법&quot;&gt;nn.Module을 상속한 클래스를 정의하는 방법&lt;/h3&gt;

&lt;p&gt;가장 정석이 되는 방법이다. 또한, 복잡한 모델을 구현하는 데 적합하다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TwoLinearLayerNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TwoLinearLayerNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TwoLinearLayerNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;역시 동일한 모델을 구현하였다. 여러분의 코딩 스타일에 따라, &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#relu&quot;&gt;ReLU&lt;/a&gt; 등의 Activation function을 &lt;code class=&quot;highlighter-rouge&quot;&gt;forward()&lt;/code&gt;에서 바로 정의해서 쓰거나, &lt;code class=&quot;highlighter-rouge&quot;&gt;__init__()&lt;/code&gt;에 정의한 후 forward에서 갖다 쓰는 방법을 선택할 수 있다. 후자의 방법은 아래와 같다.&lt;br /&gt;
물론 변수명은 전적으로 여러분의 선택이지만, activation1, relu1 등의 이름을 보통 쓰는 것 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TwoLinearLayerNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TwoLinearLayerNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activation1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activation1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TwoLinearLayerNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;두 코딩 스타일의 차이점 중 하나는 import하는 것이 다르다(F.relu와 nn.ReLU는 사실 거의 같다). Activation function 부분에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.nn.functional&lt;/code&gt;은 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.nn&lt;/code&gt;의 Module에 거의 포함되는데, &lt;code class=&quot;highlighter-rouge&quot;&gt;forward()&lt;/code&gt;에서 정의해서 쓰느냐 마느냐에 따라 다르게 선택하면 되는 정도이다.&lt;/p&gt;

&lt;h3 id=&quot;cfgconfig를-정의한-후-모델을-생성하는-방법&quot;&gt;cfg(config)를 정의한 후 모델을 생성하는 방법&lt;/h3&gt;

&lt;p&gt;처음 보면 알아보기 까다로운 방법이지만, &lt;em&gt;매우&lt;/em&gt; 복잡한 모델의 경우 &lt;code class=&quot;highlighter-rouge&quot;&gt;.cfg&lt;/code&gt; 파일을 따로 만들어 모델의 구조를 정의하는 방법이 존재한다. 많이 쓰이는 방법은 대략 두 가지 정도인 것 같다.&lt;/p&gt;

&lt;p&gt;먼저 PyTorch documentation에서 찾을 수 있는 방법이 있다. 예로는 &lt;a href=&quot;https://arxiv.org/abs/1409.1556&quot;&gt;VGG&lt;/a&gt;를 가져왔다. 코드는 &lt;a href=&quot;https://pytorch.org/docs/0.4.0/_modules/torchvision/models/vgg.html&quot;&gt;여기&lt;/a&gt;에서 찾을 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;VGG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init_weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VGG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classifier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(...)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_initialize_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):...&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_initialize_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):...&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;make_layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_norm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;conv2d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BatchNorm2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'A'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'D'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'E'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'M'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;vgg16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;VGG 16-layer model (configuration &quot;D&quot;)&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'init_weights'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VGG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;make_layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cfg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'D'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_zoo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_urls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'vgg16'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여기서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;.cfg&lt;/code&gt; 파일이 사용되지는 않았으나, &lt;code class=&quot;highlighter-rouge&quot;&gt;cfg&lt;/code&gt;라는 변수가 configuration을 담당하고 있다. VGG16 모델을 구성하기 위해 cfg 변수의 해당하는 부분을 읽어 &lt;code class=&quot;highlighter-rouge&quot;&gt;make_layer&lt;/code&gt; 함수를 통해 모델을 구성한다.&lt;/p&gt;

&lt;p&gt;더 복잡한 모델은 아예 따로 &lt;code class=&quot;highlighter-rouge&quot;&gt;.cfg&lt;/code&gt; 파일을 빼놓는다. &lt;a href=&quot;https://greeksharifa.github.io/paper_review/2018/10/26/YOLOv2/&quot;&gt;YOLO&lt;/a&gt;의 경우 수백 라인이 넘기도 한다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.cfg&lt;/code&gt; 파일은 대략 &lt;a href=&quot;https://github.com/marvis/pytorch-yolo2/blob/master/cfg/yolo.cfg&quot;&gt;다음&lt;/a&gt;과 같이 생겼다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[net]
# Testing
batch=1
subdivisions=1
# Training
# batch=64
# subdivisions=8
...

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이를 파싱하는 &lt;a href=&quot;https://github.com/marvis/pytorch-yolo2/blob/master/cfg.py&quot;&gt;코드&lt;/a&gt;도 있어야 한다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;parse_cfg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cfgfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;blocks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cfgfile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'r'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rstrip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'#'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;continue&lt;/span&gt;        
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'['&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;blocks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'type'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lstrip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'['&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rstrip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;']'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# set default value
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'type'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'convolutional'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'batch_normalize'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'='&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'type'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'_type'&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readline&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;blocks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blocks&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이 방법의 경우 대개 depth가 수십~수백에 이르는 아주 거대한 모델을 구성할 때 사용되는 방법이다. 많은 수의 github 코드들이 이런 방식을 사용하고 있는데, 그러면 그 모델은 굉장히 복잡하게 생겼다는 뜻이 된다.&lt;/p&gt;

&lt;h3 id=&quot;torchvisionmodels의-모델을-사용하는-방법&quot;&gt;torchvision.models의 모델을 사용하는 방법&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/torchvision/models.html&quot;&gt;torchvision.models&lt;/a&gt;에서는 미리 정의되어 있는 모델들을 사용할 수 있다. 이 모델들은 그 구조뿐 아니라 &lt;code class=&quot;highlighter-rouge&quot;&gt;pretrained=True&lt;/code&gt; 인자를 넘김으로써 pretrained weights를 가져올 수도 있다.&lt;/p&gt;

&lt;p&gt;2019.02.12 시점에서 사용 가능한 모델 종류는 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;AlexNet&lt;/li&gt;
  &lt;li&gt;VGG-11, VGG-13, VGG-16, VGG-19&lt;/li&gt;
  &lt;li&gt;VGG-11, VGG-13, VGG-16, VGG-19 (with batch normalization)&lt;/li&gt;
  &lt;li&gt;ResNet-18, ResNet-34, ResNet-50, ResNet-101, ResNet-152&lt;/li&gt;
  &lt;li&gt;SqueezeNet 1.0, SqueezeNet 1.1&lt;/li&gt;
  &lt;li&gt;Densenet-121, Densenet-169, Densenet-201, Densenet-161&lt;/li&gt;
  &lt;li&gt;Inception v3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;모델에 따라 train mode와 eval mode가 정해진 경우가 있으므로 이는 주의해서 사용하도록 한다.&lt;/p&gt;

&lt;p&gt;모든 pretrained model을 쓸 때 이미지 데이터는 [3, W, H] 형식이어야 하고, W, H는 224 이상이어야 한다. 또 아래 코드처럼 정규화된 이미지 데이터로 학습된 것이기 때문에, 이 모델들을 사용할 때에는 데이터셋을 이와 같이 정규화시켜주어야 한다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.485&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.456&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.406&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.229&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.225&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;사용법은 대략 다음과 같다. 사실 이게 거의 끝이고, 나머지는 다른 일반 모델처럼 사용하면 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchvision.models&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# model load
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alexnet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alexnet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vgg16&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vgg16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vgg16_bn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vgg16_bn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;resnet18&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resnet18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;squeezenet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeezenet1_0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;densenet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;densenet161&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;inception&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inception_v3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# pretrained model load
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resnet18&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resnet18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vgg16&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vgg16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;set-loss-functioncreterion-and-optimizer&quot;&gt;Set Loss function(creterion) and Optimizer&lt;/h1&gt;

&lt;h2 id=&quot;pytorch-loss-function의-종류&quot;&gt;Pytorch Loss function의 종류&lt;/h2&gt;

&lt;p&gt;참조: &lt;a href=&quot;https://pytorch.org/docs/stable/nn.html#loss-functions&quot;&gt;Loss functions&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Loss function은 모델이 추측한 결과(prediction 또는 output)과 실제 정답(label 또는 y 등)의 &lt;em&gt;loss&lt;/em&gt;를 계산한다. 이는 loss function을 어떤 것을 쓰느냐에 따라 달라진다. 예를 들어 regression model에서 MSE(Mean Squared Error)를 쓸 경우 평균 제곱오차를 계산한다.&lt;/p&gt;

&lt;p&gt;사용법은 다른 함수들도 아래와 똑같다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MSELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;21&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;41&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;52&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 예측값
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 정답
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;       &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# tensor(2.)
# loss = (2^2 + 1^2 + 0^2 + 1^2 + 2^2) / 5 = 2
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;criterion_reduction_none&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MSELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'none'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion_reduction_none&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# tensor([4., 1., 0., 1., 4.])
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여러 코드들을 살펴보면, loss function을 정의할 때는 보통 &lt;code class=&quot;highlighter-rouge&quot;&gt;creterion&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;loss_fn&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;loss_function&lt;/code&gt;등의 이름을 사용하니 참고하자.&lt;/p&gt;

&lt;p&gt;홈페이지를 참조하면 각 함수별 설명에 ‘Creates a criterion that measures…‘라 설명이 되어 있다. 위의 예시를 보면 알겠지만 해당 함수들이 당장 loss를 계산하는 것이 아니라 loss를 계산하는 기준을 정의한다는 뜻이다.&lt;br /&gt;
또 많은 함수들은 &lt;code class=&quot;highlighter-rouge&quot;&gt;reduce&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;size_average&lt;/code&gt; argument를 갖는다. loss를 계산하여 평균을 내는 것이 아니라 각 원소별로 따로 계산할 수 있게 해 준다. 그러나 2019.02.16 기준으로 다음과 비슷한 경고가 뜬다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;reduce args will be deprecated, please use reduction=’none’ instead.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;따라서 &lt;code class=&quot;highlighter-rouge&quot;&gt;reduction&lt;/code&gt; argument를 쓰도록 하자. 지정할 수 있는 종류는 ‘none’ | ‘mean’ | ‘sum’ 세 가지이다. 기본값은 mean으로 되어 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;nn.L1Loss&lt;/strong&gt;: 각 원소별 차이의 절댓값을 계산한다.
&lt;img src=&quot;/public/img/PyTorch/2018-11-10-pytorch-usage-03-How-to-Use-PyTorch/02.PNG&quot; alt=&quot;L1&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;nn.MSELoss&lt;/strong&gt;: Mean Squared Error(평균제곱오차) 또는 squared L2 norm을 계산한다.
&lt;img src=&quot;/public/img/PyTorch/2018-11-10-pytorch-usage-03-How-to-Use-PyTorch/03.PNG&quot; alt=&quot;MSE&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;nn.CrossEntropyLoss&lt;/strong&gt;: Cross Entropy Loss를 계산한다. nn.LogSoftmax() and nn.NLLLoss()를 포함한다. weight argument를 지정할 수 있다.
&lt;img src=&quot;/public/img/PyTorch/2018-11-10-pytorch-usage-03-How-to-Use-PyTorch/04.PNG&quot; alt=&quot;CE&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;nn.CTCLoss&lt;/strong&gt;: Connectionist Temporal Classification loss를 계산한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;nn.NLLLoss&lt;/strong&gt;: Negative log likelihood loss를 계산한다.
&lt;img src=&quot;/public/img/PyTorch/2018-11-10-pytorch-usage-03-How-to-Use-PyTorch/05.PNG&quot; alt=&quot;NLL&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;nn.PoissonNLLLoss&lt;/strong&gt;: target이 poission 분포를 가진 경우 Negative log likelihood loss를 계산한다.
&lt;img src=&quot;/public/img/PyTorch/2018-11-10-pytorch-usage-03-How-to-Use-PyTorch/06.PNG&quot; alt=&quot;PNLL&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;nn.KLDivLoss&lt;/strong&gt;: Kullback-Leibler divergence Loss를 계산한다.
&lt;img src=&quot;/public/img/PyTorch/2018-11-10-pytorch-usage-03-How-to-Use-PyTorch/07.PNG&quot; alt=&quot;KLDiv&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;nn.BCELoss&lt;/strong&gt;: Binary Cross Entropy를 계산한다. 
&lt;img src=&quot;/public/img/PyTorch/2018-11-10-pytorch-usage-03-How-to-Use-PyTorch/08.PNG&quot; alt=&quot;BCE&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;nn.BCEWithLogitsLoss&lt;/strong&gt;: Sigmoid 레이어와 BCELoss를 하나로 합친 것인데, 홈페이지의 설명에 따르면 두 개를 따로 쓰는 것보다 이 함수를 쓰는 것이 조금 더 수치 안정성을 가진다고 한다.
&lt;img src=&quot;/public/img/PyTorch/2018-11-10-pytorch-usage-03-How-to-Use-PyTorch/09.PNG&quot; alt=&quot;BCE&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;이외에 &lt;strong&gt;MarginRankingLoss, HingeEmbeddingLoss, MultiLabelMarginLoss, SmoothL1Loss, SoftMarginLoss, MultiLabelSoftMarginLoss, CosineEmbeddingLoss, MultiMarginLoss, TripletMarginLoss&lt;/strong&gt;를 계산하는 함수들이 있다. 필요하면 찾아보자.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;pytorch-optimizer의-종류&quot;&gt;Pytorch Optimizer의 종류&lt;/h2&gt;

&lt;p&gt;참조: &lt;a href=&quot;https://pytorch.org/docs/stable/optim.html&quot;&gt;torch.optim&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/#nnmodule-%EB%82%B4%EC%9E%A5-%ED%95%A8%EC%88%98&quot;&gt;여기&lt;/a&gt;에도 간략하게 언급했었지만, GPU CUDA를 사용할 계획이라면 optimizer를 정의하기 전에 미리 해놓아야 한다(&lt;code class=&quot;highlighter-rouge&quot;&gt;model.cuda()&lt;/code&gt;). 공식 홈페이지에 따르면,&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If you need to move a model to GPU via .cuda(), please do so before constructing optimizers for it. Parameters of a model after .cuda() will be different objects with those before the call.
In general, you should make sure that optimized parameters live in consistent locations when optimizers are constructed and used.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이유를 설명하자면&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;optimizer는 argument로 model의 parameter를 입력받는다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.cuda()&lt;/code&gt;를 쓰면 모델의 parameter가 cpu 대신 gpu에 올라가는 것이므로 다른 object가 된다.&lt;/li&gt;
  &lt;li&gt;따라서 optimizer에 model parameter의 위치를 전달한 후 &lt;code class=&quot;highlighter-rouge&quot;&gt;.cuda()&lt;/code&gt;를 실행하면, 학습시켜야 할 parameter는 GPU에 올라가 있는데 optimizer는 cpu에 올라간 엉뚱한 parameter 위치를 참조하고 있는 것이 된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;그러니 순서를 지키자.&lt;/p&gt;

&lt;p&gt;optimizer 정의는 다음과 같이 할 수 있다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;optimizer에 대해 알아 두어야 할 것이 조금 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;optimizer는 &lt;code class=&quot;highlighter-rouge&quot;&gt;step()&lt;/code&gt; method를 통해 argument로 전달받은 parameter를 업데이트한다.&lt;/li&gt;
  &lt;li&gt;모델의 parameter별로(per-parameter) 다른 기준(learning rate 등)을 적용시킬 수 있다. &lt;a href=&quot;https://pytorch.org/docs/stable/optim.html#per-parameter-options&quot;&gt;참고&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.optim.Optimizer(params, defaults)&lt;/code&gt;는 모든 optimizer의 base class이다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nn.Module&lt;/code&gt;과 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;state_dict()&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;load_state_dict()&lt;/code&gt;를 지원하여 optimizer의 상태를 저장하고 불러올 수 있다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;zero_grad()&lt;/code&gt; method는 optimizer에 연결된 parameter들의 gradient를 0으로 만든다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.optim.lr_scheduler&lt;/code&gt;는 epoch에 따라 learning rate를 조절할 수 있다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Optimizer의 종류:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;optim.Adadelta, optim.Adagrad, optim.Adam, optim.SparseAdam, optim.Adamax&lt;/li&gt;
  &lt;li&gt;optim.ASGD, &lt;em&gt;optim.LBFGS&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;optim.RMSprop, optim.Rprop&lt;/li&gt;
  &lt;li&gt;optim.SGD&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;LBFGS는 per-parameter 옵션이 지원되지 않는다. 또한 memory를 다른 optimizer에 비해 많이 잡아먹는다고 한다.&lt;/p&gt;

&lt;h2 id=&quot;pytorch-lrlearning-rate-scheduler의-종류&quot;&gt;Pytorch LR(Learning Rate) Scheduler의 종류&lt;/h2&gt;

&lt;p&gt;LR(Learning Rate) Scheduler는 미리 지정한 횟수의 epoch이 지날 때마다 lr을 감소(decay)시켜준다.&lt;br /&gt;
이는 학습 초기에는 빠르게 학습을 진행시키다가 minimum 근처에 다다른 것 같으면 lr을 줄여서 더 최적점을 잘 찾아갈 수 있게 해주는 것이다.&lt;/p&gt;

&lt;p&gt;종류는 여러 개가 있는데, 마음에 드는 것을 선택하면 된다. 아래쪽에 어떻게 lr이 변화하는지 그림을 그려 놓았다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;lr Scheduler의 종류:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;optim.lr_scheduler.LambdaLR: lambda 함수를 하나 받아 그 함수의 결과를 lr로 설정한다.&lt;/li&gt;
  &lt;li&gt;optim.lr_scheduler.StepLR: 특정 step마다 lr을 gamma 비율만큼 감소시킨다.&lt;/li&gt;
  &lt;li&gt;optim.lr_scheduler.MultiStepLR: StepLR과 비슷한데 매 step마다가 아닌 지정된 epoch에만 gamma 비율로 감소시킨다.&lt;/li&gt;
  &lt;li&gt;optim.lr_scheduler.ExponentialLR: lr을 지수함수적으로 감소시킨다.&lt;/li&gt;
  &lt;li&gt;optim.lr_scheduler.CosineAnnealingLR: lr을 cosine 함수의 형태처럼 변화시킨다. lr이 커졌다가 작아졌다가 한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;optim.lr_scheduler.ReduceLROnPlateau&lt;/strong&gt;: 이 scheduler는 다른 것들과는 달리 학습이 잘 되고 있는지 아닌지에 따라 동적으로 lr을 변화시킬 수 있다. 보통 validation set의 loss를 인자로 주어서 사전에 지정한 epoch동안 loss가 줄어들지 않으면 lr을 감소시키는 방식이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;각 scheduler는 공통적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;last_epoch&lt;/code&gt; argument를 갖는다. Default value로 -1을 가지며, 이는 초기 lr을 optimizer에서 지정된 lr로 설정할 수 있도록 한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/PyTorch/2018-11-10-pytorch-usage-03-How-to-Use-PyTorch/10.PNG&quot; width=&quot;100%&quot; alt=&quot;10_Scheduler&quot; /&gt;&lt;/center&gt;

&lt;p&gt;코드는 아래와 같이 작성하였다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;re&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;random&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;scheduler_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_scheduler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ReduceLROnPlateau&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                         &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'min'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                         &lt;span class=&quot;n&quot;&gt;factor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                         &lt;span class=&quot;n&quot;&gt;patience&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 이외에도 인자가 많다. 찾아보자.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_scheduler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LambdaLR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;lr_lambda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_scheduler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StepLR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;n&quot;&gt;step_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                              &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_scheduler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MultiStepLR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                   &lt;span class=&quot;n&quot;&gt;milestones&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                                   &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_scheduler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ExponentialLR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                     &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_scheduler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CosineAnnealingLR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                         &lt;span class=&quot;n&quot;&gt;T_max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                         &lt;span class=&quot;n&quot;&gt;eta_min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;reObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'&amp;lt;torch\.optim\.lr_scheduler\.(.+) object.*&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scheduler&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scheduler_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;scheduler_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scheduler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scheduler_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;lr_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scheduler_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'ReduceLROnPlateau'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;scheduler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;scheduler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param_groups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'lr'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# print('epoch: {:3d}, lr={:.6f}'.format(epoch, lr))
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;lr_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scheduler_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# plt.savefig('scheduler')
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;조금 더 자세한 설명은 &lt;a href=&quot;https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate&quot;&gt;홈페이지&lt;/a&gt;를 참조하자.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# 1.0은 보통 너무 크다. 하지만 예시이므로 1을 주었다.
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Learning Rate가 scheduler에 따라 어떻게 변하는지 보려면 이곳을 바꾸면 된다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scheduler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_scheduler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LambdaLR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                        &lt;span class=&quot;n&quot;&gt;lr_lambda&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.95&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_group&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param_groups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'lr'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'epoch: {:3d}, lr={:.6f}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;scheduler&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;epoch:   1, lr=1.000000
epoch:   2, lr=1.000000
epoch:   3, lr=0.950000
epoch:   4, lr=0.902500
epoch:   5, lr=0.857375
epoch:   6, lr=0.814506
epoch:   7, lr=0.773781
epoch:   8, lr=0.735092
epoch:   9, lr=0.698337
epoch:  10, lr=0.663420
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;train-model&quot;&gt;Train Model&lt;/h1&gt;

&lt;p&gt;일반적인 machine learning의 학습 방법은 다음과 같다. 입력은 input, 모델의 출력은 output, 정답은 target이라고 하자.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;model structure, loss function, optimizer 등을 정한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;forward-propagation&lt;/strong&gt;: input을 모델에 통과시켜 output을 계산한다.&lt;/li&gt;
  &lt;li&gt;loss function으로 output과 target 간 &lt;strong&gt;loss&lt;/strong&gt;를 계산한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;back-propagation&lt;/strong&gt;: loss와 chain rule을 활용하여 모델의 각 레이어에서 gradient($\Delta w$)를 계산한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;update&lt;/strong&gt;: $ w \leftarrow w - \alpha\Delta w $식에 의해 모델의 parameter를 update한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Pytorch의 학습 방법은 다음과 같다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;model structure, loss function, optimizer 등을 정한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;optimizer.zero_grad()&lt;/code&gt;: 이전 epoch에서 계산되어 있는 parameter의 gradient를 0으로 초기화한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;output = model(input)&lt;/code&gt;: input을 모델에 통과시켜 output을 계산한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;loss = loss_fn(output, target)&lt;/code&gt;: output과 target 간 &lt;strong&gt;loss&lt;/strong&gt;를 계산한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;loss.backward()&lt;/code&gt;: loss와 chain rule을 활용하여 모델의 각 레이어에서 gradient($\Delta w$)를 계산한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;optimizer.step()&lt;/code&gt;: $w \leftarrow w - \alpha\Delta w$식에 의해 모델의 parameter를 update한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;거의 일대일 대응되지만 다른 점이 하나 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;optimizer.zero_grad()&lt;/code&gt;: Pytorch는 gradient를 &lt;code class=&quot;highlighter-rouge&quot;&gt;loss.backward()&lt;/code&gt;를 통해 계산하지만, 이 함수는 이전 gradient를 덮어쓴 뒤 새로 계산하는 것이 아니라, 이전 gradient에 &lt;strong&gt;&lt;em&gt;누적하여&lt;/em&gt;&lt;/strong&gt; 계산한다.
    &lt;ul&gt;
      &lt;li&gt;&lt;em&gt;귀찮은데?&lt;/em&gt; 라고 생각할 수는 있다. 그러나 이러한 누적 계산 방식은 RNN 모델을 구현할 때는 오히려 훨씬 편하게 코드를 작성할 수 있도록 도와준다.&lt;/li&gt;
      &lt;li&gt;그러니 gradient가 누적될 필요 없는 모델에서는 model에 input를 통과시키기 전 &lt;code class=&quot;highlighter-rouge&quot;&gt;optimizer.zero_grad()&lt;/code&gt;를 한번 호출해 주기만 하면 된다고 생각하면 끝이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Pytorch가 대체 어떻게 &lt;code class=&quot;highlighter-rouge&quot;&gt;loss.backward()&lt;/code&gt; 단 한번에 gradient를 자동 계산하는지에 대한 설명도 하면,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모든 Pytorch Tensor는 &lt;code class=&quot;highlighter-rouge&quot;&gt;requires_grad&lt;/code&gt; argument를 가진다. 일반적으로 생성하는 Tensor는 기본적으로 해당 argument 값이 &lt;code class=&quot;highlighter-rouge&quot;&gt;False&lt;/code&gt;이며, 따로 &lt;code class=&quot;highlighter-rouge&quot;&gt;True&lt;/code&gt;로 설정해 주면 gradient를 계산해 주어야 한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;nn.Linear&lt;/code&gt; 등의 module은 생성할 때 기본적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;requires_grad=True&lt;/code&gt;이기 때문에, 일반적으로 모델의 parameter는 gradient를 계산하게 된다.
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-02-Linear-Regression-Model/#import&quot;&gt;참고(3번 항목)&lt;/a&gt;: Pytorch 0.4.0 버전 이전에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Variable&lt;/code&gt; class가 해당 역할을 수행하였지만, deprecated되었다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;마지막 레이어만 원하는 것으로 바꿔서 그 레이어만 학습을 수행하는 형태의 transfer learning을 &lt;code class=&quot;highlighter-rouge&quot;&gt;requires_grad&lt;/code&gt;를 이용해 손쉽게 구현할 수 있다. 이외에도 특정 레이어만 gradient를 계산하지 않게 하는 데에도 쓸 수 있다. 아래 예시는 512개의 class 대신 100개의 class를 구별하고자 할 때 resnet18을 기반으로 transfer learning을 수행하는 방식이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resnet18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pretrained&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Replace the last fully-connected layer
# Parameters of newly constructed modules have requires_grad=True by default
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Optimize only the classifier
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;requires_grad=True&lt;/code&gt;인 Tensor로부터 연산을 통해 생성된 Tensor도 &lt;code class=&quot;highlighter-rouge&quot;&gt;requires_grad=True&lt;/code&gt;이다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;with torch.no_grad():&lt;/code&gt; 범위 안에서는 gradient 계산을 하지 않는다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;with torch.no_grad():&lt;/code&gt; 안에서 선언된 &lt;code class=&quot;highlighter-rouge&quot;&gt;with torch.enable_grad():&lt;/code&gt; 범위 안에서는 다시 gradient 계산을 한다. 이 두 가지 기능을 통해 국지적으로 gradient 계산을 수행하거나 수행하지 않을 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x.requires_grad:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'y.requires_grad:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;172&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z.requires_grad:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z.requires_grad:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enable_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z.requires_grad:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z.grad_fn:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;y:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;z:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'y.grad:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'z.grad:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x.requires_grad: False
y.requires_grad: True
z.requires_grad: True
z.requires_grad: False
z.requires_grad: True
z.grad_fn: &amp;lt;AddBackward0 object at 0x0000028634614780&amp;gt;
x: tensor([1.4013e-45]) 
y: tensor([1.], requires_grad=True) 
z: tensor([175.], grad_fn=&amp;lt;AddBackward0&amp;gt;)
y.grad: tensor([172.])
z.grad: None
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;튜토리얼이 조금 더 궁금하다면 &lt;a href=&quot;https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html&quot;&gt;여기&lt;/a&gt;를 참고해도 좋다.&lt;/p&gt;

&lt;p&gt;학습할 때 알아두면 괜찮은 것들을 대략 정리해보았다. 어떤 식으로 학습하는 것이 좋은지(learning rate 선택 기준 등)는 양이 너무 방대하기에 여기에는 적지 않는다.&lt;/p&gt;

&lt;h2 id=&quot;cuda-use-gpu&quot;&gt;CUDA: use GPU&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/cuda.html&quot;&gt;CUDA&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.cuda.is_available()&lt;/code&gt;: 학습을 시킬 때는 GPU를 많이 사용한다. GPU가 사용가능한지 알 수 있다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.cuda.device(device)&lt;/code&gt;: 어느 device(GPU나 CPU)를 쓸 지 선택한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.cuda.device_count()&lt;/code&gt;: 현재 선택된 device의 수를 반환한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.cuda.init()&lt;/code&gt;: C API를 쓰는 경우 명시적으로 호출해야 한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.cuda.set_device(device)&lt;/code&gt;: 현재 device를 설정한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.cuda.manual_seed(seed)&lt;/code&gt;: 랜덤 숫자를 생성할 시드를 정한다. multi-gpu 환경에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;manual_seed_all&lt;/code&gt; 함수를 사용한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;torch.cuda.empty_cache()&lt;/code&gt;: 사용되지 않는 cache를 release하나, 가용 메모리를 늘려 주지는 않는다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;간단한 학습 과정은 다음 구조를 따른다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 변수명으로 input을 사용하는 것은 비추천. python 내장 함수 이름이다.
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# RNN에서는 생략될 수 있음
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;visualize-and-save-results&quot;&gt;Visualize and save results&lt;/h1&gt;

&lt;h2 id=&quot;visualization-library&quot;&gt;Visualization Library&lt;/h2&gt;

&lt;p&gt;Visualization은 이 글에서 설명하지 않겠다. 기본적으로 python의 그래프 패키지인 &lt;code class=&quot;highlighter-rouge&quot;&gt;matplotlib&lt;/code&gt;을 많이 쓰며, &lt;code class=&quot;highlighter-rouge&quot;&gt;graphviz&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;seaborn&lt;/code&gt; 등의 다른 라이브러리도 잘 보이는 편이다.&lt;/p&gt;

&lt;h2 id=&quot;save--load-model&quot;&gt;Save &amp;amp; Load Model&lt;/h2&gt;

&lt;p&gt;모델을 저장하는 방법은 여러 가지가 있지만, pytorch를 사용할 때는 다음 방법이 가장 권장된다. 아주 유연하고 또 간단하기 때문이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Save&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Load&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TheModelClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# model.eval() # 테스트 시
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 참고로 model.load_state_dict(PATH)와 같이 쓸 수는 없다.
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;epoch별로 checkpoint를 쓰면서 저장할 때는 다음과 같이 혹은 비슷하게 쓰면 좋다. checkpoint를 쓸 때는 단순히 모델의 parameter뿐만 아니라 epoch, loss, optimizer 등을 저장할 필요가 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Save&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;'epoch'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;'model_state_dict'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;'optimizer_state_dict'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;'loss'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Load&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TheModelClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TheOptimizerClass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;checkpoint&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;checkpoint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'model_state_dict'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;checkpoint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'optimizer_state_dict'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;checkpoint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'epoch'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;checkpoint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'loss'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# model.train() or model.eval()
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;일반적으로 저장한 모델 파일명은 &lt;code class=&quot;highlighter-rouge&quot;&gt;.pt&lt;/code&gt;나 &lt;code class=&quot;highlighter-rouge&quot;&gt;.pth&lt;/code&gt; 확장자를 쓴다. 모델을 포함하여 여러 가지를 같이 저장할 때는 &lt;code class=&quot;highlighter-rouge&quot;&gt;.tar&lt;/code&gt; 확장자를 자주 쓰는 편이다.&lt;/p&gt;

&lt;p&gt;모델을 불러오고 나서 계속 학습시킬 것이라면 &lt;code class=&quot;highlighter-rouge&quot;&gt;model.train()&lt;/code&gt;, 테스트를 할 것이라면 &lt;code class=&quot;highlighter-rouge&quot;&gt;model.eval()&lt;/code&gt;으로 모드를 설정하도록 한다. 이유는 이 글에 설명이 있다.&lt;/p&gt;

&lt;p&gt;모델이 여러 개라면&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;'modelA_state_dict'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;modelA&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;'modelB_state_dict'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;modelB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;처럼 쓰면 그만이다.&lt;/p&gt;

&lt;p&gt;구조가 조금 다른 모델에다가 parameter를 load하고 싶을 경우 load할 때 다음처럼 쓴다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;load_state_dict&lt;/code&gt; 함수는 기본적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;strict=True&lt;/code&gt; 옵션을 갖고 있으며, 이는 불러올 모델과 저장된 모델의 레이어의 개수와 이름 등이 &lt;em&gt;같아야만&lt;/em&gt; 오류 없이 불러온다.&lt;/p&gt;

&lt;p&gt;따라서 transfer learning이나, 복잡한 모델을 새로 학습시키고 싶을 때 모델의 일부라도 parameter를 불러오고 싶다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;strict=False&lt;/code&gt; argument를 설정하면 된다.&lt;br /&gt;
이는 레이어들이 정확히 일치하지 않아도 매칭이 되는 레이어가 일부라도 있다면 그 레이어들에 한해서 parameter를 load한다.&lt;br /&gt;
또 parameter 개수는 같지만 이름은 다른 레이어에 parameter를 불러오고 싶을 때는, &lt;code class=&quot;highlighter-rouge&quot;&gt;state_dict&lt;/code&gt;는 딕셔너리이기 때문에 그냥 해당 딕셔너리의 이름만 바꿔서 load하면 그만이다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pickle&lt;/code&gt; 또는 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.save&lt;/code&gt;를 통해 model 전체를 통째로 저장하는 방법은 간편하기는 하지만 이후 불러올 때는 해당 모델과 완전히 똑같이 생긴 모델에만 사용 가능하기 때문에 확장성과 재사용성이 떨어진다.&lt;br /&gt;
layer 이름과 parameter를 mapping하여 저장하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;state_dict&lt;/code&gt;를 쓰는 것이 transfer learinng을 쉽게 할 수 있는 등 범용성이 더 좋다.&lt;/p&gt;

&lt;p&gt;device를 바꿔서 저장하고 싶다면, &lt;code class=&quot;highlighter-rouge&quot;&gt;load_state_dict&lt;/code&gt;에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;map_location&lt;/code&gt; argument를 설정하거나, &lt;code class=&quot;highlighter-rouge&quot;&gt;model.to(device)&lt;/code&gt; 함수를 사용하면 된다. 자세한 것은 &lt;a href=&quot;https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-across-devices&quot;&gt;홈페이지&lt;/a&gt;를 참조한다. GPU를 사용할 때 바꿔줘야 하는 부분은 &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/#nnmodule-%EB%82%B4%EC%9E%A5-%ED%95%A8%EC%88%98&quot;&gt;여기&lt;/a&gt;의 cuda 부분을 참고한다.&lt;/p&gt;

&lt;h3 id=&quot;torchsave--torchload&quot;&gt;torch.save &amp;amp; torch.load&lt;/h3&gt;

&lt;p&gt;내부적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;pickle&lt;/code&gt;을 사용하며, 따라서 모델뿐 아니라 일반 tensor, 기타 다른 모든 python 객체를 저장할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;nnmodulestate_dict--nnmoduleload_state_dict&quot;&gt;nn.Module.state_dict &amp;amp; nn.Module.load_state_dict&lt;/h3&gt;

&lt;p&gt;우선 &lt;code class=&quot;highlighter-rouge&quot;&gt;state_dict&lt;/code&gt;는 간단히 말해 모델의 상태를 딕셔너리 형태로 표현하는 것이다. 그러면 모델의 상태는 어떻게 정의되는가?&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;state_dict&lt;/code&gt;로 저장되는 모델의 상태는 learnable parameters이며, &lt;code class=&quot;highlighter-rouge&quot;&gt;state_dict&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;{레이어 이름: parameter tensor}&lt;/code&gt;의 형태를 갖는 딕셔너리이다.&lt;br /&gt;
딱 그뿐이다. 간단하지 않은가?&lt;/p&gt;

&lt;p&gt;Optimizer도 &lt;code class=&quot;highlighter-rouge&quot;&gt;state_dict&lt;/code&gt;를 갖고 있는데, 이 경우는 사용된 hyperparameter 등의 상태가 저장된다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pytorch.org/tutorials/beginner/saving_loading_models.html&quot;&gt;공식 홈페이지&lt;/a&gt;의 예시를 일부 가져오면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 모델이 이렇게 생겼으면, 
&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;120&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 이 코드에 의해
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param_tensor&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 이렇게 출력된다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;       &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;       &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;       &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;120&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;         &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;120&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# optimizer는
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var_name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 이렇다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;param_groups&lt;/span&gt;     &lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'lr'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'momentum'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'dampening'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'weight_decay'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;s&quot;&gt;'nesterov'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'params'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4675713712&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4675713784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4675714720&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]}]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;q--a&quot;&gt;Q &amp;amp; A&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;model.train()&lt;/code&gt;과 &lt;code class=&quot;highlighter-rouge&quot;&gt;model.eval()&lt;/code&gt;은 모델이 학습 모드인지, 테스트 모드인지를 정하는 것이다. 이는 dropout이나 batchnorm이 있는 모델의 경우 학습할 때와 테스트할 때 모델이 달라지기 때문에 세팅하는 것이다(또한 필수이다). &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.no_grad()&lt;/code&gt;는 (대개 일시적으로) 해당 범위 안에서 gradient 계산을 중지시킴으로써 메모리 사용량을 줄이고 계산 속도를 빨리 하는 것이다. &lt;a href=&quot;https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615&quot;&gt;참고&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;optimizer.zero_grad()&lt;/code&gt;를 사용하는 이유. &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/#train-model&quot;&gt;참고&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Pytorch 코드들 중에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.autograd.Variable&lt;/code&gt;을 사용한 경우가 많다. Pytorch 0.4.0 버전 이후로는 Tensor 클래스에 통합되어 더 이상 쓸 필요가 없다. &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-02-Linear-Regression-Model/#import&quot;&gt;참고(3번 항목)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;역시 Pytorch 코드들 중에는 loss를 tensor가 아닌 그 값을 가져올 때 &lt;code class=&quot;highlighter-rouge&quot;&gt;loss.data[0]&lt;/code&gt; 등의 표현식은 에러를 뱉는 경우가 많다. 이는 0.4 이후 버전의 PyTorch에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;loss.item()&lt;/code&gt;으로 그 값을 가져오도록 변경되었기 때문이다.
    &lt;ul&gt;
      &lt;li&gt;Pytorch의 loss는 이전에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;Variable&lt;/code&gt;에 할당된 &lt;code class=&quot;highlighter-rouge&quot;&gt;size=(1, )&lt;/code&gt;의 tensor였지만 이제는 scalar 형태이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;댓글로 문의하시면 확인 후 포스팅에 추가 가능합니다.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Bootstrap, Bagging, Boosting</title>
   <link href="http://localhost:4000/TripleB/"/>
   <updated>2018-11-06T00:00:00+09:00</updated>
   <id>http://localhost:4000/TripleB</id>
   <content type="html">&lt;h2 id=&quot;bootstrap-부트스트랩의-개념&quot;&gt;Bootstrap: 부트스트랩의 개념&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;통계학에서의 부트스트랩과 기계학습에서의 부트스트랩은 그 의미가 다른 점도 있지만 본질적으로는 같다고 할 수 있다. 통계학적으로는 정확한 분포를 모르는 데이터의 통계치의 분포를 알아내기 위하여 Random Sampling을 하는 경우를 말하며, 종종 측정된 샘플이 부족한 경우에도 사용된다.&lt;br /&gt;
기계학습에서는 기본적으로 Random Sampling을 통해 데이터의 수를 늘리는 것을 말한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;decision-tree-의사-결정-나무&quot;&gt;Decision Tree: 의사 결정 나무&lt;/h2&gt;
&lt;p&gt;내용을 입력합시당&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;bagging-배깅&quot;&gt;Bagging: 배깅&lt;/h2&gt;
&lt;p&gt;Bagging은 Bootstrap Aggregatint의 줄임말이다. 특별히 부트스트랩이 over-fitting을 줄이는 데에 사용될 때를 말한다. 주어진 데이터에 대해 여러 번의 Random Sampling을 통해 Training Data를 추출하고 (여러 개의 부트스트랩을 생성), 독립된 모델로서 각각의 자료를 학습시키고 이를 앙상블로서 결합하여 최종적으로 하나의 예측 모형을 산출하는 방법이라고 할 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2018-11-06-TripleB/01.jpg&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;예를 들어 단일 Decision Tree는 변동성이 매우 크다. 이러한 단일 Decision Tree를 여러 개 결합하여 모델을 형성한다면 과적합을 방지할 수도 있고 안정된 결과를 산출할 수 있을 것이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2018-11-06-TripleB/02.jpg&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;대표적인 예가 Random Forest이며, Sample의 예측변수들의 결합 시 Target Variable이 연속형일 때는 평균을, 범주형일 때는 다중 투표를 사용한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;boosting-부스팅&quot;&gt;Boosting: 부스팅&lt;/h2&gt;
&lt;p&gt;배깅이 독립적으로 모델을 학습시킨다면, 부스팅은 이전의 잘못을 파악하고 이를 이용하여 다음 번에는 더 나은 모델을 만들어 내자는 목표를 추구하면서 학습하는 방법이다. 분류 문제로 예를 들면, 잘못 분류된 개체들을 다음 번에는 더 잘 분류하고 싶은 것이 당연하다. 부스팅은 잘못 본류된 개체들에 집중하여 새로운 분류 규칙을 만드는 것을 반복하는 방법이며, 이는 결국 약한 예측모형들을 결합하여 강한 예측모형을 만드는 과정으로 서술할 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2018-11-06-TripleB/03.jpg&quot; width=&quot;20%&quot; /&gt;&lt;/center&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;xgboost-이론&quot;&gt;XGBoost 이론&lt;/h2&gt;
&lt;p&gt;XGBoost는 Extreme Gradient Boosting의 줄임말로, 2014년에 등장하여 이후 지금까지 널리 쓰이고 있는 강력한 기계학습 알고리즘이다.&lt;br /&gt;
본 글에서는 XGBoost의 창시자인 Tianqi Chen과 Carlos Guestrin이 2016년 publish한&lt;br /&gt;
[XGBoost: A Scalable Tree Boosting System] 논문과 Chen의 관련 강연을 기초로 하여&lt;br /&gt;
알고리즘에 대해 설명하도록 하겠다.&lt;/p&gt;

&lt;p&gt;알고리즘에 대한 설명이 끝난 이후에는 XGBoost Python의 메서드와 패키지의 주요 기능에 대해 알아본 뒤, Hyperparameter들을 튜닝하는 법에 대해 설명할 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;XGBoost의 강점&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Regularization: 복잡한 모델에 대하여 페널티를 주는 Regularization 항이 있기 때문에 과적합을 방지할 수 있다.&lt;/li&gt;
  &lt;li&gt;Handling Sparse Data: XGB는 원핫인코딩이나 결측값 등에 의해 발생한 Sparse Data(0이 많은 데이터) 또한 무리 없이 다룰 수 있다.&lt;/li&gt;
  &lt;li&gt;Weighted Quantile Sketch: 가중치가 부여된 데이터 또한 Weighted Percentile Sketch 알고리즘을 통해 다룰 수 있다.&lt;/li&gt;
  &lt;li&gt;Block Structure for parallel learning: 데이터는 정렬되어 in-memory units (blocks)에 저장된다. 이 데이터는 이후에 계속 반복적으로 재사용이 가능하기 때문에 다시 계산할 필요가 없다. 이를 통해 빠르게 Split Point를 찾아낼 수 있고 Column Sub-sampling을 진행할 수 있다.&lt;/li&gt;
  &lt;li&gt;Cache Awarness: 하드웨어를 최적으로 사용하도록 고안되었다.&lt;/li&gt;
  &lt;li&gt;Out-of-core computing: 거대한 데이터를 다룰 때 디스크 공간을 최적화하고 사용 가능 범위를 최대화한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;[1] Regularized Learning Objective&lt;/strong&gt;&lt;br /&gt;
n개의 example과 m개의 feature(변수)로 이루어진 데이터셋이 있다고 할 때,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;D = {(x_i, y_i)} (|D| = n, x_i \in \mathbb{R^m}, y_i \in \mathbb{R})&lt;/script&gt;

&lt;p&gt;앙상블 모델은 output을 예측하기 위해 K개의 additive functions(가법 함수)를 이용한다. 
즉, f(x)는 q(x)라는 Tree 구조의 weight을 의미하는데,&lt;/p&gt;

&lt;p&gt;$ \vec{x_i} $라는 i번째 데이터가 Input으로 들어왔을 때, 각각의 Tree가 Decision Rule을 통해 산출한 &lt;strong&gt;score = output = $ f_k(x_i) $&lt;/strong&gt; 을 모두 더한 값을 아래의 식과 같이 &lt;strong&gt;최종 output = $ \hat{y_i} $&lt;/strong&gt; 으로 출력하게 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{y_i} = \phi(\vec{x_i}) = \sum_{k=1}^K f_k(\vec{x_i}), f_k \in \mathbb{F}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{F} = \{ f(\vec{x}) = w_{q(x)} \} (q:\mathbb{R} \rightarrow T, w \in \mathbb{R}^T)&lt;/script&gt;

&lt;p&gt;여기서 K는 Tree의 개수를, T는 Tree 안에 있는 leaf의 개수를, w는 leaf weights를, $ w_i $는 i번째 leaf의 score를 의미한다.&lt;br /&gt;
q는 example을 leaf index에 매핑하는 Tree 구조를 말하는데 이 안에는 물론 Tree 내부의 수많은 Decision Rule을 포함한다.&lt;br /&gt;
F는 모든 Regression Trees를 포함하는 space of functions를 의미하며,&lt;br /&gt;
여기서 Classification and Regression Trees의 경우 CART라고도 한다.&lt;/p&gt;

&lt;p&gt;이러한 함수들을 학습하기 위해서는 다음과 같은 &lt;strong&gt;Objective Function&lt;/strong&gt;을 상정할 필요가 있다.&lt;br /&gt;
아래의 Regularized Objective는 예측 값과 실제 값 사이의 차이와 Regularized Term으로 구성된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\phi) = \sum_{i}^{n} l(\hat{y_i}, y_i) + \sum_{k=1}^{K} \Omega(f_k)&lt;/script&gt;

&lt;p&gt;여기서 $ \Omega(f) = \gamma T + \frac{1}{2} \lambda \Vert{w}\Vert^2  $&lt;/p&gt;

&lt;p&gt;물론 위의 $ l $은 미분 가능한 convex loss function이 될 것이며,&lt;br /&gt;
간단한 예로는 Square Loss나 Log Loss를 생각할 수 있을 것이다.&lt;/p&gt;

&lt;p&gt;오른쪽 부분인 $ \Omega $의 역할은 모델이 너무 복잡해지는 것을 막는 페널티 항이다.&lt;br /&gt;
이 항은 과적합을 방지하기 위해 final learnt weights을 부드럽게 만들어줄 것이다.
(&lt;strong&gt;Smoothing&lt;/strong&gt;)&lt;/p&gt;

&lt;p&gt;항을 자세히 보면, Tree 개수가 너무 많아지거나 leaf weights의 L2 norm이 너무 커지면 전체 Loss를 증가시키는 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[2] Gradient Tree Boosting&lt;/strong&gt;&lt;br /&gt;
위에서 본 전체 Loss는 각각의 Tree 구조 자체( f(x) )를 포함하고 있기 때문에 최적화하기가 까다롭다. 따라서 아래의 방법으로 최적화 과정에 논의해볼 것이다.&lt;/p&gt;

&lt;p&gt;일단 $ \hat{y_i}^{(t)} $를 t번 째 iteration(t번 째 Tree)에서의 i번 째 Instance(실제 개체)의 예측 값이라고 해보자,&lt;/p&gt;

&lt;p&gt;이 값은 아래의 과정에 의해 표현될 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\hat{y_i}^{(0)} = 0&lt;/script&gt;&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\hat{y_i}^{(1)} = f_1(x_i) + \hat{y_i}^{(0)}&lt;/script&gt;&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;...&lt;/script&gt;&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\hat{y_i}^{(t)} = \sum_{k=1}^{t} f_k(x_i)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;따라서 전체 Loss를 아래와 같이 표현할 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L^{(t)} = \sum_{i=1}^{n} l({y_i}, \hat{y_i}^{(t-1)} + f_t(\vec{x_i})) + \Omega(f_t)&lt;/script&gt;

&lt;p&gt;이 단계에서 위의 $ l $ 부분을 2차항까지 사용한 테일러 전개에 의해 근사적으로 구하면, 다시 아래와 같이 표현할 수 있다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2018-11-06-TripleB/04.jpg&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;예를 들어 $ l $을 Square Loss로 사용하였다면, 아래와 같은 전개가 가능할 것이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2018-11-06-TripleB/06.jpg&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;일반화된 식으로 다시 보면 상수항을 제거하고 남은 step t에서의 근사한 전체 Loss는 아래와 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2018-11-06-TripleB/05.jpg&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;blockquote&gt;
  &lt;p&gt;여기서 잠시 $ I_j = {i|q(\vec{x_i} = j)} $를&lt;br /&gt;
instance set of leaf j (leaf j의 할당 결과물)이라고 정의하겠다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;위의 식에서 정규화 항을 확장하여 정리해보면,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{L}^{(t)} = \sum_{i=1}^{n} [g_i f_i(\vec{x_i}) + \frac{1}{2}h_i f_t^2(\vec{x_i})] + \gamma T + \frac{1}{2} \sum_{j=1}^{T} w_j^2&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= \sum_{i=1}^{n} [g_i w_q(\vec{x_i}) + \frac{1}{2}h_i w_q^2(\vec{x_i})] + \gamma T + \frac{1}{2} \sum_{j=1}^{T} w_j^2&lt;/script&gt;

&lt;p&gt;example 단위에서 leaf 단위로 식을 재표현해주면,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;= \sum_{j=1}^{T} [ (\sum_{i \in I_j} g_i)w_j + \frac{1}{2} (\sum_{i \in I_j} h_i + \lambda) w_j^2 ] + \gamma T&lt;/script&gt;

&lt;p&gt;식을 보기 좋게 표현하기 위해 아래와 같은 정의를 사용하겠다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;G_j = \sum_{i \in I_j} g_i, H_j = \sum_{i \in I_j} h_i&lt;/script&gt;

&lt;p&gt;고정된 $ q(\vec{x}) $에 대하여 위의 식 = 0으로 놓고 계산하면,&lt;br /&gt;
leaf j의 최적 weight을 계산할 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_j^* = - \frac{G_j} {H_j + \lambda}&lt;/script&gt;

&lt;p&gt;이 때의 전체 Loss는 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{L}^{(t)}(q) = - \frac{1}{2} \sum_{j=1}^{T} \frac{G_{j}^2} {H_j + \lambda} + \gamma T&lt;/script&gt;

&lt;p&gt;정리하자면, 위의 식은 사실상 q라는 Tree 구조의 성능(quality)을 측정하는 Scoring Function의 역할을 수행하게 된다. 이 Score는 Decision Tree에서의 불순도와 같은 역할을 한다.&lt;/p&gt;

&lt;p&gt;그런데 다만 여기서 생각해야 할 점은, 발생가능한 수많은 Tree의 구조를 일일히 다 평가할 수는 없다는 것이다. 이를 위해 &lt;strong&gt;Greedy 알고리즘&lt;/strong&gt;이 사용되는데, 이 알고리즘은 단일 Leaf에서 시작하여 가지를 반복적으로 확장해 나가는 방법을 말한다.&lt;/p&gt;

&lt;p&gt;$ I_L, I_R $을 각각 split 이후의 좌측, 우측 노드의 Instance Sets라고 할 때,&lt;br /&gt;
&lt;strong&gt;Gain&lt;/strong&gt; 혹은 &lt;strong&gt;Loss reduction&lt;/strong&gt;이라고 불리는 아래의 식은,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Gain = L_{split} = \frac{1}{2} [ \frac{G_{L}^2} {H_L + \lambda} + \frac{G_{R}^2} {H_R + \lambda} - \frac{ (G_{L} + G_{R})^2 } {H_L + H_R + \lambda} ] - \gamma&lt;/script&gt;

&lt;p&gt;Left Child의 스코어 + Right Child의 스코어 - Split 안했을 때의 스코어 - Complexity cost by introducing additional leaf로 표현된다.&lt;/p&gt;

&lt;p&gt;이는, split을 했을 때의 이득 (loss reduction)이 $ \gamma $로 표현되는 어떤 상수보다 작으면, split을 하지 말라는 뜻이다.&lt;br /&gt;
즉, &lt;strong&gt;Training Loss Reduction &amp;lt; Regularization Constant&lt;/strong&gt;라면 split을 중지하게 되며,&lt;br /&gt;
이는 &lt;strong&gt;Pruning&lt;/strong&gt; 시스템이라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pruning&lt;/strong&gt;에는 2가지 방법이 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Pre-Stopping: Best Split이 음수 Gain을 가지면 Stop한다. 다만 Future Split에서의 이득을 고려하지 못하므로 주의가 요구된다.&lt;/li&gt;
  &lt;li&gt;Post-Pruning: Max_depth까지 확자한 후에 Negative Gain을 가진 Split 모두를 가지치기 한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;[3] Efficient Findings of the Best Split&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Exact Greedy Algorithm&lt;/strong&gt;에서는 데이터를 Feature Value에 따라 정렬한 후 이와 같은 Gain을 반복적으로 계산하여 가장 높은 Gain을 바탕으로 Split을 결정하게 된다.&lt;br /&gt;
(In order to do so efficiently, the algorithm must first sort the data according to feature values and visit the data in sorted order to accumulate the gradient statistics for the structure score)&lt;br /&gt;
(자세한 내용은 논문을 참고할 것)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Approximate Algorithm&lt;/strong&gt;에서는 적절한 Split 후보들을 선정한 후 그 중에서만 찾게 된다.&lt;/p&gt;

&lt;p&gt;직관적으로는 다음과 같은 과정을 거친다고 말할 수 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Split할 양 쪽의 g, h의 합을 계산하는 것&lt;/li&gt;
  &lt;li&gt;정렬된 Instances(개체)를 left -&amp;gt; right 방향으로 스캔하면 feature 속에서 best split을 결정하기에 충분하다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;[3] Shrinkage and Colums Subsampling&lt;/strong&gt;&lt;br /&gt;
위에서 설명된 정규화 과정 외에도 추가적으로 과적합을 막기 위한 방법이 도입된다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Shrinkage&lt;/strong&gt;는 Tree Boosting의 각 단계를 실행한 이후 $ \eta $라는 factor를 도입하여 새로 추가된 weight을 스케일링해주는 기법이다. tochastic optimization과 유사한 방법인데, shrinkage는 모델을 향상시키기 위해 각각의 개별 Tree와 미래의 Tree의 leaves space의 영향력을 감소시킨다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Column(Feature) Subsampling&lt;/strong&gt;은 Random Forest에서도 사용된 기법이다. 이 기법은 전통적인 Row- subsampling에 비해 더욱 효과적이고 빠르다고 알려져 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[4] Weighted Quantile Sketch&lt;/strong&gt;&lt;br /&gt;
위에서 언급하였듯이 근사 알고리즘에서는 후보 Split을 제안하는데, 보통 이 때 feature의 percentil은 후보들이 데이터 상에서 고르게 분포하도록 만든다.&lt;br /&gt;
그런데 XGBoost는 가중치가 부여된 데이터에 대해서도 효과적인 Handling이 가능하다.&lt;br /&gt;
(Weighted quantile sketch algorithm can handle weighted data with a provable theoretical guarantee)&lt;/p&gt;

&lt;p&gt;논문의 4페이지를 살펴보면, Rank Function과 전체 Loss 식의 재표현을 통해서 위의 설명을 간단히 증명하고 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[5] Sparsity-aware Split Finding&lt;/strong&gt;&lt;br /&gt;
현실에서 데이터를 다룰 때 직면하게 되는 가장 큰 문제는 input인 $ \vec{x} $가 매우 sparse하다는 것이다. 이 현상에는 대표적으로 3가지 원인이 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;결측값&lt;/li&gt;
  &lt;li&gt;통계학에서의 빈번한 zero entries&lt;/li&gt;
  &lt;li&gt;원 핫 인코딩&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;XGB는 내재적으로 이러한 현상을 효과적으로 Handling할 수 있다.&lt;br /&gt;
왜냐하면 데이터를 통해 Optimal Default Direction이 학습되기 때문이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[6] System Design&lt;/strong&gt;&lt;br /&gt;
글의 서두에서 언급하였는데, 하드웨어 측면에서도 XGB는 우수한 성능을 보인다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Block Structure for parallel learning: 데이터는 정렬되어 in-memory units (blocks)에 저장된다. 이 데이터는 이후에 계속 반복적으로 재사용이 가능하기 때문에 다시 계산할 필요가 없다. 이를 통해 빠르게 Split Point를 찾아낼 수 있고 Column Sub-sampling을 진행할 수 있다.&lt;/li&gt;
  &lt;li&gt;Cache Awarness: 하드웨어를 최적으로 사용하도록 고안되었다.&lt;/li&gt;
  &lt;li&gt;Out-of-core computing: 거대한 데이터를 다룰 때 디스크 공간을 최적화하고 사용 가능 범위를 최대화한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;XGB는 또한 Early Stopping 기능도 갖고 있다.&lt;br /&gt;
XGb는 참고로 Feature Engineering이나 Hyper Parameter 자동 튜닝 등의 기능은 갖고 있지 못하다.&lt;/p&gt;

&lt;p&gt;이로써 XGBoost의 이론적 배경에 대해 살펴보았다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;xgboost-패키지-methods&quot;&gt;XGBoost 패키지 Methods&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;지금부터는 XGBoost Python을 효과적을 Implement하는 방법에 대해 설명한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;xgboost-parameter-tuning&quot;&gt;XGBoost Parameter Tuning&lt;/h2&gt;
&lt;p&gt;파라미터 튜닝의 세부사항을 설명하기 전에, 가장 전반적인 2가지 사항에 대해 설명한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Control Overfitting&lt;br /&gt;
일차적으로는 모델 Complexity를 직접적으로 조절할 수 있는데, 이는 max_depth, min_child_weight, gamma 파라미터 조정에 해당한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이후에 학습 과정을 Noise에 Robust하게 만들기 위해 Randomness를 추가하는 방법이 있는데, 이는 subsample, colsample_bytree 파라미터 조정에 해당한다.&lt;br /&gt;
또는 stepsize eta를 줄일 수도 있는데, 이 때는 num_round를 늘려야만 한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;link: [https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;Handle Imbalanced Dataset&lt;br /&gt;
불균형 데이터를 효과적으로 다루기 위해서는 scale_pos_weight 파라미터 조정을 통해 positive &amp;amp; negative weights를 균형적으로 맞출 수 있다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;만약 오직 right probability를 예측하는 것에만 관심이 있다면,&lt;br /&gt;
Dataset을 균형적으로 맞추기 힘드므로, max_delta_step 파라미터를 1과 같은 유한 실수로 세팅하면 효과적인 convergence(수렴)을 가능하게 할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;XGBoost Parameters&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;XGB 파라미터는 크게 3가지로 구분된다.&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;General, Booster, Task paramers&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;General Parameters&lt;/strong&gt;는 부스팅을 위해 어떤 부스터를 쓰는지와 관련이 있다.&lt;br /&gt;
&lt;strong&gt;Booster Parameters&lt;/strong&gt;는 선택한 Booster에 의존한다.&lt;br /&gt;
&lt;strong&gt;Task Paramters&lt;/strong&gt;는 학습 시나리오를 결정한다. 예를 들어, Regression tasks는 ranking tasks와 관련하여 다른 파라미터를 사용할 수 있다.&lt;/p&gt;

&lt;p&gt;참고로 R에서는 _대신 .를 사용하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. General Parameters&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;booster [default=gbtree]&lt;/strong&gt;&lt;br /&gt;
gbtree(기본값), gblinear(선형), dart(tee based model 사용)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;silent [default=0]&lt;/strong&gt;&lt;br /&gt;
0은 학습 과정을 출력해라, 1은 출력하지 마라.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;nthread [default=최대치]&lt;/strong&gt;&lt;br /&gt;
XGB를 돌리기 위해 사용될 병렬 스레드의 개수&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;disable_default_eval_metric [default=0]&lt;/strong&gt;&lt;br /&gt;
flag to disable default metric. Set to &amp;gt;0 to disable&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;num_pbuffer, num_feature는 자동적으로 설정됨&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;2. Booster Parameters&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;eta [default=0.3, alias=learning_rate]&lt;/strong&gt;&lt;br /&gt;
과적합을 방지하기 위해 업데이트 과정에서 사용되는 shrinkage의 step size이다. 각 부스팅 단계이후 우리는 새로운 features에 대한 weights를 얻을 수 있는데, eta는 부스팅 과정을 더욱 보수적으로 만들기 위해 feature weights를 축소한다. 결론적으로 과적합을 방지하는 파라미터다!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;gamma [default=0, alias=min_split_loss]&lt;/strong&gt;&lt;br /&gt;
Tree의 leaf split을 진행하기 위해 필요한 최소 Loss Reduction을 뜻한다.&lt;br /&gt;
gamma가 커질수록, 알고리즘은 더욱 보수적으로 만들어질 것이다.&lt;br /&gt;
min_loss_reduction이라는 다른 이름을 생각해볼 때, 이 파라미터는 아래의 식에서 $ \gamma $를 뜻한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Gain = L_{split} = \frac{1}{2} [ \frac{G_{L}^2} {H_L + \lambda} + \frac{G_{R}^2} {H_R + \lambda} - \frac{ (G_{L} + G_{R})^2 } {H_L + H_R + \lambda} ] - \gamma&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;max_depth [default=6]&lt;/strong&gt;&lt;br /&gt;
Tree구조의 최대 깊이이다. 0을 입력하면 한계치를 설정하지 않음을 뜻한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;min_child_weight [default=1]&lt;/strong&gt;&lt;br /&gt;
Child Node에 필요한 Instance weight(hessian)의 최소합.&lt;br /&gt;
만약 Tree의 Split 과정이 진행되면서 instance weight의 합이 min_child_weight보다 작은 leaf node가 나타난다면, Tree는 계속해서 Split을 진행하도록 설정하는 것이다.&lt;br /&gt;
결론적으로 min_child_weight가 커질수록, 알고리즘은 더욱 보수적으로 변화한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;max_delta_step [default=0]&lt;/strong&gt;&lt;br /&gt;
Maximum delta step we allow each leaf output to be.&lt;br /&gt;
디폴트로 설정된 0은 제한이 없음을 뜻한다.&lt;br /&gt;
양수로 설정이 되면, update step을 더욱 보수적으로 만들어준다.&lt;br /&gt;
일반적으로 이 파라미터는 불필요한데, Logistic Regression에서 데이터셋이 심각하게 불균형한 경우 [1-10]에 해당하는 값을 설정한다면 도움이 될 수도 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;subsample [default=1]&lt;/strong&gt;&lt;br /&gt;
Training Instances의 Subsample 비율을 말한다.&lt;br /&gt;
예를 들어 0.5로 설정될 경우, XGB가 학습 데이터의 절반을 랜덤하게 샘플링한다는 것을 뜻한다. Dropout과 유사한 측면이 있다.&lt;br /&gt;
수치가 작아질 수록 과적합을 방지하지만 학습이 더뎌질 수 있다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;colsample_bytree [default=1]&lt;/strong&gt;&lt;br /&gt;
Subsample ratio of columns when constructing each tree.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;colsample_bylevel [default=1]&lt;/strong&gt;&lt;br /&gt;
Subsample ratio of columns for each split, in each level.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;lambda [default=1, alias:reg_lambda]&lt;/strong&gt;&lt;br /&gt;
Weight에 대한 L2 정규화항. 커질수록 모델을 보수적으로 만든다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\phi) = \sum_{i}^{n} l(\hat{y_i}, y_i) + \sum_{k=1}^{K} \Omega(f_k) \leftarrow  \Omega(f) = \gamma T + \frac{1}{2} \lambda \Vert{w}\Vert^2&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;alpha [default=0, alias: reg_alpha]&lt;/strong&gt;&lt;br /&gt;
Weight에 대한 L1 정규화항.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;tree_method [defaul=auto]&lt;/strong&gt;&lt;br /&gt;
Tree 구성 구조 방법을 말한다. 단, Distributed and external memory 버전은 오직 approx만 지원한다.&lt;br /&gt;
auto외에는 exact(Exact Greedy 알고리즘), approx(Approximate Greedy 알고리즘), hist(Fast Histo Optimized Approxmate Greedy 알고리즘), gpu_exact, gpu_hist 등이 있다.&lt;br /&gt;
auto로 두면 적당한 크기의 데이터셋에 대해서는 exact를 선택하고, 데이터셋이 매우 커지면 approx를 자동으로 선택한다.&lt;br /&gt;
이 방법들에 대한 간략한 설명은 위 논문 리뷰에서 다루었다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;scale_pos_weight [default=1]&lt;/strong&gt;&lt;br /&gt;
positive &amp;amp; negative weights의 밸런스를 조정하므로, 불균형 데이터에 대해 유용한 파라미터이다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;3. Task Parameters&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;objective [default=reg:linear]&lt;/strong&gt;&lt;br /&gt;
reg:linear, reg:logistic, binary:logistic, binary:logitraw, binary:hinge
위의 것에서 gpu:추가 가능&lt;br /&gt;
count:poisson, survival:cos, multi:softmax, multi:softprob, rank:pairwise, rank:ndcg, rank:map, reg:gamma&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;base_score [default=0.5]&lt;/strong&gt;&lt;br /&gt;
The initial prediction score of all instances, global bias.&lt;br /&gt;
바꿀 필요 없다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;eval_metric&lt;/strong&gt;&lt;br /&gt;
rmse, mae, logloss, error, auc, mlogloss, …&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;seed&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Dart Booster이나 Linear Booster를 선택하였을 때 따라오는 추가적인 파라미터 조정은 Documentation을 참조할 것.&lt;br /&gt;
Console에서만 사용가능한 Line Parameter들도 있다.&lt;br /&gt;
Link: [https://xgboost.readthedocs.io/en/latest/parameter.html]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;adaboost&quot;&gt;AdaBoost&lt;/h2&gt;
&lt;p&gt;AdaBoost는 Additive Boosting의 줄임말로, 1995년에 등장하였지만 빠르고 정확한 성능으로 좋은 평가를 받고 있는 알고리즘이다.&lt;br /&gt;
간결한 설명을 위해 본 논문의 설명은 m개의 training data에 대하여 Y는 = {-1, +1}로,&lt;br /&gt;
Binary Classification 문제로 범위를 제한한다.&lt;/p&gt;

&lt;p&gt;AdaBoost는 t개의 weak(base) learning algorithm을 반복적으로 호출하여 학습을 진행한다. (t = 1 ~ T)&lt;/p&gt;

&lt;p&gt;여기서 t번 째 round에서의 training example i에 대한 weight distribution을 $ D_t(i) $이라고 하자.&lt;/p&gt;

&lt;p&gt;초기에 weight은 균일 분포로서 초기화되어 모두 동일하게 설정되지만,&lt;br /&gt;
잘못 분류된 example에 대한 weights는 증가하게 된다. 이렇게 되면 weak learner가 다음 round에서 학습을 진행할 때 이러한 example에 대해 더욱 집중하게 하는 효과를 낼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Weak Learner&lt;/strong&gt;의 일은 $ D_t $ 분포에 적합한 weak hypothesis $ h_t : X \rightarrow {-1, +1} $을 찾는 것이다.&lt;br /&gt;
Weak Learner는 $ D_t $를 다시 학습할 때 사용하거나 $ D_t $에 따라 다시 표본이 추출될 수 있다.&lt;br /&gt;
그 weak hypothesis의 성능은 다음과 같이 Error를 계산하여 평가할 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\epsilon_t = P_{i \sim D_t} [ h_t(x_i) \neq y_i] = \sum_{i:h_t(x_i) \neq y_i} D_t(i)&lt;/script&gt;

&lt;p&gt;Adaboost의 부스팅 알고리즘은 아래와 같다. 사실 그리 어렵지는 않다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2018-11-06-TripleB/07.jpg&quot; width=&quot;90%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;$ \alpha_t $는 결국 $ h_t $에 배정된 가중치라고 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Analyzing the training error&lt;/strong&gt;&lt;br /&gt;
$ \gamma_t $를 모델의 예측이 Random Guess보다 얼마나 나은지를 나타낸다고 하면,&lt;br /&gt;
$ h_t $의 Error인 $ \epsilon_t $은 $ \frac{1}{2} - \gamma_t $로 표현할 수 있다.&lt;/p&gt;

&lt;p&gt;아래 식은, 최종 hypothesis H의 Training Error는 일정 수치보다 작을 수 밖에 없음을 나타내는데,&lt;br /&gt;
이는 만약 Weak Hypothesis가 적어도 Random Guess보다는 낫다면, 결과적으로 Training Error는 지수적으로 빠르게 감소할 수 밖에 없음을 나타낸다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2018-11-06-TripleB/08.jpg&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;이전 알고리즘들도 이와 유사한 과정을 거쳤지만 이들은 $ \gamma_t $의 하한선인 $ \gamma $라는 상수에 대한 사전 정의가 필요했다. AdaBoost는 그러한 과정이 필요 없으며, 각각의 Weak Hypothesis의 Error rates에 adapt하는 모습을 보여준다.&lt;br /&gt;
이 때문에 AdaBoost는 Adaptive Boosting이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Generalization Error&lt;/strong&gt;&lt;br /&gt;
기존의 연구는 최종 Hypothesis의 Generalization에러를 Training Error의 관점에서 설명할 때,&lt;br /&gt;
아래와 같은 식으로 나타냈었는데, 이는 T가 커질 때, boosting 모델은 결국 과적합한다는 것을 의미한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2018-11-06-TripleB/09.jpg&quot; width=&quot;35%&quot; /&gt;&lt;/center&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Sign&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;T&lt;/td&gt;
      &lt;td&gt;boosting round 수&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;d&lt;/td&gt;
      &lt;td&gt;hypotheseis의 공간의 compexity의 standard measure인 VC-차원&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;m&lt;/td&gt;
      &lt;td&gt;example 수&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$ \hat{Pr(.)} $&lt;/td&gt;
      &lt;td&gt;empirical probability on the training example&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;그런데 이후의 연구를 보면 이는 종종 사실이 아닌 것으로 나타났다.&lt;br /&gt;
특히 AdaBoost의 경우 Training Error가 0에 도달한 이후에 지속적인 학습을 진행한 결과,&lt;br /&gt;
(Generalization Error)Test Error가 점차적으로 감소한 것을 알 수 있었다.&lt;/p&gt;

&lt;p&gt;이를 설명하기 위해 다른 개념이 도입되었는데, 아래를 Maring of exmaple(x, y)라고 한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;{Margin} = \frac{y * \sum_t \alpha_t h_t(x)} {\sum_t \alpha_t}&lt;/script&gt;

&lt;p&gt;이 식은 [-1, +1]에 속하며 H가 example을 적절히 분류했을 때 0의 값을 가진다.&lt;br /&gt;
이 Margin의 Magnitude는 prediction의 confidence를 측정한다고 해석할 수 있다.&lt;/p&gt;

&lt;p&gt;이후에 증명된 바에 따르면,&lt;br /&gt;
Training Set에서 Margin이 더욱 증가하면 이는 Generalization Error의 상위의 상한선으로 변환된다고 한다.&lt;/p&gt;

&lt;p&gt;식으로 표현하면 아래와 같은데, $ \theta $로 표현되는 상한선(Upper Bound)가 클 수록 Prediction에 자신이 있다는 뜻이고, 이 $ \theta $는 T에 독립적이기 때문에 반복 횟수가 증가해도 Error가 증가하지 않는다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Machine_Learning/2018-11-06-TripleB/10.jpg&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;AdaBoost의 이와 같은 기재는 game-theoretic setting과 같은 방식으로도 이해될 수 있다.&lt;br /&gt;
이는 Boosting이 어떤 특정 게임의 반복 play라고 할 때,&lt;br /&gt;
AdaBoost는 이 게임에 반복적으로 참여하여 근사적으로 게임을 푸는 General한 알고리즘의 특별한 케이스라고 해석하는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Experimetns and Applications&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;AdaBoost는 간단하고 사용하기 쉽다. weak learner에 대한 사전지식이 필요없으며 여러 method와 결합하여 사용이 가능하다.&lt;/li&gt;
  &lt;li&gt;T 빼고는 튜닝할 Hyperparameter가 없다.&lt;/li&gt;
  &lt;li&gt;Noise에 민감하다.&lt;/li&gt;
  &lt;li&gt;AdaBoost의 operation은 선형 번류기의 coordinate-wise gradient descent로 해석할 수 있다.&lt;/li&gt;
  &lt;li&gt;AdaBoost는 Outlier를 찾아내는 데에 뛰어난 성능을 보인다. (높은 Weight은 Outlier일 확률이 높다.)&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;light-gbm&quot;&gt;Light GBM&lt;/h2&gt;
&lt;p&gt;Light GBM은&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>PyTorch 사용법 - 02. Linear Regression Model</title>
   <link href="http://localhost:4000/pytorch-usage-02-Linear-Regression-Model/"/>
   <updated>2018-11-02T00:00:00+09:00</updated>
   <id>http://localhost:4000/pytorch-usage-02-Linear-Regression-Model</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-00-references/&quot;&gt;PyTorch 사용법 - 00. References&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-01-introduction/&quot;&gt;PyTorch 사용법 - 01. 소개 및 설치&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-02-Linear-Regression-Model/&quot;&gt;PyTorch 사용법 - 02. Linear Regression Model&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/&quot;&gt;PyTorch 사용법 - 03. How to Use PyTorch&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2019/06/12/pytorch-usage-04-RNN-Model/&quot;&gt;PyTorch 사용법 - 04. Recurrent Neural Network Model&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이 글에서는 가장 기본 모델인 Linear Regression Model의 Pytorch 프로젝트를 살펴본다.&lt;/p&gt;

&lt;p&gt;사용되는 torch 함수들의 사용법은 &lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-00-references/&quot;&gt;여기&lt;/a&gt;에서 확인할 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;프로젝트-구조&quot;&gt;프로젝트 구조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;02_Linear_Regression_Model/
    &lt;ul&gt;
      &lt;li&gt;main.py&lt;/li&gt;
      &lt;li&gt;data/
        &lt;ul&gt;
          &lt;li&gt;02_Linear_Regression_Model_Data.csv&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;results/&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;일반적으로 데이터는 &lt;code class=&quot;highlighter-rouge&quot;&gt;data/&lt;/code&gt; 디렉토리에 넣는다.&lt;/li&gt;
  &lt;li&gt;코드는 git에 두고, &lt;code class=&quot;highlighter-rouge&quot;&gt;data/&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일에 추가하여 데이터는 git에 올리지 않는다. 파일은 다른 서버에 두고 필요할 때 다운로드한다. 일반적으로 dataset은 그 크기가 수 GB 혹은 그 이상도 될 수 있기 때문에 upload/download 시간이 굉장히 길어지기도 하고, &lt;a href=&quot;https://github.com/&quot;&gt;Git&lt;/a&gt;이 100MB 이상의 큰 파일은 업로드를 지원하지 않기 때문이기도 하다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;물론 이 예제 프로젝트는 너무 간단하여 그냥 &lt;code class=&quot;highlighter-rouge&quot;&gt;data/&lt;/code&gt; 디렉토리 없이 해도 상관없다.&lt;br /&gt;
그리고 &lt;code class=&quot;highlighter-rouge&quot;&gt;output/&lt;/code&gt; 또는 &lt;code class=&quot;highlighter-rouge&quot;&gt;results/&lt;/code&gt; 디렉토리를 만들도록 한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;import&quot;&gt;Import&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음 파일을 다운로드하여 &lt;code class=&quot;highlighter-rouge&quot;&gt;data/&lt;/code&gt; 디렉토리에 넣는다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/greeksharifa/Tutorial.code/blob/master/Python/PyTorch_Usage/02_Linear_Regression_Model/data/02_Linear_Regression_Model_Data.csv&quot;&gt;02_Linear_Regression_Model_Data.csv&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://pytorch.org/&quot;&gt;torch&lt;/a&gt;: 설명이 필요없다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/nn.html&quot;&gt;from torch import nn&lt;/a&gt;: nn은 Neural Network의 약자이다. torch의 nn 라이브러리는 Neural Network의 모든 것을 포괄하며, Deep-Learning의 가장 기본이 되는 1-Layer Linear Model도 &lt;code class=&quot;highlighter-rouge&quot;&gt;nn.Linear&lt;/code&gt; 클래스를 사용한다. 이 예제에서도 &lt;strong&gt;nn.Linear&lt;/strong&gt;를 쓴다.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;nn.Module&lt;/strong&gt;은 모든 Neural Network Model의 Base Class이다. 모든 Neural Network Model(흔히 Net이라고 쓴다)은 &lt;strong&gt;nn.Module&lt;/strong&gt;의 subclass이다. nn.Module을 상속한 어떤 subclass가 Neural Network Model로 사용되려면 다음 두 메서드를 override해야 한다.
        &lt;ul&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;__init__(self)&lt;/code&gt;: &lt;strong&gt;&lt;em&gt;Initialize.&lt;/em&gt;&lt;/strong&gt; 여러분이 사용하고 싶은, Model에 사용될 구성 요소들을 정의 및 초기화한다. 대개 다음과 같이 사용된다.
            &lt;ul&gt;
              &lt;li&gt;self.conv1 = nn.Conv2d(1, 20, 5)&lt;/li&gt;
              &lt;li&gt;self.conv2 = nn.Conv2d(20, 20, 5)&lt;/li&gt;
              &lt;li&gt;self.linear1 = nn.Linear(1, 20, bias=True)&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;forward(self, x)&lt;/code&gt;: &lt;strong&gt;&lt;em&gt;Specify the connections.&lt;/em&gt;&lt;/strong&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;__init__&lt;/code&gt;에서 정의된 요소들을 잘 연결하여 모델을 구성한다. Nested Tree Structure가 될 수도 있다. 주로 다음처럼 사용된다.
            &lt;ul&gt;
              &lt;li&gt;x = F.relu(self.conv1(x))&lt;/li&gt;
              &lt;li&gt;return F.relu(self.conv2(x))&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;다른 말로는 위의 두 메서드를 override하기만 하면 손쉽게 Custom net을 구현할 수 있다는 뜻이기도 하다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;참고: &lt;strong&gt;torch.autograd.Variable&lt;/strong&gt;은 이전에는 auto gradient 계산을 위해 tensor에 필수적으로 씌워 주어야 했으나, PyTorch 0.4.0 버전 이후로 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.Tensor&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.autograd.Variable&lt;/code&gt; 클래스가 통합되었다. 따라서 PyTorch 구버전을 사용할 예정이 아니라면 Variable은 쓸 필요가 전혀 없다.
    &lt;ul&gt;
      &lt;li&gt;인터넷에 돌아다니는 수많은 코드의 Variable Class는 0.4.0 버전 이전에 PyTorch를 시작한 사람들이 쓴 것이다.&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/autograd.html#variable-deprecated/&quot;&gt;https://pytorch.org/docs/stable/autograd.html#variable-deprecated/&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://pytorch.org/blog/pytorch-0_4_0-migration-guide/&quot;&gt;https://pytorch.org/blog/pytorch-0_4_0-migration-guide/&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;load-data&quot;&gt;Load Data&lt;/h2&gt;

&lt;h3 id=&quot;데이터-준비&quot;&gt;데이터 준비&lt;/h3&gt;

&lt;p&gt;지금의 경우는 전처리할 필요가 없으므로 그냥 데이터를 불러오기만 하면 된다. 데이터가 어떻게 생겼는지도 확인해 보자.&lt;br /&gt;
데이터가 어떤지 살펴보는 것은 모델을 결정하는 데 있어 매우 중요하다.&lt;/p&gt;

&lt;p&gt;다운로드는 &lt;a href=&quot;https://drive.google.com/open?id=1gVxV5eD5NfyEO4aHSyAGmsDgUco8FQPb&quot;&gt;여기&lt;/a&gt;에서 할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/02_Linear_Regression_Model_Data.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Avoid copy data, just refer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'y'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'02_Linear_Regression_Model_Data'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/PyTorch/2018-11-02-pytorch-usage-02-Linear-Regression-Model/02_Linear_Regression_Model_Data.png&quot; alt=&quot;02_Linear_Regression_Model_Data&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;from_numpy&lt;/strong&gt;로 불러오는 이유는 데이터를 복사하여 새로 텐서를 생성하는 대신 원 데이터와 메모리를 공유하는 텐서를 쓰기 위함이다. 지금은 상관없지만 대용량의 데이터를 다룰 때에는 어떤 함수가 데이터를 복사하는지 아닌지를 확실하게 알아둘 필요가 있다.&lt;br /&gt;
물론, 정말 대용량의 데이터의 경우는 read_csv로 한번에 불러오지 못한다. 이는 데이터를 &lt;em&gt;batch&lt;/em&gt;로 조금씩 가져오는 것으로 해결하는데, 이에 대해서는 나중에 살펴보자.&lt;/p&gt;

&lt;p&gt;참고: 이 데이터는 다음 코드를 통해 생성되었다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data/02_Linear_Regression_Model_Data.csv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'y'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;define-and-load-model&quot;&gt;Define and Load Model&lt;/h2&gt;

&lt;p&gt;매우 간단한 모델이므로 코드도 짧다.&lt;br /&gt;
여기서는 여러분의 편의를 위해 함수들의 parameter 이름을 명시하도록 한다.&lt;/p&gt;

&lt;p&gt;PyTorch에서 Linear 모델은 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.nn.Linear&lt;/code&gt; 클래스를 사용한다. 여기서는 단지 x를 y로 mapping하는 일차원 직선($ y = wx + b $)을 찾고 싶은 것이므로, &lt;code class=&quot;highlighter-rouge&quot;&gt;in_features&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;out_features&lt;/code&gt;는 모두 1이다.&lt;br /&gt;
&lt;strong&gt;nn.Linear&lt;/strong&gt;은 &lt;strong&gt;nn.Module&lt;/strong&gt;의 subclass로 in_features개의 input을 선형변환을 거쳐 out_features개의 output으로 변환한다. parameter 개수는 $ (in _ features \times out _ features [ + out _ features]) $ 개이다. 마지막 항은 &lt;strong&gt;bias&lt;/strong&gt;이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
Linear(in_features=1, out_features=1, bias=True)
Parameter containing:
tensor([[-0.9360]], requires_grad=True)
Parameter containing:
tensor([0.7960], requires_grad=True)
&quot;&quot;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;별다른 utility 함수가 필요 없으므로 따로 &lt;code class=&quot;highlighter-rouge&quot;&gt;utils.py&lt;/code&gt;는 만들지 않는다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;set-loss-functioncreterion-and-optimizer&quot;&gt;Set Loss function(creterion) and Optimizer&lt;/h2&gt;

&lt;p&gt;적절한 모델을 선정할 때와 마찬가지로 loss function과 optimizer를 결정하는 것은 학습 속도와 성능을 결정짓는 중요한 부분이다.&lt;br /&gt;
지금과 같이 간단한 Linear Regression Model에서는 어느 것을 사용해도 학습이 잘 된다. 하지만, 일반적으로 성능이 좋은 &lt;code class=&quot;highlighter-rouge&quot;&gt;AdamOptimizer&lt;/code&gt;를 사용하도록 하겠다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MSELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
tensor([[-0.1399],
        [-1.0759],
        [-2.0119],
        [-2.9478],
        [-3.8838],
        [-4.8197],
        [-5.7557],
        [-6.6917],
        [-7.6276],
        [-8.5636]], grad_fn=&amp;lt;ThAddmmBackward&amp;gt;)
&quot;&quot;&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고: 보통 변수명은 criterion 혹은 loss_function 등을 이용한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;train-model&quot;&gt;Train Model&lt;/h2&gt;

&lt;p&gt;Train은 다음과 같이 이루어진다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;모델에 데이터를 통과시켜 예측값(현재 모델의 weights로 prediction)을 얻은 뒤&lt;/li&gt;
  &lt;li&gt;실제 정답과 loss를 비교하고&lt;/li&gt;
  &lt;li&gt;gradient를 계산한다.&lt;/li&gt;
  &lt;li&gt;이 값을 통해 weights를 업데이트한다(backpropagation).&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
        Show your intermediate results
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;코드의 각 라인을 설명하면 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;prediction&lt;/code&gt;: 모델에 데이터(x)를 집어넣었을 때 예측값(y). 여기서는 $ y = wx + b $의 결과들이다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;loss&lt;/code&gt;: criterion이 MSELoss로 설정되어 있으므로, prediction과 y의 평균제곱오차를 계산한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;optimizer.zero_grad()&lt;/code&gt;: optimizer의 grad를 0으로 설정한다. PyTorch는 parameter들의 gradient를 계산해줄 때 grad는 계속 누적되도록 되어 있다. 따라서 gradient를 다시 계산할 때에는 0으로 세팅해주어야 한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;loss.backward()&lt;/code&gt;: gradient 계산을 역전파(backpropagation)한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;optimizer.step()&lt;/code&gt;: 계산한 gradient를 토대로 parameter를 업데이트한다($ w \leftarrow w - \alpha \Delta w, b \leftarrow b - \alpha \Delta b $)&lt;/li&gt;
  &lt;li&gt;학습 결과를 중도에 확인하고 싶으면 그래프를 중간에 계속 그려주는 것도 한 방법이다.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;visualize-and-save-results&quot;&gt;Visualize and save results&lt;/h2&gt;

&lt;p&gt;결과를 그래프로 보여주는 부분은 &lt;code class=&quot;highlighter-rouge&quot;&gt;matplotlib.pyplot&lt;/code&gt;에 대한 내용이므로 여기서는 넘어가도록 하겠다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;display_results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xlim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scatter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'b--'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'loss={:.4}, w={:.4}, b={:.4}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# plt.savefig('results/02_Linear_Regression_Model_trained.png')
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;display_results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/PyTorch/2018-11-02-pytorch-usage-02-Linear-Regression-Model/02_Linear_Regression_Model_trained.png&quot; alt=&quot;02_Linear_Regression_Model_Trained&quot; /&gt;&lt;/p&gt;

&lt;p&gt;모델을 저장하려면 &lt;code class=&quot;highlighter-rouge&quot;&gt;torch.save&lt;/code&gt; 함수를 이용한다. 저장할 모델은 대개 &lt;code class=&quot;highlighter-rouge&quot;&gt;.pt&lt;/code&gt; 확장자를 사용한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;obj&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'02_Linear_Regression_Model.pt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고: &lt;code class=&quot;highlighter-rouge&quot;&gt;.pt&lt;/code&gt; 파일로 저장한 PyTorch 모델을 load해서 사용하려면 다음과 같이 한다. 이는 나중에 &lt;strong&gt;Transfer Learning&lt;/strong&gt;과 함께 자세히 다루도록 하겠다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;loaded_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'02_Linear_Regression_Model.pt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;display_results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loaded_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;정확히 같은 결과를 볼 수 있을 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;전체 코드는 &lt;a href=&quot;https://github.com/greeksharifa/Tutorial.code/blob/master/Python/PyTorch_Usage/02_Linear_Regression_Model/main.py&quot;&gt;여기&lt;/a&gt;에서 살펴볼 수 있다.&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>PyTorch 사용법 - 01. 소개 및 설치</title>
   <link href="http://localhost:4000/pytorch-usage-01-introduction/"/>
   <updated>2018-11-02T00:00:00+09:00</updated>
   <id>http://localhost:4000/pytorch-usage-01-introduction</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-00-references/&quot;&gt;PyTorch 사용법 - 00. References&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-01-introduction/&quot;&gt;PyTorch 사용법 - 01. 소개 및 설치&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-02-Linear-Regression-Model/&quot;&gt;PyTorch 사용법 - 02. Linear Regression Model&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/&quot;&gt;PyTorch 사용법 - 03. How to Use PyTorch&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2019/06/12/pytorch-usage-04-RNN-Model/&quot;&gt;PyTorch 사용법 - 04. Recurrent Neural Network Model&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;간단한-소개&quot;&gt;간단한 소개&lt;/h2&gt;

&lt;p&gt;PyTorch는 유연성과 속도를 모두 갖춘 딥러닝 연구 플랫폼이다. GPU 사용이 가능하기 때문에 속도가 상당히 빠르다.&lt;br /&gt;
또 입문 난이도가 높지 않은 편이고 코드가 간결하다.&lt;br /&gt;
현재는 TensorFlow의 사용자가 많지만, 그 특유의 비직관적인 구조와 난이도 때문에 요즘은 PyTorch의 사용자가 늘어나는 추세이다.&lt;/p&gt;

&lt;h3 id=&quot;tensorflow와의-비교&quot;&gt;TensorFlow와의 비교&lt;/h3&gt;

&lt;p&gt;TensorFlow는 구현 패러다임이 Define and Run인데 비해, PyTorch는 Define by Run이다.&lt;/p&gt;

&lt;p&gt;무슨 말인가 하면, TensorFlow는 코드를 직접 돌리는 환경인 세션을 만들고, placeholder를 선언하고 이것으로 계산 그래프를 만들고(Define), 코드를 실행하는 시점에 데이터를 넣어 실행하는(Run) 방식이다.&lt;br /&gt;
이는 계산 그래프를 명확히 보여주면서 실행시점에 데이터만 바꿔줘도 되는 유연함을 장점으로 가지지만, 그 자체로 비직관적이다. 그래서 딥러닝 프레임워크 중 난이도가 가장 높은 편이다.&lt;/p&gt;

&lt;p&gt;하지만 PyTorch는 그런 어려움이 없다. 일반적인 Python 코딩이랑 크게 다를 바 없다. 선언과 동시에 데이터를 집어넣고, 세션 같은 것도 필요없이 그냥 돌리면 끝이다. 덕분에 코드가 간결하고, 난이도가 낮다.&lt;br /&gt;
한 가지 단점은 아직 사용자가 적어 구글링했을 때 검색 결과가 많지 않다는 정도?&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;설치-방법&quot;&gt;설치 방법&lt;/h2&gt;

&lt;script data-ad-client=&quot;ca-pub-9951774327887666&quot; async=&quot;&quot; src=&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;

&lt;p&gt;&lt;a href=&quot;https://pytorch.org/&quot;&gt;여기&lt;/a&gt;를 참조한다. 자신에게 맞는 OS, package manager, Python 버전, CUDA 버전 등을 선택하면 그에 맞는 명령어 집합이 나온다. 이를 명령창에 실행하면 설치가 진행된다.&lt;br /&gt;
torchvision을 설치할 경우에 무슨 라이브러리가 없다면서 에러 메시지가 뜨긴 하는데, 사용하는 데 별 문제는 없을 것이다. 만약 자신이 그 부분을 꼭 써야 한다면 에러를 해결하고 넘어가자.&lt;/p&gt;

&lt;p&gt;설치를 완료했으면, 명령창에 다음과 같이 입력해보자. Anadonda를 플랫폼으로 사용한다면 conda 설정은 직접 해 주어야 한다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;python&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 이 부분은 Python Interpreter에서 입력함.
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;  
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과가 대략 다음과 같이 나오면 설치가 완료되었다. 숫자가 다른 것은 랜덤이니 신경 쓰지 말자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/PyTorch/2018-11-02-pytorch-usage-01-Introduction/01_run_pytorch.PNG&quot; alt=&quot;01_run_pytorch.PNG&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;gpu-사용을-위한-설치&quot;&gt;GPU 사용을 위한 설치&lt;/h2&gt;

&lt;p&gt;GPU 사용을 위한 필수 절차는 다음과 같다. &lt;em&gt;경우의 수가 너무 많아서 스크린샷은 생략&lt;/em&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;호환성 체크&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;컴퓨터에 있는 GPU의 &lt;strong&gt;compute capability&lt;/strong&gt; 확인
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://developer.nvidia.com/cuda-gpus&quot;&gt;여기&lt;/a&gt;에서 확인&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;compute capability에 맞는 CUDA SDK 버전 확인
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/CUDA#GPUs_supported&quot;&gt;여기&lt;/a&gt;에서 확인&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Pytorch와 CUDA의 호환성 확인
        &lt;ul&gt;
          &lt;li&gt;설치하고자 하는 PyTorch(또는 Tensorflow)가 지원하는 최신 CUDA 버전이 있다. 이보다 상위 버전의 CUDA를 설치하면 PyTorch 코드가 제대로 돌아가지 않는다.&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;https://pytorch.org/&quot;&gt;Pytorch 홈페이지&lt;/a&gt;에서 정해주는 CUDA 버전을 설치하는 쪽이 편하다. 2020.02.13 기준 최신 버전은 10.1이다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;CUDA에 맞는 cuDNN 버전 확인
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;https://developer.nvidia.com/rdp/cudnn-archive&quot;&gt;여기&lt;/a&gt;에서 확인할 수 있다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;CUDA 설치&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;&lt;a href=&quot;https://developer.nvidia.com/cuda-toolkit-archive&quot;&gt;CUDA toolkit archive&lt;/a&gt;에서 원하는 CUDA를 다운받는다. 운영체제와 버전 등을 체크하고, 가능하면 Installer Type은 network가 아닌 local로 받는다. 인터넷으로 설치하면서 받는 것이 아닌 한번에 설치파일을 받는 식이다.
        &lt;ul&gt;
          &lt;li&gt;같은 버전인데 update가 추가된 버전이 있다. 보통은 이것까지 추가로 설치해 주는 쪽이 좋다. base installer를 먼저 설치한 뒤에 추가로 설치해 주도록 하자.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;설치 파일로 CUDA를 설치한다. 설치 시에는 다른 프로그램을 설치하거나 제거하는 중이면 실행이 되지 않으니 주의하자.&lt;/li&gt;
      &lt;li&gt;cuda visual studio integration 관련해서 설치 실패가 뜨는 경우가 많은데, 이 부분이 필요한 코드를 실행할 일이 있다면 이 단계에서 설치해 주는 것이 좋다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;cuDNN 설치&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;우선 &lt;a href=&quot;https://developer.nvidia.com/rdp/cudnn-archive&quot;&gt;cudnn-archive&lt;/a&gt;에서 사용하고자 하는 CUDA에 맞는 버전을 찾아 다운받는다.&lt;/li&gt;
      &lt;li&gt;윈도우의 경우 압축을 풀어 CUDA 설치 폴더(&lt;code class=&quot;highlighter-rouge&quot;&gt;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1&lt;/code&gt;)에 붙여넣기 하면 된다. 폴더 경로는 설치한 CUDA 버전에 따라 달라진다.&lt;/li&gt;
      &lt;li&gt;Ubuntu 등의 경우는 홈페이지에 명시된 절차를 따르도록 하자.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;환경변수 등록&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;윈도우의 경우 &lt;code class=&quot;highlighter-rouge&quot;&gt;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin&lt;/code&gt;을 등록하자.
        &lt;ul&gt;
          &lt;li&gt;실행이 잘 안 되는 경우 상위 또는 하위 폴더 몇 개를 추가 등록하면 되는 경우도 있다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Ubuntu 등의 경우는 다음과 비슷하다. 자신의 OS에 맞춰서 구글링하자.
        &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; export PATH=/usr/local/cuda-10.1/bin${PATH:+:${PATH}}
 export LD_LIBRARY_PATH=/usr/local/cuda-10.1/lib64\${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;설치 확인&lt;/strong&gt;
    &lt;ol&gt;
      &lt;li&gt;다음 코드를 python을 실행하여 입력해보고 &lt;code class=&quot;highlighter-rouge&quot;&gt;True&lt;/code&gt;가 뜨면 성공한 것이다.
        &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_available&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;        &lt;/div&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;pytorch-project-구조&quot;&gt;PyTorch Project 구조&lt;/h2&gt;

&lt;p&gt;프로젝트의 구조는 코딩하는 사람 마음대로이긴 하나, 기본적으로는 다음과 같은 구조를 따른다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Set HyperParameter and Run&lt;/li&gt;
  &lt;li&gt;Load Data&lt;/li&gt;
  &lt;li&gt;Define and Load Models
3-1. Define util functions&lt;/li&gt;
  &lt;li&gt;Set Loss function(creterion) and Optimizer&lt;/li&gt;
  &lt;li&gt;Train Model&lt;/li&gt;
  &lt;li&gt;Visualize and save results&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;PyTorch는 각 단계에서 다음의 장점을 갖는다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;PyTorch가 아닌 Python의 특징인데, 여러분은 많은 Machine Learning 코드를 보면서 &lt;code class=&quot;highlighter-rouge&quot;&gt;python train.py --epochs 50 --batch-size 16&lt;/code&gt; 등 많은 옵션을 설정할 수 있는 것을 보았을 것이다. Python의 &lt;code class=&quot;highlighter-rouge&quot;&gt;argparse&lt;/code&gt; 패키지는 이것을 가능하게 해 준다.&lt;/li&gt;
  &lt;li&gt;데이터 로드 시 &lt;code class=&quot;highlighter-rouge&quot;&gt;DataLoader&lt;/code&gt;라는 클래스를 제공한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;DataLoader&lt;/code&gt;를 통해 데이터를 불러오면, 이 안에서 데이터 처리에 대한 거의 모든 것을 쉽게 수행할 수 있다.
    &lt;ul&gt;
      &lt;li&gt;이를테면 Data Augmentation 같은 것도 전부 제공된다.&lt;/li&gt;
      &lt;li&gt;여러 종류의 Data Transformation이 지원된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;일반적인 모델을 불러올 때는 다른 Deep Learning Framework도 대체로 간결하지만, PyTorch는 &lt;code class=&quot;highlighter-rouge&quot;&gt;torchvision&lt;/code&gt;이라는 패키지에서 따로 pretrain까지 된 모델들을 제공하므로 다른 곳에서 모델을 다운로드할 필요 없이 이를 바로 쓸 수 있다.
2-1. 많은 프로그래머들이 &lt;code class=&quot;highlighter-rouge&quot;&gt;utils.py&lt;/code&gt;에 유틸리티 함수(예를 들면 &lt;a href=&quot;https://greeksharifa.github.io/paper_review/2018/10/26/YOLOv2/&quot;&gt;YOLO&lt;/a&gt;에서 &lt;a href=&quot;https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/&quot;&gt;IoU&lt;/a&gt;를 구하는 함수)를 따로 빼내어 여러 가지를 한번에 정의한다. 프로젝트에서 부가적인 부분은 따로 관리하는 것이 가독성이 좋다.&lt;/li&gt;
  &lt;li&gt;이 부분은 다른 Deep Learning Framework와 비슷하다.&lt;/li&gt;
  &lt;li&gt;Tensorflow와는 달리 Session을 설정할 필요가 없다.&lt;/li&gt;
  &lt;li&gt;이 부분도 역시 비슷하다.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-02-Linear-Regression-Model/&quot;&gt;다음 글&lt;/a&gt;에서는 Linear Regression Model을 예로 들어서 간단한 프로젝트의 구조를 설명하도록 하겠다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-00-references/&quot;&gt;Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;PyTorch에서 자주 사용되는 함수들을 정리한 글이다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>PyTorch 사용법 - 00. References</title>
   <link href="http://localhost:4000/pytorch-usage-00-references/"/>
   <updated>2018-11-02T00:00:00+09:00</updated>
   <id>http://localhost:4000/pytorch-usage-00-references</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-00-references/&quot;&gt;PyTorch 사용법 - 00. References&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-01-introduction/&quot;&gt;PyTorch 사용법 - 01. 소개 및 설치&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/02/pytorch-usage-02-Linear-Regression-Model/&quot;&gt;PyTorch 사용법 - 02. Linear Regression Model&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/&quot;&gt;PyTorch 사용법 - 03. How to Use PyTorch&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/pytorch/2019/06/12/pytorch-usage-04-RNN-Model/&quot;&gt;PyTorch 사용법 - 04. Recurrent Neural Network Model&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;본 글의 일부 예제는 &lt;a href=&quot;https://pytorch.org/docs/stable/index.html&quot;&gt;Pytorch Documentation&lt;/a&gt;에서 가져왔음을 밝힙니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;데이터-타입dtype&quot;&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/tensor_attributes.html?highlight=dtype#torch.torch.dtype&quot;&gt;데이터 타입(dtype)&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;모든 텐서는 기본적으로 dtype을 갖고 있다. 데이터 타입(dtype)이란 데이터가 정수형인지, 실수형인지, 얼마나 큰 범위를 가질 수 있는지 등을 나타낸다.&lt;br /&gt;
종류는 아래 표와 같다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Data type&lt;/th&gt;
      &lt;th&gt;dtype&lt;/th&gt;
      &lt;th&gt;CPU tensor&lt;/th&gt;
      &lt;th&gt;GPU tensor&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;32-bit floating point&lt;/td&gt;
      &lt;td&gt;torch.float32 or torch.float&lt;/td&gt;
      &lt;td&gt;torch.FloatTensor&lt;/td&gt;
      &lt;td&gt;torch.cuda.FloatTensor&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;64-bit floating point&lt;/td&gt;
      &lt;td&gt;torch.float64 or torch.double&lt;/td&gt;
      &lt;td&gt;torch.DoubleTensor&lt;/td&gt;
      &lt;td&gt;torch.cuda.DoubleTensor&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;16-bit floating point&lt;/td&gt;
      &lt;td&gt;torch.float16 or torch.half&lt;/td&gt;
      &lt;td&gt;torch.HalfTensor&lt;/td&gt;
      &lt;td&gt;torch.cuda.HalfTensor&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8-bit integer (unsigned)&lt;/td&gt;
      &lt;td&gt;torch.uint8&lt;/td&gt;
      &lt;td&gt;torch.ByteTensor&lt;/td&gt;
      &lt;td&gt;torch.cuda.ByteTensor&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8-bit integer (signed)&lt;/td&gt;
      &lt;td&gt;torch.int8&lt;/td&gt;
      &lt;td&gt;torch.CharTensor&lt;/td&gt;
      &lt;td&gt;torch.cuda.CharTensor&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;16-bit integer (signed)&lt;/td&gt;
      &lt;td&gt;torch.int16 or torch.short&lt;/td&gt;
      &lt;td&gt;torch.ShortTensor&lt;/td&gt;
      &lt;td&gt;torch.cuda.ShortTensor&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;32-bit integer (signed)&lt;/td&gt;
      &lt;td&gt;torch.int32 or torch.int&lt;/td&gt;
      &lt;td&gt;torch.IntTensor&lt;/td&gt;
      &lt;td&gt;torch.cuda.IntTensor&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;64-bit integer (signed)&lt;/td&gt;
      &lt;td&gt;torch.int64 or torch.long&lt;/td&gt;
      &lt;td&gt;torch.LongTensor&lt;/td&gt;
      &lt;td&gt;torch.cuda.LongTensor&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;사용법은 어렵지 않다. 텐서 생성시 &lt;code class=&quot;highlighter-rouge&quot;&gt;dtype=torch.float&lt;/code&gt;과 같이 parameter를 지정해 주기만 하면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;tensor-creation&quot;&gt;Tensor Creation&lt;/h2&gt;

&lt;h3 id=&quot;torcharange&quot;&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/torch.html?highlight=arange#torch.arange&quot;&gt;torch.arange&lt;/a&gt;&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# torch.arange(start=0, end, step=1, out=None, dtype=None, 
#              layout=torch.strided, device=None, requires_grad=False) → Tensor
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;start 이상 end 미만까지 step 간격으로 dtype 타입인 1차원 텐서를 &lt;strong&gt;생성&lt;/strong&gt;한다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;out&lt;/code&gt; parameter로 결과 텐서를 저장할 변수(텐서)를 지정할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;torchlinspace&quot;&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/torch.html?highlight=linspace#torch.linspace&quot;&gt;torch.linspace&lt;/a&gt;&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# torch.linspace(start, end, steps=100, out=None, dtype=None, 
#                layout=torch.strided, device=None, requires_grad=False) → Tensor
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;start 이상 end 미만까지 총 steps 개수의 dtype 타입인 1차원 텐서를 &lt;strong&gt;생성&lt;/strong&gt;한다.&lt;br /&gt;
&lt;strong&gt;torch.arange&lt;/strong&gt;에서 step은 간격을, &lt;strong&gt;torch.linspace&lt;/strong&gt;에서 steps는 개수를 의미한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;10.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;5.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;   &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;   &lt;span class=&quot;mf&quot;&gt;5.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;10.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;steps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;1.1111&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;2.2222&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;3.3333&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;4.4444&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  
         &lt;span class=&quot;mf&quot;&gt;5.5556&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;6.6667&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;7.7778&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;8.8889&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.0000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;torchfrom_numpy&quot;&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/torch.html?highlight=from_numpy#torch.from_numpy&quot;&gt;torch.from_numpy&lt;/a&gt;&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# torch.from_numpy(ndarray) → Tensor
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;numpy array인 ndarray로부터 텐서를 만든다. 이 함수는 데이터를 &lt;strong&gt;복사가 아닌 참조&lt;/strong&gt;를 한다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;from_numpy&lt;/code&gt;로 만들어진 텐서는 해당 ndarray와 메모리를 공유하며, 어느 한쪽의 데이터를 변경 시 둘 다 변경된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;torchrandn&quot;&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/torch.html?highlight=randn#torch.randn&quot;&gt;torch.randn&lt;/a&gt;&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# torch.randn(*sizes, out=None, dtype=None, 
#             layout=torch.strided, device=None, requires_grad=False) → Tensor
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;N(0, 1) 정규분포를 따르는 sizes 크기의 텐서를 &lt;strong&gt;생성&lt;/strong&gt;한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.5954&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;2.8929&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0923&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.1719&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.4709&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1996&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;tensor-reshape&quot;&gt;Tensor Reshape&lt;/h2&gt;

&lt;h3 id=&quot;torchunsqueezetensorunsqueeze&quot;&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/torch.html#torch.unsqueeze&quot;&gt;torch.unsqueeze(Tensor.unsqueeze)&lt;/a&gt;&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# torch.unsqueeze(input, dim, out=None) → Tensor
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dim&lt;/code&gt; parameter 위치에 길이 1짜리 차원을 추가한 텐서를 만든다. 이 함수는 데이터를 &lt;strong&gt;복사가 아닌 참조&lt;/strong&gt;를 한다. 원본 텐서와 메모리를 공유하며, 어느 한쪽의 데이터를 변경 시 둘 다 변경된다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;dim&lt;/code&gt;은 [ -input.dim() - 1, input.dim() + 1] 범위를 갖는다. 음수 dim은 dim + input.dim() + 1과 같다.&lt;br /&gt;
원본 텐서의 size가 (2, 3, 4)라면, unsqueeze(1) 버전은 (2, 1, 3, 4), unsqueeze(2) 버전은 (2, 3, 1, 4)이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;tensor-operation&quot;&gt;Tensor Operation&lt;/h2&gt;

&lt;h3 id=&quot;torchcat&quot;&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/torch.html?highlight=cat#torch.cat&quot;&gt;torch.cat&lt;/a&gt;&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# torch.cat(seq, dim=0, out=None) → Tensor
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;두 텐서를 이어 붙인다(concatenate). 데이터를 &lt;strong&gt;복사&lt;/strong&gt;한다.&lt;br /&gt;
concatenate하는 차원을 제외하고는 size가 같거나 empty여야 한다. 즉 shape=(2, 3, 4)인 텐서는 shape=(2, 1, 4)와는 &lt;code class=&quot;highlighter-rouge&quot;&gt;dim=1&lt;/code&gt;일 때만 concatenate가 가능하다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;104&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;101&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;102&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;103&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;101&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;102&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;103&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;torchtensorbackward&quot;&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/autograd.html?highlight=backward#torch.Tensor.backward&quot;&gt;torch.Tensor.backward&lt;/a&gt;&lt;/h3&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;torchnn&quot;&gt;torch.nn&lt;/h2&gt;

&lt;h3 id=&quot;torchnnlinear&quot;&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/nn.html?highlight=linear#torch.nn.Linear&quot;&gt;torch.nn.Linear&lt;/a&gt;&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# class torch.nn.Linear(in_features, out_features, bias=True)
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Linear 모델 클래스를 생성한다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;in_features&lt;/code&gt; 길이의 데이터를 Linear Transformation을 통해 &lt;code class=&quot;highlighter-rouge&quot;&gt;out_features&lt;/code&gt; 길이의 데이터로 변환할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;containing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3469&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.1542&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.4830&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2903&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.4949&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.4592&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Parameter&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;containing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0965&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;mf&quot;&gt;0.5427&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;torchnnmseloss&quot;&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/nn.html?highlight=mseloss#torch.nn.MSELoss&quot;&gt;torch.nn.MSELoss&lt;/a&gt;&lt;/h3&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;torchoptim&quot;&gt;torch.optim&lt;/h2&gt;

&lt;h3 id=&quot;torchoptimadam&quot;&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam&quot;&gt;torch.optim.Adam&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;torchoptimoptimizerzero_grad&quot;&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/optim.html?highlight=zero_grad#torch.optim.Optimizer.zero_grad&quot;&gt;torch.optim.Optimizer.zero_grad&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&quot;torchoptimoptimizerstep&quot;&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/optim.html?highlight=optimizer%20step#torch.optim.Optimizer.step&quot;&gt;torch.optim.Optimizer.step&lt;/a&gt;&lt;/h3&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;save-and-load&quot;&gt;Save and Load&lt;/h2&gt;

&lt;h3 id=&quot;torchsave&quot;&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/torch.html?highlight=save#torch.save&quot;&gt;torch.save&lt;/a&gt;&lt;/h3&gt;

&lt;hr /&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Andre_Derain_Fishing_Boats_Collioure.jpg&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Andre_Derain_Fishing_Boats_Collioure.jpg&quot; alt=&quot;01_new_repository&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;
</content>
 </entry>
 
 <entry>
   <title>RC task using CNN/Daily dataset</title>
   <link href="http://localhost:4000/RC-task/"/>
   <updated>2018-11-01T00:00:00+09:00</updated>
   <id>http://localhost:4000/RC-task</id>
   <content type="html">&lt;h3 id=&quot;a-thorough-examination-of-the-cnndaily-mail-reading-comprehension-task&quot;&gt;A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;본 글은 Danqi Chen, Jason Bolton, Christopher D. Manning가 2016년에 Publish한 위 논문을 리뷰한 것이다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;본 논문은 CNN/Daily Mail 데이터셋의 심도 있는 분석을 목적으로 하며, 어떠한 수준의 자연어가 요구되는지를 파악하는 것을 목적으로 한다.&lt;/p&gt;

&lt;h3 id=&quot;rc-task-and-systems&quot;&gt;RC Task and systems&lt;/h3&gt;
&lt;p&gt;데이터셋은 아래와 같은 3가지의 구성 요소를 지닌다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Element&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;passage&lt;/td&gt;
      &lt;td&gt;new article&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;question&lt;/td&gt;
      &lt;td&gt;close_style task&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;answer&lt;/td&gt;
      &lt;td&gt;question entity&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;한 passage의 단어들을 d차원으로 임베딩하여 m개의 token을 형성하였다고 할 때,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p = {p_1, p_2, ..., p_m}, q = {q_1, ..., q_l}&lt;/script&gt;

&lt;p&gt;q의 경우 오직 하나의 “placeholder” token을 가진다.&lt;br /&gt;
목적은 결국 p와 E(모든 abstract entity markers의 집합)의 교집합에 속하는 a를 찾는 것인데,&lt;br /&gt;
이는 answer(답)가 named entity 리스트에서 선택된다는 것을 의미한다.&lt;/p&gt;

&lt;p&gt;본 논문의 모델은 Hermann의 Attentive Model을 기반으로 하며 일부 수정을 기하였다.&lt;br /&gt;
대략적인 구조는 아래 그림과 같다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-11-01-RC-task/01.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;d차원으로 임베딩 된 $ p_i $, $ q_j $ 벡터들은 (i = 1~m, j = 1~l) 각각 Bidirectional RNN에 인풋으로 투입된다. hidden state들을 수직으로 concat한 것을 $ \tilde{p_i} $라고 한며 이 벡터의 차원은 h이다. q역시 마찬가지로 h차원이다.&lt;/p&gt;

&lt;p&gt;기본 구조는 GRU를 사용하였다. (계산 심플)&lt;/p&gt;

&lt;p&gt;Attention의 경우 아래와 같이 계산된다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-11-01-RC-task/02.jpg&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;attention weight인 $ \alpha_i $ 는 스칼라이며, contextual embedding vector인 $ \tilde{p_i} $ 과 q의 관련 정도를 의미한다. 이 값이 클 수록 질문과 paragraph의 관련성이 강하다는 것을 의미한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;output vector&lt;/strong&gt;인 &lt;strong&gt;o&lt;/strong&gt;는 (n, 1) 벡터이며 모든 contextual embedding vectors의 가중합으로 생각하면 된다.&lt;/p&gt;

&lt;p&gt;이를 통해 최종적으로 아래와 같이 답을 계산한다. 손실함수는 NLL을 사용한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-11-01-RC-task/03.jpg&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;Hermann의 모델과의 차이점은 아래와 같다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Bilinear Term을 사용하여 q와 p사이의 상호작용을 명확히 했다.&lt;/li&gt;
  &lt;li&gt;output vector를 직접적으로 예측에 사용하였다.&lt;/li&gt;
  &lt;li&gt;모든 단어를 후보로 두지 않고 entities 중 passage에 나타나는 (p와 E의 교집합) 단어들만 후보로 두었다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;training&quot;&gt;Training&lt;/h3&gt;
&lt;p&gt;빈번하게 등장하는 5만개의 단어만을 사용하였고, 임베딩 차원이 d=100인 GloVe를 사용하였다.&lt;br /&gt;
attention과 output 모수들은 균일분포로 초기화되었고, GRU weights은 정규분포로 초기화 되었다.&lt;/p&gt;

&lt;p&gt;hidden size는 128과 256을 사용하였고, SGD 알고리즘을 32 배치사이즈로서 사용하였다.&lt;br /&gt;
0.2의 dropout을 임베딩 layer에 사용하였고, gradient의 norm이 10을 넘을 경우 gradient clipping을 사용하였다.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Self Attention</title>
   <link href="http://localhost:4000/Self-Attention/"/>
   <updated>2018-10-29T00:00:00+09:00</updated>
   <id>http://localhost:4000/Self Attention</id>
   <content type="html">&lt;h3 id=&quot;a-structured-self-attentive-sentence-embedding&quot;&gt;A Structured Self-Attentive Sentence Embedding&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;본 글은 Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou, Yoshua Bengio가 2017년에 Publish한 위 논문을 리뷰한 것이다.&lt;br /&gt;
특별히 본 글은 Presentation에 사용된 PDF 발표자료로 대체하겠다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-10-29-Self-Attention/01.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-10-29-Self-Attention/02.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-10-29-Self-Attention/03.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-10-29-Self-Attention/04.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-10-29-Self-Attention/05.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-10-29-Self-Attention/06.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-10-29-Self-Attention/07.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;
</content>
 </entry>
 
 <entry>
   <title>YOLOv2</title>
   <link href="http://localhost:4000/YOLOv2/"/>
   <updated>2018-10-26T00:00:00+09:00</updated>
   <id>http://localhost:4000/YOLOv2</id>
   <content type="html">&lt;h3 id=&quot;you-only-look-once-unified-real-time-object-detection&quot;&gt;You Only Look Once: Unified, Real-Time Object Detection&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;본 글은 Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi가 2016년에 Publish한 위 논문을 리뷰한 것이며, 추가적으로 구현을 위한 Loss Function 설명과 코드를 첨부하였다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;unified-detection&quot;&gt;Unified Detection&lt;/h3&gt;
&lt;p&gt;YOLO version2는 기본적으로 end-to-end training 방법을 취하고 있으며 학습이 완료되었을 때 실시간으로
테스트가 가능할 만큼 빠른 속도를 보이는 강점을 갖고 있다.&lt;br /&gt;
본 글은 416 X 416 이미지를 기준으로 설명을 진행하도록 하겠다.&lt;br /&gt;
YOLO의 핵심은 이미지를 Grid Cell로 나누어 각각의 Cell이 Object Detection을 위한 정체성을 갖게끔 만든다는 것이다.&lt;br /&gt;
예를 들어 416 X 416의 이미지는 아래와 같은 Darknet이라는 CNN 구조를 거치게 된다.&lt;br /&gt;
(참고로 아래는 Pytorch 기준으로 Channels_first를 적용하였다.)&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;layer&lt;/th&gt;
      &lt;th&gt;size&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;[None, 3, 416, 416]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;[None, 32, 208, 208]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;[None, 64, 104, 104]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;[None, 128, 52, 52]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;[None, 256, 26, 26]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;[None, 512, 13, 13]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;[None, 1024, 13, 13]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;[None, 1024, 13, 13]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;[None, 1024, 13, 13]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;skip:&lt;/td&gt;
      &lt;td&gt;[None, 64, 26, 26] -&amp;gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;skip:&lt;/td&gt;
      &lt;td&gt;[None, 256, 13, 13]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;[None, 1280, 13, 13]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;[None, 1024, 13, 13]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;[None, 35, 13, 13]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Output으로 나온 [35, 13, 13]에서 13 X 13은 Grid의 size이다. 35는 추후에 설명하겠다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-10-26-YOLOv2/01.jpg&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;출처: https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;p&gt;위 그림과 같이 정리된 13 X 13 = 169개의 Cell은 이제 각각 Object을 detect하기 위한 정체성을 갖게 된다. 만일 실제(Ground-truth: GT) Object의 &lt;strong&gt;중심 좌표(center coordinate)&lt;/strong&gt;가 Cell 내부에 위치한다면, 그 Cell은 해당 Object를 detect할 책임을 지게 되는 것이다.&lt;br /&gt;
(If the center of an object falls into a grid cell, that grid cell is reponsible for detecting that object)&lt;/p&gt;

&lt;p&gt;각각의 Grid Cell은 이제 5개의 bbox를 예측하게 되고, 각각의 box에 대해 confidence score를 계산하게 된다. 5개는 YOLOv2에서 정한 숫자이고, YOLOv3에선 총 9개가 등장하게 된다.&lt;/p&gt;

&lt;p&gt;자세한 설명을 위해 35라는 숫자에 대해 부연 설명을 하도록 하겠다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;35 = 5 * (1 + 4 + 2)&lt;/script&gt;

&lt;p&gt;5 = bbox 개수&lt;br /&gt;
1 = box_confidence = P(Object) * IOU_truth_pred&lt;br /&gt;
4 = boxes = box coordinates (bounding box 좌표 4개: x, y, w, h)&lt;br /&gt;
2 = box_class_probs (예측하고자 하는 class의 개수와 길이가 같다.)&lt;/p&gt;

&lt;p&gt;box_confidence는 그 Cell에 Object가 있을 확률에 IOU_truth_pred를 곱하게 되는데, P(Object)는 당연히 0 또는 1이다. 이 값에 GT_bbox(truth)와 pred_bbox(pred)의 IOU를 계산하여 곱해주면 box_confidence가 되는 것이다. P(Object)가 0일 경우 이 값은 물론 0이 된다.&lt;/p&gt;

&lt;p&gt;boxes의 경우 bbox 좌표를 뜻하는데, 후에 IOU를 계산할 때에는 이와 같이 중심 좌표(x, y)와 box 길이(w, h)를 기준으로 계산하는 것이 불편하기 때문에 왼쪽 상단 좌표(x1, y1)과 오른쪽 하단 좌표(x2, y2)로 고쳐주도록 한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;box_to_corner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;box1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    abs_coord 형식인 bbox의 [x, y, w, h]를 [x1, y1, x2, y2]로 변환한다.
    :param box1: [..., 4]
    :param box2: [..., 4]
    :return: [..., 1] X 8
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b1_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[...,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[...,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[...,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[...,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b2_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[...,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[...,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[...,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[...,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;b1_x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_x2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b1_y1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_y2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;b2_x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_x2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b2_y1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_y2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_y1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b1_y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_y1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b2_y2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고로 현재 https://github.com/KU-DIA/BasicNet에서 관련 코드를 확인할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;blockquote&gt;
    &lt;p&gt;이제 box_class_probs를 보면 이 값은 P(Class_i | Object)를 뜻하는데, Object가 있을 경우 i번째 Class일 조건부 확률을 뜻한다.
사실 이 값만으로는 추후 과정 진행이 어렵기 때문에 위에서 구한 box_confidence와 이 box_class_probs를 브로드캐스팅 곱을 통해 계산해주면,&lt;/p&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;class_scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box_confidence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box_class_probs&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOU&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
             &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Class_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOU&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위와 같이 class_scores를 구할 수 있다.&lt;br /&gt;
이 class_scores 텐서는 본인이 설정한 Class 수만큼의 길이를 가지는데(정확히 “길이”는 아니지만), 본 예에서는 2로 설정하였기 때문에 앞으로도 2라는 숫자를 계속 사용하도록 하겠다.&lt;/p&gt;

&lt;p&gt;이 class_scores는 각각의 box가 가지는 class-specific confidence score를 의미하게 된다. 만약 설정한 Class를 사람, 고양이라고 한다면, 각 class_scores 텐서는 그 Cell이 “사람”을 detect할 확률, “고양이”를 detect할 확률을 담고 있는 것이다.&lt;/p&gt;

&lt;p&gt;이후에 여러 과정이 추가되기는 하지만, 본질적으로 이렇게 표현된 class_scores에서 가장 높은 값을 갖는 class_index를 찾아 output으로 반환하게 된다.&lt;/p&gt;

&lt;p&gt;다시 위로 돌아가서 &lt;strong&gt;[None, 35, 13, 13]&lt;/strong&gt; 구조에서, 35는 5 X 7이라는 것을 확인하였다.&lt;br /&gt;
바로 위에서 7은 1(box_confidence), 4(bbox 좌표), 2(box_class_probs)로 분해되는 것을 보았는데,&lt;br /&gt;
1과 2가 브로드캐스팅 곱을 통해 길이 2의 class_scores로 정리되었다.&lt;br /&gt;
위 class_scores는 cell 기준으로 존재하는데, cell 하나당 5개의 bbox를 갖고, 이러한 cell은 총 13 X 13개 있으므로, 이제 우리는 13 X 13 X 5개의 class_scores 텐서를 갖게 되었다.&lt;/p&gt;

&lt;p&gt;그런데 그냥 이런식으로 진행하게 되면, 845개의 텐서가 등장하는데, 너무 많다.&lt;br /&gt;
이제부터는 텐서의 수를 효과적으로 줄여 학습을 준비하는 과정에 대해 설명하겠다.&lt;br /&gt;
사실 아예 삭제하는 것은 아니고, 필요없는 텐서의 값들을 죄다 0으로 바꿔주는 작업이다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;filter_by_confidence
    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;filter_by_confidence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;confidence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_probs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
 &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
 confidence가 threshold보다 낮은 경우 제거해준다.
 남은 confidence와 class_probs를 곱하여 class_scores를 생성한다.
 :param confidence: (None, 1)
 :param boxes: (None, 4)
 :param class_probs: (None, C)
 :param threshold: 필터링 threshold
 &quot;&quot;&quot;&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;confidence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;confidence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;
    
 &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;하략&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_scores를&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;계산하여&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;반환함&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;용어를 정리하자면, confidence = box_confidence, class_probs = box_class_probs이다.&lt;br /&gt;
위 함수는 일정 threshold보다 작은 box_confidence를 갖는 box_confidence를 아예 0으로 바꿔준다.&lt;br /&gt;
왜냐하면 P(Object)가 0에 근접할 경우, background(Object가 없음)라는 의미인데, 이들의 bbox를 찾는 것은 의미가 없기 때문이다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Non_max_suppression
    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;nms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
 &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
 :param boxes: bbox 좌표, (None, 4)
 :param class_scores: confidence * class_prob_scores, 클래스 별 score, (None, C)
 :param threshold: NMS Threshold
 &quot;&quot;&quot;&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_number&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[...,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

     &lt;span class=&quot;c1&quot;&gt;# 현재 class 내에서 class_score를 기준으로 내림차순으로 정렬한다.
&lt;/span&gt;     &lt;span class=&quot;n&quot;&gt;sorted_class_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sorted_class_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;descending&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

     &lt;span class=&quot;c1&quot;&gt;# idx: 아래 bbox_max의 Index
&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# bbox_max_idx: 정렬된 class_scores를 기준으로 가장 큰 score를 가지는 bbox Index
&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bbox_max_idx&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sorted_class_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())):&lt;/span&gt;
         &lt;span class=&quot;c1&quot;&gt;# 기준 class_score가 0이라면 비교할 필요가 없다.
&lt;/span&gt;         &lt;span class=&quot;c1&quot;&gt;# 아래 threshold 필터링에서 0으로 바뀐 값이기 때문이다.
&lt;/span&gt;         &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bbox_max_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
             &lt;span class=&quot;c1&quot;&gt;# 0이 아니라면 순서대로 criterion_box(bbox_max)로 지정된다.
&lt;/span&gt;             &lt;span class=&quot;n&quot;&gt;bbox_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bbox_max_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;

             &lt;span class=&quot;c1&quot;&gt;# criterion_box(bbox_max)가 아닌 다른 box들을 리스트로 미리 지정한다.
&lt;/span&gt;             &lt;span class=&quot;c1&quot;&gt;#others = [index for index in list(sorted_class_index.numpy()) if index != i]
&lt;/span&gt;             &lt;span class=&quot;n&quot;&gt;others&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sorted_class_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;

             &lt;span class=&quot;c1&quot;&gt;# 비교 대상 box들에 대해서
&lt;/span&gt;             &lt;span class=&quot;c1&quot;&gt;# bbox_cur_idx: 비교 대상 bbox Index
&lt;/span&gt;             &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bbox_cur_idx&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;others&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;bbox_cur&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bbox_cur_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;iou&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_iou&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bbox_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bbox_cur&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                 &lt;span class=&quot;c1&quot;&gt;# print(bbox_max_idx, bbox_cur_idx, iou)
&lt;/span&gt;
                 &lt;span class=&quot;c1&quot;&gt;# iou가 threshold를 넘으면 (기준 box와 비교 대상 box가 너무 많이 겹치면)
&lt;/span&gt;                 &lt;span class=&quot;c1&quot;&gt;# 그 해당 box의 현재 class의 class_score를 0으로 만들어 준다.
&lt;/span&gt;                 &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iou&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                     &lt;span class=&quot;n&quot;&gt;class_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bbox_cur_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;

 &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_scores&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;사실 Cell 별로 각각 bbox를 5개씩 갖게 되면 인접한 Cell들끼리는 bbox가 마구 겹칠 것이다. 또, bbox의 크기가 충분히 클 경우 이미지 바깥으로 벗어나기도 할 것인데, 한 이미지에 Object 수가 수백개 있는 것이 아닌 이상, 이렇게 많은 bbox는 필요하지 않은 것이 자명하다.&lt;/p&gt;

&lt;p&gt;NMS 작업은 이 문제를 효과적으로 해결해준다. 쉽게 말해서 “왕”을 뽑는 느낌인데, 특정 class_scores가 높은 bbox와 과하게 겹치는 (IOU가 높은) 다른 녀석들을 제거하는 것이다.&lt;/p&gt;

&lt;p&gt;“사람”을 detect하는 class_scores를 기준으로 class_scores를 내림차순으로 정렬한다. 제일 큰 첫 번째 값과 나머지 값들을 쌍으로 IOU를 계산하여 과하게 겹치는 (기준 threshold)를 넘는 값은 0으로 바꿔준다.&lt;/p&gt;

&lt;p&gt;이 과정이 끝나면 [None, 35, 13, 13]이라는 크기 자체는 바뀌진 않지만, 중간중간에 많은 숫자가 0으로 바뀌어 있을 것이다. (1, 2번 기준을 충족하지 못한 값들)&lt;br /&gt;
이제 이를 바탕으로 training을 시키면 된다.&lt;/p&gt;

&lt;h3 id=&quot;training&quot;&gt;Training&lt;/h3&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-10-26-YOLOv2/02.jpg&quot; width=&quot;90%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;위 그림은 YOLOv2의 Loss Function이다. YOLO의 최대 장점은 이렇게 Loss Function을 하나로 통합하여 효과적인 학습을 가능하게 했다는 점이다.&lt;/p&gt;

&lt;p&gt;https://curt-park.github.io/2017-03-26/yolo/에서 Loss Function과 관련한 기본적인 설명을 얻을 수 있는데, 추가적으로 설명을 하도록 하겠다.&lt;/p&gt;

&lt;p&gt;먼저 1, 2줄은 bbox 좌표에 관한 Loss Function이다. 앞에 있는 $ \lambda_{coord} $는 5로 설정되었다.&lt;br /&gt;
$ S^2 $은 Grid Cell의 개수를 의미하며 본 예에서는 13 X 13을 의미한다. $ B $는 정해둔 bbox (anchors) 개수이며 본 예에서는 5를 의미한다. 이렇게 모든 Cell에서 5개 씩의 bbox를 계산하여 GT_bbox와 차이를 좁혀나가는 것이다.&lt;/p&gt;

&lt;p&gt;여기서 앵커에 대해 잠깐 설명하자면, 이 앵커는 빠른 학습을 위해 설정된 bbox의 초기값이라고 생각하면 된다. 그냥 무작정 Cell에다가 bbox를 그린다면 그 크기의 편차가 매우 심할 것이다. 미리 object들의 크기를 대략적으로 계산하여 가장 많이 등장할 법한, 가장 유사한 크기의 bbox 크기를 미리 계산해두어 저장한 것이 바로 앵커인데, 이는 보통 Clustering 기법을 통해 미리 계산된다.&lt;/p&gt;

&lt;p&gt;이렇게 미리 계산된 앵커를 초기값으로 투입하고, GT_bbox 좌표와의 차이를 빠르게 줄여 나가는 것이 1, 2번째 줄의 목표라고 하겠다.&lt;/p&gt;

&lt;p&gt;그리고 $ 1_{i, j}^{obj} $ 라는 Indicator Function의 기능이 매우 중요한데, 이 지시함수는 i번째 Grid Cell에서 j번째 bbox에 Object가 존재할 경우 1이고, 아니면 0이다.&lt;/p&gt;

&lt;p&gt;아래의 $ 1&lt;em&gt;{i, j}^{noobj} $ 는 반대의 의미를 가지며, $ 1&lt;/em&gt;{i}^{obj} $ 는 오직 Cell 소속 여부와 관련이 있다.&lt;/p&gt;

&lt;p&gt;3, 4번째 줄은 Object가 있는지 없는지에 대한 Loss를 계산하게 되고,&lt;br /&gt;
5번째 줄은 P(Class_i | Object) = Conditional Class Probability의 Loss를 계산하게 된다.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;빠른 속도와 괜찮은 정확도를 가졌지만 YOLOv2의 단점은 작은 물체나 겹치는 물체들을 효과적으로 Localization하지 못한다는 것이다. 이는 version3에서 상당부분 업그레이드 된다.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Attention</title>
   <link href="http://localhost:4000/Attention/"/>
   <updated>2018-09-17T00:00:00+09:00</updated>
   <id>http://localhost:4000/Attention</id>
   <content type="html">&lt;h3 id=&quot;neural-machine-translation-by-jointly-learning-to-align-and-translate&quot;&gt;Neural Machine Translation by Jointly Learning to Align and Translate&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;본 글은 Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio가 2014년에 Publish한 위 논문을 리뷰한 것이다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Basic Encoder-Decoder 모델은 source sentence의 모든 정보를 fixed-length vector로 압축하는 방식을 골자로 한다.&lt;br /&gt;
그러나 이 모델은 긴 문장을 대상으로 할 때 어려움을 겪는 것이 일반적이다.&lt;br /&gt;
이를 해결하기 위해 본 논문에서 제안된 새로운 모델은 &lt;strong&gt;target word&lt;/strong&gt;를 예측하는 것과 관련된 source sentence의 부분을 자동적으로 soft-search하여 이와 같은 문제를 해결해낸다.&lt;br /&gt;
(learns to align and translate jointly)&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;encodes the input sentence into sequence of vectors and&lt;br /&gt;
chooses a subset of these vectors adaptively while decoding the translation.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;background-nmt&quot;&gt;Background: NMT&lt;/h3&gt;
&lt;p&gt;translation의 핵심은 source sentence &lt;strong&gt;x&lt;/strong&gt;가 주어졌을 때의 &lt;strong&gt;y&lt;/strong&gt;의 조건부확률을 최대화하는 target sentence &lt;strong&gt;y&lt;/strong&gt;를 찾는 것이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;arg\max_{y} p(\vec{y}|x)&lt;/script&gt;

&lt;p&gt;번역 모델에 의해 이러한 조건부 분포가 학습되면, source sentence가 주어졌을 때 상응하는 번역된 문장은 위의 조건부 확률을 최대화하는 문장을 찾음으로써 generate된다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;RNN Encoder-Decoder&lt;/em&gt;는 이전 리뷰에서 다룬 적이 있으므로 생략하도록 한다.&lt;/p&gt;

&lt;h3 id=&quot;learning-to-align-and-translate&quot;&gt;Learning to align and translate&lt;/h3&gt;
&lt;p&gt;모델의 구성 요소를 하나하나 살펴보기 이전에 notation에 관한 정리를 진행하겠다.&lt;/p&gt;

&lt;p&gt;$y_i$: i time에서의 target word&lt;br /&gt;
$s_i$: i time에서의 디코더 Hidden State&lt;br /&gt;
$c_i$: i time에서의 context vector = annotations의 가중합&lt;br /&gt;
$\alpha_{ij}$: attention weight = normalized score = 연결 확률&lt;br /&gt;
$h_j$: j time에서의 인코더 Hidden State = annotations&lt;br /&gt;
$e_{ij}$: attention score = unnormalized score&lt;br /&gt;
$f, g$ = 비선형 함수&lt;/p&gt;

&lt;p&gt;명확히 하자면, subscript &lt;strong&gt;i&lt;/strong&gt;는 디코더를 명시하며, subscript &lt;strong&gt;j&lt;/strong&gt;는 인코더를 명시한다.&lt;/p&gt;

&lt;p&gt;이제 모델의 구성 요소를 살펴볼 것이다.&lt;br /&gt;
먼거 타겟 word $y_i$를 예측하기 위한 조건부 확률은 아래와 같이 정의된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y_i|y_1, ..., y_{i-1}, \vec{x}) = g(y_{i-1}, s_i, c_i)&lt;/script&gt;

&lt;p&gt;이 중 디코더의 i time Hidden State인 $s_i$를 먼저 살펴보면,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s_i = f(s_{i-1}, y_{i-1}, c_i)&lt;/script&gt;

&lt;p&gt;Basic Encoder-Decoder 모델과 달리 target word를 예측하기 위한 조건부 확률은 분리된 context vector $c_i$에 의존한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Context Vector&lt;/strong&gt; $c_i$는 annotations $h_j$의 가중합이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;c_i = \sum_{j=1}^{T_x} \alpha_{ij} h_j&lt;/script&gt;

&lt;p&gt;여기서 $h_j$는 j time annotation으로, input sequence의 i번째 단어 주위 부분에 강하게 집중하여 input sequence에 대한 정보를 담게 된다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Bidirectional RNN&lt;/em&gt;&lt;br /&gt;
이 $h_j$는 forward RNN의 Hidden States와 backward RNN의 Hidden States를 세로로 합친 열벡터이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_j = [\overrightarrow{h_j}^T | \overleftarrow{h_j}^T]^T&lt;/script&gt;

&lt;p&gt;이러한 방식으로 $h_j$는 두 방향 모두로 words들을 요약한 정보를 담게 된다.&lt;/p&gt;

&lt;p&gt;이제 &lt;strong&gt;attention weight&lt;/strong&gt; $a_{ij}$가 어떻게 계산되는지 살펴보겠다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;a_{ij} = \frac{ exp(e_{ij}) } {\sum_{k=1}^{T_x} exp(e_{ik}) }&lt;/script&gt;

&lt;p&gt;이 $a_{ij}$는 &lt;strong&gt;Normalized Score&lt;/strong&gt;라고 할 수 도 있다. 왜냐하면 softmax함수의 확률로서 계산되기 때문이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Unnormalized Score&lt;/strong&gt;인 $e_{ij}$는 아래와 같이 계산된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e_{ij} = a(s_{i-1}, h_j)&lt;/script&gt;

&lt;p&gt;여기서 a함수는 &lt;strong&gt;alignment model&lt;/strong&gt;이다. 이 a를 다른 component와 함께 학습되는 순전파 신경망으로서 모수화한다.&lt;br /&gt;
이 alignment model은 j time 인풋이 i time 아웃풋과 얼마나 유사한지를 평가하게 된다.&lt;br /&gt;
또한 이 모델은 잠재변수로 설정되지 않고, soft alignment를 직접적으로 계산하여 cost function의 gradient가 역전파될 수 있도록 하게 만든다.&lt;br /&gt;
계산 방법은 마지막 부분에서 설명하도록 하겠다.&lt;/p&gt;

&lt;p&gt;위 설명을 보면, 결국 i번째 &lt;strong&gt;Context Vector&lt;/strong&gt;인 $c_i$는 expected annotation over all the annotations with probabilities $\alpha_{ij}$라고 할 수 있다.&lt;br /&gt;
이 $\alpha_{ij}$는 다음 Hidden State인 $s_i$를 결정하고 target word $y_i$를 generate하는 데에 있어 $h_j$의 중요성을 결정하는 역할을 하게 된다.&lt;/p&gt;

&lt;p&gt;즉 이는 일종의 &lt;strong&gt;attention&lt;/strong&gt;이라는 개념으로 설명될 수 있다.&lt;br /&gt;
디코더는 source sentence의 어떤 부분에 &lt;strong&gt;집중&lt;/strong&gt;해야 하는지 결정하게 되는 것이다.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;제안된 모델은 다음 target word를 generate하는 데에 관련이 있는 정보에만 집중하며 이 때문에 source sentence의 길이에 상당히 robust하다.&lt;br /&gt;
다만 unknown or rare words를 다루는 데 있어서는 좀 더 보완이 필요하다.&lt;/p&gt;

&lt;h3 id=&quot;details-about-model-architecture&quot;&gt;Details about Model Architecture&lt;/h3&gt;
&lt;p&gt;이 부분에서는 Appendix에 나와 있는 수식들을 종합하여, 본 논문에서 제안한 RNNSearch라는 모델의 구조에 대해 정리하도록 하겠다.&lt;br /&gt;
논문이 굉장히 친절하여 Matrix의 차원이 정확하고 자세하게 나와있으므로 반드시 참고할 필요가 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;상수에 대한 설명은 아래와 같다.&lt;br /&gt;
$m$: word embedding 차원, 본 모델에선 620 &lt;br /&gt;
$n$: 인코더/디코더 Hidden Units의 수, 본 모델에선 1000&lt;br /&gt;
$n’$: Alignment Model 내에서의 Hidden Units의 수, 본 모델에선 1000&lt;br /&gt;
$l$: , 본 모델에선 500&lt;br /&gt;
$T_x$: source sentence의 길이&lt;br /&gt;
$K_x$: source language의 vocab_size&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;벡터들의 크기는 아래와 같다.&lt;br /&gt;
$y_i$: (k, 1)&lt;br /&gt;
$s_i$: (n, 1)&lt;br /&gt;
$h_i$: (n, 1)&lt;br /&gt;
$v_a$: (n’, 1)&lt;br /&gt;
$z_i$: (n, 1)&lt;br /&gt;
$r_i$: (n, 1)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;행렬들의 크기는 아래와 같다. W, U, C는 모두 Parameter Matrix이다.&lt;br /&gt;
$X$: ($T_x$, $K_x$)&lt;br /&gt;
$Y$: ($T_y$, $K_y$)&lt;br /&gt;
$E$: (m, K), x와 결합할 때는 $K_x$, y와 결합할 때는 $K_y$&lt;br /&gt;
$W$: (n, m), $W, W_z, W_r$에 한정&lt;br /&gt;
$W_a$: (n’, n), Alignment 모델에서 사용&lt;br /&gt;
$U$: (n, n), $U, U_z, U_r$에 한정&lt;br /&gt;
$U_a$: (n’, 2n), Alignment 모델에서 사용&lt;br /&gt;
$C$: (n, 2n), $C, C_z, C_r$에 한정&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Encoder&lt;/strong&gt;&lt;br /&gt;
source sentence Matrix &lt;strong&gt;X&lt;/strong&gt;는 번역 대상인 하나의 문장을 뜻한다.&lt;br /&gt;
각각의 열벡터는 $\vec{x_i}$로 표기되며 이 벡터의 크기는 $K_x$로,&lt;br /&gt;
source language의 vocab_size를 의미한다.&lt;/p&gt;

&lt;p&gt;인코더의 Bidirectional RNN은 아래와 같이 계산된다.&lt;br /&gt;
(Bias항은 잠시 삭제한다.)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h_j = (1 - z_i) \odot h_{j-1} + z_i \odot \tilde{h_j}&lt;/script&gt;

&lt;p&gt;위에서 $z_i$가 Update Gate이며, 각 Hidden State가 이전 activation을 유지하느냐 마느냐를 결정한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{h_j} = tanh(W*Ex_j + U[r_j \odot h_{j-1}])&lt;/script&gt;

&lt;p&gt;위에서 $r_j$가 Reset Gate이며, 이전 State의 정보를 얼마나 Reset할지 결정한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;z_j = \sigma(W_z * Ex_j + U_z * h_{j-1})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r_j = \sigma(W_r * Er_j + U_x * h_{j-1})&lt;/script&gt;

&lt;p&gt;위에서 계산한 식은 $\overrightarrow{h_j}$, $\overleftarrow{h_j}$ 모두에게 통용되며,&lt;br /&gt;
이를 stack하여 annotation $h_j$를 만들게 되는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Decoder&lt;/strong&gt;&lt;br /&gt;
디코더의 Hidden State인 $s_i$ 역시 계산 방식은 유사하다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;s_i = (1 - z_i) \odot s_{i-1} + z_i \odot \tilde{s_i}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{s_i} = tanh(W*Ex_i + U[r_i \odot s_{i-1}] + C*c_i)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;z_i = \sigma(W_z * Ex_i + U_z * s_{i-1} + C_zc_i)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;r_i = \sigma(W_r * Er_j + U_x * s_{i-1} + C_rc_i)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;c_i = \sum_{j=1}^{T_x}a_{ij}h_j&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;a_{ij} = \frac{ exp(e_{ij}) } {\sum_{k=1}^{T_x} exp(e_{ik}) }&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;e_{ij} = v_a^T tanh(W_a * s_{i-1} + U_a * h_j)&lt;/script&gt;

&lt;p&gt;최종적으로 Decoder State $s_{i-1}$, Context Vector $c_i$, 마지막 generated word $y_{i-1}$을 기반으로, target word $y_i$의 확률을 아래와 같이 정의한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(y_i|s_i, y_{i-1}, c_i) \propto exp(y_i^T W_o t_i)&lt;/script&gt;

&lt;p&gt;즉 오른쪽 편에 있는 스칼라값에 정비례한다는 뜻이다.&lt;br /&gt;
잠시 행렬의 차원을 정의하고 진행하겠다.&lt;/p&gt;

&lt;p&gt;$W_o$: ($K_y$, $l$)&lt;br /&gt;
$U_o$: ($2l$, n)&lt;br /&gt;
$V_o$: ($2l$, m)&lt;br /&gt;
$C_o$: ($2l$, 2n)&lt;br /&gt;
이들은 모두 Parameter이다.&lt;/p&gt;

&lt;p&gt;이제 $t_i$를 정의할 것인데, 그 전에 두 배 크기인 candidate $\tilde{t_i}$를 먼저 정의하겠다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\tilde{t_i} = U_o * s_{i-1} + V_o * Ey_{i-1} + C_oc_i&lt;/script&gt;

&lt;p&gt;차원을 맞춰보면 위 벡터는 크기가 ($2l$, 1)인 것을 알 수 있을 것이다.&lt;br /&gt;
이제 이 벡터에서 아래와 같은 maxout과정을 거치면,&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-09-27-Attention/a1.png&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;$t_i$는 아래와 같이 정의된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;t_i = [ max(\tilde{t_{i, 2j-1}}, \tilde{t_{i, 2j}}) ]_{j=1, ..., l}^T&lt;/script&gt;

&lt;p&gt;아주 멋지다.&lt;br /&gt;
&lt;strong&gt;The End&lt;/strong&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>RNN Encoder-Decoder</title>
   <link href="http://localhost:4000/RNN-Encoder-Decoder/"/>
   <updated>2018-09-10T00:00:00+09:00</updated>
   <id>http://localhost:4000/RNN Encoder-Decoder</id>
   <content type="html">&lt;h3 id=&quot;learning-phrase-representations-using-rnn-encoder-decoder-for-statistical-machine-translation&quot;&gt;Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;본 글은 Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio가 2014년에 Publish한 위 논문을 리뷰한 것이다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Abstract&lt;/strong&gt;&lt;br /&gt;
Encoder의 역할은 a sequence of symbols를 고정된 길이의 vector representation으로 나타내는 것이고, Decoder의 역할은 그 representation을 다시 sequence of symbols로 나타내는 것이다.&lt;/p&gt;

&lt;p&gt;두 모델은 jointly train되는데, 그 목적은 source sequence가 주어졌을 때,&lt;br /&gt;
target sequence가 나타날 조건부 확률을 최대화하는 것이다.&lt;br /&gt;
= (Maximize the conditional probability of a target sequence given a source sequence.)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;br /&gt;
본 논문은 SMT(Statistical Machine Translation)의 영역에서 모델을 분석하는 것을 주요 목적으로 하고 있다.&lt;/p&gt;

&lt;p&gt;연구자들은 memor capacity와 학습 효율을 향상시키기 위해 다소 복잡한(sophiscated) Hidden Unit을 사용하였으며, 영어를 프랑스어로 번역하는 과정을 통해 그 성능을 평가하였다.&lt;/p&gt;

&lt;p&gt;본 논문에서 제안한 RNN Encoder의 경우 phrase table에서 언어학적 규칙(regularities)을 잡아내는 역할을 수행하였으며 이는 사실 전반적인 번역 성능의 향상을 꾀하는 과정의 일부로 평가된다. Decoder의 경우 phrase의 continuous space representation을 학습하는데, 이는 phrase의 의미론적(semantic)이고 통사론적(syntactic) 구조를 저장하는 역할을 수행한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RNN Encoder-Decoder&lt;/strong&gt;&lt;br /&gt;
기본적인 RNN은 sequence에서 다음 symbol을 예측하는 방향으로 학습됨으로써 sequence의 확률 분포를 학습한다.&lt;br /&gt;
이 때 시간t에 대한 output은 $ p(x_t | x_{t-1}, …, x_1) $와 같은 조건부 확률로 표현된다.&lt;br /&gt;
따라서 sequence &lt;strong&gt;x&lt;/strong&gt;의 확률은 아래와 같이 표현할 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(x) = \prod_{t=1}^T p(x_t | x_{t-1}, ..., x_1)&lt;/script&gt;

&lt;p&gt;(위 $p(x)$의 x는 &lt;strong&gt;x&lt;/strong&gt; vector이며, 위와 같은 식으로 표현되는 이유는 곱셈정리에 의한 것임)&lt;br /&gt;
이전의 symbol들에 근거하여 다음 symbol을 예측한다고 볼 수 있다.&lt;/p&gt;

&lt;p&gt;본 논문에서 제안하는 RNN Encoder-Decoder 모델은 다소 새로운 구조를 갖고 있다. Encoder는 input sequence &lt;strong&gt;x&lt;/strong&gt;의 원소 symbol들을 연속적으로 읽어 들인다.&lt;br /&gt;
(reads each symbol of an input sequence &lt;strong&gt;x&lt;/strong&gt; sequentially)&lt;/p&gt;

&lt;p&gt;이 과정 속에서 시간 t의 hidden state는 아래와 같이 업데이트 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
h_{&lt;t&gt;} = f(h_{&lt;t-1&gt;}, x_t) %]]&gt;&lt;/script&gt;

&lt;p&gt;즉, 이전 hidden state와 시간t의 새로운 input $x_t$에 의해 업데이트 되는 것이다.&lt;br /&gt;
모든 reading이 끝나고 나서 나면 RNN의 hidden state는 모든 input sequence에 대한 summary &lt;strong&gt;c&lt;/strong&gt;이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-09-10-RNN-Encoder-Decoder/r1.jpg&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;Decoder는 주어진 hidden state $h_{&lt;t-1&gt;}$을 바탕으로  
다음 symbol $ y_{&lt;t&gt;} $를 예측함으로써 output sequence를 생성하도록 학습된다.&lt;/t&gt;&lt;/t-1&gt;&lt;/p&gt;

&lt;p&gt;다만 여기서 주목할 점은, 기본 RNN과 달리 새로운 hidden state는 summary &lt;strong&gt;c&lt;/strong&gt;와&lt;br /&gt;
이전 output symbol $ y_{t-1} $에도 conditioned 되어 있다는 것이다.&lt;br /&gt;
즉 아래와 같이 표현될 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
h_{&lt;t&gt;} = f(h_{&lt;t-1&gt;}, y_{t-1}, c) %]]&gt;&lt;/script&gt;

&lt;p&gt;다음 symbol의 조건부 확률 분포는 아래와 같이 나타낼 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
P(y_t | y_{t-1}, ..., y_1, c) = g(h_{&lt;t&gt;}, y_{t-1}, c) %]]&gt;&lt;/script&gt;

&lt;p&gt;정리하자면, RNN Encoder-Decoder의 두 성분은 아래의 조건부 로그 가능도를 최대화하도록 결합하여 학습된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\max_{\theta} {1 \over N} \sum_{n=1}^N log p_{\theta} (y_n|x_n)&lt;/script&gt;

&lt;p&gt;여기서 $\theta$는 모델 parameter의 집합을 의미하며,&lt;br /&gt;
$y_n$은 output sequence를 $x_n$은 input sequence를 의미한다.&lt;/p&gt;

&lt;p&gt;이렇게 학습된 RNN Encoder-Decoder는 크게 2가지 방법으로 활용될 수 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;주어진 input sequence에 대해 새로운 target sequence를 생성할 수 있다.&lt;/li&gt;
  &lt;li&gt;input &amp;amp; output sequences 쌍의 적합성을 평가할 수 있다. (Score)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;2.3절인 &lt;em&gt;Hidden Unit that Adatively Remembers and Forgets&lt;/em&gt;부분은 LSTM Unit의 기본 형식을 따르고 있기 때문에 식에 대한 리뷰는 생략하겠다. 다만 사용된 용어만을 살펴 보면 아래과 같다.&lt;/p&gt;

&lt;p&gt;Reset Gate $r_j$, Update Gate $z_j$, Proposed Unit $h_j^{t}$&lt;/p&gt;

&lt;p&gt;효과에 대해 설명하자면,&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Reset Gate가 0에 가까워질 때, 시간 t의 &lt;strong&gt;Candidate hidden state&lt;/strong&gt;는 이전 hidden state를 잊고(ignore, forget) 시간 t의 현재 input x로 Reset하게 된다.&lt;/li&gt;
  &lt;li&gt;Updated Gate는 이전(시간 t-1) hidden state의 정보가 얼마나 현재(시간 t) hidden state에 영향을 줄 것인가를 결정한다. 이를 통해 lont-term 정보를 효과적으로 보존(rembember)한다.&lt;/li&gt;
  &lt;li&gt;각각의 hidden unit은 Reset/Update Gate를 각각 갖고 있기 때문에, different time scales에 나타나는 종속성(dependencies)를 포착(capture)하는 법을 학습하게 된다. short-term dependencies를 포착하는 법을 학습한 unit들의 Reset Gate는 자주 활성화 될 것이며, long-term dependencies를 포착하는 법을 학습한 unit들의 Update Gate는 자주 활성화될 것이다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Statistical Machine Translation: SMT&lt;/strong&gt;&lt;br /&gt;
앞에서도 설명하였듯이 SMT의 기본 목표는 주어진 source sentence에 대하여 translation을 찾는 것이고, 식으로 표현하자면 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(f|e) \propto p(e|f) * p(f)&lt;/script&gt;

&lt;p&gt;일단 Phrase Pairs를 평가하는 측면에서 본 모델을 살펴보도록 하겠다.&lt;br /&gt;
RNN Encoder-Decoder를 학습시킬 때, 기존 말뭉치들에서 각각의 phrase pair들의 출현 빈도는 고려하지 않는다.&lt;br /&gt;
그 이유는 2가지로 풀이 된다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;계산량 감소를 위해서이다.&lt;/li&gt;
  &lt;li&gt;본 모델이 단순히 출현빈도 Rank에 영향을 받지 않게 하기 위함이다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;사실 phrase 속에 존재하는 translation probability는 이미 원래 corpus의 phrase pairs의 출현 빈도를 반영한다. 모델이 학습 과정 속에서 이러한 출현 빈도에 따른 어떤 규칙을 학습하는 것이 아니라, 언어학적 규칙(linguistic regularities)을 학습하도록 하는 것이 핵심이라고 할 수 있다.&lt;br /&gt;
(learning the manifold of plausible translations)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Experiments&lt;/strong&gt;&lt;br /&gt;
대규모의 데이터가 구축되었지만 실제 학습을 위해서 본 논문의 저자는 source &amp;amp; target vocab을 가장 자주 등장한 15,000개의 단어로 한정하였다. 이는 전체 데이터셋의 93%를 커버한다고 밝혔다.&lt;/p&gt;

&lt;p&gt;학습과정에 대한 자세한 사항은 논문을 참조하기 바란다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;&lt;br /&gt;
결과적으로 RNN Encoder-Decoder는 phrase pairs 내에 있는 언어학적 규칙을 포착하고, 적절하게 구성된 target phrases 또한 제안하는 데에도 좋은 성능을 보이는 것으로 확인되었다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Structure of Encoder&lt;/strong&gt;&lt;br /&gt;
source phrase X와 Y의 형태는 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X = (x_1, x_2, ... , x_N), Y = (y_1, y_2, ... , y_N)&lt;/script&gt;

&lt;p&gt;X.shape = (N, K), Y.shape = (N, K)&lt;/p&gt;

&lt;p&gt;물론 여기서 각 세로 벡터는 one-hot vector이다.&lt;br /&gt;
source phrase의 각 단어는 500차원의 벡터로 임베딩된다.&lt;br /&gt;
Encoder의 Hidden state는 1000개의 unit을 갖고 있다.&lt;br /&gt;
(시간 t의 hidden state $h_{&lt;t-1&gt;}$의 shape = (1000, 1))&lt;/t-1&gt;&lt;/p&gt;

&lt;p&gt;위 hidden state가 계산되는 과정을 살펴보면,&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Reset Gate&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
r = \sigma(W_r e(x_t) + U_r h_{&lt;t-1&gt;}) %]]&gt;&lt;/script&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;(1000, 1) = (1000, 500) X (500, 1) + (1000, 1000) X (1000, 1)&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Update Gate&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
z = \sigma(W_z e(x_t) + U_z h_{&lt;t-1&gt;}) %]]&gt;&lt;/script&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;shape은 위와 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Candidate&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\tilde{h}^{&lt;t&gt;} = tanh(W e(x_t) + U(r \odot h_{&lt;t-1&gt;} )) %]]&gt;&lt;/script&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;(1000, 1) = (1000, 500)X(500, 1) + (1000, 1000)X(1000, 1)$\odot$(1000, 1)&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Hidden State&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
h^{&lt;t&gt;} = z h^{&lt;t-1&gt;} + (1-z) \tilde{h}^{&lt;t&gt;} %]]&gt;&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Representatino of the source phrase: 농축된 정보&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
c = tanh(V h^{&lt;t&gt;}) %]]&gt;&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Structure of Decoder&lt;/strong&gt;&lt;br /&gt;
Soon to be updated&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Vehicle Color Recognition</title>
   <link href="http://localhost:4000/Vehicle-Color-Recognition/"/>
   <updated>2018-09-07T00:00:00+09:00</updated>
   <id>http://localhost:4000/Vehicle Color Recognition</id>
   <content type="html">&lt;h3 id=&quot;vehicle-color-recognition-using-cnn&quot;&gt;Vehicle Color Recognition using CNN&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;본 글은 Reza Fuad Rachmadi, I Ketut Eddy Purnama가 2018년에 Publish한 위 논문을 리뷰한 것이다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;br /&gt;
본 논문의 목표는 Color Distribution에 기반하여 CNN을 통해 색깔을 classify하는 것이다. RGB의 경우 정확히 분포로 분류할 수 없기 때문에 CIE Lab과 HSV로 변환 후 분석에 들어가도록 하였다. 데이터셋은 Vehicle(자동차)로 정하였다. (p1)&lt;/p&gt;

&lt;p&gt;Color Detection이 쉽지 않은 이유는 여러가지가 있지만 대표적인 예로, 날씨의 변화, 영상/이미지의 품질 차이, 문양/패턴의 차이 등을 들 수 있다.&lt;br /&gt;
또한 이와 더불어 명백한 단색을 제외하고는 사람에 따라 색깔 인식 내지는 분류를 하는 방식이 다르기 때문이다.&lt;br /&gt;
이렇기 때문에 사실 그 물체의 어떤 부분을 확인하여 색깔 구분의 핵심으로 삼는지가 굉장히 중요한 방법이다. 예를 들어 ‘차’의 색깔을 구분한다고 할 때, 타이어의 색깔로 구분을 짓는 사람은 별로 없을 것이다. 그보다는 차체의 보닛을 중심으로 색깔을 구분할 것이다.&lt;br /&gt;
이 때문에 Region Selection 역시 색깔 구분에 있어 핵심적인 역할을 수행한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;CNN Architecture&lt;/strong&gt;&lt;br /&gt;
구조는 일반적인 CNN에서 특별히 변화된 부분이 없다. 사실 Alexnet과 거의 유사한 형태를 지녔고, 마지막에 많은 수의 Parameter를 포함하는 Fully Connected Layer를 삽입하였기 때문에, 학습에 시간이 조금 소요될 것으로 예상되었다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Results and Discusssion&lt;/strong&gt;&lt;br /&gt;
결과는 나쁘지 않은 수준이다. 이 논문의 경우 특별히 다른 방법을 적용하였다기 보다는 기본 CNN을 적용하여 8개의 단색에 대해 Classification을 수행하였기 때문에, 기본적인 구조로도 충분한 결과를 얻은 것으로 보인다.&lt;br /&gt;
다만 Gray와 Green 색깔 구분에 있어 약간의 어려움을 겪었고 (정확도가 대략 10% 가까이 떨어짐), Gray와 White 색깔 구분 역시도 약간의 어려움을 겪은 것으로 결과가 나타났다.&lt;br /&gt;
이는 사실상 색깔이란 것이 이산형으로 보기 어려운 구분 방식을 따르기 때문으로 풀이된다.&lt;br /&gt;
논문은 구분 논리에 대해 자세히 설명하고 있지는 않지만, 첫 번째 CNN Layer가 low-level feature를 추출한다는 설명을 제공하고 있다. 이는 다른 Object Detection과 크게 다르지 않은 논리이다.&lt;br /&gt;
이후 Lyaer들은 차량의 전면 부분의 이미지를 추출하여 Color Detection의 핵심적인 부분으로 삼고 있는 것을 확인할 수 있었으며, 이는 사람의 인식 방법과 유사함을 알 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;추가적 논의&lt;/strong&gt;&lt;br /&gt;
이 부분은 논문에 게재된 내용이 아니고, 필자가 다른 작은 프로젝트를 수행하면서 다른 접근법에 대해 생각해보다가 이해한 내용을 덧붙인 것이다.&lt;/p&gt;

&lt;p&gt;Superpixel이란 개념이 있다. Segmentation에 있어 상당히 많이 사용되는 개념인데, 유사한 pixel 값들을 하나의 평균 값으로 묶어서 표현하는 것이다.&lt;br /&gt;
Segment의 수에 따라 마치 blur처리를 한 듯한 느낌이 들기도 한다.&lt;/p&gt;

&lt;p&gt;이를 구현하는 방법은 여럿 있겠지만 skimage라는 파이썬 패키지가 매우 유용하다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;image_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'~/target.jpg'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_to_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;255.&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# n_segments: 몇 개의 구역으로 나누고 싶은가?
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;segmentation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;slic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compactness&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_segments&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;regions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;regionprops&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;input_img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label2rgb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'avg'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;위와 같은 코드를 이미지에 적용하면 Superpixel을 구현할 수 있다. 이렇게 유사한 Pixel들을 묶어 색깔의 다양성을 줄이고 나면, 색깔 판별에 좀 더 도움이 될 것으로 판단하였다.&lt;/p&gt;

&lt;p&gt;이후에 색깔을 추출해 내는 방법은 크게 2가지가 있을 것으로 생각된다.&lt;br /&gt;
먼저 이후에 CNN을 적용하여 위 논문과 유사한 방식으로 색깔을 하나 판별해 내는 것인데, 이 역시 괜찮은 성능을 보이는 것으로 확인되었다.&lt;br /&gt;
그런데 만약 색깔이 여러개라면? 단색이 아니라, 줄무늬 내지는 물방울 문양을 가진 옷을 판별해야 하다면?&lt;br /&gt;
이 때는 Superpixel화 된 이미지 데이터에 Kmeans Clustering을 적용하여 유사한 색깔들을 소수의 군집으로 묶고, 이 중 높은 빈도수를 보이는 색깔들을 중심 색깔들로 추출할 수 있을 것이다.&lt;/p&gt;

&lt;p&gt;아래 블로그에서 예시를 찾을 수 있었다.&lt;br /&gt;
https://technology.condenast.com/story/handbag-brand-and-color-detection&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>GRU</title>
   <link href="http://localhost:4000/GRU/"/>
   <updated>2018-09-07T00:00:00+09:00</updated>
   <id>http://localhost:4000/GRU</id>
   <content type="html">&lt;h3 id=&quot;empirical-evaluation-of-gated-recurrent-nn-on-sequence-modeling&quot;&gt;Empirical Evaluation of Gated Recurrent NN on Sequence Modeling&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;본 글은 Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, Yoshua Bengio가 2014년에 publish한 Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling을 리뷰한 것이다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Background&lt;/strong&gt;&lt;br /&gt;
RNN은 전통적인 feedforward NN의 확장판으로 이해할 수 있다. 가장 큰 특징 중 하나는 이 네크워크는 variable-length sequence input을 처리할 수 있다는 것이다.(p1)&lt;br /&gt;
본 논문은 LSTM과 GRU의 비교를 main purpose로 두고 있다.&lt;br /&gt;
그 이유는 LSTM이 효과적이기는 하나 상대적으로 복잡한 구조를 갖고 있기도 하고,&lt;br /&gt;
제안된 GRU가 구조가 조금 더 단순함에도 불구하고 일부 경우에서 더 나은 성능을 보였기 때문이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Long Short-Term Memory Unit&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;LSTM Unit의 구조는 아래와 같다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-09-07-GRU/G1.png&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;시간 t에 대하여 j번 째 LSTM Unit은 아래와 같은 구조를 가진다.&lt;/p&gt;

&lt;p&gt;Candidate $ \tilde{c} $에 대하여&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\tilde{c}_t^j = tanh(W_c * x_t + U_c * h_{t-1})^j&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Memory Cell $c$에 대하여&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;c_t^j = f_t^j * c_{t-1}^j + i_{t}^j * \tilde{c}_t^j&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Output Gate $o$에 대하여&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;{o}_t^j = \sigma(W_o * x_t + U_o * h_{t-1} + V_o * c_t)^j&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Output $h$에 대하여&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;h_t^j = o_t^j * tanh(c_t^j)&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;LSTM 구조의 핵심은 총 3개의 Gate(Input Gate, Forget Gate, Output Gate)를 통해 저장될 정보를 적절히 컨트롤한다는 것이다.&lt;br /&gt;
&lt;strong&gt;Forget Gat&lt;/strong&gt;의 경우 $ c_{t-1}^j $ (과거 정보)를 버릴 것인지 말 것인지를 결정하고,&lt;br /&gt;
&lt;strong&gt;Input Gate&lt;/strong&gt;의 경우 시간 t의 candidate로 업데이트를 할 것인지 말 것인지를 결정하게 된다.&lt;br /&gt;
최종적으로 &lt;strong&gt;Output Gate&lt;/strong&gt; $ o_{t}^j $는 hyperbolic tangent activation function을 통과한 $ c_t^j $와 곱해져 &lt;strong&gt;Output&lt;/strong&gt; $ h_t^j $를 형성하게 된다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gated Recurrent Unit&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;GRU Unit의 구조는 아래와 같다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018-09-07-GRU/G2.png&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;시간 t에 대하여 j번 째 GRU Unit은 아래와 같은 구조를 가진다.&lt;/p&gt;

&lt;p&gt;Reset Gate $r$에 대하여&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;{r}_t^j = \sigma(W_r * x_t + U_r * h_{t-1})^j&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Candidate $ \tilde{h} $에 대하여&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;\tilde{h}_t^j = tanh(W * x_t + U * (r_t \odot h_{t-1})^j&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reset Gate&lt;/strong&gt;는 과거의 Activation value ($ h_{t-1} $)이 새로운 후보 $\tilde{h}_{t}$에 영향을 줄 것인지 말 것인지를 결정하는 관문의 역할을 한다.&lt;/p&gt;

&lt;p&gt;만약 위의 Reset Gate이 0에 가까울 경우, 바로 위의 식의 오른쪽 부분이 0이 됨으로써, 
자연스럽게 과거의 값 ($h_{t-1}$)을 잊게 해준다. (Forget) 참고로 식의 오른쪽 편의 $\odot$은 Elementwise Multiplication을 뜻한다.&lt;/p&gt;

&lt;p&gt;자 이제 &lt;strong&gt;Candidate&lt;/strong&gt;이 준비되었다.&lt;/p&gt;

&lt;p&gt;Memory Cell $c$에 대하여&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;c_t^j = f_t^j * c_{t-1}^j + i_{t}^j * \tilde{c}_t^j&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Update Gate $z$에 대하여&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;{z}_t^j = \sigma(W_z * x_t + U_z * h_{t-1})^j&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;이 &lt;strong&gt;Update Gate&lt;/strong&gt;는 얼마나 새로운 값으로 업데이트하고 싶은지를 결정하게 되는데, 이 말은 아래 식에서 이 &lt;strong&gt;Update Gate&lt;/strong&gt;의 값이 0에 가까울 경우 (sigmoid를 통과하였으므로) &lt;strong&gt;Candidate&lt;/strong&gt;의 영향력은 0가 되는 것이고, 이전 Activation $h_{t-1}$이 그대로 살아남는 것을 의미한다.&lt;/p&gt;

&lt;p&gt;Output $h$에 대하여&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;h_t^j = (1- z_t^j) * h_{t-1}^j + z_t^j * \tilde{h}_t)^j&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Discussion&lt;/strong&gt;&lt;br /&gt;
LSTM과 GRU가 기존의 traditional한 구조와 가장 차별화되는 포인트는 아래와 같다.&lt;br /&gt;
1) 각각의 Unit은 여러 단계에 걸친 input stream에 있어 구체적인 feature의 존재를 지속적으로 기억하는 데에 있어 좋은 성능을 발휘한다.&lt;br /&gt;
즉, 긴 길이의 Sequence를 Input으로 받는다 하더라도 초기의 정보에 대해 큰 소실 없이 저장이 가능하다는 뜻이다.&lt;/p&gt;

&lt;p&gt;2) 일종의 Shortcut path를 만들어 오차가 vanish하지 않고 적절하게 역전파될 수 있도록 한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Experiments and Results&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;Sequence Modeling은 여러 sequences에 대한 확률 분포를 학습하는 것을 목적으로 한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;즉, training sequences에 대하여 아래와 같은 model의 log-likelihood를 최대화하는 것을 목적으로 한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\underset{x}{\mathrm{max}} \frac{1}{N} \sum_{n=1}^{N} \sum_{n=1}^{T_n} logp(x_t^n | x_1^n, ..., x_(t-1)^n; \theta )&lt;/script&gt;

&lt;p&gt;여기서 $\theta$는 model parameters를 뜻한다.&lt;/p&gt;

&lt;p&gt;결과만을 요약하자면, GRU와 LSTM이 traditional tanh-RNN를 능가하는 것은 명확하게 확인되었지만, GRU와 LSTM의 비교우위를 판별하기 위해서는 추가적인 연구가 필요하다고 확인되었다.&lt;br /&gt;
(비록 GRU과 하나의 데이터셋을 제외하고는 근소하게 LSTM를 능가했지만)&lt;/p&gt;

&lt;p&gt;*데이터셋은 polyphonic music data와 raw speech signal data를 사용하였다.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>파이썬 정규표현식(re) 사용법 - 09. 기타 기능</title>
   <link href="http://localhost:4000/regex-usage-09-other-functions/"/>
   <updated>2018-08-24T00:00:00+09:00</updated>
   <id>http://localhost:4000/regex-usage-09-other-functions</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/20/regex-usage-01-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 01. Basic&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/21/regex-usage-02-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 02. 문자, 경계, flags&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/22/regex-usage-03-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 03. OR, 반복&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/28/regex-usage-04-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 04. 그룹, 캡처&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/04/regex-usage-05-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 05. 주석, 치환, 분리&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/05/regex-usage-06-advanced/&quot;&gt;파이썬 정규표현식(re) 사용법 - 06. 치환 함수, 양방탐색, 조건문&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-07-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 07. 예제(숫자)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-08-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 08. 예제(단어, 행)&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/24/regex-usage-09-other-functions/&quot;&gt;파이썬 정규표현식(re) 사용법 - 09. 기타 기능&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이 글에서는 &lt;strong&gt;re&lt;/strong&gt; 패키지에 포함된, 지금까지의 글에서 다루지 않았던 함수와 속성 등을 다루도록 하겠다.&lt;/p&gt;

&lt;p&gt;본 글에서 정규표현식은 &lt;code class=&quot;highlighter-rouge&quot;&gt;regex&lt;/code&gt;와 같이, 일반 문자열은 ‘regex’와 같이 표시하도록 한다.&lt;/p&gt;

&lt;p&gt;파이썬 버전은 3.6을 기준으로 하나, 3.x 버전이면 (아마) 동일하게 쓸 수 있다.&lt;br /&gt;
2.7 버전은 한글을 포함한 비 알파벳 문자 처리가 다르다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;함수&quot;&gt;함수&lt;/h2&gt;

&lt;h3 id=&quot;reescapestring&quot;&gt;re.escape(string)&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;re.escape&lt;/strong&gt; 함수는 문자열을 입력받으면 특수문자들을 이스케이프 처리시켜 준다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;r'((\d)\2{4,})'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;escape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;\(\(\\d\)\\2\{4\,\}\)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;repurge&quot;&gt;re.purge()&lt;/h3&gt;

&lt;p&gt;사실 설명하지 않은 것이 있는데, &lt;strong&gt;re&lt;/strong&gt; 패키지는 &lt;strong&gt;re.compile&lt;/strong&gt;로 만들어 놓은 객체들을 cache에 저장해 둔다. 최대 100개까지라고 알려져 있으며, 그 수를 넘어갈 경우 초기화된다고 한다.&lt;br /&gt;
물론 여러분은 아마 한 프로그램 내에서 100개 이상의 다른 정규식을 쓸 일은 없으니 크게 신경 쓸 필요는 없다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;re.purge&lt;/strong&gt; 함수는 이 cache를 초기화하는 함수이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;purge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;

&lt;p&gt;결과는 아무것도 출력되지 않는다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;속성&quot;&gt;속성&lt;/h2&gt;

&lt;h3 id=&quot;reregexflag&quot;&gt;re.RegexFlag&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/21/regex-usage-02-basic/#%EB%A7%88%EC%B9%A8%ED%91%9C%EB%8A%94-%EA%B0%9C%ED%96%89-%EB%AC%B8%EC%9E%90%EC%99%80-%EC%9D%BC%EC%B9%98-%EC%98%B5%EC%85%98&quot;&gt;이전 글&lt;/a&gt;에서 flags를 설명했었는데, 이 flag들이 어떤 것이 있는지 알려주는 객체가 re 안에 내장되어 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RegexFlag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;RegexFlag.ASCII
RegexFlag.IGNORECASE
RegexFlag.LOCALE
RegexFlag.UNICODE
RegexFlag.MULTILINE
RegexFlag.DOTALL
RegexFlag.VERBOSE
RegexFlag.TEMPLATE
RegexFlag.DEBUG
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;retemplate&quot;&gt;re.TEMPLATE&lt;/h3&gt;

&lt;p&gt;아마 쓸 일이 없을 듯하므로 설명은 생략한다. (?)&lt;/p&gt;

&lt;p&gt;다만 이런 것이 있다는 것만 소개한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;redebug&quot;&gt;re.DEBUG&lt;/h3&gt;

&lt;p&gt;reObj를 출력하면 컴파일한 정규식을 그대로 출력하던 것을 기억할 것이다. &lt;strong&gt;re.debug&lt;/strong&gt;는 일종의 디버깅 모드로서, 정규식의 대략적인 구조를 알 수 있다.&lt;br /&gt;
말 그대로 디버깅용으로 쓰면 될 듯하다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\d{3,6}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DEBUG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'AS 123123 ars'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;MAX_REPEAT 3 6
  IN
    CATEGORY CATEGORY_DIGIT
re.compile('\\d{3,6}', re.DEBUG)
['123123']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;reObj의 사용법은 기본 compile된 객체와 완전히 같다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;reerror&quot;&gt;re.error&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;re.error&lt;/strong&gt;는 compile 함수에 전달된 문자열이 유효하지 않은 정규식일 때 발생하는 에러 타입이다. try-except 구문으로 처리하면 된다. 자세한 사용법은 아래 예시로만 보여도 충분할 듯 하다.&lt;/p&gt;

&lt;p&gt;참고로 아래 코드의 phi는 원주율을 소수점 1만 자리까지 저장한 문자열이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;regex_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;r'((\d)\2{4,})'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;r'((\d)\1{4,})'&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;regex&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;regex_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;reObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;regex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;phi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;except&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;Invalid regular expression %s&amp;gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;regex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'done'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['999999']
done
&amp;lt;Invalid regular expression ((\d)\1{4,})&amp;gt;
done
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;무엇이 유효하지 않은지는 &lt;em&gt;연습문제로 남겨두도록 하겠다.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;조금 더 자세한 사용법은 &lt;a href=&quot;https://docs.python.org/3/library/re.html#re.error&quot;&gt;여기&lt;/a&gt;를 참조한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이것으로 정규표현식에 대한 글을 마치도록 한다.&lt;br /&gt;
조금 더 복잡한 예제를 정리해 두면 좋겠지만, 그때그때 맞게 쓰는 것이 더 나을 것 같아서 굳이 따로 정리할 필요는 없을 것 같다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>GitHub 사용법 - 08. Conflict</title>
   <link href="http://localhost:4000/github-usage-08-conflict/"/>
   <updated>2018-08-19T00:00:00+09:00</updated>
   <id>http://localhost:4000/github-usage-08-conflict</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 글을 읽는 여러분이, 만약 git을 많이 써 봐서 익숙한 것이 아니라면, 반드시 손으로 직접 따라 칠 것을 권한다. 눈으로만 보면 100% 잊어버린다.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/08/15/github-usage-07-diff-add-commit-gitignore-intermediate/&quot;&gt;저번 글&lt;/a&gt;에서 작업하던 것을 이어서 한다. 저번 글에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;diff&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;add&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;commit&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt;에 대해서 알아보았다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;conflict&quot;&gt;Conflict&lt;/h2&gt;

&lt;p&gt;Conflict는 이름 그대로 충돌인데, 다음의 경우일 때 conflict가 생긴다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;같은 파일의 같은 부분을 동시에 두 곳(이상)에서 수정했을 때&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이런 경우는 보통 여러 사람의 분업이 명확하게 이루어지지 않아 코드의 같은 부분을 수정할 때 일어난다.&lt;br /&gt;
물론 1인 팀에서도 코드 관리를 잘못하여, 혹은 여러 컴퓨터에서 작업하게 될 때 이러한 실수가 일어나기도 한다.&lt;/p&gt;

&lt;p&gt;Conflict의 발생 및 해결 순서는 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;동시에 같은 파일의 같은 부분을 수정하고, merge 혹은 push를 할 때 일어난다. 이는 같은 파일을 수정했다 하더라도 명확히 다른 부분이 수정되었다면 git이 알아서 병합 과정을 처리해준다는 뜻이다.
    &lt;ul&gt;
      &lt;li&gt;충돌이 일어났다면, git은 병합 과정을 진행하지 않고 충돌 상태를 그대로 둔다. 알아서 처리하는 대신 사용자가 충돌을 살펴보고 원하는 코드만 남길 때까지 기다린다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;사용자가 편집기에서 코드를 원하는 부분만 남긴다. 충돌이 일어난 부분은 git이 명확하게 표시를 해 준다.
    &lt;ul&gt;
      &lt;li&gt;표시를 한다는 것은, 실제로 코드 파일을 git이 수정한다는 뜻이다. 물론 알아서 충돌을 해결한다는 뜻이 아니라, “여기 충돌 생겼어”하고 강력하게 표시를 한다는 뜻이다. 만약 코드 테스트를 한다면 틀림없이 이 부분에서 syntax error가 뜬다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;사용자가 직접 수정을 끝냈으면, commit을 한 다음 merge 혹은 push 작업을 완료한다.
    &lt;ul&gt;
      &lt;li&gt;이때 따로 새로운 commit이 생기는 대신 원래 있어야 할 merge commit만 생성된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;하나씩 살펴보자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;1-conflict-발생시키기&quot;&gt;1. Conflict 발생시키기&lt;/h3&gt;

&lt;p&gt;일부러는 절대 해서는 안 되지만, 예시를 보여주어야 하기 때문에 고의로 conflict를 발생시켜 보겠다.&lt;/p&gt;

&lt;p&gt;일단은 git_tutorial repo의 3rd-branch로 이동한 다음, &lt;code class=&quot;highlighter-rouge&quot;&gt;git rebase master&lt;/code&gt; 명령을 실행한다.&lt;br /&gt;
2nd-branch부터 시작한 수정사항이 반영되어있지 않기 때문이다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout 3rd-branch&lt;br /&gt;
git rebase master&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;second.py&lt;/code&gt;의 마지막에 다음을 추가한다.&lt;/p&gt;

&lt;p&gt;git_tutorial repo의 2nd-branch로 이동한 다음, &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;의 마지막에 다음을 추가한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout 2nd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Desired sentence in 2nd-branch&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;commit을 한 뒤, master branch에서 2nd-branch의 내용을 merge한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git add first.py&lt;br /&gt;
git commit -m “Desired commit from 2nd-branch”&lt;br /&gt;
git checkout master&lt;br /&gt;
git merge 2nd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그리고 3rd-branch로 이동하여 비슷하게 반복한다. 수정하는 파일은 당연히 &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;이다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout 3rd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Unwanted sentence in 3nd-branch&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;git add first.py&lt;br /&gt;
git commit -m “Unwanted commit from 2nd-branch”&lt;br /&gt;
git checkout master&lt;br /&gt;
git merge 3rd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_19_github_usage_08_Conflict/01_conflict.PNG&quot; alt=&quot;01_conflict&quot; /&gt;&lt;/p&gt;

&lt;p&gt;예상대로 conflict가 뜬다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;2-conflict-해결하기&quot;&gt;2. Conflict 해결하기&lt;/h3&gt;

&lt;p&gt;이제 편집기로 가서 &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;를 살펴보라. 메모장 코딩을 하는 것이 아니라면, 에러 표시줄이 여럿 보일 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_19_github_usage_08_Conflict/02_file.PNG&quot; alt=&quot;02_file&quot; /&gt;&lt;/p&gt;

&lt;p&gt;파일을 살펴보면 확실히 어느 부분에서 conflict가 일어났는지 바로 확인이 가능하다.&lt;br /&gt;
참고로 필자와 빈 줄의 개수가 달라도 별 상관은 없다.&lt;/p&gt;

&lt;p&gt;git이 수정해놓은 부분을 보면 다음과 갈은 구조로 되어 있다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt; HEAD
(현재 브랜치의 HEAD의 내용)
=======
(merge한 브랜치의 내용)
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; (merge한 브랜치 내용)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여기서 각 브랜치의 내용 중 사용자가 원하는 부분만 남기고 모두 지우면 된다. 한쪽 브랜치의 내용만 남길 수도 있고, 양쪽 모두의 내용의 일부 혹은 전체를 남길 수도 있다.&lt;/p&gt;

&lt;p&gt;수정을 마쳤으면 필요 없는 부분인 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt;&amp;lt; HEAD&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;=======&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt; &amp;lt;branch&amp;gt;&lt;/code&gt; 등은 모두 제거하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_19_github_usage_08_Conflict/04_resolve.PNG&quot; alt=&quot;04_resolve&quot; /&gt;&lt;/p&gt;

&lt;p&gt;예상대로 남길 부분은 “Desired sentence”이므로 이 문장만 남기고 나머지 부분은 모두 삭제하면 된다.&lt;/p&gt;

&lt;p&gt;IDE에 따라서는 다음과 같이 표시될 수도 있다. 이때는 조금 더 편하게 진행할 수 있다.&lt;br /&gt;
아래 예시는 Visual Studio Code의 경우이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_19_github_usage_08_Conflict/03_vscode.PNG&quot; alt=&quot;03_vscode&quot; /&gt;&lt;/p&gt;

&lt;p&gt;수정하기 전 ‘변경 사항 비교’를 누르면 어떤 부분이 다른지를 양쪽에 나누어 보여준다.&lt;br /&gt;
내용을 확인한 뒤 ‘현재 변경 사항 수락’을 누르면 원하는 부분만 남겨지고 나머지는 알아서 삭제될 것이다. 물론 다른 부분을 남겨도 상관없다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;3-commitmerge--push하기&quot;&gt;3. commit(merge) &amp;amp; push하기&lt;/h3&gt;

&lt;p&gt;그리고 수정한 파일을 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt; 명령으로 추가한 뒤 commit한다. 정상적으로 처리되었는지 보기 위해 로그도 한번 출력해 보자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git add first.py&lt;br /&gt;
git commit&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_19_github_usage_08_Conflict/05_commit.PNG&quot; alt=&quot;05_commit&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;ESC 입력 후 :wq&lt;/strong&gt;&lt;br /&gt;
git log –oneline&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_19_github_usage_08_Conflict/06_merge.PNG&quot; alt=&quot;06_merge&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이러면 conflict가 해결된 것이다. remote repo에 push하자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git push&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그리고 3rd-branch로 이동하여 rebase를 한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout 3rd-branch&lt;br /&gt;
git rebase master&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;4-conflict가-발생하지-않는-경우&quot;&gt;4. Conflict가 발생하지 않는 경우&lt;/h3&gt;

&lt;p&gt;조금 전 처음에 했던 것처럼 2nd-branch로 이동해 업데이트한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout 2nd-branch&lt;br /&gt;
git rebase master&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이번엔 &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt; 파일 끝에 다음을 추가한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;This is the 2nd sentence written in 2nd-branch.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그리고 &lt;code class=&quot;highlighter-rouge&quot;&gt;second.py&lt;/code&gt;의 내용은 다음 문장 빼고 모두 지운다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;This is the 1st sentence written in 2nd-branch.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다시 비슷한 과정을 반복한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git add *.py&lt;br /&gt;
git commit -m “No-collision commit from 2nd-branch”&lt;br /&gt;
git checkout master&lt;br /&gt;
git merge 2nd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout 3rd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;다음으로는 3rd-branch로 이동하여, &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt; 파일의 내용을 다음 문장 빼고는 모두 지운다.&lt;br /&gt;
지우기 전에, &lt;code class=&quot;highlighter-rouge&quot;&gt;print(&quot;This is the 1st sentence written in 2nd-branch.&quot;)&lt;/code&gt; 문장은 없어야 정상이다. 있다면, checkout을 제대로 했는지 살펴보라.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Desired sentence in 2nd-branch&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;git add first.py&lt;br /&gt;
git commit -m “No-collision commit from 3rd-branch”&lt;br /&gt;
git checkout master&lt;br /&gt;
git merge 3rd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_19_github_usage_08_Conflict/07_no_conflict.PNG&quot; alt=&quot;07_no_conflict&quot; /&gt;&lt;/p&gt;

&lt;p&gt;문제없이 잘 병합된 것을 확인할 수 있다. 다른 파일, 혹은 같은 파일을 수정했더라도 수정한 부분이 다르면 conflict가 일어나지 않는다.&lt;br /&gt;
위 예시의 경우 &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;를 2nd-branch에서는 파일의 끝 부분을, 3rd-branch에서는 파일의 시작 부분을 수정했기 때문에 문제가 일어나지 않았다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;5-이유없이-conflict가-생기는-것-같은-경우&quot;&gt;5. 이유없이 conflict가 생기는 것 같은 경우&lt;/h3&gt;

&lt;p&gt;사실 이유가 없는 경우는 없지만, 간혹 두 branch 간 차이가 전혀 없어 보이고 파일 수정까지 끝마쳤는데도 conflict가 계속해서 발생하는 경우가 있다.&lt;/p&gt;

&lt;p&gt;다른 원인일 수도 있지만, 정말로 아무 차이도 없어 보인다면 운영체제의 line-feed 문자의 차이로 인한 문제일 수 있다.&lt;br /&gt;
즉 Windows는 &lt;code class=&quot;highlighter-rouge&quot;&gt;'\r\n'&lt;/code&gt;을, Linux나 Mac은 &lt;code class=&quot;highlighter-rouge&quot;&gt;'\n'&lt;/code&gt;을 개행 문자로 사용하기 때문인데, 이 차이를 제대로 인식하지 못해 실패하는 경우가 있으니 참고하면 되겠다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/questions/861995/is-it-possible-for-git-merge-to-ignore-line-ending-differences/12194759#12194759&quot;&gt;해결법&lt;/a&gt;은 다음과 갈다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git config merge.renormalize true&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그리고 merge를 시도하면 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/&quot;&gt;다음 글&lt;/a&gt;에서는 Git 전체 명령어 사용법을 다룬다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;git-명령어&quot;&gt;Git 명령어&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-00-command-list/&quot;&gt;GitHub 사용법 - 00. Command List&lt;/a&gt;에서 원하는 명령어를 찾아 볼 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>BOJ 01000(A+B), 01001(A-B), 01002(터렛) 문제 풀이</title>
   <link href="http://localhost:4000/PS-01000~01002/"/>
   <updated>2018-08-16T00:00:00+09:00</updated>
   <id>http://localhost:4000/PS-01000~01002</id>
   <content type="html">&lt;h2 id=&quot;참조&quot;&gt;참조&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;분류&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/1000&quot;&gt;A+B&lt;/a&gt;, &lt;a href=&quot;https://www.acmicpc.net/problem/1001&quot;&gt;A-B&lt;/a&gt;, &lt;a href=&quot;https://www.acmicpc.net/problem/1002&quot;&gt;터렛&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이 글에서 설명하는 코드&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/BOJ/01000~01002.cpp&quot;&gt;01000~01002&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;boj-1000ab&quot;&gt;BOJ 1000(A+B)&lt;/h2&gt;

&lt;h3 id=&quot;개요&quot;&gt;개요&lt;/h3&gt;

&lt;h4 id=&quot;시간복잡도--o1-&quot;&gt;시간복잡도: $ O(1) $&lt;/h4&gt;
&lt;h4 id=&quot;공간복잡도--o1-&quot;&gt;공간복잡도: $ O(1) $&lt;/h4&gt;

&lt;h3 id=&quot;문제-풀이&quot;&gt;문제 풀이&lt;/h3&gt;

&lt;p&gt;단순 구현 문제이다. 이 문제는 여러분이 어떤 식으로 이 사이트에 제출해야 하는지를 시험할 수 있는 문제이다. 아래 구현과 같이 하면 된다.&lt;/p&gt;

&lt;h3 id=&quot;구현&quot;&gt;구현&lt;/h3&gt;

&lt;p&gt;다음과 같다. 이 문제는 C 스타일로 구현하였다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;stdio.h&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;scanf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%d%d&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%d&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;boj-1001a-b&quot;&gt;BOJ 1001(A-B)&lt;/h2&gt;

&lt;h3 id=&quot;개요-1&quot;&gt;개요&lt;/h3&gt;

&lt;h4 id=&quot;시간복잡도--o1--1&quot;&gt;시간복잡도: $ O(1) $&lt;/h4&gt;
&lt;h4 id=&quot;공간복잡도--o1--1&quot;&gt;공간복잡도: $ O(1) $&lt;/h4&gt;

&lt;h3 id=&quot;문제-풀이-1&quot;&gt;문제 풀이&lt;/h3&gt;

&lt;p&gt;이 문제 역시 단순 구현 문제이다. 이 문제도 여러분이 어떤 식으로 이 사이트에 제출해야 하는지를 시험할 수 있는 문제이다. 아래 구현과 같이 하면 된다.&lt;br /&gt;
사실 바로 위 문제에서 딱 한 글자만 바꿔도 된다.&lt;/p&gt;

&lt;h3 id=&quot;구현-1&quot;&gt;구현&lt;/h3&gt;

&lt;p&gt;다음과 같다. 이 문제는 C++ 스타일로 구현하였다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;iostream&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ios&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sync_with_stdio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고로, &lt;code class=&quot;highlighter-rouge&quot;&gt;cin&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;cout&lt;/code&gt; 함수는 &lt;code class=&quot;highlighter-rouge&quot;&gt;scanf&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;printf&lt;/code&gt;에 비해 느리기 때문에, main 함수 첫 줄과 같은 구문을 써 주어야 한다.&lt;br /&gt;
단 &lt;code class=&quot;highlighter-rouge&quot;&gt;ios::sync_with_stdio(false);&lt;/code&gt;를 썼을 때는 &lt;code class=&quot;highlighter-rouge&quot;&gt;cin&lt;/code&gt;과 &lt;code class=&quot;highlighter-rouge&quot;&gt;cout&lt;/code&gt;을 &lt;code class=&quot;highlighter-rouge&quot;&gt;scanf&lt;/code&gt;나 &lt;code class=&quot;highlighter-rouge&quot;&gt;printf&lt;/code&gt;를 같이 쓰면 안 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;boj-1002터렛&quot;&gt;BOJ 1002(터렛)&lt;/h2&gt;

&lt;h3 id=&quot;개요-2&quot;&gt;개요&lt;/h3&gt;

&lt;h4 id=&quot;시간복잡도--o1--2&quot;&gt;시간복잡도: $ O(1) $&lt;/h4&gt;
&lt;h4 id=&quot;공간복잡도--o1--2&quot;&gt;공간복잡도: $ O(1) $&lt;/h4&gt;

&lt;h3 id=&quot;문제-풀이-2&quot;&gt;문제 풀이&lt;/h3&gt;

&lt;p&gt;이 문제도 구현 문제지만, 알고리즘 문제를 풀어본 경험이 별로 없으면 충분히 헷갈릴 수 있는 문제이다.&lt;/p&gt;

&lt;p&gt;이 문제의 답의 종류는 4종류이다. 먼저 종이에 원 2개를 그려보고 답의 개수가 될 수 있는 가지수를 생각하면 답을 얻을 수 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;위치의 개수가 무한대인 경우는 터렛 2개가 같은 위치에 있는 경우이다. 사실은 문제 데이터가 잘못되지 않았다면 거리 r1과 r2도 같아야 한다. 답은 -1이다. 두 원이 완전히 일치하는 경우이다.&lt;/li&gt;
  &lt;li&gt;만약에 두 사람이 구한 거리의 합이 두 터렛의 거리보다 멀면 불가능하다. 비슷하게 거리의 차가 터렛의 거리보다 짧아도 불가능하다. 답은 0이다. 두 원이 만나지 않는 경우이다.&lt;/li&gt;
  &lt;li&gt;만약 터렛1, 터렛2, 마린이 일직선상에 있고 거리의 합 또는 차가 일치하면 답은 1이다. 두 원이 접하는 경우이다.&lt;/li&gt;
  &lt;li&gt;그 이외의 경우라면 답은 2이다. 두 원이 두 점에서 만나는 경우이다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;구현-2&quot;&gt;구현&lt;/h3&gt;

&lt;p&gt;다음과 같다. R과 r은 각각 거리의 합의 제곱 또는 차의 제곱이다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;stdio.h&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;scanf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%d&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TC&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;scanf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%d%d%d%d%d%d&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_square&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_square&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_square&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;puts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;-1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_square&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R_square&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_square&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_square&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;puts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_square&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;R_square&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_square&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r_square&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;puts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; 
            &lt;span class=&quot;n&quot;&gt;puts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>GitHub 사용법 - 07. diff, add, commit, .gitignore 중급</title>
   <link href="http://localhost:4000/github-usage-07-diff-add-commit-gitignore-intermediate/"/>
   <updated>2018-08-15T00:00:00+09:00</updated>
   <id>http://localhost:4000/github-usage-07-diff-add-commit-gitignore-intermediate</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 글을 읽는 여러분이, 만약 git을 많이 써 봐서 익숙한 것이 아니라면, 반드시 손으로 직접 따라 칠 것을 권한다. 눈으로만 보면 100% 잊어버린다.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/08/12/github-usage-06-branch-intermediate/&quot;&gt;저번 글&lt;/a&gt;에서 작업하던 것을 이어서 한다. 저번 글에서는 다른 local repo의 branch update까지 살펴보았다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;git-add-git-diff&quot;&gt;git add, git diff&lt;/h2&gt;

&lt;p&gt;다시 git_tutorial_clone 디렉토리 밖으로 빠져 나와서, 원래 git_tutorial repository로 돌아가자. 그리고 업데이트를 한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;cd ../../git_tutorial&lt;br /&gt;
git pull&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-02-create-project/#git-add&quot;&gt;여기&lt;/a&gt;에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt; 명령의 다양한 옵션을 설명했었다.&lt;br /&gt;
페이지를 옮겨다니기 귀찮을 것이므로 다시 한번 가져왔다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;명령어&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;git add first.py&lt;/td&gt;
      &lt;td&gt;first.py 파일 하나를 staging area에 추가한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git add my_directory/                               &lt;/td&gt;
      &lt;td&gt;my_directory라는 이름의 디렉토리와 그 디렉토리 안의 모든 파일과 디렉토리를 staging area에 추가한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git add .&lt;/td&gt;
      &lt;td&gt;현재 폴더의 모든 파일과 디렉토리, 하위 디렉토리에 든 전부를 staging area에 추가한다. 규모가 큰 프로젝트라면 써서는 안 된다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git add -p [&amp;lt;파일&amp;gt;]&lt;/td&gt;
      &lt;td&gt;파일의 일부를 staging하기&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git add -i&lt;/td&gt;
      &lt;td&gt;Git 대화 모드를 사용하여 파일 추가하기&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git add -u [&amp;lt;경로&amp;gt;]&lt;/td&gt;
      &lt;td&gt;수정되고 추적되는 파일의 변경 사항 staging하기&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;사실은 위의 것 말고도 조금 다른 방법이 있다. 바로 와일드카드이다.&lt;/p&gt;

&lt;p&gt;파일을 추가할 때 &lt;code class=&quot;highlighter-rouge&quot;&gt;.py&lt;/code&gt; 파일을 전부 추가하고 싶다고 하자. 그러면 다음과 같이 쓸 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git add first.py&lt;br /&gt;
git add second.py&lt;br /&gt;
…&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그러나 이는 귀찮을 뿐더러 빠트리는 경우도 얼마든지 있을 수 있다. 이럴 땐 &lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt; 를 사용한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git add *.py&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이를 사용하면 &lt;code class=&quot;highlighter-rouge&quot;&gt;.py&lt;/code&gt;로 끝나는 모든 파일이 staging area에 추가된다.&lt;/p&gt;

&lt;p&gt;표에서 위쪽 세 종류의 명령은 어려운 부분이 아니므로, 다른 옵션을 설명하겠다.&lt;/p&gt;

&lt;h3 id=&quot;git-diff&quot;&gt;git diff&lt;/h3&gt;

&lt;p&gt;2nd-branch로 이동한다. master에는 직접 수정을 가하지 않는다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout 2nd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그리고 second.py를 수정한다. 최종 결과물은 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'1st'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Why don't you answer me, git?&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'2nd'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;This is the 1st sentence written in 2nd-branch.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'3rd'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'4th'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고로 모든 파일의 마지막 줄에는 빈 줄은 추가해 두는 것이 commit log를 볼 때 편하다. 이유는 마지막에 빈 줄만 추가하고 staging시켜 보면, 마지막 줄의 내용을 삭제한 후 마지막 줄의 내용 그리고 빈 줄을 추가한 것처럼 나오기 때문이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/07_diff.PNG&quot; alt=&quot;07_diff&quot; /&gt;&lt;/p&gt;

&lt;p&gt;별로 깔끔하지 않기 때문에 빈 줄을 추가하라. commit log 볼 때뿐만 아니라 나중에 편집할 때에도 조금 더 편하다.&lt;br /&gt;
IDE에 따라서는 빈 줄이 없으면 경고를 띄워 주기도 한다.&lt;/p&gt;

&lt;p&gt;여기서 다음 명령을 입력하면 지금까지 어떤 수정사항이 있었는지 볼 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git diff&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/07_diff_2.PNG&quot; alt=&quot;07_diff_2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git diff&lt;/code&gt;는 아무 옵션 없이 입력하면 staging area에 반영되지 않은 수정사항을 보여준다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;git diff HEAD&lt;/code&gt;와 기능이 같다.&lt;/p&gt;

&lt;p&gt;diff 역시 많은 옵션이 있는데, 간략히 살펴보도록 하겠다.&lt;/p&gt;

&lt;p&gt;local branch 간 비교는 &lt;code class=&quot;highlighter-rouge&quot;&gt;git diff [&amp;lt;branch1&amp;gt;] &amp;lt;branch2&amp;gt;&lt;/code&gt;와 같이 한다. 브랜치명을 하나만 쓰면 현재 local branch와 비교한다.&lt;br /&gt;
물론 remote branch와의 비교도 가능하다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git diff 3rd-branch&lt;br /&gt;
git diff 2nd-branch origin/2nd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;커밋간 비교도 가능하다. &lt;code class=&quot;highlighter-rouge&quot;&gt;git diff [&amp;lt;commit1&amp;gt;] &amp;lt;commit2&amp;gt;&lt;/code&gt;&lt;br /&gt;
역시 첫번째를 생략하면 현재 상태와 비교한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git diff 317200f&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;다른 옵션들은 나중에 설명하도록 하겠다. 일단은 여기까지만 하자.&lt;/p&gt;

&lt;h3 id=&quot;git-add--p-파일&quot;&gt;git add -p [&amp;lt;파일&amp;gt;]&lt;/h3&gt;

&lt;p&gt;그리고 다음 명령을 입력한다. 지금은 &lt;code class=&quot;highlighter-rouge&quot;&gt;second.py&lt;/code&gt;만 수정했기 때문에 해당 파일만 추가한다.&lt;br /&gt;
조금 위의 표에서 봤듯이 &lt;code class=&quot;highlighter-rouge&quot;&gt;-p&lt;/code&gt; 옵션은 파일의 일부만을 staging(staging area에 올리는 것)하는 과정이다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;-p&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;--patch&lt;/code&gt;의 단축 옵션이다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git add -p second.py&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그러면 다음과 같이 뜬다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/08_patch.PNG&quot; alt=&quot;08_patch&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;초록색 줄은 추가된 줄, 빨간색 줄은 삭제된 줄이다.&lt;/li&gt;
  &lt;li&gt;파일의 일부분만을 추가하는데, 모든 한 줄마다 따로 추가하는 것이 아니라 hunk라는 덩어리로 한 번에 staging area에 추가할지 말지를 결정한다. 만약에 git이 나눠준 hunk가 너무 크다면, &lt;code class=&quot;highlighter-rouge&quot;&gt;s&lt;/code&gt;를 입력하여 더 잘게 쪼갠다. 위의 경우는 너무 크기 때문에, 잘게 쪼갤 것이다.&lt;/li&gt;
  &lt;li&gt;만약에 무슨 옵션이 있는지 궁금하다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt;를 입력하라. 도움말이 표시된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;명령&lt;/th&gt;
      &lt;th&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;y&lt;/td&gt;
      &lt;td&gt;stage this hunk&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;n&lt;/td&gt;
      &lt;td&gt;do not stage this hunk&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;q&lt;/td&gt;
      &lt;td&gt;quit; do not stage this hunk or any of the remaining ones&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;a&lt;/td&gt;
      &lt;td&gt;stage this hunk and all later hunks in the file&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;d&lt;/td&gt;
      &lt;td&gt;do not stage this hunk or any of the later hunks in the file&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;g&lt;/td&gt;
      &lt;td&gt;select a hunk to go to&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;/&lt;/td&gt;
      &lt;td&gt;search for a hunk matching the given regex&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;j&lt;/td&gt;
      &lt;td&gt;leave this hunk undecided, see next undecided hunk&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;J&lt;/td&gt;
      &lt;td&gt;leave this hunk undecided, see next hunk&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;k&lt;/td&gt;
      &lt;td&gt;leave this hunk undecided, see previous undecided hunk&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;K&lt;/td&gt;
      &lt;td&gt;leave this hunk undecided, see previous hunk&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;s&lt;/td&gt;
      &lt;td&gt;split the current hunk into smaller hunks&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;e&lt;/td&gt;
      &lt;td&gt;manually edit the current hunk&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;?&lt;/td&gt;
      &lt;td&gt;print help&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;s&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;y&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;y&lt;/code&gt;를 차례대로 입력한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;s&lt;/code&gt;를 입력하면 3개의 hunk로 분리되었다고 알려 준다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/09_hunk.PNG&quot; alt=&quot;09_hunk&quot; /&gt;&lt;/p&gt;

&lt;p&gt;참고:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;untracked files는 &lt;code class=&quot;highlighter-rouge&quot;&gt;-p&lt;/code&gt;를 할 때 나오지 않는다. 새로 추가된 파일이라면 먼저 staging area에 올린 후, 수정한 파일만을 &lt;code class=&quot;highlighter-rouge&quot;&gt;p&lt;/code&gt; 옵션으로 처리하라.&lt;/li&gt;
  &lt;li&gt;디버깅을 위해 넣어 놓은 print문 등을 제거하고 push할 때 유용하다.&lt;/li&gt;
  &lt;li&gt;파일명으로 추가하는 대신 &lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;나 &lt;code class=&quot;highlighter-rouge&quot;&gt;.&lt;/code&gt;를 쓰는 것도 가능하다.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;git-add--i-파일&quot;&gt;git add -i [&amp;lt;파일&amp;gt;]&lt;/h3&gt;

&lt;p&gt;대화형으로 파일 수정사항을 staging area에 추가하는 방법이다. &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;를 수정하자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Hello, git!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# instead of &quot;Hello, World!&quot;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Hi, git!!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'1st'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;This is the 1st sentence written in 1st-branch.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;This is the 1st sentence written in 3rd-branch.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'2nd'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그리고 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add -i first.py&lt;/code&gt;를 입력한 다음, 다음 그림대로 따라 해 보자.&lt;br /&gt;
중간쯤에 아무것도 안하고 Enter만 입력한 곳이 있는데, 이렇게 하면 선택한 파일들이 staging area에 추가된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/10_i.PNG&quot; alt=&quot;10_i&quot; /&gt;&lt;/p&gt;

&lt;p&gt;파란색으로 강조된 부분을 잘 따라가면 이해하기 어렵진 않을 것이다.&lt;/p&gt;

&lt;p&gt;위와 같이 하면 &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt; 파일이 staging area에 추가된다.&lt;/p&gt;

&lt;h3 id=&quot;git-add--u-경로&quot;&gt;git add -u [&amp;lt;경로&amp;gt;]&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git add .&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add -u&lt;/code&gt;는 하는 일이 비슷하지만, 차이점은 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git add .&lt;/code&gt;는 현재 디렉토리의 모든 변경사항을 staging area에 추가한다. untracked files를 포함한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git add -u&lt;/code&gt;는 업데이트(‘u’)된 파일, 즉 untracked files는 제외하고 staging area에 추가한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;뒤에 경로를 추가하면 해당 디렉토리 혹은 파일들에 대해서만 위의 작업을 수행한다.&lt;/p&gt;

&lt;p&gt;아무 파일이나 하나 추가한 다음 차이를 확인하자. &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt; 파일 끝에 다음을 추가하고, &lt;code class=&quot;highlighter-rouge&quot;&gt;dummy1.txt&lt;/code&gt; 파일을 생성만 하자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'test git add .'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/11_short.PNG&quot; alt=&quot;11_short&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-s&lt;/code&gt; 옵션을 줄 때 ‘??’는 untracked files를 의미한다.&lt;/p&gt;

&lt;p&gt;이제 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add .&lt;/code&gt;로 staging area에 추가해 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/12_add.PNG&quot; alt=&quot;12_add&quot; /&gt;&lt;/p&gt;

&lt;p&gt;모두 추가되었다.&lt;/p&gt;

&lt;p&gt;이제 조금 전과 비슷하게 &lt;code class=&quot;highlighter-rouge&quot;&gt;second.py&lt;/code&gt; 파일의 끝에 다음을 추가하고 &lt;code class=&quot;highlighter-rouge&quot;&gt;dummy2.txt&lt;/code&gt; 파일을 생성만 하자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'test git add -u'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/13_u.PNG&quot; alt=&quot;13_u&quot; /&gt;&lt;/p&gt;

&lt;p&gt;untracked files 상태인 &lt;code class=&quot;highlighter-rouge&quot;&gt;dummy2.txt&lt;/code&gt;는 여전히 추가되지 않은 상태로 남아 있는 것을 볼 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;git-commit-중급&quot;&gt;git commit: 중급&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git commit&lt;/code&gt;에도 옵션은 굉장히 많으나, 여기서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;-v&lt;/code&gt; 옵션과 tag 두 가지만 설명한다.&lt;/p&gt;

&lt;h3 id=&quot;-v-옵션&quot;&gt;-v 옵션&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-v&lt;/code&gt; 옵션은 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt;의 &lt;code class=&quot;highlighter-rouge&quot;&gt;-p&lt;/code&gt;와 비슷하다. 즉 수정사항을 미리 볼 수 있는데, &lt;code class=&quot;highlighter-rouge&quot;&gt;git diff&lt;/code&gt;를 밑에 보여주는 것과 비슷하다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git commit -v&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/15_v.PNG&quot; alt=&quot;15_v&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;i&lt;/strong&gt; 입력 후, 커밋 메시지는 적당히 입력하고 &lt;strong&gt;ESC&lt;/strong&gt;, &lt;strong&gt;:wq&lt;/strong&gt; 를 입력하라. &lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-02-create-project/#%EB%8B%A4%EC%8B%9C-commit%ED%95%98%EA%B8%B0&quot;&gt;무엇&lt;/a&gt;인지 까먹지 않았기를 바란다.&lt;/p&gt;

&lt;h3 id=&quot;tag&quot;&gt;tag&lt;/h3&gt;

&lt;p&gt;commit에는 태그를 붙일 수 있다. 여러분이 블로그에서 볼 수 있는 그 태그와 같은 기능이다.&lt;/p&gt;

&lt;p&gt;태그에는 두 종류가 있는데, 단순 태그 기능만 하는 Lightweight 태그와 태그를 만든 사람, 시간, 메시지, 서명 정보 등을 저장하는 Annotated 태그가 있다.&lt;/p&gt;

&lt;p&gt;먼저 Lightweight 태그는 다음과 같이 붙일 수 있다. 뒤에 commit 코드를 명시하지 않으면 현재 commit에 붙는다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git tag v0.7&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;버전 정보를 저장할 때 태그로 하면 편하다.&lt;/p&gt;

&lt;p&gt;현 repo의 태그 목록을 확인하려면 다음을 입력한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git tag&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;태그의 정보를 자세히 확인하고 싶다면 다음과 같이 입력한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git show v0.7&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/14_tag.PNG&quot; alt=&quot;14_tag&quot; /&gt;&lt;/p&gt;

&lt;p&gt;태그를 삭제하려면 &lt;code class=&quot;highlighter-rouge&quot;&gt;-d&lt;/code&gt; 옵션을 붙인다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git tag -d v0.7&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Annotated 태그를 붙일 때에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;-a&lt;/code&gt; 옵션을 사용한다. 메시지를 입력하려면 &lt;code class=&quot;highlighter-rouge&quot;&gt;-m&lt;/code&gt; 옵션을 붙인다.&lt;br /&gt;
메시지를 입력하지 않으면 일반적인 커밋 메시지를 쓰지 않았을 때처럼 vim 편집기가 열린다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git tag -a v0.7 -m “git tutorial ver 0.7”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;뒤에 commit 코드를 명시할 경우 이전 커밋에도 태그를 붙일 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git tag v0.5 90ce4f2&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;당연하게도 여러분이 직접 커밋을 만들었다면 커밋 코드는 다를 것이다. &lt;code class=&quot;highlighter-rouge&quot;&gt;git log&lt;/code&gt;로 먼저 확인 후 원하는 커밋에 태깅하도록 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/16_tag.PNG&quot; alt=&quot;16_tag&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그림에서 커밋 로그에 ‘tag: v0.5’ 등이 생겼음을 확인하라.&lt;/p&gt;

&lt;p&gt;이제 push를 하자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git push&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그러나 태그는 &lt;code class=&quot;highlighter-rouge&quot;&gt;git push&lt;/code&gt;명령에 자동으로 remote repo에 올라가지 않는다.&lt;br /&gt;
태그는 따로 올리면 된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git push origin v0.5&lt;br /&gt;
git push origin –tags&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;--tags&lt;/code&gt; 옵션은 모든 태그를 remote repo에 올린다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;gitignore-중급&quot;&gt;.gitignore 중급&lt;/h2&gt;

&lt;p&gt;사실 &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 사용법은 어렵지 않다. 파일을 제외하거나, 디렉토리를 제외하거나, 와일드카드를 사용하여 여러 파일을 staging area에 올라가는 것을 막는 것뿐이다. 각각은 다음과 같이 사용한다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일의 각각 다른 줄에 추가하면 된다.&lt;br /&gt;
이 내용은 &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일에 추가하지 않아도 된다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dummy_txt
data/
*.tar
data/raw/*
*dummy*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;대신 한 가지 흔히 하는 실수를 다루도록 하겠다. 데이터 파일이나 설정 파일, IDE가 자동으로 생성한 파일 등은 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add .&lt;/code&gt;를 생각없이 사용하다 보면 어느새 remote repo에 올라가 있는 경우가 많은데, 이 파일은 나중에 &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일에 추가해도 repo에서 자동으로 사라지지 않는다.&lt;/p&gt;

&lt;p&gt;예제를 하나 갖고 왔다. 우선 git_tutorial 디렉토리를 PyCharm IDE로 열거나, 아니면 &lt;code class=&quot;highlighter-rouge&quot;&gt;.idea/&lt;/code&gt;라는 디렉토리를 하나 만들어 보자.&lt;/p&gt;

&lt;p&gt;PyCharm으로 열면 자동으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;.idea/&lt;/code&gt;라는 디렉토리가 생겨버린다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/18_status.PNG&quot; alt=&quot;18_status&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이를 그냥 생각없이 추가하면 직접 생성하지도 않은 수많은 파일들이 추가된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/19_add.PNG&quot; alt=&quot;19_add&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그리고 한번 remote repo에 올려 보자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git commit -m “Doong!”&lt;br /&gt;
git push&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이건 그다지 좋은 상황이 아니기 때문에, remote repo에서 제거하려고 한다. 서둘러 &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일에 다음을 추가한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idea&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dummy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그리고 3종 세트를 입력하자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git add .gitignore&lt;br /&gt;
git commit -m “edit .gitignore: remove .idea/ directory”&lt;br /&gt;
git push&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/20_browser.PNG&quot; alt=&quot;20_browser&quot; /&gt;&lt;/p&gt;

&lt;p&gt;물론 앞서 말한 대로, 자동으로 지워지지 않는다.&lt;/p&gt;

&lt;p&gt;이럴 때는 어디선가 본 듯한 명령을 사용한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git rm –cached .idea/ -r&lt;br /&gt;
git rm –cached *dummy*&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;디렉토리를 제거하려고 할 때는 &lt;code class=&quot;highlighter-rouge&quot;&gt;-r&lt;/code&gt; 옵션을 사용한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/21_rm.PNG&quot; alt=&quot;21_rm&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 push를 한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt; 명령은 필요없다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/22_push.PNG&quot; alt=&quot;22_push&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이와 같은 실수를 막기 위해서는, 아예 &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일에 git에 올라가지 말아야 할 파일을 정리해 두는 것도 괜찮다.&lt;br /&gt;
추천하는 것은 데이터 파일, 설정 파일, 패키지, 압축 파일 등이다.&lt;/p&gt;

&lt;p&gt;PyCharm 기준으로는 구글링을 하면 적당히 쓸 만한 설정 파일을 구할 수도 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/github/gitignore/blob/master/Global/JetBrains.gitignore&quot;&gt;여기&lt;/a&gt; 아니면&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://gist.github.com/fjcaetano/4069311&quot;&gt;여기&lt;/a&gt; 등등&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;이제 master branch에 merge를 하자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout master&lt;br /&gt;
git merge 2nd-branch&lt;br /&gt;
git push&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/08/19/github-usage-08-conflict&quot;&gt;다음 글&lt;/a&gt;에서는 대망의 conflict에 대해서 알아본다. 여러 사람이 작업 분할을 충실하게 하지 않는다면 필히 만나게 될 것이다.&lt;br /&gt;
물론 혼자서도 만들 수도 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;git-명령어&quot;&gt;Git 명령어&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-00-command-list/&quot;&gt;GitHub 사용법 - 00. Command List&lt;/a&gt;에서 원하는 명령어를 찾아 볼 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Fast R-CNN</title>
   <link href="http://localhost:4000/Fast_RCNN/"/>
   <updated>2018-08-13T00:00:00+09:00</updated>
   <id>http://localhost:4000/Fast_RCNN</id>
   <content type="html">&lt;h3 id=&quot;fast-rcnn&quot;&gt;Fast RCNN&lt;/h3&gt;
&lt;blockquote&gt;
  &lt;p&gt;이 포스트는 Ross Girshick의 Fast R-CNN 논문을 리뷰하는 것을 목적으로 한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;background&quot;&gt;Background&lt;/h4&gt;
&lt;p&gt;이 알고리즘의 핵심은 R-CNN의 여러 단점들을 상당 부분 해소했다는 점이다.&lt;br /&gt;
R-CNN의 단점은 아래와 같았다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;
      &lt;p&gt;&lt;strong&gt;Training is a multi-stage pipeline&lt;/strong&gt;&lt;br /&gt;
CNN과 SVM, 그리고 Bounding Box Regressor까지 다 따로 따로 학습되었기 때문에,&lt;br /&gt;
효율적이지 못한 학습 과정을 지니고 있었다.&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Training is expensive&lt;/strong&gt;&lt;br /&gt;
각각의 object proposal에 대해서 feature가 추출되기 때문에 이 많은 feature를&lt;br /&gt;
저장하는 데에는 많은 비용이 수반되었다.&lt;/li&gt;
    &lt;li&gt;&lt;strong&gt;Object detection is slow&lt;/strong&gt;&lt;br /&gt;
모든 ROI는 하나 씩 CNN을 통과해야 했기 때문에 굉장히 느렸다.&lt;br /&gt;
즉, sharing computation이 없었다는 뜻이다.&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;전체-파이프라인-구조&quot;&gt;전체 파이프라인 구조&lt;/h4&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018_08_13_Fast_RCNN/01.PNG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;논문에 있는 위 그림을 조금 더 자세히 표현해 보자면 아래와 같다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018_08_13_Fast_RCNN/02.PNG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;마지막 부분을 먼저 보면,&lt;br /&gt;
각각의 ROI feature vector는 여러 개의 FC layers에 들어간 후, 2개의 output으로 분화된다. 첫 번째는 K+1의 길이를 가진 class 분류 벡터에 softmax 활성화 함수를 적용하여 class를 예측하고, (K = 총 class의 개수, background까지 추가하여 K+1이 됨) 두 번재는 각각의 class에 대해 4개의 bbox 값을 output으로 반환한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ROI pooling layer&lt;/strong&gt;는 각기 다른 비율과 크기를 지닌 이미지를 그 비율을 유지한 상태로 이미지를 축소시키는 기능을 갖고 있을 뿐만 아니라, 수많은 ROI를 동시에 feature map에 투사하여 fixed size의 small feature map들을 반환하게 된다.&lt;/p&gt;

&lt;p&gt;위 그림처럼 ROI pooling은 원하는 크기에 맞추어 (예: 7X7) 이미지를 축소시키는데, 
여기서는 max pooling을 사용하여 각 ROI에 맞는 이미지의 핵심 정보를 추출하였다.&lt;br /&gt;
Pooling 작업은 각각의 feature map channel에 대해 독립적으로 수행된다.&lt;/p&gt;

&lt;p&gt;참고로 Deep CNN에서는 VGG16을 사용하였는데, include_top = FALSE 옵션을 주어, 
아래 FC layer들을 모두 제거하고 이를 통해 feature map을 반환하며, 마지막 max pooling 대신 ROI pooling layer를 배치하게 된다.&lt;/p&gt;

&lt;h4 id=&quot;training&quot;&gt;Training&lt;/h4&gt;
&lt;p&gt;Fast RCNN에서는 더욱 효과적인 training method가 제안되었는데, 이는 feature sharing이라는 큰 특징을 지닌다.&lt;br /&gt;
SGD 미니배치들이 계층적으로 추출(sampling)되는데 그 순서는 이미지 -&amp;gt; ROI이다. 
먼저 N개의 이미지가 하나의 미니배치로써 추출되고 나면, R/N개의 ROI가 각 이미지로부터 추출된다. 즉, 결과적으로 N개의 이미지와 R개의 ROI가 추출되는 셈이다.&lt;br /&gt;
같은 이미지에 대응하는 ROI는 forward &amp;amp; backward pass에서 computation과 memeory를 공유하기 때문에, training 속도가 매우 빠르다. 이론 상으로는 이러한 ROI가 correlated 되어 있기 때문에 training convergence를 느리게 만들 수 있는데, 실제로 N=2, R=128로 학습을 해본 결과 큰 문제가 없는 것으로 판명되었다.&lt;/p&gt;

&lt;h4 id=&quot;multi-task-loss&quot;&gt;Multi-task loss&lt;/h4&gt;
&lt;p&gt;본 논문에서는 classification loss와 localization loss를 형식 상 합쳐서 (concatenate) 동시에 학습이 진행되도록 설계하였다. 전체 Loss Function은 아래와 같은데,&lt;br /&gt;
K+1 category에 대해,&lt;br /&gt;
$p = (p_0, p_1, … , p_K)$&lt;br /&gt;
$u$ = ground-truth class (정답 레이블)&lt;br /&gt;
$v$ = grund-truth bounding box regression target (bbox 좌표 정답))&lt;br /&gt;
$t^u = (t_x^k, t_y^k, t_w^k, t_h^k)$ - bounding box regression offset&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(p, u, t^u, v) = L_{classification}(p, u) + \lambda[u \geq 1] * L_{localization}(t^u, v)&lt;/script&gt;

&lt;p&gt;당연히 위 식은 다시 2개로 쪼개서 설명해야 한다.&lt;br /&gt;
&lt;script type=&quot;math/tex&quot;&gt;L_{classification} = -log(p, u)&lt;/script&gt;&lt;br /&gt;
위 식은 true class u에 대한 log loss function이다.&lt;/p&gt;

&lt;p&gt;$x = t_i^u - v_i$ 일 때,
$L_{localizaion} = \sum_{i\in{x,y,w,h}} 0.5 x^2$ if $|x| &amp;lt; 1$
$L_{localizaion} = \sum_{i\in{x,y,w,h}}|x| - 0.5$ otherwise&lt;/p&gt;

&lt;p&gt;인데, 위 함수를 $smooth_{L_i}$라고 한다.&lt;br /&gt;
위 함수는 그림으로 그려보면 아래와 같이 생겼는데,&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Paper_Review/2018_08_13_Fast_RCNN/03.png&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;outlier에 상당히 robust하기 때문에 learning rate 튜닝 과정 속에서 gradient가 explode하는 위험성을 줄여준다.&lt;/p&gt;

&lt;p&gt;The Iversion bracket Indicator Function이라고 불리는 $[u\geq1]$은 background class일 때 0이 되고 u가 1보다 클 때(실제 object가 있을 때) 1을 반환하는 함수이다. 즉, 배경으로 판별되었을 경우 이를 0으로 만들어 굳이 weight를 학습시키지 않는다는 의미이다.&lt;/p&gt;

&lt;p&gt;$\lambda$의 경우 2개의 loss 사이의 balance를 조절하는 하이퍼파라미터인데, 여기서는 1을 사용하였다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>GitHub 사용법 - 06. branch 관리</title>
   <link href="http://localhost:4000/github-usage-06-branch-intermediate/"/>
   <updated>2018-08-12T00:00:00+09:00</updated>
   <id>http://localhost:4000/github-usage-06-branch-intermediate</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 글을 읽는 여러분이, 만약 git을 많이 써 봐서 익숙한 것이 아니라면, 반드시 손으로 직접 따라 칠 것을 권한다. 눈으로만 보면 100% 잊어버린다.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/08/11/github-usage-05-branch-basic/&quot;&gt;저번 글&lt;/a&gt;에서 작업하던 것을 이어서 한다. 저번 글에서는 두 사람이 각각 브랜치를 만들어 자신의 브랜치에서 작업하는 상황을 가정하여 진행했었다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;branch-naming&quot;&gt;Branch naming&lt;/h2&gt;

&lt;p&gt;Branch 관리는 사실 하기 나름이지만, &lt;a href=&quot;https://nvie.com/posts/a-successful-git-branching-model/&quot;&gt;다음의 방법&lt;/a&gt;이 괜찮기에 추천한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;기본적으로 &lt;strong&gt;master&lt;/strong&gt; 브랜치에서 진행한다. 이건 아주 기본적인 사항이다. master branch는 곧 배포할 코드를 보관한다.&lt;/li&gt;
  &lt;li&gt;개발의 중심이 되는 브랜치는 &lt;strong&gt;develop&lt;/strong&gt; 브랜치에서 진행한다. develop 브랜치에서는 지금까지 merge된 코드들이 오류 없이 안정적으로 동작하는지를 검사한다. 물론 develop 브랜치에 merge되기 전에도 다른 팀원들이 검사하는 것이 일반적이지만, 모든 것을 다 판별할 수는 없기 때문에 안정성을 검사하는 것이다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;feature&lt;/strong&gt; 브랜치는 새로운 기능을 추가할 때 사용된다. 기능을 새로이 개발해야 할 때 local에서 만든 다음, 개발이 끝나면 develop 브랜치로 merge된다. 일반적으로 local에서 진행되고 remote repo에 push되지 않으나, 여러 명이 한 기능을 동시에 개발하는 경우에는 push한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;release&lt;/strong&gt; 브랜치는 실제 동작 환경과 유사한 곳에서 테스트를 한번 더 하는 브랜치인데, 서버 환경이거나 아주 큰 프로젝트같은 것이 아니라면 굳이 필요하지는 않다. develop 브랜치로부터 생성되고, 안정성 검사가 끝나면 master branch로 version number와 함께 merge된다. 일반적으로 release 관련 작업은 주기적(1주 등)으로 이루어진다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;hotfix&lt;/strong&gt; 브랜치는 배포 이후에 발견된 버그를 빠르게 고쳐 패치하기 위한 브랜치이다(hotfix 패치는 어디선가 많이 봤을 것이다). 대개 master 혹은 develop 브랜치에서 생성되며 버그를 고친 이후에는 둘 모두에 각각 merge된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위의 경우는 큰 프로젝트 혹은 서버의 경우이고, 규모가 작은 프로젝트라면 master 브랜치와 개인 브랜치(feature 브랜치와 비슷), 그리고 필요하다면 develop 브랜치 정도까지만 있어도 괜찮다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;branch-update&quot;&gt;Branch update&lt;/h2&gt;

&lt;p&gt;저번 글에서 master, 2nd-branch, 3rd-branch까지 만들어서 작업을 했었다. 그런데 이 모든 내용은 local repo에 절대 자동으로 업데이트되지 않는다.&lt;/p&gt;

&lt;p&gt;git_tutorial_clone 폴더로 이동한다. &lt;a href=&quot;https://greeksharifa.github.io/github/2018/07/08/github-usage-03-clone-log-gitignore/#local-directory-%EC%83%9D%EC%84%B1&quot;&gt;여기&lt;/a&gt;에서 했었는데, 아마 기억하고 있을 것이다.&lt;/p&gt;

&lt;p&gt;그리고 브랜치 상태를 확인해 보자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git status&lt;br /&gt;
git branch -a&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/01_clone.PNG&quot; alt=&quot;01_clone&quot; /&gt;&lt;/p&gt;

&lt;p&gt;업데이트를 전혀 안 했기 때문에, &lt;code class=&quot;highlighter-rouge&quot;&gt;git pull&lt;/code&gt;을 입력해 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/02_pull.PNG&quot; alt=&quot;02_pull&quot; /&gt;&lt;/p&gt;

&lt;p&gt;remote repo는 업데이트되었다. 만약 잘 되지 않았다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;git fetch&lt;/code&gt;를 추가로 입력하라. 이 명령은 저번 글에서 설명하였다.&lt;br /&gt;
그러나 local branch 목록은 전혀 업데이트되지 않았다.&lt;/p&gt;

&lt;p&gt;업데이트하기 전에, 우선 브라우저로 가서 2nd-branch로 이동한다. 그리고 &lt;code class=&quot;highlighter-rouge&quot;&gt;second.py&lt;/code&gt;를 수정한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/03_browser.PNG&quot; alt=&quot;03_browser&quot; /&gt;&lt;/p&gt;

&lt;p&gt;마지막 줄에 다음을 추가한다. 이렇게 브라우저에서도 파일을 수정할 수 있다.&lt;br /&gt;
추천되는 방법은 아니지만, readme.md를 수정하는 용도로는 쓸 만하다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Directly modified sentence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/04_browser.PNG&quot; alt=&quot;04_browser&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그리고 &lt;strong&gt;Commit changes&lt;/strong&gt; 버튼을 누른다.&lt;/p&gt;

&lt;p&gt;다시 git_tutorial_clone/git_tutorial 폴더로 돌아오자.&lt;/p&gt;

&lt;p&gt;local branch 목록은 전혀 업데이트되지 않았다. 이는 git은 자동으로 모든 것을 복사해오지 않기 때문이다.&lt;/p&gt;

&lt;p&gt;remote branch를 local branch로 가져오는 방법은 다음과 같다.&lt;/p&gt;

&lt;p&gt;첫번째 방법:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout -t origin/2nd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-t&lt;/code&gt; 옵션은 &lt;code class=&quot;highlighter-rouge&quot;&gt;--track&lt;/code&gt;과 같다.&lt;br /&gt;
만약 이전 버전의 git을 쓰고 있다면, &lt;code class=&quot;highlighter-rouge&quot;&gt;-b&lt;/code&gt; 옵션을 추가로 붙인다.&lt;/p&gt;

&lt;p&gt;두번째 방법:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout 2nd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그리고 다음을 입력한다. 이는 checkout 하기 전 master 브랜치에서 진행해도 상관없다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;git pull&lt;br /&gt;
type second.py&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;type&lt;/code&gt;은 윈도우 명령창에서 파일의 내용을 출력하는 명령어이다. Linux 환경에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;cat&lt;/code&gt;이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/05_local.PNG&quot; alt=&quot;05_local&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 방법은 branch를 직접 가져오는 것이다. git pull을 하면 파일 내용이 업데이트된다.&lt;/p&gt;

&lt;p&gt;그런데 remote branch를 가져오는 다른 방법이 있다. &lt;em&gt;detached HEAD&lt;/em&gt; 상태로 가져오는 방법인데,&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;이는 branch의 내용을 갖고 오면서 직접 수정도 할 수 있지만,&lt;/li&gt;
  &lt;li&gt;commit이나 push를 할 수는 없고,&lt;/li&gt;
  &lt;li&gt;다른 branch로 checkout하면 사라진다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_12_github_usage_06_branch-intermediate/06_detached.PNG&quot; alt=&quot;06_detached&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;지금까지 remote branch를 가져오는 법을 알아보았다. &lt;a href=&quot;https://greeksharifa.github.io/github/2018/08/15/github-usage-07-diff-add-commit-gitignore-intermediate/&quot;&gt;다음 글&lt;/a&gt;에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;git diff&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;git commit&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt;의 더 자세한 사용 방법을 알아본다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;git-명령어&quot;&gt;Git 명령어&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-00-command-list/&quot;&gt;GitHub 사용법 - 00. Command List&lt;/a&gt;에서 원하는 명령어를 찾아 볼 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>GitHub 사용법 - 05. branch 기본 2</title>
   <link href="http://localhost:4000/github-usage-05-branch-basic/"/>
   <updated>2018-08-11T00:00:00+09:00</updated>
   <id>http://localhost:4000/github-usage-05-branch-basic</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 글을 읽는 여러분이, 만약 git을 많이 써 봐서 익숙한 것이 아니라면, 반드시 손으로 직접 따라 칠 것을 권한다. 눈으로만 보면 100% 잊어버린다.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/08/07/github-usage-04-branch-basic/&quot;&gt;저번 글&lt;/a&gt;에서 작업하던 것을 이어서 한다. 저번 글에서 1st-branch를 만들고 master에 merge한 뒤 삭제하는 작업을 진행했었다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;branch-생성-checkout-강제-삭제&quot;&gt;Branch 생성, checkout, 강제 삭제&lt;/h2&gt;

&lt;p&gt;현재 작업 트리의 상황은 다음과 같다. 1st-branch가 삭제되어 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_11_github_usage_05_branch-basic/01.png&quot; alt=&quot;01&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 브랜치 2개를 더 만들어 보자. 다음 명령을 입력한다.&lt;br /&gt;
2nd-branch는 여러분이 사용하는 브랜치이고, 3rd-branch는 여러분 말고 다른 팀원이 사용하는 branch라 생각하자.&lt;br /&gt;
물론 사람을 데려오긴 어렵기 때문에, 여러분이 직접 두 개를 다 만들도록 한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git branch 2nd-branch&lt;br /&gt;
git checkout -b 3rd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;첫 번째 명령은 다 알 것이라고 생각하고, 두 번째 명령은 조금 다르다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;git checkout&lt;/code&gt;은 원래 다른 브랜치로 이동할 때 쓰는데, &lt;code class=&quot;highlighter-rouge&quot;&gt;-b&lt;/code&gt; 옵션을 주면 해당 브랜치를 만들면서 checkout하는 효과를 갖는다. 즉, 여러분은 현재 3rd-branch 브랜치에 위치해 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_11_github_usage_05_branch-basic/02_create.PNG&quot; alt=&quot;02_create&quot; /&gt;&lt;/p&gt;

&lt;p&gt;물론 위와 같이 이미 있는 이름으로 만드려고 하면 이미 존재한다고 오류를 뱉어낸다.&lt;/p&gt;

&lt;p&gt;이미 완전히 삭제해버린 브랜치 이름(1st-branch)로 만드는 것은 오류를 뱉어내지 않는다.&lt;br /&gt;
그러나 뭔가 확실하지 않은 부분이 있다면 똑같은 이름으로 재생성하는 것은 별로 추천되지 않는다.&lt;/p&gt;

&lt;h3 id=&quot;옵션-branch-재생성-강제-삭제&quot;&gt;옵션: Branch 재생성, 강제 삭제&lt;/h3&gt;

&lt;p&gt;하지만 예시를 보여주기 위해 만들어 보겠다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git branch 1st-branch&lt;br /&gt;
git checkout 1st-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그리고 &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt; 파일을 생성하고 마지막 줄에 다음을 입력한다. 곧 삭제할 것이기 때문에 아무거나 입력해도 괜찮다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Dummy!'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음으로 여러분은 이 수정 사항이 쓸모 있는 것이라고 생각하고 다음 명령까지 진행했다고 하자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git add first.py&lt;br /&gt;
git commit -m “dummy!”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;커밋 메시지가 너무 단순하다고 생각된다면, 다음 명령을 입력하라.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git commit –amend&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그러면 (아마도 vim이라고 하는) 편집기가 뜬다. 이 편집기의 사용법은 나중에 좀 더 자세히 다룰 텐데, 지금은 다음 과정만 따른다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;처음 편집기에 들어왔을 때는 ‘명령 모드’이다. 여기서 &lt;code class=&quot;highlighter-rouge&quot;&gt;i&lt;/code&gt;를 누르면 &lt;code class=&quot;highlighter-rouge&quot;&gt;INSERT&lt;/code&gt; 모드(명령창의 맨 아래에 뜬다)가 되어, 커밋 메시지를 수정할 수 있다.&lt;/li&gt;
  &lt;li&gt;다음으로 커밋 메시지를 바꾼다. &lt;code class=&quot;highlighter-rouge&quot;&gt;Dummy commit!&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;그리고 다음 키들을 차례로 입력한다. 하나도 틀려서는 안 된다.
    &lt;ol&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ESC&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;:&lt;/code&gt;   (콜론)&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;wq&lt;/code&gt;  (영문자 두 개이다)&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Enter&lt;/code&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;그러면 작성했던 커밋 메시지가 수정된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_11_github_usage_05_branch-basic/03_1st_branch.PNG&quot; alt=&quot;03_1st_branch&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_11_github_usage_05_branch-basic/04_dummy_commit.PNG&quot; alt=&quot;04_dummy_commit&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기까지는 문제가 없다. 그러나 추천되지 않는 행동이기에, 바로 삭제하려고 한다.&lt;br /&gt;
여러분도 프로젝트를 진행하다 보면 브랜치를 만들고 작업을 하다가 필요가 없어져서 삭제하려고 하는 상황이 올 것이다.&lt;/p&gt;

&lt;p&gt;2nd-branch로 checkout을 하고 삭제 명령을 입력한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout 2nd-branch&lt;br /&gt;
git branch -d 1st-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그러나 에러가 뜬다. 변경된 작업사항을 push하거나 merge하지 않았기 때문에, 수정사항을 잃어버릴 수도 있다고 경고하는 것이다.&lt;br /&gt;
물론 여러분은 이것이 쓸모없는 브랜치인 것을 알기 때문에, 강제로라도 삭제하면 된다.&lt;/p&gt;

&lt;p&gt;친절하게도 강제 삭제 명령을 git에서 알려 주었다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git branch -D 1st-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_11_github_usage_05_branch-basic/05_D.PNG&quot; alt=&quot;05_D&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 2nd-branch에서 다시 시작하자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;non-fast-forward-병합&quot;&gt;Non fast-forward 병합&lt;/h2&gt;

&lt;p&gt;이번엔 두 개의 서브 브랜치(참고로 티켓 브랜치라고도 부른다)에서 모두 master에 변경사항을 만들어 볼 것이다.&lt;br /&gt;
두 명의 사람이 각각 자신의 브랜치를 만들어서 master에 적용하려는 상황을 생각하라.&lt;br /&gt;
참고: 같은 컴퓨터에서는 명령창을 두 개 놓고 다른 브랜치에서 작업하는 것은 불가능하다.&lt;/p&gt;

&lt;p&gt;우선 2nd-branch에서, &lt;code class=&quot;highlighter-rouge&quot;&gt;second.py&lt;/code&gt; 파일의 끝에 다음을 추가한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;This is the 1st sentence written in 2nd-branch.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그리고 다음 명령들을 차례로 입력한다. 이 부분은 fast-forward 병합이다.&lt;br /&gt;
참고: 명령창에서 second.py를 입력할 때 ‘s’ 정도만 타이핑한 후 &lt;code class=&quot;highlighter-rouge&quot;&gt;Tab&lt;/code&gt; 키를 누르면 파일(또는 디렉토리) 이름이 자동완성된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git add second.py&lt;br /&gt;
git commit -m “This is the 1st commit written in 2nd-branch”&lt;br /&gt;
git checkout master&lt;br /&gt;
git merge 2nd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;파일 수정 시 빈 줄을 몇 개나 넣었느냐에 따라서 수정 사항(1 file changed, 3 insertions(+), 1 deletion(-)) 이 달라 보일 수 있으나, 여기선 별 상관 없다.&lt;br /&gt;
참고: 마지막 두 줄은 &lt;code class=&quot;highlighter-rouge&quot;&gt;git merge master 2nd-branch&lt;/code&gt;로 가능하다. 그러나 해당 브랜치에서 추가 작업이 필요한 경우 별로 편리한 명령은 아니다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_11_github_usage_05_branch-basic/06_fast.PNG&quot; alt=&quot;06_fast&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그리고 이제 커밋 코드를 확인해 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_11_github_usage_05_branch-basic/07_log.PNG&quot; alt=&quot;07_log&quot; /&gt;&lt;/p&gt;

&lt;p&gt;16진수 코드가 같다. fast-forward 방식으로 병합되었기 때문임은 설명했다.&lt;/p&gt;

&lt;p&gt;이제 3rd-branch로 이동한다.&lt;br /&gt;
그리고 3rd-branch에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;에 다음을 추가한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;This is the 1st sentence written in 3rd-branch.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그리고 다음 명령들을 입력한다. 조금 전과 매우 유사하다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git add first.py&lt;br /&gt;
git commit -m “This is the 1st commit written in 3rd-branch”&lt;br /&gt;
git checkout master&lt;br /&gt;
git merge 3rd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;세 브랜치의 로그를 확인해 보면 위와는 조금 차이가 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_11_github_usage_05_branch-basic/08_log.PNG&quot; alt=&quot;08_log&quot; /&gt;&lt;/p&gt;

&lt;p&gt;작업 트리를 그려보면 다음과 같다. master로 checkout했을 때를 기준으로 하였다(HEAD).&lt;br /&gt;
또한 fast-forward와 non fast-forward를 구분하여 그렸다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_11_github_usage_05_branch-basic/09.png&quot; alt=&quot;09&quot; /&gt;&lt;/p&gt;

&lt;p&gt;명령창에서 그래프를 그릴 수도 있다. 다음 둘 중 하나를 입력한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git log –graph&lt;br /&gt;
git log –graph –oneline&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_11_github_usage_05_branch-basic/10_graph.PNG&quot; alt=&quot;10_graph&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 그림들에서는 설명할 것이 많다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;2nd-branch merge 시: master에 새로운 수정사항이 없는 상태에서 다른 서브 브랜치의 커밋을 merge했을 때, fast-forward 방식으로 merge된다. 작업 트리에서 보듯이 master는 해당 브랜치의 커밋을 그대로 가져올 뿐이다.&lt;/li&gt;
  &lt;li&gt;3rd-branch merge 시: master에 수정사항이 있는 경우(2nd-branch로부터의 커밋 1개), non fast-forward 방식으로 merge된다. 이 때는 master가 3rd-branch의 커밋을 그대로 가져오기는 하지만, merge commit(90ce4f2)이라는 새로운 커밋이 생성된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;보충 설명은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;빨간색 글씨로 (origin/master)이라 되어 있는 부분이 있다. 이는 remote repo의 HEAD가 현재 local repo의 어떤 커밋까지 적용되어 있는지를 의미한다. 여러분은 ‘This is 1st commit written in 1st-branch’까지만 remote repo에 push했기 때문에, 현재 remote repo는 그 위치에 멈춰 있다. 이후에 push를 하면 위치가 바뀔 것이다.&lt;/li&gt;
  &lt;li&gt;master의 로그를 보면,
    &lt;ol&gt;
      &lt;li&gt;(origin/master) 이후에 (2nd-branch)가 있다. 이는 2nd-branch로부터 (merge하여) 가져온 커밋임을 의미한다. 바로 다음의 (3rd-branch)도 마찬가지이다.&lt;/li&gt;
      &lt;li&gt;(HEAD -&amp;gt; master)는 이전에 잠깐 설명했었는데, 현재 위치(HEAD)를 나타내는 동시에 현재 브랜치의 이름을 나타낸다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;로그를 출력한 그림의 맨 윗부분을 보면, “Your branch is ahead of ‘origin/master’ by 3 commits”라는 문구가 있다. 이는 조금 전 설명과도 일치하는 부분인데, 여러분의 local repo의 master가 remote repo의 master보다 3개의 커밋만큼 수정사항이 더 많다는 뜻이다. 3개의 커밋은 각각 (origin/master) 커밋 이후의 커밋들 3개이다.
    &lt;ol&gt;
      &lt;li&gt;(2nd-branch) This is the 1st commit written in 2nd-branch&lt;/li&gt;
      &lt;li&gt;(3rd-branch) This is the 1st commit written in 3rd-branch&lt;/li&gt;
      &lt;li&gt;(HEAD -&amp;gt; master) Merge branch ‘3rd-branch’&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;그럼 왜 2nd-branch와 3rd-branch로 checkout했을 때는 그런 메시지가 없는지 알 수 있을 것이다.
    &lt;ol&gt;
      &lt;li&gt;2nd-branch와 3rd-branch는 push한 적이 전혀 없다. 즉, remote repo에는 해당 브랜치들에 대한 정보가 전혀 없다. 브라우저를 켜서 확인해보라.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이제 local repo의 master의 변경사항을 remote repo에 업데이트하자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git status&lt;br /&gt;
git push&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_11_github_usage_05_branch-basic/11_push.PNG&quot; alt=&quot;11_push&quot; /&gt;&lt;/p&gt;

&lt;p&gt;master에서는 파일을 직접 수정하지 않고 merge만 했기 때문에, &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt;나 &lt;code class=&quot;highlighter-rouge&quot;&gt;git commit&lt;/code&gt; 명령이 따로 필요 없다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_11_github_usage_05_branch-basic/12_browser.PNG&quot; alt=&quot;12_browser&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ticket-branch-업데이트&quot;&gt;Ticket branch 업데이트&lt;/h2&gt;

&lt;p&gt;티켓 브랜치(서브 브랜치)의 로그는 master의 로그보다 조금씩 적었다. 그 이유는 master에는 모든 수정사항이 적용되었지만, 2nd-branch와 3rd-branch는 각각 상대 서브 브랜치의 수정사항이 적용되어있지 않기 때문이다.&lt;/p&gt;

&lt;p&gt;물론 2nd-branch와 3rd-branch는 각각 서로 부모 자식 간의 관계가 아니기 때문에, 서로 직접 상호작용할 이유는 없다.&lt;br /&gt;
상호작용은 직접 연관된 master와만 하면 된다.&lt;/p&gt;

&lt;p&gt;master에 적용된 수정사항(자신의 것이 아닌, 팀원이 만든 커밋을 가져온다)을 가져오고 싶으면 다음을 수행하라.&lt;br /&gt;
바로 push까지 수행한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout 2nd-branch&lt;br /&gt;
git rebase master&lt;br /&gt;
git push –set-upstream origin 2nd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_11_github_usage_05_branch-basic/13_2nd.PNG&quot; alt=&quot;13_2nd&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 그림에서 “Fast-forwarded 2nd-branch to master.”라는 문구를 볼 수 있다. 2nd-branch에서 더 이상의 수정사항이 발생하지 않은 상태에서 master의 커밋을 가져왔기 때문에 fast-forward 조건이 성립하고, 이를 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;다음 명령들을 수행하여 master의 로그와 비교하면 2nd-branch의 로그와 커밋 코드가 완전히 같아졌음을 볼 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout master&lt;br /&gt;
git log –oneline&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;팀원의 브랜치도 업데이트해 주자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout 3rd-branch&lt;br /&gt;
git merge master&lt;br /&gt;
git push –set-upstream origin 3rd-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 경우에는 merge나 rebase나 별다른 차이가 없다.&lt;/p&gt;

&lt;p&gt;이제 브랜치의 기본적인 내용은 끝났다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;merge-vs-rebase&quot;&gt;Merge vs Rebase&lt;/h2&gt;

&lt;p&gt;브랜치 간 병합을 수행할 수 있는 명령은 merge와 rebase가 있는데, 간략히 차이를 적어 보면 다음과 같다.&lt;/p&gt;

&lt;p&gt;Merge: &lt;code class=&quot;highlighter-rouge&quot;&gt;git merge &amp;lt;branch&amp;gt;&lt;/code&gt;로 사용. 해당 브랜치의 변경사항을 현재 브랜치로 (그대로) 가지고 온다. 이때 가져온 커밋들은 현재 HEAD의 위쪽에 그대로 쌓인다. 경우에 따라 Merge commit이 남을 수 있다.&lt;br /&gt;
Rebase: 이름 그대로 base를 바꾸는 것이다. base가 되는 커밋의 위치를 바꾼다.&lt;/p&gt;

&lt;p&gt;base를 예시를 들어 설명하면,&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;3rd-branch는 master에서 생성되었다. 이때 생성 시점은 master가 “6df3479 This is 1st commit written in 1st-branch” 커밋까지 포함한 상태였다. 여기서 3rd-branch의 base는 바로 이 커밋이다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git rebase master&lt;/code&gt; 명령을 실행하면, master의 tip(HEAD) 으로 base를 재설정한다. 그러면 master의 커밋들로부터 시작한 셈이 되므로, master의 커밋들을 가져온 결과와 같다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Merge와 rebase는 사용법이 조금 다르다. 이는 나중에 설명하도록 하겠다.&lt;br /&gt;
사람에 따라서는 별 구분 없이 사용하기도 한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이제 git의 branch에 대한 기본적인 설명을 알아보았으니, &lt;a href=&quot;https://greeksharifa.github.io/github/2018/08/12/github-usage-06-branch-intermediate/&quot;&gt;다음 글&lt;/a&gt;에서는 브랜치를 관리하는 법에 대해서 알아본다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;git-명령어&quot;&gt;Git 명령어&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-00-command-list/&quot;&gt;GitHub 사용법 - 00. Command List&lt;/a&gt;에서 원하는 명령어를 찾아 볼 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>GitHub 사용법 - 04. branch 기본 1</title>
   <link href="http://localhost:4000/github-usage-04-branch-basic/"/>
   <updated>2018-08-07T00:00:00+09:00</updated>
   <id>http://localhost:4000/github-usage-04-branch-basic</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 글을 읽는 여러분이, 만약 git을 많이 써 봐서 익숙한 것이 아니라면, 반드시 손으로 직접 따라 칠 것을 권한다. 눈으로만 보면 100% 잊어버린다.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/07/08/github-usage-03-clone-log-gitignore/&quot;&gt;저번 글&lt;/a&gt;에서 작업하던 것을 이어서 한다. 그때 master branch란 말을 잠깐 언급했었다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;branch&quot;&gt;Branch&lt;/h2&gt;

&lt;p&gt;여러분은 별다른 설정을 하지 않았지만 master branch에서 계속 작업을 하고 있었다.&lt;br /&gt;
&lt;strong&gt;master branch&lt;/strong&gt;란 모든 repository의 기본 혹은 메인이라고 보면 된다. 일반적으로 repo의 모든 것은 master branch를 중심으로 행해진다.&lt;/p&gt;

&lt;p&gt;큰 프로젝트든 개인 프로젝트이든 최종 결과물은 master branch에 있기 마련이며, master branch로부터 파생된 다른 branch들로부터 수정 사항을 만든 다음 master에 병합하는 과정을 거치게 된다.&lt;/p&gt;

&lt;p&gt;여러 사람이 협업할 경우 각자 따로 브랜치를 쓰게 되며, 각 브랜치에서는 새로운 기능을 개발하거나 버그 수정이 이루어진다. 물론 완료되면 master branch에 병합되게 된다.&lt;/p&gt;

&lt;p&gt;위의 설명이 정석적인 git repo의 운영방법이고, master branch에는 일반적으로 직접 수정을 가하지 않는다. 따라서 별다른 일이 없다면 본 글에서부터는 master branch에 직접 commit을 날리지 않고, branch를 만든 다음 병합하는 과정을 거칠 것이다.&lt;/p&gt;

&lt;p&gt;잠깐 브라우저를 켜서 브랜치 부분을 클릭해 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/01_init_screen.PNG&quot; alt=&quot;01_init_screen&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그러면 ‘Default’로 표시되어 있는 master branch 하나가 보일 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/02_master.PNG&quot; alt=&quot;02_master&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 명령어 입력을 시작하자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;branch-목록-보기&quot;&gt;branch 목록 보기&lt;/h3&gt;

&lt;p&gt;목록을 보는 옵션은 여러 가지가 있다. &lt;code class=&quot;highlighter-rouge&quot;&gt;git branch&lt;/code&gt; 혹은 &lt;code class=&quot;highlighter-rouge&quot;&gt;git branch --list&lt;/code&gt;를 입력해 보자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/03_list.PNG&quot; alt=&quot;03_list&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 명령은 local repo에 저장되어 있는 branch들의 리스트를 보여 준다. 다른 branch를 만들지 않았기 때문에 master 하나밖에 보이지 않을 것이다.&lt;/p&gt;

&lt;p&gt;이제 여러분은 다음과 같은 형태의 트리를 갖고 있다.&lt;br /&gt;
그렇다. branch는 tree의 것이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/04_branch.png&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;조금 더 자세하게 그리기 위해, &lt;code class=&quot;highlighter-rouge&quot;&gt;git log --oneline&lt;/code&gt;을 명령창에 입력한다. &lt;a href=&quot;https://greeksharifa.github.io/github/2018/07/08/github-usage-03-clone-log-gitignore/#local-repo-%EC%83%81%ED%83%9C-%ED%99%95%EC%9D%B8%ED%95%98%EA%B3%A0-git-pull%EB%A1%9C-local-repo-%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8%ED%95%98%EA%B8%B0&quot;&gt;무엇을 하는 것&lt;/a&gt;인지 잊어버리지는 않았을 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/05_log.PNG&quot; alt=&quot;05_log&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 트리를 다시 그려보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/06_branch.png&quot; alt=&quot;06_branch&quot; /&gt;&lt;/p&gt;

&lt;p&gt;앞으로 위와 비슷한 그림이 자주 나올 텐데, 각각의 의미를 정확히 알고 있는 것이 앞으로 git을 이해하는 데 큰 도움이 될 것이다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;저번 글에서 간략히 언급했는데, 앞의 복잡한 숫자는 16진수 숫자로서 각 커밋의 고유한 코드이다. 유일한 값이므로 어떤 커밋인지 분간할 때 도움이 될 것이다.
    &lt;ol&gt;
      &lt;li&gt;여러분이 커밋 메시지를 간략하게 작성할수록 16진수 코드를 봐야 하는 상황이 많아진다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;16진수 코드 다음에는 여러분이 입력한 커밋 메시지가 나온다.&lt;/li&gt;
  &lt;li&gt;(HEAD -&amp;gt; master, origin/master) 메시지는 이전 글에서 설명했다. 사실 1, 2번도 전부 설명했다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;그런데 origin이 무엇인지 궁금하지 않은가?&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;옵션-origin&quot;&gt;옵션: origin&lt;/h3&gt;

&lt;p&gt;저번 글에서는 일반적으로 remote repo의 이름은 origin으로 둔다고 하였다. 그러나 이는 사용자 마음이다.&lt;/p&gt;

&lt;p&gt;dummy repo를 하나 만들자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/08_dummy.PNG&quot; alt=&quot;08_dummy&quot; /&gt;&lt;/p&gt;

&lt;p&gt;dummy local repo도 만들어 올려보자. 이때 origin 대신 dummy_origin으로 입력해 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/10_dummy.PNG&quot; alt=&quot;10_dummy&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그리고 파일을 수정하고 추가한 뒤 git push origin master를 입력하면 오류가 뜬다.&lt;br /&gt;
dummy_origin으로 입력하면 잘 되는 것을 확인할 수 있다.&lt;br /&gt;
즉 origin은 add나 commit 명령처럼 정해져 있는 것이 아니라 사용자가 마음대로 정하는 것이지만, 별다른 이유가 없다면 origin으로 두는 것이 괜찮다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/12_dummy.PNG&quot; alt=&quot;12_dummy&quot; /&gt;&lt;/p&gt;

&lt;p&gt;참고로 &lt;code class=&quot;highlighter-rouge&quot;&gt;git status -s&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;git status&lt;/code&gt;보다 간략한 버전이다.&lt;/p&gt;

&lt;p&gt;이제 dummy는 dummy니까 갖다 버리면 된다. Settings 탭의 맨 아래로 가보면 다음과 같은 부분이 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/14_dummy.PNG&quot; alt=&quot;14_dummy&quot; /&gt;&lt;/p&gt;

&lt;p&gt;삭제하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/15_dummy.PNG&quot; alt=&quot;15_dummy&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;원격-branch-목록-보기&quot;&gt;원격 branch 목록 보기&lt;/h3&gt;

&lt;p&gt;이제 dummy repo는 잊어버리고, 원래 하던 것으로 돌아오자.&lt;/p&gt;

&lt;p&gt;local repo 말고 remote repo의 브랜치를 알고 싶다면 다음 중 하나를 입력한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git branch -r&lt;br /&gt;
git branch –remote&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;local이랑 remote 전부 보고 싶으면 다음을 입력한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git branch -a&lt;br /&gt;
git branch –all&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/07_branch_op.PNG&quot; alt=&quot;07_branch_op&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-r&lt;/code&gt; 옵션과 &lt;code class=&quot;highlighter-rouge&quot;&gt;-a&lt;/code&gt; 옵션의 remote repo 표기가 조금 다르다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;-a&lt;/code&gt; 옵션은 local repo와 remote repo를 구분하기 위해 ‘remotes/’를 remote repo 앞에 붙인다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;-r&lt;/code&gt; 옵션은 remote repo만 보여주기 때문에 ‘remotes/’ 표시가 필요 없다.&lt;/p&gt;

&lt;p&gt;이제 local repo와 remote repo에 무엇이 있는지 알았으니, 브랜치를 새로 만들어 보자.&lt;br /&gt;
원래는 서브 브랜치를 새로 생성할 메인 브랜치(master일 필요는 없다)로 이동하는 과정이 우선되어야 하지만, 지금은 master branch 하나뿐이므로 그럴 이유가 없다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git branch 1st-branch&lt;br /&gt;
git branch -a&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/16_create_branch.PNG&quot; alt=&quot;16_create_branch&quot; /&gt;&lt;/p&gt;

&lt;p&gt;현재 있는 브랜치 앞에는 ‘*‘이 있다. 여러분의 컴퓨터 환경에 따라 다를 수는 있으나, Windows cmd 기준으로는 현재 있는 브랜치는 초록색, remote repo의 브랜치는 빨간색으로 표시된다.&lt;/p&gt;

&lt;h3 id=&quot;branch-이동-checkout&quot;&gt;branch 이동: checkout&lt;/h3&gt;

&lt;p&gt;이제 새로운 브랜치로 이동해 보자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout 1st-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/17_checkout.PNG&quot; alt=&quot;17_checkout&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;에 다음을 추가한다. 이제부터 여러분은 &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;를 수정한 다음, 커밋을 만들고, master branch에 병합하는 과정을 거칠 것이다.&lt;br /&gt;
앞서 설명했듯 서브 브랜치를 만들어서 그곳에서 작업한 후 master branch에 병합하는 것이 정석적인 방법이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;This is the 1st sentence written in 1st-branch.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그리고 3종 세트를 입력한다. 싫으면 &lt;a href=&quot;https://greeksharifa.github.io/github/2018/07/08/github-usage-03-clone-log-gitignore/#%EC%98%B5%EC%85%98-3%EC%A2%85-%EC%84%B8%ED%8A%B8-%EA%B0%84%ED%8E%B8-%EC%9E%85%EB%A0%A5%EC%9C%88%EB%8F%84%EC%9A%B0-%EA%B8%B0%EC%A4%80&quot;&gt;옵션&lt;/a&gt;에서 다루었던 &lt;code class=&quot;highlighter-rouge&quot;&gt;push.bat&lt;/code&gt;을 입력해도 상관없다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/18_1st_commit.PNG&quot; alt=&quot;18_1st_commit&quot; /&gt;&lt;/p&gt;

&lt;p&gt;사실 그냥은 안 된다. remote repo 기준에서 여러분이 로컬에 만든 1st-branch라는 브랜치는 전혀 알 수 없는 것(정확히는 local repo에 upstream branch가 없는 것이다)이며, 연결 작업이 필요하다.&lt;br /&gt;
다행히 upstream branch(local branch와 연결할 remote branch)를 설정하는 방법을 명령창에서 친절히 알려 준다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git push –set-upstream origin 1st-branch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;remote repo 이름이 origin이고 current branch의 이름이 1st-branch이기 때문에 저렇게 입력해주면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/19_upstream.PNG&quot; alt=&quot;19_upstream&quot; /&gt;&lt;/p&gt;

&lt;p&gt;브라우저를 확인해보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/20_push.PNG&quot; alt=&quot;20_push&quot; /&gt;&lt;/p&gt;

&lt;p&gt;브랜치가 2개가 되었음을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;이제 다음과 같은 상태가 되었다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/21_log.PNG&quot; alt=&quot;21_log&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/22_branch.png&quot; alt=&quot;22_branch&quot; /&gt;&lt;/p&gt;

&lt;p&gt;참고로 1st-branch의 커밋들의 16진수 코드는 master branch의 같은 커밋의 16진수 코드와 똑같다.&lt;br /&gt;
master branch로부터 생성했으니 당연한 말이다.&lt;/p&gt;

&lt;p&gt;방금 수정했기 때문에, &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;의 현재 상태는 다음과 같을 것이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Hello, git!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# instead of &quot;Hello, World!&quot;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Hi, git!!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;This is the 1st sentence written in 1st-branch.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그럼 이제 master branch로 다시 돌아가 본다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git checkout master&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그리고 &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;를 다시 확인해 보라.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Hello, git!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# instead of &quot;Hello, World!&quot;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Hi, git!!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;마지막 문장이 사라졌을 것이다. 편집기를 사용하고 있었다면 ‘다시 로드’를 클릭하라.&lt;/p&gt;

&lt;p&gt;여러분은 1st-branch에서 작업했을 뿐이다. master branch로부터 서브 브랜치를 생성하는 순간부터, 어떤 새로운 상호작용을 하기 전까지 1st-branch는 master branch와는 ‘거의’ 독립적인 공간에 가깝다. 따라서 branch를 checkout하는 순간 1st-branch에서 수정했던 사항이 보이지 않게 되는 것이다.&lt;/p&gt;

&lt;p&gt;물론 진짜로 사라진 것은 아니다. 다시 1st-branch로 checkout하면 내용이 돌아올 것이다.&lt;br /&gt;
아무튼 다시 master branch로 이동하자.&lt;/p&gt;

&lt;h3 id=&quot;브랜치-병합-merge&quot;&gt;브랜치 병합: merge&lt;/h3&gt;

&lt;p&gt;글의 윗부분에서 프로젝트 진행 과정을 설명하면서 다음과 비슷한 말을 했었다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;서브 브랜치를 만들어 작업한다.&lt;/li&gt;
  &lt;li&gt;메인 브랜치(master branch)로 이동한다.&lt;/li&gt;
  &lt;li&gt;서브 브랜치의 내용을 메인 브랜치에 병합한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위 과정 중 여러분은 1, 2번을 완료했다. 이제 3번을 하기만 하면 된다.&lt;br /&gt;
현재 브랜치가 master branch인지 꼭 확인한 후 다음을 진행해야 한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git merge 1st-branch&lt;br /&gt;
git push&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;참고로 merge한다고 remote repo에 절대로 자동으로 올라가지 않는다. 따라서 push를 해 주어야 한다. 이&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/23_merge.PNG&quot; alt=&quot;23_merge&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그리고 &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;를 확인하면 1st-branch에서 추가했던 문장이 들어 있는 것을 확인할 수 있다.&lt;br /&gt;
또한 커밋의 16진수 코드도 1st-branch의 것과 같음을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/24_log.PNG&quot; alt=&quot;24_log&quot; /&gt;&lt;/p&gt;

&lt;p&gt;즉 다음과 같은 상태이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/25_branch.png&quot; alt=&quot;25_branch&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위와 같이 병합하는 것을 fast-forward라 한다. fast-forward는 master branch에서 서브 브랜치(1st-branch)를 하나 만든 뒤 master에는 별다른 수정 사항이 없을 때 위 그림처럼 master branch에는 같은 코드의 커밋이 적용되며, 빨리감기하듯 따라간다는 점에서 이러한 이름이 붙었다.&lt;/p&gt;

&lt;h3 id=&quot;branch-삭제-목록-업데이트&quot;&gt;branch 삭제, 목록 업데이트&lt;/h3&gt;

&lt;p&gt;그런데 그림을 보면 master와 1st-branch는 모두 살아 있는 branch이다. 실제로 1st-branch에 커밋을 만들고 push하면 1st-branch만 업데이트된다.&lt;br /&gt;
이는 Merge 명령은 non-destructive operation으로, master branch에서 1st-branch의 내용을 가져간다 해도 1st-branch는 전혀 변경되지 않는다.&lt;br /&gt;
다른 블로그들에서는 완전히 같은 곳을 가리키는 것처럼 말하지만, 실제로는 “정말로” 같은 레퍼런스인 것은 아니다. git은 모든 걸 자동으로 해주지는 않기 때문이다.&lt;br /&gt;
그러나 bugfix같이 잠시 만들었다가 없앨 목적으로 만든 branch라면, 이 브랜치를 없앨 필요가 있다.&lt;br /&gt;
물론 이 예제의 경우 bugfix는 아니지만, 몇 줄짜리 코드에 bug가 있으면… 흠.&lt;/p&gt;

&lt;p&gt;브랜치를 제거할 때는 두 가지를 확인해야 한다. local branch와 remote branch이다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git branch -d 1st-branch&lt;br /&gt;
git push -d origin 1st-branch&lt;br /&gt;
git fetch&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;당연히 -d 대신 –delete도 가능하다.&lt;/p&gt;

&lt;p&gt;세 번째 명령 &lt;strong&gt;git fetch&lt;/strong&gt;는 원격 브랜치 목록을 업데이트하는 것이다. 원격 브랜치 목록도 자동으로 업데이트되지 않기 때문이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/26_delete.PNG&quot; alt=&quot;26_delete&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_08_07_github_usage_04_branch-basic/27_1.PNG&quot; alt=&quot;27_1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;remote repo에도 master branch 하나만 남은 것을 확인할 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/08/11/github-usage-05-branch-basic/&quot;&gt;다음 글&lt;/a&gt;에서는 branch에 대해서 더 알아본다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;git-명령어&quot;&gt;Git 명령어&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-00-command-list/&quot;&gt;GitHub 사용법 - 00. Command List&lt;/a&gt;에서 원하는 명령어를 찾아 볼 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>파이썬 정규표현식(re) 사용법 - 08. 예제(단어, 행)</title>
   <link href="http://localhost:4000/regex-usage-08-example/"/>
   <updated>2018-08-06T00:00:00+09:00</updated>
   <id>http://localhost:4000/regex-usage-08-example</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/20/regex-usage-01-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 01. Basic&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/21/regex-usage-02-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 02. 문자, 경계, flags&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/22/regex-usage-03-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 03. OR, 반복&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/28/regex-usage-04-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 04. 그룹, 캡처&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/04/regex-usage-05-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 05. 주석, 치환, 분리&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/05/regex-usage-06-advanced/&quot;&gt;파이썬 정규표현식(re) 사용법 - 06. 치환 함수, 양방탐색, 조건문&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-07-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 07. 예제(숫자)&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-08-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 08. 예제(단어, 행)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/24/regex-usage-09-other-functions/&quot;&gt;파이썬 정규표현식(re) 사용법 - 09. 기타 기능&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이 글에서는 정규표현식으로 처리할 수 있는 예제를 설명한다.&lt;/p&gt;

&lt;p&gt;본 글에서 정규표현식은 &lt;code class=&quot;highlighter-rouge&quot;&gt;regex&lt;/code&gt;와 같이, 일반 문자열은 ‘regex’와 같이 표시하도록 한다.&lt;/p&gt;

&lt;p&gt;파이썬 버전은 3.6을 기준으로 하나, 3.x 버전이면 (아마) 동일하게 쓸 수 있다.&lt;br /&gt;
2.7 버전은 한글을 포함한 비 알파벳 문자 처리가 다르다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;단어&quot;&gt;단어&lt;/h2&gt;

&lt;h3 id=&quot;기초&quot;&gt;기초&lt;/h3&gt;

&lt;p&gt;문제 1: colour, Color, color 등 모든 버전의 color에 일치되는 정규식을 작성하라.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 1 정답보기&lt;/summary&gt;
    &lt;p&gt;r'\b(?i)colou?r\b'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;(?i)&lt;/code&gt; 모드 변경자 대신에 &lt;strong&gt;re.IGNORECASE&lt;/strong&gt; 옵션을 주어도 상관없다.&lt;/p&gt;

&lt;p&gt;다음 문제는 이전에 본 적이 있는 문제이다.&lt;/p&gt;

&lt;p&gt;문제 2: cat에는 일치되지 않고, cat을 포함하면서 그보다 긴 단어, staccato, cats, tomcat 등에 일치되는 정규식을 작성하라.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 2 정답보기&lt;/summary&gt;
    &lt;p&gt;r'\Bcat\B'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;특정-단어-배제&quot;&gt;특정 단어 배제&lt;/h3&gt;

&lt;p&gt;문제 3: 이번에는 특정 단어를 제외시켜 보자. reg를 제외한 모든 단어에 일치되도록 하는 정규식을 작성하라.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 3 정답보기&lt;/summary&gt;
    &lt;p&gt;r'\b(?!reg\b)\w+'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;생각하기 조금 어려웠을 것 같다.&lt;/p&gt;

&lt;p&gt;부정 전방탐색이 빛을 발하는 순간이다. 부정 전방탐색을 씀으로써 앞에 단어 경계가 있고(&lt;code class=&quot;highlighter-rouge&quot;&gt;\b&lt;/code&gt;), ‘reg’로 이루어져 있으며(&lt;code class=&quot;highlighter-rouge&quot;&gt;reg&lt;/code&gt;), 바로 뒤에 &lt;code class=&quot;highlighter-rouge&quot;&gt;\b&lt;/code&gt;이 나와 끝나버리는, 즉 ‘reg’에 정확히 일치되는 순간이 되면 위 정규식은 일치에 실패한다.&lt;br /&gt;
따라서 특정 단어 ‘reg’를 배제할 수 있게 된다. 부정 전방탐색의 일치에 실패하면, 그 다음 부분인 &lt;code class=&quot;highlighter-rouge&quot;&gt;\w+&lt;/code&gt;를 갖고 일치를 시도한다. 단어면 성공할 것이다.&lt;/p&gt;

&lt;p&gt;문제 4: 이번엔 특정 단어뿐 아니라 그 단어를 포함하는 단어도 제외시켜 보자. reg뿐만 아니라 regex, register, dreg 등은 모두 제외되어야 한다.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 4 정답보기&lt;/summary&gt;
    &lt;p&gt;r'\b(?:(?!cat)\w)+\b'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;문제 3번을 생각해냈으면 이 문제도 풀 수 있을 것이라고 생각한다.&lt;/p&gt;

&lt;p&gt;주어진 조건은 프로그래밍이 가능한 다음 세 문장으로 압축할 수 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;단어 중간의 어떤 부분에서든 그 앞에 ‘reg’가 와서는 안 된다. &lt;code class=&quot;highlighter-rouge&quot;&gt;(?!cat)\w&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;1번을 만족했으면, 단어 문자가 1개 이상은 있어야 한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;( ... \w)+&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;물론 양끝에 단어 경계는 있어야 한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;\b ... \b&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위 세 조건을 적용시키면 ‘reg’가 단어에 포함된다면 일치되지 않는다는 사실을 알 수 있다.&lt;/p&gt;

&lt;p&gt;문제 5: 바로 뒤에 숫자가 따라오는 단어를 무시하는, 다른 모든 단어를 검색하는 정규식을 작성하라. 단어와 숫자 사이에는 비 단어 문자가 온다고 가정하자.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 5 정답보기&lt;/summary&gt;
    &lt;p&gt;r'\b\w+\b(?!\W+\d+\b'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이번에도 부정 전방탐색을 사용하면 된다. 무엇을 제외하고 싶다면 부정 양방탐색을, 다른 조건을 더 추가해야 한다면 긍정 양방탐색을 사용한다는 것을 기억하자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;행&quot;&gt;행&lt;/h2&gt;

&lt;h3 id=&quot;빈-행-제거&quot;&gt;빈 행 제거&lt;/h3&gt;

&lt;p&gt;문제 6: 빈 행을 제거하자. 예컨대 ‘\n\n’ 을 ‘\n’ 하나로 치환하여 불필요한 행을 제거하는 식이다. 운영체제에 독립적으로 작성되어야 한다.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 6 정답보기&lt;/summary&gt;
    &lt;p&gt;re.sub(r'\n+', r'\n', string)&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;개행 문자 말고 모든 공백 문자를 하나로 치환하려면 다음을 쓰면 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\s+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;' '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;가로 공백 문자만 치환하려면 &lt;code class=&quot;highlighter-rouge&quot;&gt;\s&lt;/code&gt; 대신 &lt;code class=&quot;highlighter-rouge&quot;&gt;[ \t]&lt;/code&gt;를 사용하라.&lt;/p&gt;

&lt;h3 id=&quot;중복-행-제거&quot;&gt;중복 행 제거&lt;/h3&gt;

&lt;p&gt;문제 7: 중복 행을 제거하자. 똑같은 내용의 행이 두 번 이상 반복되는 행을 하나만 남겨두고 모두 제거하자.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 7 정답보기&lt;/summary&gt;
    &lt;p&gt;re.sub(r'^(.*)(?:(?:\r?\n|\r)\1)+$', r'\1', re.MULTILINE)&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;복잡해 보이지만 크게 어렵진 않다. 중복 행이란 다음과 같은 구조일 것이다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;행 내용&lt;/li&gt;
  &lt;li&gt;행 구분자&lt;/li&gt;
  &lt;li&gt;행 내용&lt;/li&gt;
  &lt;li&gt;행 구분자&lt;/li&gt;
  &lt;li&gt;행 내용
…&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;행 내용은 &lt;code class=&quot;highlighter-rouge&quot;&gt;(.*)&lt;/code&gt;으로 간단히 해결된다. 나중에 똑같은 것을 일치시켜야 하므로 캡처 그룹을 사용한다.&lt;br /&gt;
그리고 행 구분자를 사용하는데, 운영체제에 상관없이 사용하기 위해 조금 복잡하게(&lt;code class=&quot;highlighter-rouge&quot;&gt;\r?\n|\r&lt;/code&gt;)이 들어갔지만, 자신이 무슨 운영체제에서 프로그래밍하고 있으며 어떤 운영체제에서 작성된 파일을 갖고 있는지 안다면 하나만 써도 무방하다.&lt;br /&gt;
그 다음은 행 내용을 재사용하기 위한 &lt;code class=&quot;highlighter-rouge&quot;&gt;\1&lt;/code&gt;, 1회 이상 반복을 위한 &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt;, 그리고 한 행만 남겨두고 제거하기 위한 &lt;code class=&quot;highlighter-rouge&quot;&gt;r'\1'&lt;/code&gt;을 사용하면 해결된다.&lt;/p&gt;

&lt;p&gt;주의할 점으로는 &lt;strong&gt;re.MULTILINE&lt;/strong&gt; 옵션을 주어야 하며, &lt;strong&gt;re.DOTALL&lt;/strong&gt;은 절대로 주어서는 안 되는 옵션이라는 점이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;조금 더 복잡한 예제를 정리해 두면 좋겠지만, 그때그때 맞게 쓰는 것이 더 나을 것 같아서 굳이 따로 정리할 필요는 없을 것 같다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/24/regex-usage-09-other-functions/&quot;&gt;다음 글&lt;/a&gt;에서는 &lt;strong&gt;re&lt;/strong&gt; 패키지에 포함된 다른 함수들을 다루도록 하겠다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>파이썬 정규표현식(re) 사용법 - 07. 예제(숫자)</title>
   <link href="http://localhost:4000/regex-usage-07-example/"/>
   <updated>2018-08-06T00:00:00+09:00</updated>
   <id>http://localhost:4000/regex-usage-07-example</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/20/regex-usage-01-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 01. Basic&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/21/regex-usage-02-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 02. 문자, 경계, flags&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/22/regex-usage-03-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 03. OR, 반복&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/28/regex-usage-04-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 04. 그룹, 캡처&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/04/regex-usage-05-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 05. 주석, 치환, 분리&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/05/regex-usage-06-advanced/&quot;&gt;파이썬 정규표현식(re) 사용법 - 06. 치환 함수, 양방탐색, 조건문&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-07-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 07. 예제(숫자)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-08-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 08. 예제(단어, 행)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/24/regex-usage-09-other-functions/&quot;&gt;파이썬 정규표현식(re) 사용법 - 09. 기타 기능&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이 글에서는 정규표현식으로 처리할 수 있는 예제를 설명한다.&lt;/p&gt;

&lt;p&gt;본 글에서 정규표현식은 &lt;code class=&quot;highlighter-rouge&quot;&gt;regex&lt;/code&gt;와 같이, 일반 문자열은 ‘regex’와 같이 표시하도록 한다.&lt;/p&gt;

&lt;p&gt;파이썬 버전은 3.6을 기준으로 하나, 3.x 버전이면 (아마) 동일하게 쓸 수 있다.&lt;br /&gt;
2.7 버전은 한글을 포함한 비 알파벳 문자 처리가 다르다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;숫자&quot;&gt;숫자&lt;/h2&gt;

&lt;h3 id=&quot;십진-정수&quot;&gt;십진 정수&lt;/h3&gt;

&lt;p&gt;문제 1: 가장 간단한 십진 정수를 찾는 정규식을 작성하라.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 1 정답보기&lt;/summary&gt;
    &lt;p&gt;r'\b[0-9]+\b'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;문제 2: 가장 일반적인 형태의 십진 정수를 찾는 정규식을 작성하라. 맨 앞에 ‘+’ 혹은 ‘-‘ 기호가 붙어 있을 수 있으며, 기호와 숫자 사이에는 공백이 하나 있을 수 있다.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 2 정답보기&lt;/summary&gt;
    &lt;p&gt;r'(?:[+-] ?)?\b\d+\b'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;비 아스키 숫자를 포함하고 싶다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;\d&lt;/code&gt;를, 오로지 아라비아 숫자 10개만 숫자로 인식하게 하고 싶다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;[0-9]&lt;/code&gt;를 사용하도록 한다.&lt;br /&gt;
또한 문자열 전체에 일치되게 하고 싶다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;\A&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;\Z&lt;/code&gt;를 사용하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;십진-정수의-leading-zero-제거&quot;&gt;십진 정수의 leading-zero 제거&lt;/h4&gt;

&lt;p&gt;문제 3: 십진 정수의 앞에 오는 0들을 제거하는 정규식을 작성하라. 기호는 없다고 가정하자.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 3 정답보기&lt;/summary&gt;
    &lt;p&gt;re.sub(r'\b0*([1-9][0-9]*|0)\b', r'\1', string)&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;leading-zero가 될 수 있는 부분과 그렇지 않은 부분을 구분하기만 하면 이 문제는 풀린다. 그리고 leading-zero를 제거하는 것이 목표이므로 캡처된 부분으로 &lt;strong&gt;re.sub&lt;/strong&gt; 메서드를 쓰면 해결된다.&lt;/p&gt;

&lt;p&gt;한 가지 주의점은 ‘0’ 또는 ‘00’ 등 진짜 0밖에 없는 경우이다. 이 경우 0을 하나 남겨두어야 하기 때문에, leading-zero 뒤 숫자 부분에서 0을 한 개 남겨 두었다(&lt;code class=&quot;highlighter-rouge&quot;&gt;|0&lt;/code&gt;).&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;16진수&quot;&gt;16진수&lt;/h3&gt;

&lt;p&gt;문제 4: 16진수를 찾는 정규식을 작성하라. 0-9의 숫자와 A-F 알파벳만 쓴다고 하자.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 4 정답보기&lt;/summary&gt;
    &lt;p&gt;r'\A[0-9A-F]+\Z'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;문제 5: 16진수를 찾는 정규식을 작성하라. 16진수는 아라비아 숫자 10개 또는 A-F, a-f를 사용하되 대문자와 소문자를 섞어 쓰지는 않는다. 또한, 16진수임을 나타내기 위해 숫자 바로 앞에 ‘0x’나 ‘&amp;amp;H’(hexa의 의미)를 붙이거나, 혹은 숫자 뒤에 ‘H’를 붙인다.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 5 정답보기&lt;/summary&gt;
    &lt;p&gt;r'(\b0x|&amp;amp;H)?(?:[0-9A-F]+|[0-9a-f]+)(?(1)|H?)\b'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;꽤 어려워 보일 것이다. 정규식은 복잡해지면 주석이 꼭 필요하다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;(\b0x|&amp;amp;H)?&lt;/code&gt;: 보통 단어 경계를 맨 앞에 두는데, 이번엔 다자택일 중 하나에 두었다. 이유는 엠퍼샌드(‘&amp;amp;’)는 문자 집합에 포함되지 않으므로 단어 경계를 쓰면 안 된다.
    &lt;ol&gt;
      &lt;li&gt;앞에 16진수 식별자를 두는 것은 선택적이므로 &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt;를 쓴다.&lt;/li&gt;
      &lt;li&gt;그리고 이 부분은 첫 번째 캡처 그룹을 형성한다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;(?:[0-9A-F]+|[0-9a-f]+)&lt;/code&gt;: 16진수 숫자를 나타내는 부분만 빼고 싶다면 앞부분의 비 캡처 그룹임을 의미하는 &lt;code class=&quot;highlighter-rouge&quot;&gt;?:&lt;/code&gt;를 빼면 된다.
    &lt;ol&gt;
      &lt;li&gt;대소문자 혼용을 허용하지 않았으므로 대문자를 쓸 때와 소문자를 쓸 때를 분리하였다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;(?(1)|H?)&lt;/code&gt;: 조건문이다. 첫 번째 캡처 그룹에서 만약에 ‘0x’나 ‘&amp;amp;H’가 일치되었으면, 뒤에 또 ‘H’ 식별자를 두지는 않는다. 따라서 일치되었으면(‘맞으면’) 아무것도 없는 경우를, 일치되지 않았으면 ‘H’ 식별자를 선택적으로 일치시킬 수 있도록 한다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;\b&lt;/code&gt;: 단어 경계이다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;참고-지정된-범위의-숫자인지-확인&quot;&gt;참고: 지정된 범위의 숫자인지 확인&lt;/h3&gt;

&lt;p&gt;이는 정규식으로 작성하길 추천하지 않는다. 아니면 함수로 따로 빼 두는 것을 추천한다.&lt;br /&gt;
그냥 숫자인지만 정규식으로 확인하고, 주어진 범위인지는 다른 함수로 확인하자.&lt;/p&gt;

&lt;p&gt;그래도 예를 하나 들어 보겠다. 얼마나 복잡한지를 느끼면 된다.&lt;/p&gt;

&lt;p&gt;문제 6: 1 이상 365 이하의 정수인지를 확인하는 정규식을 작성하라.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 6 정답보기&lt;/summary&gt;
    &lt;p&gt;r'(36[0-5]|3[0-5][0-9]|[12][0-9]{2}|[1-9][0-9]?)'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;그냥 따로 씁시다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;number&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\d+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'몇 이상 몇 이하의 수 38개'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;number&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;number&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;365&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Yei!'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Yei!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;부동소수점-수&quot;&gt;부동소수점 수&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/22/regex-usage-03-basic/&quot;&gt;3번째 글&lt;/a&gt;의 끝에서 다음과 같은 문제가 있었다.&lt;/p&gt;

&lt;p&gt;문제 7: 1.2이나 3.72e3, 1.002e-12 같은 수를 부동소수점 수 또는 과학적 표기법으로 표기한 수라고 한다. 이와 같은 수에 일치하는 정규표현식을 작성하라.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 7 정답보기&lt;/summary&gt;
    &lt;p&gt;r'\b\d*\.\d+(e\d+)?'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;조금 더 일반화한 버전을 문제로 하나 더 내 보았다.&lt;/p&gt;

&lt;p&gt;문제 8 : 다음 조건에 맞는 부동소수점 수를 찾는 정규식을 작성하라.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;부호부, 정수부, 가수부는 선택이다.&lt;/li&gt;
  &lt;li&gt;지수부 역시 선택이다.&lt;/li&gt;
  &lt;li&gt;정수부가 없으면 가수부는 필수이다.&lt;/li&gt;
  &lt;li&gt;가수부가 없으면 소수점은 선택이다.&lt;/li&gt;
&lt;/ol&gt;

&lt;details&gt;
    &lt;summary&gt;문제 8 정답보기&lt;/summary&gt;
    &lt;p&gt;r'[+-]?(\b[0-9]+(\.[0-9]*)?|\.[0-9]+)([eE][+-]?[0-9]+\b)?'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;정수부와 가수부가 동시에 없으면 안 되는 조건은 조건문을 사용해도 되고, 다자택일을 사용해도 된다. 이 경우는 다자택일을 사용했다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;로마-숫자&quot;&gt;로마 숫자&lt;/h3&gt;

&lt;p&gt;문제 9: 현대식 로마 숫자에 일치되는 정규식을 작성하라. ‘IV’는 가능하고, ‘IIII’는 불가능하다.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 9 정답보기&lt;/summary&gt;
    &lt;p&gt;r'\b(?=[MDCLXVI])M*(C[MD]|D?C*)(X[CL]|L?X*)(I[XV]|V?I*)\b'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;(?=[MDCLXVI])&lt;/code&gt;: 로마 숫자는 0이 없기 때문에, 문자가 하나라도 있는지 체크하는 전방탐색 구문이다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;M*&lt;/code&gt;: 로마 숫자에서 1000은 개수만큼 집어넣는다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt; (C[MD]|D?C*)&lt;/code&gt;: 작은 숫자가 앞에 오는 경우를 따로 빼서 다자택일로 처리하였다. 로마 숫자의 규칙을 생각하면 그리 어려운 부분은 아니다.&lt;/li&gt;
  &lt;li&gt;나머지 부분은 3번과 같다.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-08-example/&quot;&gt;다음 글&lt;/a&gt;에서는 단어와 행 처리에 관한 예제를 다루도록 하겠다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>파이썬 정규표현식(re) 사용법 - 06. 치환 함수, 양방탐색, 조건문</title>
   <link href="http://localhost:4000/regex-usage-06-advanced/"/>
   <updated>2018-08-05T00:00:00+09:00</updated>
   <id>http://localhost:4000/regex-usage-06-advanced</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/20/regex-usage-01-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 01. Basic&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/21/regex-usage-02-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 02. 문자, 경계, flags&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/22/regex-usage-03-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 03. OR, 반복&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/28/regex-usage-04-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 04. 그룹, 캡처&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/04/regex-usage-05-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 05. 주석, 치환, 분리&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/05/regex-usage-06-advanced/&quot;&gt;파이썬 정규표현식(re) 사용법 - 06. 치환 함수, 양방탐색, 조건문&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-07-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 07. 예제(숫자)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-08-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 08. 예제(단어, 행)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/24/regex-usage-09-other-functions/&quot;&gt;파이썬 정규표현식(re) 사용법 - 09. 기타 기능&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이 글에서는 정규표현식 고급 기술에 대해서 설명한다.&lt;/p&gt;

&lt;p&gt;본 글에서 정규표현식은 &lt;code class=&quot;highlighter-rouge&quot;&gt;regex&lt;/code&gt;와 같이, 일반 문자열은 ‘regex’와 같이 표시하도록 한다.&lt;/p&gt;

&lt;p&gt;파이썬 버전은 3.6을 기준으로 하나, 3.x 버전이면 (아마) 동일하게 쓸 수 있다.&lt;br /&gt;
2.7 버전은 한글을 포함한 비 알파벳 문자 처리가 다르다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;정규표현식-고급-치환-함수-사용&quot;&gt;정규표현식 고급: 치환 함수 사용&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;\public\img\정규표현식(re)\2018-08-05-regex-usage-05-intermediate\01_sub.PNG&quot; alt=&quot;01&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여러분은 &lt;strong&gt;re.sub&lt;/strong&gt;을 쓸 때 특정 문자열 혹은 정규식 내의 일부분은 그대로 갖다 쓰는 법을 배웠다.&lt;/p&gt;

&lt;p&gt;그런데 일치부에 나타나지도 않고, literal text에도 나타나지 않는 문자열로 치환하고 싶은 경우가 있을 수 있다.&lt;br /&gt;
예를 들면 문자열 안에서 소수로 표현된 숫자를 찾은 다음 퍼센티지(%)로 변환하는 것을 정규식으로 쓴다고 하자.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;re.sub&lt;/strong&gt; 메서드는 인자 &lt;strong&gt;repl&lt;/strong&gt;을 받을 때 정규식 일치부나 literal text 말고도 함수를 받을 수도 있다.&lt;br /&gt;
이 함수는 인자로 matchObj를 받으며, 문자열을 최종적으로 반환해야 한다.&lt;/p&gt;

&lt;p&gt;예시를 보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;convertToPercentage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;number&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;number&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'%'&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'\b0\.\d+\b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;repl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;convertToPercentage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Red 0.250, Green 0.001, Blue 0.749, Black 1.5'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Red 25.0%, Green 0.1%, Blue 74.9%, Black 1.5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아주 어려운 내용이라서 advanced인 것은 아니고, 활용도가 높기 때문에 고급 기능으로 분류하였다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;정규표현식-중급-행-단위-검색&quot;&gt;정규표현식 중급: 행 단위 검색&lt;/h2&gt;

&lt;p&gt;행 단위로 자르는 것은 사실 어렵지 않다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'''java - Click on button until alert is present in Selenium	2017년 5월 23일
Click OK on alert Selenium Webdriver	2016년 6월 5일
python - Click the javascript popup through webdriver	2012년 5월 29일
selenium - Read Message From Alert and click on OK	2012년 5월 17일
stackoverflow.com 검색결과 더보기'''&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\r&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;reObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'(\d+)년\s+(\d+)월\s+(\d+)일'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'.'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'.'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Not exists'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2017.5.23
2016.6.5
2012.5.29
2012.5.17
Not exists
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그러나 한 가지 주의할 점은 운영체제(OS: Windows, Mac, Linux)별로 라인피드(개행문자)가 다르다는 것이다. Windows는 ‘\r\n’를 행 구분자로 가지며, 각각 캐리지 리턴과 라인피드이다. 유닉스 계열인 Mac과 Linux는 ‘\n’을 가진다.&lt;br /&gt;
이 구분이 절대적인 것은 아니지만, 운영체제의 개행문자가 뭔지 확신이 서지 않는다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;\r?\n&lt;/code&gt;으로 쓰는 것이 안전하다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;정규표현식-고급-전방탐색과-후방탐색&quot;&gt;정규표현식 고급: 전방탐색과 후방탐색&lt;/h2&gt;

&lt;p&gt;먼저 전방탐색이란 정규표현식이 진행하는 (원래) 방향으로, 문자열 처음에서 끌으로 가는 방향으로 탐색하는 것이다.&lt;br /&gt;
물론 후방탐색은 그 반대이다.&lt;/p&gt;

&lt;p&gt;전방/후방탐색, 즉 양방탐색은 그 자체로 문자열에 일치된다기보다는, 문자열이 일치되기 위한 조건을 설정하는 것이다.&lt;br /&gt;
이미 여러분은 실제 문자열에 일치되지 않으면서 조건 설정을 하는 정규표현식을 몇 개 봐 왔다. &lt;code class=&quot;highlighter-rouge&quot;&gt;\b&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;\A&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt; 등이 그 예이다.&lt;/p&gt;

&lt;p&gt;어쨌든 양방탐색의 종류는 네 가지이다. 각각 긍정/부정 전방/후방 탐색이다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;긍정 전방탐색은 &lt;code class=&quot;highlighter-rouge&quot;&gt;(?=&amp;lt;regex&amp;gt;)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;긍정 후방탐색은 &lt;code class=&quot;highlighter-rouge&quot;&gt;(?&amp;lt;=&amp;lt;regex&amp;gt;)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;부정 전방탐색은 &lt;code class=&quot;highlighter-rouge&quot;&gt;(?!&amp;lt;regex&amp;gt;)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;부정 후방탐색은 &lt;code class=&quot;highlighter-rouge&quot;&gt;(?&amp;lt;!&amp;lt;regex&amp;gt;)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;으로 쓴다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;p&amp;gt;&lt;/code&gt; 태그 안의 모든 텍스트를 검사한다고 하자. 그러나 여러분은 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;p&amp;gt;&lt;/code&gt; 태그까지 문자열로 뽑아내고 싶지는 않을 것이므로, 이는 정규식의 일치부에 넣지 않도록 한다. 이때 후방탐색과 전방탐색을 문자 덩어리 앞뒤에 쓰면, &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;p&amp;gt;&lt;/code&gt; 태그 안이라는 조건을 설정하면서 동시에 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;p&amp;gt;&lt;/code&gt; 태그는 일치부에서 제외시킬 수 있다.&lt;/p&gt;

&lt;p&gt;예시를 보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'(?&amp;lt;=&amp;lt;p&amp;gt;)\w+(?=&amp;lt;/p&amp;gt;)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                &lt;span class=&quot;s&quot;&gt;'Kakao &amp;lt;p&amp;gt;ryan&amp;lt;/p&amp;gt; keep a straight face.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ryan
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;p&amp;gt;&lt;/code&gt; 태그는 제외된 것을 볼 수 있다.&lt;br /&gt;
위의 예시를 해석하면, 단어 문자에 해당하는 연속된 글자를 찾는데(&lt;code class=&quot;highlighter-rouge&quot;&gt;\w+&lt;/code&gt;), 그 앞에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;p&amp;gt;&lt;/code&gt; 문자열이 반드시 있어야 하고, 문자열 바로 뒤에는 역시 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;/p&amp;gt;&lt;/code&gt; 태그가 있어야 한다는 뜻이다.&lt;/p&gt;

&lt;p&gt;실제로 문자열이 일치되는 것은 아님을 보여주기 위해, 쓸데없이 복잡하게 만든 예시를 하나 만들어 보았다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;p&amp;gt;(?&amp;lt;=&amp;lt;p&amp;gt;)(\w+)(?=&amp;lt;/p&amp;gt;)&amp;lt;/p&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;'Kakao &amp;lt;p&amp;gt;ryan&amp;lt;/p&amp;gt; keep a straight face.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ryan
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이러한 양방탐색 조건을 지정하는 것도, 명시적인 캡처로 인식되지 않는다.&lt;/p&gt;

&lt;p&gt;부정 양방탐색도 사용법은 같다. 하지만 긍정 양방탐색은 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;regex&amp;gt;&lt;/code&gt;에 해당하는 문자열이 있어야만 일치에 성공하는 데 반해, 부정 양방탐색은 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;regex&amp;gt;&lt;/code&gt;와 일치에 실패해야만 그 다음 비교를 이어나간다.&lt;/p&gt;

&lt;p&gt;보통 사람들은 비밀번호를 설정할 때 영문자 몇 개, 숫자 몇 개(보통 생일과 관련이 있다), 그리고 특수문자를 넣으라는 홈페이지의 요구대로 느낌표 하나를 끝에 붙인다.&lt;br /&gt;
그런데 여기서는 특수문자조차 없는 비밀번호를 찾으려고 한다. 즉 마지막에 ‘!’가 없는 비밀번호를 모두 찾는다고 하자.&lt;/p&gt;

&lt;p&gt;이를 찾는 정규식은 다음과 같다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'[a-z]+\d+(?!!)\b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'tube1109! gorio303 ryan416'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['gorio303', 'ryan416']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;느낌표가 없는 비밀번호는 두 개이다. 그리고 이를 잘 찾아 주었다.&lt;/p&gt;

&lt;p&gt;물론 이렇게 간단한 데 양방탐색을 지정하여 쓰면 오히려 더 귀찮다. 하지만 이 기능을 쓸 데가 언젠가는 있을 것이다.&lt;/p&gt;

&lt;p&gt;참고로, 파이썬의 후방탐색은 좀 비효율적으로 구현되어 있다고 알려져 있다. 따라서 후방탐색을 써야만 하는 경우에는 다음과 같이 대체하는 방법도 고려할 수 있다.&lt;/p&gt;

&lt;p&gt;조금 전 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;p&amp;gt;&lt;/code&gt; 태그 예시를 대체한 것이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;p&amp;gt;(\w+)&amp;lt;/p&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;'Kakao &amp;lt;p&amp;gt;ryan&amp;lt;/p&amp;gt; keep a straight face.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ryan
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이 방법이 더 깔끔할 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;정규표현식-고급-조건문&quot;&gt;정규표현식 고급: 조건문&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;이 부분은 한빛미디어의 ‘한 권으로 끝내는 정규표현식’ 책을 참고하였다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여러분은 프로그래밍 언어에서 삼항 연산자로 조건문을 쓰는 것을 본 적이 있을 것이다.&lt;/p&gt;

&lt;p&gt;C++의 예시는 다음과 같다.&lt;/p&gt;
&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;파이썬은 다음과 같다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;정규표현식에서의 조건문은 다음과 같다. 조건문은, 캡처 그룹을 사용해 앞에서 문자열이 일치되었는지 아닌지에 따라 다음 부분에서는 다른 일치 조건을 제시해야 할 때 쓰인다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(?(숫자)맞으면|아니면)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;맞으면 또는 아니면에는 어떤 정규식이든 사용할 수 있다. 다만 그 안에서도 다자택일(&lt;code class=&quot;highlighter-rouge&quot;&gt;|&lt;/code&gt;, OR)을 사용하려면 그 전체를 &lt;code class=&quot;highlighter-rouge&quot;&gt;( )&lt;/code&gt;로 묶어주어야 한다.&lt;/p&gt;

&lt;p&gt;참고로 (숫자)는 여러분이 알고 있는 그 캡처랑 비슷한 것이다. 재참조부를 쓸 때 &lt;code class=&quot;highlighter-rouge&quot;&gt;\1&lt;/code&gt;과 같이 썼는데, 조건문에서는 단지 &lt;code class=&quot;highlighter-rouge&quot;&gt;(1)&lt;/code&gt;로 바뀌었을 뿐이다.&lt;/p&gt;

&lt;p&gt;예시로, &lt;code class=&quot;highlighter-rouge&quot;&gt;(a)?b(?(1)c|d)&lt;/code&gt;를 살펴보자. 이는 &lt;code class=&quot;highlighter-rouge&quot;&gt;abc|bd&lt;/code&gt;와 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;먼저 &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;를 검사한다. 만약 찾는 문자열에 ‘a’가 있으면 첫 번째 명시적 캡처에는 ‘a’가 들어간다. 만약 ‘a’가 없으면, 빈 문자열이 (1)에 저장된다.&lt;/li&gt;
  &lt;li&gt;그 다음은 &lt;code class=&quot;highlighter-rouge&quot;&gt;b&lt;/code&gt;이다. 만약 ‘b’가 없으면 일치에 실패하고 다음 위치로 넘어가게 된다. ‘b’가 있다고 가정하자.&lt;/li&gt;
  &lt;li&gt;그리고 이제 조건문이다. 만약 앞에서 ‘a’가 일치되었으면, 좀 전 일치된 ‘b’ 바로 다음에 ‘c’가 있는지를 검사한다. 만약 ‘a’가 없었으면, ‘b’ 다음에 ‘d’가 있는지를 찾게 된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;다른 굉장히 복잡한 예시를 하나 들도록 하겠다(출처는 위에서 밝힌 책이다).&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;콤마로 구분되고&lt;/li&gt;
  &lt;li&gt;one, two, three와 일치되되&lt;/li&gt;
  &lt;li&gt;각 단어는 최소 한번씩은 등장해야 하며&lt;/li&gt;
  &lt;li&gt;각 단어가 몇 개가 있든지 일치되어야 한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;정답은&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;r'\b(?:(?:(one)|(two)|(three))(?:,|\b)){3,}(?(1)|(?!))(?(2)|(?!))(?(3)|(?!))'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이다.&lt;/p&gt;

&lt;p&gt;하나씩 살펴보면,&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;\b&lt;/code&gt;: 단어 경계는 이제 알 것이다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;(?:(one)|(two)|(three))&lt;/code&gt;: one이나 two이거나 three를 캡처한다. 각각 따로 캡처되도록 바깥쪽 캡처 그룹은 비 캡처 그룹으로 지정하였다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;(?:,|\b)&lt;/code&gt;: 문제의 조건에서 각각의 단어는 콤마(‘,’)로 구분되고 마지막 단어 뒤에는 콤마가 없을 것이므로, &lt;code class=&quot;highlighter-rouge&quot;&gt;,&lt;/code&gt; 또는 &lt;code class=&quot;highlighter-rouge&quot;&gt;\b&lt;/code&gt; 다자택일로 묶어 놓았다. 콤마를 캡처하고 싶지는 않으므로 역시 비 캡처 그룹이다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;(?:2번 3번){3,}&lt;/code&gt; 너무 길어서 2번과 3번을 따로 뺐다. 위에서 설명한 2번과 3번 전체를 감싸는 비 캡처 그룹이다. 세 단어가 각각 한 번씩은 나와야 하기 때문에, 반복 횟수는 최소 3이다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;(?(1)|(?!))&lt;/code&gt;: 이제부터 조건문이다. 이 조건문은 캡처 그룹 1번(&lt;code class=&quot;highlighter-rouge&quot;&gt;(1)&lt;/code&gt;, ‘one’)이 일치되었으면 그냥 일치되는 부분이다(‘맞으면’ 부분이 빈 문자열이다). ‘아니면’ 부분은 빈 부정 전방탐색 &lt;code class=&quot;highlighter-rouge&quot;&gt;(?!)&lt;/code&gt;인데, 빈 정규식은 항상 일치되므로(즉, &lt;code class=&quot;highlighter-rouge&quot;&gt;(1)&lt;/code&gt;에) 부정 전방탐색은 항상 실패한다. 따라서 이 조건문 &lt;code class=&quot;highlighter-rouge&quot;&gt;(?(1)|(?!))&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;(1)&lt;/code&gt;에 ‘one’이 일치되거나, 아니면 그냥 일치에 실패한다.&lt;/li&gt;
  &lt;li&gt;나머지 두 개의 조건문은 각각 ‘two’, ‘three’에 대응하며, 5번 설명과 같다. 이 세 가지 조건문을 조합하면, &lt;code class=&quot;highlighter-rouge&quot;&gt;(1)&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;(2)&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;(3)&lt;/code&gt; 중 하나라도 일치에 실패한 단어가 있다면 이 전체 정규식은 일치에 실패한다. 따라서 세 단어가 한 번이라도 나와야 한다는 조건을 만족시킨다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;조건문 안에 양방탐색을 사용할 수도 있다. 이는 보통의 정규식과 거의 비슷하게 작동한다. 정규식 대신 양방탐색 조건이 일치하면 ‘맞으면’ 부분이, 일치에 실패하면 ‘아니면’ 부분이 바로 다음 문자열에 일치되는지를 시도한다.&lt;br /&gt;
부정 양방탐색을 쓸 수도 있으나, ‘맞으면’과 ‘아니면’ 부분이 바뀌는 효과를 가져오므로 지양하자.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-07-example/&quot;&gt;다음 글&lt;/a&gt;부터는 예제를 다루도록 하겠다. 7번째 글은 숫자를 처리하는 예제에 관한 글이다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>파이썬 정규표현식(re) 사용법 - 05. 주석, 치환, 분리</title>
   <link href="http://localhost:4000/regex-usage-05-intermediate/"/>
   <updated>2018-08-04T00:00:00+09:00</updated>
   <id>http://localhost:4000/regex-usage-05-intermediate</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/20/regex-usage-01-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 01. Basic&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/21/regex-usage-02-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 02. 문자, 경계, flags&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/22/regex-usage-03-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 03. OR, 반복&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/28/regex-usage-04-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 04. 그룹, 캡처&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/04/regex-usage-05-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 05. 주석, 치환, 분리&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/05/regex-usage-06-advanced/&quot;&gt;파이썬 정규표현식(re) 사용법 - 06. 치환 함수, 양방탐색, 조건문&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-07-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 07. 예제(숫자)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-08-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 08. 예제(단어, 행)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/24/regex-usage-09-other-functions/&quot;&gt;파이썬 정규표현식(re) 사용법 - 09. 기타 기능&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이 글에서는 정규표현식 중급 기술과 python library인 &lt;code class=&quot;highlighter-rouge&quot;&gt;re&lt;/code&gt; 패키지 사용법에 대해서 설명한다.&lt;/p&gt;

&lt;p&gt;본 글에서 정규표현식은 &lt;code class=&quot;highlighter-rouge&quot;&gt;regex&lt;/code&gt;와 같이, 일반 문자열은 ‘regex’와 같이 표시하도록 한다.&lt;/p&gt;

&lt;p&gt;파이썬 버전은 3.6을 기준으로 하나, 3.x 버전이면 (아마) 동일하게 쓸 수 있다.&lt;br /&gt;
2.7 버전은 한글을 포함한 비 알파벳 문자 처리가 다르다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;정규표현식-중급-주석-추가&quot;&gt;정규표현식 중급: 주석 추가&lt;/h2&gt;

&lt;p&gt;복잡한 정규식은 써 놓고 나중에 보면 한 줄밖에 안 되는 주제에 다른 스파게비 코드만큼이나 읽기 힘들다. 위에 주석으로 한 줄 이 정규식의 의미를 써놓는 게 부족한 경우가 있을지도 모른다. 그래서 정규식 내부에 주석을 넣는 기능이 있다.&lt;/p&gt;

&lt;p&gt;주석은 특별히 어려운 부분이 아니다. 단지 &lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/21/regex-usage-02-basic/#%EB%A7%88%EC%B9%A8%ED%91%9C%EB%8A%94-%EA%B0%9C%ED%96%89-%EB%AC%B8%EC%9E%90%EC%99%80-%EC%9D%BC%EC%B9%98-%EC%98%B5%EC%85%98&quot;&gt;옵션&lt;/a&gt; 중 하나인 &lt;code class=&quot;highlighter-rouge&quot;&gt;re.VERBOSE&lt;/code&gt; 옵션을 사용하기만 하면 된다. 약자는 &lt;code class=&quot;highlighter-rouge&quot;&gt;re.X&lt;/code&gt;이다.&lt;/p&gt;

&lt;p&gt;위 옵션을 추가하면 정규식 내의 공백들이 무시된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'''
010-# 핸드폰 앞자리 
\d{4}-# 중간자리
\d{4}# 뒷자리'''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;s&quot;&gt;'010-1234-5678'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VERBOSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;010-1234-5678
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;인라인으로 쓰기 위해서는 모드 변경자 &lt;code class=&quot;highlighter-rouge&quot;&gt;(?x)&lt;/code&gt;를 쓰면 된다.&lt;/p&gt;

&lt;p&gt;위의 예시처럼 &lt;code class=&quot;highlighter-rouge&quot;&gt;re.VERBOSE&lt;/code&gt;를 쓸 때는 삼중따옴표를 쓰는 것이 가장 좋다.&lt;br /&gt;
또 일반 공백 문자는 무시되기 때문에, 정규식 내에 공백문자를 넣고 싶으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;\ &lt;/code&gt;(공백문자를 이스케이프 처리)를 사용하거나 &lt;code class=&quot;highlighter-rouge&quot;&gt;[ ]&lt;/code&gt;처럼 대괄호 내에 공백문자를 집어넣으면 된다.&lt;br /&gt;
탭 문자는 &lt;code class=&quot;highlighter-rouge&quot;&gt;\t&lt;/code&gt;로 동일하고, 개행 문자는 &lt;code class=&quot;highlighter-rouge&quot;&gt;\n&lt;/code&gt;은 무시되기 때문에(예시에선 개행을 했음에도 문자열이 이를 무시하고 일치되었다) &lt;code class=&quot;highlighter-rouge&quot;&gt;'\\n'&lt;/code&gt; 또는 r&lt;code class=&quot;highlighter-rouge&quot;&gt;'\n'&lt;/code&gt;으로 하는 것이 라인피드와 일치된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;정규표현식-중급-치환&quot;&gt;정규표현식 중급: 치환&lt;/h2&gt;

&lt;p&gt;사실 치환도 어려운 개념은 아니지만, 활용하는 방법은 꽤 많기 때문에 중급으로 분류하였다.&lt;/p&gt;

&lt;p&gt;치환은 말 그대로 정규식에 일치하는 부분 문자열을 원하는 문자열로 치환하는 것이다.&lt;br /&gt;
파이썬 문자열은 기본적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;replace&lt;/code&gt; 메서드를 갖고 있기 때문에 일반적인 문자열은 그냥 치환이 가능하다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;origin_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Ryan keep a straight face.'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;edited_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origin_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'keep'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'kept'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edited_str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Ryan kept a straight face.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그러나 이 &lt;code class=&quot;highlighter-rouge&quot;&gt;replace&lt;/code&gt;는 정규식 패턴에 대응하는 문자열을 찾아주지는 못한다. 그래서 &lt;strong&gt;re.sub&lt;/strong&gt; 메서드가 필요하다.&lt;/p&gt;

&lt;h3 id=&quot;resubpattern-repl-string-count-flags&quot;&gt;re.sub(pattern, repl, string, count, flags)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;\public\img\정규표현식(re)\2018-08-05-regex-usage-05-intermediate\01_sub.PNG&quot; alt=&quot;01&quot; /&gt;&lt;/p&gt;

&lt;p&gt;간단한 사용법은 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\d{4}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'XXXX'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'010-1234-5678'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;010-XXXX-XXXX
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;인자만 보아도 대략 감이 올 것이다. pattern, string, flags는 우리가 지금까지 써 왔던 것들이다.&lt;/p&gt;

&lt;p&gt;나머지 두 개도 어려운 부분은 아니다. &lt;strong&gt;re.sub&lt;/strong&gt;은 패턴에 일치되는 문자열은 다른 문자열로 바꿔주는 것이므로, repl은 당연히 그 ‘다른 문자열’에 해당하는 부분이다.&lt;/p&gt;

&lt;p&gt;count 인자는, 최대 몆 개까지 치환할 것인가를 지정한다. 만약 일치되는 문자열이 3인데 count=2로 지정되어 있으면 마지막 세 번째 문자열은 치환되지 않는다.&lt;br /&gt;
물론 일치되는 문자열이 count보다 적으면 그냥 전부 다 치환된다.&lt;/p&gt;

&lt;script data-ad-client=&quot;ca-pub-9951774327887666&quot; async=&quot;&quot; src=&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Gorio'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;repl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Ryan'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; \
             &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Gorio, Gorio, Gorio keep a straight face.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Ryan, Ryan, Gorio keep a straight face.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;인자가 많으므로 이번엔 파이썬의 특징인 인자 명시적 지정을 사용해 보았다.&lt;/p&gt;

&lt;p&gt;결과에서 이해되지 않는 부분은 딱히 없을 것이다.&lt;br /&gt;
참고로 &lt;strong&gt;re.sub&lt;/strong&gt;은 일치된 위치를 따로 반환해 주지 않는다.&lt;/p&gt;

&lt;h3 id=&quot;resubnpattern-repl-string-count-flags&quot;&gt;re.subn(pattern, repl, string, count, flags)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;\public\img\정규표현식(re)\2018-08-05-regex-usage-05-intermediate\02_subn.PNG&quot; alt=&quot;02&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;re.subn&lt;/strong&gt;은 &lt;strong&gt;re.sub&lt;/strong&gt;과 매우 유사하지만, 리턴하는 값이 치환된 문자열과 더불어 치환된 개수의 튜플이라는 것이 다른 점이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Gorio'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;repl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Ryan'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; \
              &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Gorio, Gorio, Gorio keep a straight face.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;('Ryan, Ryan, Gorio keep a straight face.', 2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;문자열이 두 개 치환되었으므로 2를 같이 리턴한다.&lt;/p&gt;

&lt;h3 id=&quot;정규식-일치부를-문자열에서-제거&quot;&gt;정규식 일치부를 문자열에서 제거&lt;/h3&gt;

&lt;p&gt;왜 파이썬에서는 제거 메서드를 따로 만들지 않았는지는 잘 모르지만, &lt;strong&gt;re.sub&lt;/strong&gt;으로 간단히 구현 가능하다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Tube'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Tube Ryan'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; Ryan
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;문자열을 제거할 때 공백 문자 하나가 남는 것은 흔히 하는 실수이다. 결과를 보면 ‘Ryan’ 앞에 공백 문자가 하나 있는데, 이를 실제 상황에서 본다면 은근히 신경 쓰일 것이다. 제거할 문자열 앞이나 뒤에 공백 문자를 하나 넣어서 같이 제거하도록 하자.&lt;/p&gt;

&lt;h3 id=&quot;치환-텍스트에-정규식-일치부-삽입&quot;&gt;치환 텍스트에 정규식 일치부 삽입&lt;/h3&gt;

&lt;p&gt;이번에는 문자열 치환 시 그냥 literal text가 아닌 일치된 부분을 재사용하는 방법을 알아보겠다. &lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/28/regex-usage-04-intermediate/#-%EC%88%AB%EC%9E%90-%EC%95%9E%EC%84%9C-%EC%9D%BC%EC%B9%98%EB%90%9C-%EB%AC%B8%EC%9E%90%EC%97%B4%EC%9D%84-%EB%8B%A4%EC%8B%9C-%EB%B9%84%EA%B5%90&quot;&gt;재참조부&lt;/a&gt;와 약간 비슷한 개념이다.&lt;/p&gt;

&lt;p&gt;URL을 markdown link로 변환해 보겠다. Markdown link는&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;[이름](URL)&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이렇게 구성된다.&lt;/p&gt;

&lt;p&gt;파이썬에서 전체 일치부를 치환 텍스트에 삽입하려면 &lt;code class=&quot;highlighter-rouge&quot;&gt;\g&amp;lt;0&amp;gt;&lt;/code&gt;이라는 토큰을 사용해야 한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'https?://\S+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;s&quot;&gt;'[링크](\g&amp;lt;0&amp;gt;)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;s&quot;&gt;'http://www.google.com and https://greeksharifa.github.io'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[링크](http://www.google.com) and [링크](https://greeksharifa.github.io)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;치환-텍스트에-정규식-부분-일치부-삽입&quot;&gt;치환 텍스트에 정규식 부분 일치부 삽입&lt;/h3&gt;

&lt;p&gt;여러분은 &lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/28/regex-usage-04-intermediate/#-%EC%88%AB%EC%9E%90-%EC%95%9E%EC%84%9C-%EC%9D%BC%EC%B9%98%EB%90%9C-%EB%AC%B8%EC%9E%90%EC%97%B4%EC%9D%84-%EB%8B%A4%EC%8B%9C-%EB%B9%84%EA%B5%90&quot;&gt;여기&lt;/a&gt;에서 재참조부 일부를 사용하는 방법을 배웠다. 그러면 치환 텍스트에도 이처럼 일부분을 삽입하는 방법이 있을 것이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'(\d{4})-(\d{2})-(\d{2})'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
             &lt;span class=&quot;s&quot;&gt;r'\1.\2.\3'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;s&quot;&gt;'1900-01-01'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1900.01.01
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;yyyy-mm-dd 형식이 yyyy.mm.dd 형식으로 바뀌었다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;\1&lt;/code&gt;과 같은 문법을 쓸 때에는 &lt;strong&gt;r prefix&lt;/strong&gt;를 붙여야 한다는 것을 기억하고 있을 것이다.&lt;/p&gt;

&lt;p&gt;만약 위와 같은 상황에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;\4&lt;/code&gt;를 사용한다면, 아무것도 캡처된 것이 없으므로 에러 메시지를 볼 수 있을 것이다.&lt;/p&gt;

&lt;h4 id=&quot;명명-그룹을-사용한-경우&quot;&gt;명명 그룹을 사용한 경우&lt;/h4&gt;

&lt;p&gt;조금 위에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;\g&amp;lt;0&amp;gt;&lt;/code&gt;을 사용했었다. 그러면 명명 그룹의 경우 &lt;code class=&quot;highlighter-rouge&quot;&gt;\g&amp;lt;name&amp;gt;&lt;/code&gt;을 사용한다는 것을 눈치챌 수 있을 것이다. 
비 명명 그룹은 &lt;code class=&quot;highlighter-rouge&quot;&gt;\g&amp;lt;1&amp;gt;&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;\g&amp;lt;2&amp;gt;&lt;/code&gt;, … 을 사용한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'(?P&amp;lt;year&amp;gt;\d{4})-(?P&amp;lt;month&amp;gt;\d{2})-(?P&amp;lt;day&amp;gt;\d{2})'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;s&quot;&gt;'\g&amp;lt;year&amp;gt;.\g&amp;lt;month&amp;gt;.\g&amp;lt;day&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;s&quot;&gt;'1900-01-01'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1900.01.01
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;물론 명명 그룹과 비 명명 그룹을 혼용하는 것은 여러 번 말했듯이 좋은 생각이 아니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;정규표현식-중급-split&quot;&gt;정규표현식 중급: split&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;re.sub&lt;/strong&gt; 말고도 유용한 함수는 &lt;strong&gt;re.split&lt;/strong&gt;이다. 이 메서드는 파이썬 문자열의 기본 메서드인 split과 매우 유사하나, 정규식을 처리할 수 있다.&lt;/p&gt;

&lt;p&gt;이 역시 어려운 함수는 아니기 때문에, 예시 하나를 바로 보도록 하겠다.&lt;br /&gt;
html 태그 내에서 태그를 제외한 부분으로 split하는 예제이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;[^&amp;lt;&amp;gt;]*&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;s&quot;&gt;'&amp;lt;html&amp;gt; Wow &amp;lt;head&amp;gt; header &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; Hey &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['', ' Wow ', ' header ', ' ', ' Hey ', ' ', '']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;물론 이렇게만 하면 빈 문자열 등도 많이 나온다. 이는 정규식으로 따로 처리하거나, 다음과 같이 쓰면 된다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;[^&amp;lt;&amp;gt;]*&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                  &lt;span class=&quot;s&quot;&gt;'&amp;lt;html&amp;gt; Wow &amp;lt;head&amp;gt; header &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; Hey &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['Wow', 'header', 'Hey']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;정규식이 깔끔하긴 하지만, 한 번에 모든 것을 처리하려고 하면 힘들 수 있다. 파이썬 기본 기능도 잘 활용하자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;정규표현식-초급-recompile&quot;&gt;정규표현식 초급: re.compile&lt;/h2&gt;

&lt;p&gt;여기서는 &lt;strong&gt;re.compile&lt;/strong&gt; 메서드를 알아볼 것이다.&lt;/p&gt;

&lt;p&gt;여러분은 지금까지 &lt;code class=&quot;highlighter-rouge&quot;&gt;import re&lt;/code&gt;를 사용하여 &lt;code class=&quot;highlighter-rouge&quot;&gt;re&lt;/code&gt;로부터 직접 메서드를 호출해왔다. &lt;strong&gt;re.match&lt;/strong&gt;, &lt;strong&gt;re.sub&lt;/strong&gt; 등이 그 예시이다.&lt;/p&gt;

&lt;p&gt;이 방식은 한두번 쓰고 말기에는 괜찮지만, 같은 정규식 패턴을 반복문 내에서 반복적으로 사용해야 할 경우 성능상의 부담이 있다.&lt;br /&gt;
이는 정규식은 컴파일이란 과정을 거치기 때문인데, &lt;code class=&quot;highlighter-rouge&quot;&gt;re&lt;/code&gt; 모듈로부터 직접 갖다 쓰면 매번 컴파일이란 비싼 계산을 해야 하기 때문에 성능이 떨어진다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;re.compile&lt;/strong&gt;은 컴파일을 미리 해 두고 이를 저장할 수 있다. 예시를 보자.&lt;/p&gt;

&lt;p&gt;여러분은 지금까지 이렇게 해 왔다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'\b\d+\b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Ryan 1 Tube 2 345'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이를 한 번 정도 쓰는 것이 아닌, 반복문 내에서 여러 번 쓴다면 이렇게 쓰는 것이 좋다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ryan.txt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'r'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'utf-8'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;reObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'\b\d+\b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;미리 컴파일해 두면 성능상의 이점이 있다.&lt;/p&gt;

&lt;p&gt;사용법이 조금 달라진 것이 눈에 띌 것이다.&lt;/p&gt;

&lt;p&gt;여러분은 지금까지,&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;re&lt;/code&gt; 모듈로부터 직접 match, search 등 메서드를 써 왔다.
    &lt;ul&gt;
      &lt;li&gt;인자는 기본적으로 1) 정규식 패턴과 2) 찾을 문자열이 있었다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;컴파일을 미리 하는 버전은,&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;re.compile 메서드로부터 reObj를 만든다.
    &lt;ul&gt;
      &lt;li&gt;인자는 기본적으로 1) 정규식 패턴 하나이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;reObj.match 혹은 search 등으로 문자열을 찾는다.
    &lt;ul&gt;
      &lt;li&gt;인자는 정규식 패턴은 이미 저장되어 있으므로 search 메서드에는 1) 찾을 문자열 하나만 주면 된다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;reObj가 무슨 정규식 패턴을 가졌는지 보려면 다음을 수행해 보라.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\d+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;re.compile('\\d+')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;’'를 구분하기 위해는 ‘' 도 &lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt;에 의해 이스케이프 처리되어야 하므로 ‘'가 두 개 있다는 점을 주의하라.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/05/regex-usage-06-advanced/&quot;&gt;다음 글&lt;/a&gt;에서는 정규표현식 고급 기술을 다루도록 하겠다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>LSTM1</title>
   <link href="http://localhost:4000/LSTM1/"/>
   <updated>2018-07-30T00:00:00+09:00</updated>
   <id>http://localhost:4000/LSTM1</id>
   <content type="html">&lt;h2 id=&quot;basic-lstm-with-airplane-passengers-data&quot;&gt;Basic LSTM with Airplane Passengers Data&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;본 포스트는 시계열 데이터를 예측하는 가장 기본적인 LSTM에 대해 다룬다.&lt;br /&gt;
코드는 “코딩셰프의 3분 딥러닝 케라스맛” (김성진 저)를 토대로 하였음을 밝힌다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;setting&quot;&gt;Setting&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Your path&quot;&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;seaborn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.model_selection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;kerasapp&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skeras&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;데이터셋-준비&quot;&gt;데이터셋 준비&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    Arguments: D -- 시계열 단위 길이
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fname&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/airplane.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data_dn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fname&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edit_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_dn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 결과를 멤버 변수에 저장
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;load_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fname&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/airplane.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# skipfooter: Number of lines at bottom of file to skip
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# 데이터 시트 중 승객 수에 해당하는 1번째 열만 로드
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read_csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fname&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;usecols&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;engine&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'python'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;skipfooter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# DataFrame에서 np.array로 바꿔줌: shape = (144, )
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Data Normalize
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;data_dn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_dn&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;edit_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# D개의 샘플 만큼의 시계열 데이터를 한 칸씩 옮겨 가면서
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# 시계열 벡터를 생성함
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# 레이블(y)은 D+1 샘플의 값임
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;N should be larger than D, where N is len(data)&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# X.shape = (131, 12)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# X.shape = (131, 12, 1)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# y.shape = (131, 1)
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;먼저 &lt;strong&gt;load_data&lt;/strong&gt; 함수는 데이터를 불러온 뒤, 정규화를 실행한다.&lt;br /&gt;
&lt;strong&gt;edit_data&lt;/strong&gt; 함수는 feed할 데이터를 정제하는데, 한 칸 씩 옮겨가면서 데이터를 생성하게 된다.&lt;br /&gt;
이를 바탕으로 &lt;strong&gt;Dataset&lt;/strong&gt; 클래스에서 트레이닝셋과 테스트셋을 나누게 된다.&lt;/p&gt;

&lt;h3 id=&quot;model-compiling&quot;&gt;Model Compiling&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;rnn_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# shape = X.shape[1: ]
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;m_h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m_h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;adam&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;mean_squared_error&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;모델은 간단한 LSTM이다. shape은 X_train의 1개 example의 shape이다.&lt;/p&gt;

&lt;h3 id=&quot;종합&quot;&gt;종합&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Machine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# example 수 빼고 나머지를 shape 기준으로 설정
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnn_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;validation_data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;skeras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;History of training&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Loss: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Original'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Prediction&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Validation Results&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Loss: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 목표 결과와 예측 결과의 순서를 표시하는 칼럼: Sample
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# 0 ~ len(y_test)-1까지 2번 반복되는데,
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# 첫 번째는 목표 결과의 순서 / 두 번째는 예측 결과의 순서임
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Sample'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 실제 목표 결과와 예측 결과를 순서대로 결합
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Normalized # of Passengers'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concatenate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 정보 표시 (문자열)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Type'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Original'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Prediction'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;barplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Sample&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Normalized # of Passengers&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Normalized # of Passengers&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# Training Data와 Validation Data를 합쳐서 시각화
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Prediction'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Original&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;All Results&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;중간에 matplotlib과 seaborn을 이용하여 결과를 시각화하도록 설계한 것 외에는&lt;br /&gt;
크게 특별한 것은 없는 코드이다.&lt;br /&gt;
끝 부분에 새로운 데이터프레임을 생성하여 barplot을 그리는 것을 눈여겨 봐두면 좋다.&lt;br /&gt;
결과 요약에 큰 도움이 되기 때문이다.&lt;/p&gt;

&lt;h3 id=&quot;run-code&quot;&gt;Run Code&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;machine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Machine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;machine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Run Code
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'__main__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;코드를 돌리면 다음과 같은 그래프들을 얻을 수 있다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018-07-30-LSTM1/05.PNG&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018-07-30-LSTM1/01.PNG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018-07-30-LSTM1/02.PNG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018-07-30-LSTM1/03.PNG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018-07-30-LSTM1/04.PNG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;
</content>
 </entry>
 
 <entry>
   <title>파이썬 정규표현식(re) 사용법 - 04. 그룹, 캡처</title>
   <link href="http://localhost:4000/regex-usage-04-intermediate/"/>
   <updated>2018-07-28T00:00:00+09:00</updated>
   <id>http://localhost:4000/regex-usage-04-intermediate</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/20/regex-usage-01-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 01. Basic&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/21/regex-usage-02-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 02. 문자, 경계, flags&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/22/regex-usage-03-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 03. OR, 반복&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/28/regex-usage-04-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 04. 그룹, 캡처&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/04/regex-usage-05-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 05. 주석, 치환, 분리&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/05/regex-usage-06-advanced/&quot;&gt;파이썬 정규표현식(re) 사용법 - 06. 치환 함수, 양방탐색, 조건문&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-07-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 07. 예제(숫자)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-08-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 08. 예제(단어, 행)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/24/regex-usage-09-other-functions/&quot;&gt;파이썬 정규표현식(re) 사용법 - 09. 기타 기능&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이 글에서는 정규표현식 중급 기술과 python library인 &lt;code class=&quot;highlighter-rouge&quot;&gt;re&lt;/code&gt; 패키지 사용법에 대해서 설명한다.&lt;/p&gt;

&lt;p&gt;본 글에서 정규표현식은 &lt;code class=&quot;highlighter-rouge&quot;&gt;regex&lt;/code&gt;와 같이, 일반 문자열은 ‘regex’와 같이 표시하도록 한다.&lt;/p&gt;

&lt;p&gt;파이썬 버전은 3.6을 기준으로 하나, 3.x 버전이면 (아마) 동일하게 쓸 수 있다.&lt;br /&gt;
2.7 버전은 한글을 포함한 비 알파벳 문자 처리가 다르다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;정규표현식의-중급-그룹-캡처---&quot;&gt;정규표현식의 중급: 그룹, 캡처 = ( )&lt;/h2&gt;

&lt;p&gt;소괄호 &lt;code class=&quot;highlighter-rouge&quot;&gt;( )&lt;/code&gt;에는 중요한 기능이 두 가지 있다. 그룹화와 캡처인데, 정규식의 여러 문자를 그룹으로 묶어주는 것과 정규식의 일부분에 해당하는 문자열에만 관심이 있을 때 그 부분을 따로 빼서 캡처하는 기능이다.&lt;br /&gt;
여담으로 그룹화는 기초 과정이지만 캡처와 더불어 중급 과정에 넣었다.&lt;/p&gt;

&lt;h3 id=&quot;그룹화&quot;&gt;그룹화&lt;/h3&gt;

&lt;p&gt;그룹화는 말 그대로 그룹으로 묶어주는 것이다. 지금까지의 글에서는 정규식 메타문자들의 효력은 대개 한 문자에만 적용이 되었다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'12+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'12 1212 1222'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['12', '12', '12', '1222']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;‘1212’와 같은 문자열을 찾고 싶었는데, ‘12’ 혹은 ‘1222’만 찾아진다. 즉 메타문자 &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;2&lt;/code&gt;에만 적용이 된 것이다. 이를 &lt;code class=&quot;highlighter-rouge&quot;&gt;12&lt;/code&gt; 모두에 적용시키려면 소괄호 &lt;code class=&quot;highlighter-rouge&quot;&gt;( )&lt;/code&gt;로 그룹화시켜주면 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'(12)+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'1212'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'(12)+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'1212'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'(12)+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'1212'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fullmatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'(12)+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'1212'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;_sre.SRE_Match object; span=(0, 4), match='1212'&amp;gt;
&amp;lt;_sre.SRE_Match object; span=(0, 4), match='1212'&amp;gt;
['12']
&amp;lt;_sre.SRE_Match object; span=(0, 4), match='1212'&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;정규식은 항상 최대로 일치시키는 쪽으로 문자열은 탐색하기 때문에, ‘12’가 아닌 ‘1212’를 잘 찾았다. 그런데 한 가지 이상한 결과는 &lt;strong&gt;re.findall&lt;/strong&gt; 결과이다.&lt;/p&gt;

&lt;p&gt;다른 예시를 한번 보자.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'A(12)+B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'A12B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'A(12)+B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'A1212B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'A(12)+B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'A121212B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'A(12)+B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'A12121212B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['12']
['12']
['12']
['12']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;‘A’와 ‘B’를 통해 문자열 전체가 정규식과 일치된 것을 확인할 수 있으나, ‘12’가 몇 개인지에 관계없이 딱 ‘12’만 일치되어 결과로 반환되었다. 이는 괄호가 가진 다른 기능인 캡처 때문이다.&lt;/p&gt;

&lt;h3 id=&quot;캡처&quot;&gt;캡처&lt;/h3&gt;

&lt;p&gt;캡처란 원하는 부분만을 추출하고 싶을 때 사용하는 것이다. 예를 들어 ‘yyyy-mm-dd’와 같이 날짜를 나타내는 문자열 중 월, 일을 각각 따로 빼서 쓰고 싶다고 하자.&lt;br /&gt;
그러면 따로 빼고 싶은 부분인 ‘mm’과 ‘dd’ 부분에만 소괄호의 캡처 기능을 사용하면 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\d{4}-(\d\d)-(\d\d)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'2028-07-28'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\d{4}-(\d\d)-(\d\d)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'1999/05/21 2018-07-28 2018-06-31 2019.01.01'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[('07', '28')]
[('07', '28'), ('06', '31')]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;월과 일에 해당하는 부분만 따로 빠졌음을 알 수 있다. 그리고 날짜 형식이 맞지 않는 경우에는 아예 캡처되지 않았음을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;여기서 한 가지 문제점은, 6월 31일은 존재하지 않는 날짜란 점이다. 위의 정규식은 숫자로만 처리를 했기 때문에 ‘9999-99-99’도 일치된다는 문제가 있다. 이러한 문제를 해결하는 방법은 함수를 정규식에 쓰는 것인데, 이 방법에 대해서는 &lt;a href=&quot;https://greeksharifa.github.io/references/2018/07/13/it-will-update-soon/&quot;&gt;나중&lt;/a&gt;에 알아보도록 한다.&lt;/p&gt;

&lt;h3 id=&quot;matchobjgroups&quot;&gt;matchObj.groups()&lt;/h3&gt;

&lt;p&gt;여러분은 &lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/20/regex-usage-01-basic/&quot;&gt;첫 번째 글&lt;/a&gt;에서 다음 예시를 보았을 것이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'match'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;'matchObj' is a good name, but 'm' is convenient.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;span&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# matchObj를 오랜만에 가져와 보았다. 캡처를 잘 쓰기 위해서는 matchObj가 필요하다.
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;_sre.SRE_Match object; span=(1, 6), match='match'&amp;gt;
match
1
6
(1, 6)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 정규식을 캡처를 포함한 식으로 바꿔보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'match'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;'matchObj' is a good name, but 'm' is convenient.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'# ---------------------------------------------------------------- #'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\d{4}-(\d?\d)-(\d?\d)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'1868-12-10'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;_sre.SRE_Match object; span=(1, 6), match='match'&amp;gt;
match
()
# ---------------------------------------------------------------- #
&amp;lt;_sre.SRE_Match object; span=(0, 10), match='1868-12-10'&amp;gt;
1868-12-10
('12', '10')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;matchObj의 &lt;strong&gt;group&lt;/strong&gt; 메서드는 정규식 전체의 일치부를 찾는다. 반면에 &lt;strong&gt;groups&lt;/strong&gt; 메서드는 명시적으로 캡처(&lt;code class=&quot;highlighter-rouge&quot;&gt;( )&lt;/code&gt;로 감싼 부분)한 부분을 반환한다.&lt;/p&gt;

&lt;p&gt;위의 matchObj는 캡처 구문이 없기 때문에 &lt;strong&gt;groups&lt;/strong&gt; 결과가 빈 튜플이 되는 것이다.&lt;br /&gt;
반면 m의 경우 월과 일에 해당하는 부분을 반환하였다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;group&lt;/strong&gt;과 &lt;strong&gt;groups&lt;/strong&gt;의 사용법을 좀 더 보도록 하자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;\public\img\정규표현식(re)\2018-07-20-regex-usage-04-intermediate\01_group.PNG&quot; alt=&quot;01&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;\public\img\정규표현식(re)\2018-07-20-regex-usage-04-intermediate\02_groups.PNG&quot; width=&quot;75%&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\d{4}-(\d?\d)-(\d?\d)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'1868-12-10'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m.group():'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m.group({}): {}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'m.groups():'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;m: &amp;lt;_sre.SRE_Match object; span=(0, 10), match='1868-12-10'&amp;gt;
m.group(): 1868-12-10
m.group(0): 1868-12-10
m.group(1): 12
m.group(2): 10
m.groups(): ('12', '10')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과를 보면 대략 사용법을 알 수 있을 것이다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;group(i)는 i번째 소괄호에 명시적으로 캡처된 부분만을 반환한다.&lt;/li&gt;
  &lt;li&gt;group(0)은 전체 일치부를 반환하며, group()과 효과가 같다.&lt;/li&gt;
  &lt;li&gt;groups()는 명시적으로 캡처된 모든 부분 문자열을 반환한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;i번째 캡처된 부분은, i번째 여는 괄호와 대응된다고 생각하면 된다. 캡처를 중첩해서 사용하는 경우&lt;code class=&quot;highlighter-rouge&quot;&gt;((12)+)&lt;/code&gt;, 첫 번째 캡처는 바깥쪽 소괄호이다.&lt;/p&gt;

&lt;p&gt;주의할 점은 group(0)이 0번째 캡처를 의미하는 것이 아니라 전체 일치부를 반환한다는 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;비-캡처-그룹&quot;&gt;비 캡처 그룹&lt;/h3&gt;

&lt;p&gt;그룹화를 위해 소괄호를 반드시 써야 하는데, 굳이 캡처하고 싶지는 않을 때가 있다. 예를 들어 다음과 같이 쓴다고 하자.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'((ab)+), ((123)+) is repetitive\.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Hmm... ababab, 123123 is repetitive.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# don't want
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# don't want
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ababab, 123123 is repetitive.
ababab
ab
123123
123
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;캡처 기능을 사용할 때 위의 ‘ababab’, ‘123123’을 얻고 싶을 뿐 ‘ab’나 ‘123’을 얻고 싶지는 않을 때가 있다. 그러나 소괄호는 기본적으로 캡처 기능을 갖고 있기 때문에 group(2)에는 ‘123123’ 대신 ‘ab’가 들어가 있다.&lt;br /&gt;
이는 원하는 결과가 아닐 때가 많다. 그래서 정규표현식은 비 캡처 기능을 지원한다.&lt;/p&gt;

&lt;p&gt;비 캡처 그룹은 &lt;code class=&quot;highlighter-rouge&quot;&gt;(?:&amp;lt;regex&amp;gt;)&lt;/code&gt;와 같이 사용한다. 위의 예시를 다시 써 보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'((?:ab)+), ((?:123)+) is repetitive\.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Hmm... ababab, 123123 is repetitive.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ababab, 123123 is repetitive.
ababab
123123
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;예상대로 동작하였다.&lt;/p&gt;

&lt;p&gt;비 캡처 그룹의 장점은 캡처 그룹의 번호를 이상하게 만들지 않게 할 수 있다는 것과, 쓸데없는 캡처 그룹을 &lt;strong&gt;group&lt;/strong&gt;의 반환값에 집어넣지 않게 되므로 성능상의 이점이 있다.&lt;br /&gt;
그러나 성능 향상은 보통 상황이라면 체감하기 어려울 정도이긴 하다.&lt;/p&gt;

&lt;p&gt;참고로 &lt;a href=&quot;&quot;&gt;모드 변경자&lt;/a&gt;나 비 캡처 그룹처럼 여는 소괄호 뒤에 &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt;가 있으면, &lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/22/regex-usage-03-basic/#--0%ED%9A%8C-%EB%98%90%EB%8A%94-1%ED%9A%8C-%EB%B0%98%EB%B3%B5&quot;&gt;0회 또는 1회 반복&lt;/a&gt;이나 기타 다른 의미가 아닌 특별한 기능을 하는 토큰이 된다. 앞으로 이러한 토큰들을 여럿 볼 수 있을 것이다.&lt;/p&gt;

&lt;h4 id=&quot;모드-변경자가-있는-그룹&quot;&gt;모드 변경자가 있는 그룹&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;여기&lt;/a&gt;에서 (?s)와 같은 모드 변경자를 본 적이 있을 것이다.&lt;/p&gt;

&lt;p&gt;이러한 모드 변경자는 소괄호를 쓰긴 하지만 캡처 그룹으로 작동하지 않는다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'case sensitive(?i) irrelevant'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'case sensitive IrreLEVant'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;case sensitive IrreLEVant
Traceback (most recent call last):
  File &quot;&amp;lt;input&amp;gt;&quot;, line 3, in &amp;lt;module&amp;gt;
IndexError: no such group
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;-숫자-앞서-일치된-문자열을-다시-비교&quot;&gt;\ (숫자): 앞서 일치된 문자열을 다시 비교&lt;/h3&gt;

&lt;p&gt;앞뒤가 똑같은 세 글자 단어를 찾는다고 해보자. 이를 위해서는 조금 전 살펴본 캡처가 꼭 필요하다.&lt;/p&gt;

&lt;p&gt;i번째 캡처된 문자열은 &lt;strong&gt;group(i)&lt;/strong&gt; 메서드를 통해 접근할 수 있다고 하였다. 그런데 그건 matchObj을 얻은 후의 얘기고, 정규식 내에서는 다른 방법을 쓴다. 바로 &lt;code class=&quot;highlighter-rouge&quot;&gt;\(숫자)&lt;/code&gt;이다. 예를 들면 &lt;code class=&quot;highlighter-rouge&quot;&gt;\1&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;\2&lt;/code&gt;, …이다.&lt;br /&gt;
이를 재참조부라 한다.&lt;/p&gt;

&lt;p&gt;아마 그럴 리는 없겠지만 재참조부가 10개 이상인 경우 그냥 두 자리 수를 쓰면 된다. &lt;code class=&quot;highlighter-rouge&quot;&gt;\10&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;\11&lt;/code&gt;, …&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;\b&lt;/code&gt;와 마찬가지로 &lt;code class=&quot;highlighter-rouge&quot;&gt;\1&lt;/code&gt;과 같은 문법을 쓸 때에는 앞에 &lt;strong&gt;r prefix&lt;/strong&gt;를 붙여 주어야 한다.&lt;/p&gt;

&lt;p&gt;우선 예시를 보자. 단어 경계는 정규식이 더 복잡해 보이므로 일부러 넣지 않았다. 분리된 단어만을 보고 싶다면, &lt;code class=&quot;highlighter-rouge&quot;&gt;\b&lt;/code&gt;를 넣으면 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'(\w)\w\1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'토마토 ABC aba xyxy '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'(\w)\w\1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'토마토 ABC aba xyxy '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;토마토
['토', 'a', 'x']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;첫 번째 결과는 원하는 결과이다. 그러나 &lt;strong&gt;search&lt;/strong&gt;는 하나밖에 찾지 못하므로 완벽한 답은 아니다.&lt;br /&gt;
두 번째 결과는 원하는 결과가 아닐 것이다. 이는 &lt;code class=&quot;highlighter-rouge&quot;&gt;( )&lt;/code&gt;가 들어가면 앞에서 말했듯 캡처 그룹만을 반환하기 때문이다.&lt;/p&gt;

&lt;p&gt;전체를 참조하려면 여러 방법이 있지만, 세 가지를 소개한다.&lt;/p&gt;

&lt;p&gt;첫 번째는 &lt;strong&gt;search&lt;/strong&gt;로 하나를 찾은 다음 남은 문자열로 다시 &lt;strong&gt;search&lt;/strong&gt;를 하는 것이다. 그러나 이는 괜한 코딩량이 늘어난다.&lt;/p&gt;

&lt;p&gt;두 번째는 캡처를 하나 더 만드는 것이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;match_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'((\w)\w\2)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'토마토 ABC aba xyxy '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;match_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;토마토
aba
xyx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;재참조부가 &lt;code class=&quot;highlighter-rouge&quot;&gt;\1&lt;/code&gt;이 아니라 &lt;code class=&quot;highlighter-rouge&quot;&gt;\2&lt;/code&gt;인 이유는, 여는 소괄호(opening parenthesis)의 순서를 잘 살펴보라. 바깥쪽 소괄호인, 전체를 감싸는 소괄호가 첫 번째 캡처 부분이다. 따라서 안쪽 &lt;code class=&quot;highlighter-rouge&quot;&gt;(\w)&lt;/code&gt;가 &lt;code class=&quot;highlighter-rouge&quot;&gt;\2&lt;/code&gt;에 대응된다.&lt;/p&gt;

&lt;p&gt;그러나 이 방법은 나쁘지 않지만, &lt;strong&gt;findall&lt;/strong&gt;로 찾기 때문에 위치를 찾아주지는 않는다는 단점이 있다.&lt;br /&gt;
일치부의 시작/끝 위치까지 알고 싶을 때에는 &lt;strong&gt;finditer&lt;/strong&gt;을 이용한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;finditer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'((\w)\w\2)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'토마토 ABC aba xyxy '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matchObj_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'string: {}, &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; start/end position={}, &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; 반복 부분: {}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;
          &lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;span&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;string: 토마토, 	 start/end position=(0, 3), 	 반복 부분: 토
string: aba, 	 start/end position=(8, 11), 	 반복 부분: a
string: xyx, 	 start/end position=(12, 15), 	 반복 부분: x
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고로, 이러한 &lt;code class=&quot;highlighter-rouge&quot;&gt;\1&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;\2&lt;/code&gt;, … 들은 비 명명 그룹이라고도 한다. 그 이유는, 바로 다음에 설명할 명명 그룹 때문이다.&lt;/p&gt;

&lt;h3 id=&quot;명명-그룹&quot;&gt;명명 그룹&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;\1&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;\2&lt;/code&gt;, …는 간편하긴 하지만, 그다지 눈에 잘 들어오지는 않는다. 코딩할 때 변수명을 ‘a’, ‘b’ 같은 것으로 지어 놓으면 남이 알아보기 힘든 것과 갈다.&lt;/p&gt;

&lt;p&gt;많은 프로그래밍 언어의 정규표현식은 명명 그룹 기능을 지원한다.&lt;br /&gt;
언어마다 쓰는 방법이 다르지만, 파이썬 기준으로는 &lt;code class=&quot;highlighter-rouge&quot;&gt;(?P&amp;lt;name&amp;gt;regex)&lt;/code&gt; 형식으로 쓴다.&lt;/p&gt;

&lt;p&gt;앞 절의 내용을 이해했으면 어려운 내용이 아니다.&lt;/p&gt;

&lt;p&gt;예시를 하나 보자.&lt;br /&gt;
‘2018-07-28 2018.07.28’처럼, 형식만 다른 똑같은 날짜가 있는지를 확인하는 상황을 생각하자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;r'(?P&amp;lt;year&amp;gt;\d{4})-(?P&amp;lt;month&amp;gt;\d\d)-(?P&amp;lt;day&amp;gt;\d\d) (?P=year)\.(?P=month)\.(?P=day)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'2018-07-28 2018.07.28'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2018-07-28 2018.07.28
('2018', '07', '28')
2018
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;명명 그룹의 재참조는 &lt;code class=&quot;highlighter-rouge&quot;&gt;(?P=name)&lt;/code&gt; 형식으로 쓰면 된다.&lt;/p&gt;

&lt;p&gt;사실 명명 그룹과 비 명명 그룹을 섞어 쓸 수는 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;r'(?P&amp;lt;year&amp;gt;\d{4})-(?P&amp;lt;month&amp;gt;\d\d)-(?P&amp;lt;day&amp;gt;\d\d) (?P=year)\.\2\.\3'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'2018-07-28 2018.07.28'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;2018-07-28 2018.07.28
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;하지만 기껏 가독성 높이려고 명명 그룹을 썼는데 저렇게 쓰면 가독성이 더 나빠진다. 지양하도록 하자.&lt;/p&gt;

&lt;p&gt;한 가지 주의할 점은 &lt;code class=&quot;highlighter-rouge&quot;&gt;name&lt;/code&gt; 부분은 &lt;code class=&quot;highlighter-rouge&quot;&gt;\w&lt;/code&gt;에 일치되는 문자들로만 구성해야 한다. 그렇지 않으면 ‘invalid group name’이라는 메시지를 볼 수 있을 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;반복-부분의-캡처&quot;&gt;반복 부분의 캡처&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/28/regex-usage-04-intermediate/#%EA%B7%B8%EB%A3%B9%ED%99%94&quot;&gt;이 글의 앞부분&lt;/a&gt;에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;12&lt;/code&gt;를 반복시키려고 &lt;code class=&quot;highlighter-rouge&quot;&gt;(12)+&lt;/code&gt; 정규식을 썼는데 원치 않는 결과가 나온 것을 보았을 것이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'A(12)+B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'A121212B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['12']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위의 예시처럼 문자가 한 종류(12)로 정해져 있으면 그냥 전체에다 캡처 그룹을 하나 더 만드는 것으로 해결 가능하지만, 정해진 것이 아닌 문자 집합 같은 것이라면 꽤 어려워진다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'\b(\d\d)+\b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'1, 25, 301, 4000, 55555'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['25', '00']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위의 예시는 길이가 짝수인 정수를 찾고 싶은 것이다.&lt;br /&gt;
그러나 ‘4000’ 대신 ‘00’을 찾고 싶은 사람은 별로 없을 것 같다.&lt;/p&gt;

&lt;p&gt;이를 캡처 그룹으로 한번에 묶어내는 우아한 방법은 없지만, 다른 괜찮은 해결 방법은 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;finditer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'\b(\d\d)+\b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'1, 25, 301, 4000, 55555'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matchObj_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;25
4000
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;stackoverflow에서 찾은 답변 중에는 패턴을 expand하거나 일치하는 부분만 잘라낸 다음 추가 처리를 하라는 답변이 있었는데, 그런 것보다는 위의 방법이 더 깔끔한 것 같다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/04/regex-usage-05-intermediate/&quot;&gt;다음 글&lt;/a&gt;에서는 주석, 치환, 컴파일 등을 살펴보도록 한다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Text_Generation</title>
   <link href="http://localhost:4000/Text_Generation/"/>
   <updated>2018-07-28T00:00:00+09:00</updated>
   <id>http://localhost:4000/Text_Generation</id>
   <content type="html">&lt;h2 id=&quot;text-generation-with-lstm&quot;&gt;Text Generation with LSTM&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;본 포스트는 https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py&lt;br /&gt;
의 코드를 전부를 이용한 것이며, 코드의 해석과 사용 방법을 설명하는 데에&lt;br /&gt;
주안점을 둔 것임을 밝힌다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;setting&quot;&gt;Setting&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;__future__&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_function&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.callbacks&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LambdaCallback&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LSTM&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.optimizers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RMSprop&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.utils.data_utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_file&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;random&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sys&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;io&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_model&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;참고로 새로운 텍스트를 Feed할 때에는 Corpus의 크기가 적어도 10만 문자는 되어야 하며&lt;br /&gt;
100만에 달하는 것이 가장 이상적이라고 본문에 적혀있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nietzsche.txt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'https://s3.amazonaws.com/text-datasets/nietzsche.txt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'utf-8'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'corpus length:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;600893&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;영어 버전의 니체의 글을 이용할 것인데, 이 txt파일엔 약 60만개의 문자가 담겨 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 사용된 문자 수: 57개임
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'total chars:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;57&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 각각의 문자에 대해 위치 인자를 부여함: 0~56
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;char_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;indices_char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;영어 알파벳 26개를 포함하여 이 글에는 총 57개의 문자가 사용되었는데,&lt;br /&gt;
이를 하나의 리스트로 만들어 놓은 것이 chars이다. set(text)를 통해 중복을 제거하였다.&lt;/p&gt;

&lt;p&gt;아래 &lt;strong&gt;char_indices&lt;/strong&gt;와 &lt;strong&gt;indices_char&lt;/strong&gt;은 방금 만든 chars의 element와 그 위치인자를&lt;br /&gt;
딕셔너리의 형태로 정리한 것이다. 이는 이후에 Word Matrix에 대해 &lt;strong&gt;one-hot인코딩&lt;/strong&gt;을&lt;br /&gt;
할 때 편리하게 사용된다. 아래는 그 일 부를 나열한 것이다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;' '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'!'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&quot;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;preprocessing&quot;&gt;Preprocessing&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;next_chars&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;next_chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'nb sequences:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nb&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200285&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'preface&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n\n\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;supposing that truth is a woma'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;'face&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n\n\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;supposing that truth is a woman--'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'t'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'h'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'?'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제부터는 LSTM의 Input형식에 맞게 데이터를 정제하는 작업이다.&lt;br /&gt;
60만개의 문자를 단 한 번에 feed하는 것은 Sequential 데이터에 있어서는 아무 의미가&lt;br /&gt;
없기 때문에 여기서는 40개씩 분리를 해줄 것이다. 이를 한 문장이라고 생각하면 편하다.&lt;br /&gt;
(&lt;strong&gt;maxlen=40&lt;/strong&gt;)&lt;br /&gt;
sentences와 nex_chars란 리스트를 채워나갈 것인데,&lt;br /&gt;
for loop를 보면, range(0, len(text)- maxlen, step)이라 되어 있다.&lt;br /&gt;
이를 숫자로 풀어 보면, range(0, 60만-40, 3)이다.&lt;br /&gt;
i가 0부터 시작하므로,&lt;br /&gt;
text[0:40]을 sentences에 넣어주고, text[40]을 next_chars에 넣어준다.&lt;br /&gt;
다음 반복 때에는 text[3: 43]을 sentences에 넣어주고, text[43]을 next_chars에 넣어준다.&lt;br /&gt;
이렇게 형성된 sentences의 길이는 60만을 3으로 나눈 20만이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Vectorization
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200285&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;57&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200285&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;57&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이제 feed할 Word Matrix를 만들 때가 되었다.&lt;br /&gt;
np.zeros를 통해 initialize를 시켜주는데, 그 shape은 위에 보는 것과 같이&lt;br /&gt;
200285개의 example을 두고, x의 경우 행은 40, 열은 57이다.&lt;br /&gt;
40은 maxlen을, 57은 chars의 길이를 의미한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;char_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;char_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 예시: x[3]을 보라
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;  &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;위에서 만든 x, y 넘파이 배열은 현재 0, 즉 False로 채워져 있다.&lt;br /&gt;
sentences 리스트에 담겨 있는 각 문장에서 등장하는 ‘문자’의 위치에 1을 배정한다.&lt;br /&gt;
(True로 바꿔준다.)&lt;br /&gt;
즉 20285, 40, 57의 shape을 갖고 있는 x에서 (1, 40, 57)은 한 문장 내에서 등장하는&lt;br /&gt;
40개의 문자를 57개의 총 문자를 기준으로 &lt;strong&gt;one-hot 인코딩&lt;/strong&gt;을 한 셈이다.&lt;br /&gt;
y의 경우는 문장 단위가 아니라 각 문자 단위로 인코딩을 해준다.&lt;/p&gt;

&lt;h3 id=&quot;building-model&quot;&gt;Building Model&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Build the model: a single LSTM
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 최종 아웃풋은 길이 57의 벡터
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RMSprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'categorical_crossentropy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;sampling-function&quot;&gt;Sampling Function&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temperature&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    :param preds: 확률 값을 담은 np.array
    :param temperature: exp 승수의 분모
    :return:
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# helper function to sample an index from a probability array
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;asarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float64'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temperature&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;exp_preds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exp_preds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp_preds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;probas&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multinomial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이 사용자 함수는 처음 보기엔 구조가 복잡해보인다.&lt;br /&gt;
다음 함수를 설명한 후에 그 구조를 설명하도록 하겠다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;on_epoch_end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    LambdaCallback의 인자에 전달할 것임
    각 epoch 끝에 발동하는 함수임. Generated Text를 반환한다.
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'----- Generating text after Epoch: %d'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# 60만개의 전체 text에서 랜덤하게 번호를 하나 뽑아 start_index를 설정
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;start_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diversity&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'----- diversity:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diversity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# 빈 문자열을 만들고
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;generated&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# maxlen의 길이를 가진 text를 start_index부터 추출하여 sentence에 집어 넣는다.
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;generated&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'----- Generating with seed: &quot;'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&quot;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stdout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generated&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# x_pred: Word Matrix
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# x_pred.shape: (1, 40, 57) 가로는 행은 문자열 길이,
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# 열은 57개의 기본 문자 종류
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;x_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# 위와 마찬가지로 발견된 문자에 대해 one-hot 인코딩을 해준다.
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;x_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;char_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# x_pred를 Input으로 넣고 model이 이를 predict한 것을 preds라 한다.
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# 왜 [0]으로 인덱싱 했는지는 모르겠다. 안해도 똑같은 넘파이 배열이다.
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# preds.shape: (57, 1)
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# 이 preds는 다음에 생성될 문자를 결정하는 확률값을 담은 배열이다.
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# 이 preds를 바탕으로 sample함수를 돌려 next_index와 next_char을 얻는다.
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# 이 next_index는 0 ~ len(char)-1 중 하나의 숫자를 반환함
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# 이 next_char은 위 next_index에 해당하는 문자이다.
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;next_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diversity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;next_char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices_char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

            &lt;span class=&quot;c1&quot;&gt;# 이렇게 얻은 next_char은 generated의 다음 문자로 채택되어 추가된다.
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# 1개의 문자가 늘어나는 셈
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# 문장 역시 늘어나야 할 것이다.
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;generated&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_char&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# sentence의 길이는 계속해서 maxlen으로 유지하고 제일 앞에 한 글자를 빼고
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# 뒤에 하나를 추가한다.
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# loop를 돌면서 sentence는 계속해서 뒤로 하나씩 밀리게 된다.
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# (context: 기준이 변경되는 것)
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# 이렇게 400개의 문자를 추가하고 나서 위로 올라가서
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# 총 diversity의 갯수(4개)만큼 반환한다.
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# 총 4개의 글이 반환되는 셈이다.
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sentence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_char&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stdout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stdout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flush&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이 함수는 주석으로 대부분의 설명을 대체하겠다.&lt;br /&gt;
결과적으로 이 함수는 LambdaCallback의 on_epoch_end의 인자로 그대로 전달된다.&lt;br /&gt;
일단 위의 sample함수에 대해 설명을 하자면,&lt;br /&gt;
리턴하는 값이 &lt;strong&gt;np.argmax(probas)&lt;/strong&gt;인데, 여기서 마지막 preds는&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;preds = \frac{( e^{preds} )}{\sum e^{preds}}&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;= \frac{e^{\frac{log(preds)}{temperature}}}{\sum e^{\frac{log(preds)}{temperature}}}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;softmax함수에서 그 확률을 구하는 과정이라고 생각하면 된다.&lt;br /&gt;
그리고 이 preds는 np.random.multinomial(1, preds, 1)에 인자로 삽입되는데,&lt;br /&gt;
이 preds가 이후 on_epoch_end함수에서 (57, 1)의 shape으로 만들어져 형성되기 때문에,&lt;br /&gt;
np.random.multinomial 메서드는 57개의 확률 값을 기준으로 다항 분포 추출을 하게 된다.&lt;br /&gt;
return 값으로는 그 중 가장 큰 index를 반환하게 된다.&lt;br /&gt;
즉, 다음에 올 문자로 가장 높은 문자를 확률 값에 근거하여 생성하는 것이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;print_callback&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LambdaCallback&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;on_epoch_end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;on_epoch_end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Callback은 트레이닝 과정에서 given stages에 적용될 수 있다.&lt;br /&gt;
트레이닝 중 내부의 state나 statistics를 확인할 수 있는 것이다.&lt;br /&gt;
사용을 위해서는 Sequential이나 Model 클래스의 fit 메서드에 list of callbacks을&lt;br /&gt;
전달해야 한다. 그러면 그 callback 방법은 트레이닝의 각 단계에서 called될 것이다.&lt;/p&gt;

&lt;h3 id=&quot;results&quot;&gt;Results&lt;/h3&gt;
&lt;p&gt;모델은 다음과 같이 fit한다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;callbacks&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;print_callback&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;그러면 자동으로 학습이 됨과 동시에 각 epoch마다 text를 생성할 것이다.&lt;/p&gt;

&lt;p&gt;다음은 모델 저장과 로드 코드이다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;niet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Path/Nietzsche.h5'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;niet&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Path/Nietzsche.h5'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>파이썬 정규표현식(re) 사용법 - 03. OR, 반복</title>
   <link href="http://localhost:4000/regex-usage-03-basic/"/>
   <updated>2018-07-22T00:00:00+09:00</updated>
   <id>http://localhost:4000/regex-usage-03-basic</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/20/regex-usage-01-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 01. Basic&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/21/regex-usage-02-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 02. 문자, 경계, flags&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/22/regex-usage-03-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 03. OR, 반복&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/28/regex-usage-04-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 04. 그룹, 캡처&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/04/regex-usage-05-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 05. 주석, 치환, 분리&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/05/regex-usage-06-advanced/&quot;&gt;파이썬 정규표현식(re) 사용법 - 06. 치환 함수, 양방탐색, 조건문&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-07-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 07. 예제(숫자)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-08-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 08. 예제(단어, 행)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/24/regex-usage-09-other-functions/&quot;&gt;파이썬 정규표현식(re) 사용법 - 09. 기타 기능&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이 글에서는 정규표현식 기초와 python library인 &lt;code class=&quot;highlighter-rouge&quot;&gt;re&lt;/code&gt; 패키지 사용법에 대해서 설명한다.&lt;/p&gt;

&lt;p&gt;본 글에서 정규표현식은 &lt;code class=&quot;highlighter-rouge&quot;&gt;regex&lt;/code&gt;와 같이, 일반 문자열은 ‘regex’와 같이 표시하도록 한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;정규표현식의-기초-or-반복&quot;&gt;정규표현식의 기초: OR, 반복&lt;/h2&gt;

&lt;h3 id=&quot;--다자택일&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;|&lt;/code&gt; : 다자택일&lt;/h3&gt;

&lt;p&gt;단어 ‘one’, ‘two’, ‘three’ 중 하나에 대응하고 싶다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;|&lt;/code&gt;를 쓰면 된다(백슬래시 또는 원화로 되어 있는 &lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt; 키의 shift 버전이다).&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'one|two|three'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'one four two three zero'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['one', 'two', 'three']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;작동 과정을 살펴보자.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;맨 앞에서 바로 ‘one’이 일치된다.&lt;/li&gt;
  &lt;li&gt;공백 한 개는 &lt;code class=&quot;highlighter-rouge&quot;&gt;o&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;t&lt;/code&gt; 어느 것에도 일치되지 않으므로 건너뛴다. ‘f’도 마찬가지이다.&lt;/li&gt;
  &lt;li&gt;‘four’ 의 ‘o’에 도달했다. &lt;code class=&quot;highlighter-rouge&quot;&gt;o&lt;/code&gt;는 일치되기 때문에, ‘u’에 &lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt;을 일치시켜본다. 물론 아니다.&lt;/li&gt;
  &lt;li&gt;계속 넘어가서 ‘two’의 ‘t’에 도달했다. ‘t’는 &lt;code class=&quot;highlighter-rouge&quot;&gt;t&lt;/code&gt;에 일치된다.&lt;/li&gt;
  &lt;li&gt;‘w’에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;w&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;h&lt;/code&gt; 중 일치되는 것을 찾는다. 현재 &lt;code class=&quot;highlighter-rouge&quot;&gt;tw&lt;/code&gt;까지 일치되었다.&lt;/li&gt;
  &lt;li&gt;‘o’까지 일치되어 ‘two`를 찾았다.&lt;/li&gt;
  &lt;li&gt;이와 비슷한 과정을 반복하여 ‘three’까지 찾고 종료한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;일반적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;|&lt;/code&gt;로 나열한 단어들의 순서가 중요하지는 않다. 하지만 중요한 순간이 있다.&lt;br /&gt;
다음 예시를 보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'one|oneself|onerous'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'oneself is the one thing.'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['one', 'one']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;‘oneself’가 있음에도 &lt;code class=&quot;highlighter-rouge&quot;&gt;oneself&lt;/code&gt;에 일치되지 않았다. 그 이유는 이미 ‘one’을 찾아버렸고, 정규식은 overlapping된 부분을 또 찾지 않기 때문에, ‘one’을 찾고 나서 남은 문자열은 ‘self is the one thing.’이다. 따라서 남은 문자열에서는 더 이상 &lt;code class=&quot;highlighter-rouge&quot;&gt;oneself&lt;/code&gt;를 찾을 수 없는 것이다.&lt;/p&gt;

&lt;p&gt;이 문제의 해결 방법은 두 가지다. 물론 더 있을 수도 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;당연하게도 더 긴 &lt;code class=&quot;highlighter-rouge&quot;&gt;oneself&lt;/code&gt;를 &lt;code class=&quot;highlighter-rouge&quot;&gt;one&lt;/code&gt; 앞에다 두면 해결된다.&lt;/li&gt;
  &lt;li&gt;아니면 단어 경계를 활용한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;\bone\b|\boneself\b&lt;/code&gt;로 쓰면 된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;--0회-이상-반복&quot;&gt;* : 0회 이상 반복&lt;/h3&gt;

&lt;p&gt;어떤 문자나 기호 뒤에 *(asterisk)를 붙이면 그 문자가 일치되는 만큼 일치된다. 예를 들어 &lt;code class=&quot;highlighter-rouge&quot;&gt;a*&lt;/code&gt;의 경우 ‘a’나 ‘aaa’ 혹은 ‘‘(빈 문자열)과도 일치된다.&lt;/p&gt;

&lt;p&gt;예시를 보자.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a*'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a*'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a*'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aaaa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fullmatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a*'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aaaaaa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a*'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aaabaaa aa  '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;p&amp;gt;.*&amp;lt;/p&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&amp;lt;p&amp;gt; Lorem ipsum... is boring. &amp;lt;/p&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;_sre.SRE_Match object; span=(0, 0), match=''&amp;gt;
&amp;lt;_sre.SRE_Match object; span=(0, 1), match='a'&amp;gt;
&amp;lt;_sre.SRE_Match object; span=(0, 4), match='aaaa'&amp;gt;
&amp;lt;_sre.SRE_Match object; span=(0, 6), match='aaaaaa'&amp;gt;
['aaa', '', 'aaa', '', 'aa', '', '', '']
&amp;lt;_sre.SRE_Match object; span=(0, 34), match='&amp;lt;p&amp;gt; Lorem ipsum... is boring. &amp;lt;/p&amp;gt;'&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여섯 번째 결과의 경우, 파이썬 버전에 따라 &lt;strong&gt;None&lt;/strong&gt;이 반환될 수도 있다.&lt;/p&gt;

&lt;p&gt;그런데 한 가지 이상한 결과가 보인다. 다섯 번째 실행문이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a*'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aaabaaa aa  '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# ['aaa', '', 'aaa', '', 'aa', '', '', '']
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;빈 문자열이 이상하리만큼 많이 매칭되었다. 굉장히 비직관적인 결과이지만, 빈 문자열에도 일치된다는 것을 생각했을 때 아예 틀린 것은 분명히 아니다.&lt;br /&gt;
매칭되는 빈 문자열들은 a가 아닌 다른 문자들과의 경계에서 발생한다고 생각하면 될 듯하다. 하지만, 아마 대부분 이것은 원하는 결과가 아닐 것이기 때문에, ‘a’ 덩어리를 찾고 싶다면 다음 메타문자를 보자.&lt;/p&gt;

&lt;h3 id=&quot;--1회-이상-반복&quot;&gt;+ : 1회 이상 반복&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;과 비슷하지만 무조건 한 번이라도 등장해야 한다. 위와 거의 같은 예시를 보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aaaa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fullmatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aaaaaa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aaabaaa aa  '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;p&amp;gt;.+&amp;lt;/p&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&amp;lt;p&amp;gt; Lorem ipsum... is boring. &amp;lt;/p&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;None
&amp;lt;_sre.SRE_Match object; span=(0, 1), match='a'&amp;gt;
&amp;lt;_sre.SRE_Match object; span=(0, 4), match='aaaa'&amp;gt;
&amp;lt;_sre.SRE_Match object; span=(0, 6), match='aaaaaa'&amp;gt;
['aaa', 'aaa', 'aa']
&amp;lt;_sre.SRE_Match object; span=(0, 34), match='&amp;lt;p&amp;gt; Lorem ipsum... is boring. &amp;lt;/p&amp;gt;'&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아마 이것이 여러분이 원하는 ‘a’ 덩어리를 찾은 결과일 것이다.&lt;br /&gt;
빈 문자열이 일치되지 않은 것을 기억하자.&lt;/p&gt;

&lt;h3 id=&quot;n-m--지정-횟수만큼-반복&quot;&gt;{n, m} : 지정 횟수만큼 반복&lt;/h3&gt;

&lt;p&gt;중괄호는 지정한 횟수만큼 정규식을 반복시키는 것이다. 이 쓰임으로 중괄호를 쓸 때 쓰는 방법은 세 가지가 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;{n} : 정확히 n회만큼 반복&lt;/li&gt;
  &lt;li&gt;{n, m} : n회 이상 m회 이하 반복&lt;/li&gt;
  &lt;li&gt;{n, } : n회 이상 반복. 무한히 일치될 수 있다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;물론 n은 자연수, m은 n보다 큰 정수이다.
그리 어렵지 않으므로 바로 예시를 보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a{3}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aaaaa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a{3}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aaaaaaaa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a{2,4}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a aa aaa aaaa aaaaa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a{2,}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a aa aaa aaaa aaaaa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;_sre.SRE_Match object; span=(0, 3), match='aaa'&amp;gt;
['aaa', 'aaa']
['aa', 'aaa', 'aaaa', 'aaaa']
['aa', 'aaa', 'aaaa', 'aaaaa']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;예상과는 조금 다른 결과일지도 모르겠다. 오직 ‘aaa’만을 찾고 싶을 때 &lt;code class=&quot;highlighter-rouge&quot;&gt;a{3}&lt;/code&gt;처럼 쓰면 ‘aaaaa’의 일부분인 ‘aaa’에도 일치될 수 있다. 따라서 정확히 ‘aaa’만을 찾으려면 &lt;code class=&quot;highlighter-rouge&quot;&gt;\baaa\b&lt;/code&gt;처럼 단어 경계를 활용하는 쪽이 좋다.&lt;/p&gt;

&lt;p&gt;참고로 &lt;code class=&quot;highlighter-rouge&quot;&gt;{0, }&lt;/code&gt;은 &lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;과 같고, &lt;code class=&quot;highlighter-rouge&quot;&gt;{1,}&lt;/code&gt;은 &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt;와 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;\public\img\정규표현식(re)\2018-07-20-regex-usage-03-basic\01.{0,1,}.PNG&quot; alt=&quot;01&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;--0회-또는-1회-반복&quot;&gt;? : 0회 또는 1회 반복&lt;/h3&gt;

&lt;p&gt;이 메타문자도 어렵지는 않을 것이라 생각된다. &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;{0,1}&lt;/code&gt;과 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ab?a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aa aba aaaa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['aa', 'aba', 'aa', 'aa']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;정규표현식은 항상 최대한 많은 부분을 일치시키려 한다는 것을 기억하자.&lt;/p&gt;

&lt;p&gt;참고로, 앞에서 말한 반복 메타문자들(&lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;{n, m}&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt; 등)을 정량자 또는 수량자라고 부른다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;advanced-탐욕-정량자-vs-나태-정량자&quot;&gt;Advanced: 탐욕 정량자 vs 나태 정량자&lt;/h3&gt;

&lt;p&gt;그리고 이런 정량자(수량자)들은 한 가지 중요한 특성이 있다.&lt;br /&gt;
일단 전체 문자열이 매치가 되도록 노력하고, 그 선을 지키는 선에서 일치되는 부분에는 최대한 많이 일치시키려고 한다. 즉 기본적으로 모든 정량자들은 탐욕적이며, 가능한 많은 문자열에 매치되려고 한다.&lt;/p&gt;

&lt;p&gt;말이 복잡한데, 예시를 보면서 천천히 설명하도록 하겠다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 1번 예시
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;p&amp;gt;.*&amp;lt;/p&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&amp;lt;p&amp;gt; Lorem ipsum... is boring. &amp;lt;/p&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'# ---------------------------------------------------------------- #'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 2번 예시
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;p&amp;gt;.*&amp;lt;/p&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'''
&amp;lt;p&amp;gt; part 1 &amp;lt;/p&amp;gt; part 2 &amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt; part 3 &amp;lt;/p&amp;gt; part 4 &amp;lt;/p&amp;gt;
'''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DOTALL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'# ---------------------------------------------------------------- #'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 3번 예시
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;p&amp;gt;.*?&amp;lt;/p&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'''
&amp;lt;p&amp;gt; part 1 &amp;lt;/p&amp;gt; part 2 &amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt; part 3 &amp;lt;/p&amp;gt; part 4 &amp;lt;/p&amp;gt;
'''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DOTALL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;p&amp;gt; Lorem ipsum... is boring. &amp;lt;/p&amp;gt;
# ---------------------------------------------------------------- #
&amp;lt;p&amp;gt; part 1 &amp;lt;/p&amp;gt; part 2 &amp;lt;/p&amp;gt;
&amp;lt;p&amp;gt; part 3 &amp;lt;/p&amp;gt; part 4 &amp;lt;/p&amp;gt;
# ---------------------------------------------------------------- #
&amp;lt;p&amp;gt; part 1 &amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;전체 문자열이 매치가 되도록 노력한다.&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;여러분은 조금 위에서 Lorem ipsum 예시를 보았을 것이다. 바로 위의 1번 예시는 이를 변형한 것이다.&lt;br /&gt;
사실 마침표 &lt;code class=&quot;highlighter-rouge&quot;&gt;.&lt;/code&gt;는 모든 문자에 일치되기 때문에, ‘&amp;lt;/p&amp;gt;‘에 해당하는 부분도 마침표에 일치될 수 있다. 만약에 이 부분까지 &lt;code class=&quot;highlighter-rouge&quot;&gt;.&lt;/code&gt;에 일치시켜 버린다면, &lt;code class=&quot;highlighter-rouge&quot;&gt;.*&lt;/code&gt; 부분이 ‘&amp;lt;p&amp;gt;’ 뒤쪽의 모든 문자를 집어삼켜 버리고, 따라서 정규식의 남은 패턴인 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;/p&amp;gt;&lt;/code&gt; 부분은 대조해볼 문자열이 남아있지 않으므로 실패해야 한다고 생각할 수 있다.&lt;/li&gt;
  &lt;li&gt;그러나, 정규식의 정량자들은 &lt;strong&gt;역행(backtracking)&lt;/strong&gt;을 할 줄 안다. 이 말은, &lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;나 &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt; 등은 탐욕적이기는 하지만, 전체 문자열에 일치되는 가능성마저 없애버리지는 않는다는 말과 갈다.
    &lt;ol&gt;
      &lt;li&gt;우선 &lt;code class=&quot;highlighter-rouge&quot;&gt;.*&lt;/code&gt;가 모든 문자열을 집어삼켜 ‘&amp;lt;/p&amp;gt;‘까지 해치웠다. 그러나, 정규식 패턴에는 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;/p&amp;gt;&lt;/code&gt;가 남아있기 때문에, &lt;code class=&quot;highlighter-rouge&quot;&gt;.*&lt;/code&gt;는 자신이 집어삼킨 문자열을 하나 뱉어내고, 남은 정규식 패턴 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;/p&amp;gt;&lt;/code&gt;에 대조해보라고 한다.&lt;/li&gt;
      &lt;li&gt;마지막 문자 하나인 ‘&amp;gt;‘는 매치되지 않기 때문에, &lt;code class=&quot;highlighter-rouge&quot;&gt;.*&lt;/code&gt;는 문자를 하나 더 뱉어낸다. 이제 ‘p&amp;gt;‘와 남은 정규식 패턴 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;/p&amp;gt;&lt;/code&gt;를 비교해보라고 시킨다.&lt;/li&gt;
      &lt;li&gt;역시 일치되지 않으므로, 이와 같은 과정을 정규식 패턴과 뱉어낸 문자열이 일치될 때까지 혹은 모든 문자를 뱉어낼 때까지 반복하게 된다.&lt;/li&gt;
      &lt;li&gt;Lorem ipsum 예시의 경우 4개의 문자를 뱉어내면 일치된다. 따라서 모든 문자열이 정규식 패턴과 일치되고, 전체 문자열이 결과로 반환된다.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.*&lt;/code&gt;가 먹어치웠던 문자열을 살펴보면 그 경계가 끝까지 갔다가 반대 방향으로 후퇴하는 것처럼 보인다. 그래서 이름이 &lt;strong&gt;역행&lt;/strong&gt;이다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;이는 2번 예시를 보아도 알 수 있다. &lt;code class=&quot;highlighter-rouge&quot;&gt;.*&lt;/code&gt;가 최대로 일치시키려고 하기 때문에, ‘part 1’이나 ‘part 2’까지 일치되는 것이 아닌 최대로 일치되는 부분인 ‘part 4’까지 일치시키는 것을 볼 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;3번 예시는 &lt;em&gt;나태 정량자&lt;/em&gt;를 보여준다. 나태 정량자는 별다른 것은 없고, 단지 정량자 바로 뒤에 &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt;를 붙여주기만 하면 된다. 그러면 탐욕적 정량자였던 &lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;는 최대로 일치시키는 대신 문자열은 가장 적게 먹어치우면서 일치되도록 하는 방법을 찾는다. 그래서 딱 ‘part 1’까지만 일치되고, 나머지 문자열은 버려진다.&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;+?&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;{3, 5}?&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;??&lt;/code&gt; 등도 가능하다.&lt;/li&gt;
  &lt;li&gt;사실 나태 정량자도 역행을 한다. 그러나 역행이 꼭 뒤로 가는 것을 의미하는 것이 아닌, 각 정량자가 선호하는 방향과 반대 방향으로 갈 때 역행이라고 한다. 따라서 나태 정량자는 우선 최소로 일치하는 부분을 찾은 뒤(빈 문자열), 문자열이 일치될 때까지 역행(문자열 방향으로는 뒤쪽)한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그래서 탐욕 정량자와 나태 정량자의 차이는, 유력 대조부를 제일 긴 것을 우선적으로 찾느냐, 제일 짧은 것을 우선적으로 찾느냐의 차이이다.&lt;br /&gt;
그리고 결과적으로 탐욕 정량자와 나태 정량자의 일치부가 같아지는 때도 있다. 다만 이때는 검색 순서만이 다를 뿐이다.&lt;/p&gt;

&lt;p&gt;역행에 관해서는 &lt;a href=&quot;https://greeksharifa.github.io/references/2018/07/13/it-will-update-soon/&quot;&gt;나중&lt;/a&gt;에 조금 더 자세히 다루도록 하겠다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;응용-문제&quot;&gt;응용 문제&lt;/h3&gt;

&lt;p&gt;문제 1: 1~8자리 10진수에 일치하는 정규표현식을 작성하라.&lt;/p&gt;

&lt;details&gt;
    &lt;summary&gt;문제 1 정답보기&lt;/summary&gt;
    &lt;p&gt;r'\b\d{1,8}\b'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;문제 2: 4자리 또는 8자리 16진수에 일치하는 정규표현식을 작성하라. 16진수는 0~9, a~f를 사용한다. 예시는 abcd1992, 7fffffff, 2dfa9a00이다.
윈도우 오류에서 ‘0xC1900101’ 비슷한 에러를 많이 봤을 것이다.&lt;/p&gt;

&lt;details&gt;
    &lt;summary&gt;문제 2 정답보기&lt;/summary&gt;
    &lt;p&gt;r'\b[0-9a-f]{4}\b|\b[0-9a-f]{8}\b'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;문제 3: 1.2이나 3.72e3, 1.002e-12 같은 수를 부동소수점 수 또는 과학적 표기법으로 표기한 수라고 한다. 이와 같은 수에 일치하는 정규표현식을 작성하라.&lt;/p&gt;

&lt;details&gt;
    &lt;summary&gt;문제 3 정답보기&lt;/summary&gt;
    &lt;p&gt;r'\b\d*\.\d+(e\d+)?'&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;파이썬 버전 3.6 기준으로, &lt;code class=&quot;highlighter-rouge&quot;&gt;\b&lt;/code&gt;를 쓰려면 &lt;strong&gt;r prefix&lt;/strong&gt;를 붙여 주어야 한다고 했었다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;문제 3의 정답에 아직 설명하지 않은 소괄호 &lt;code class=&quot;highlighter-rouge&quot;&gt;( )&lt;/code&gt;가 있다. 이는 &lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/28/regex-usage-04-intermediate/&quot;&gt;다음 글&lt;/a&gt;에서 설명한다.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>파이썬 정규표현식(re) 사용법 - 02. 문자, 경계, flags</title>
   <link href="http://localhost:4000/regex-usage-02-basic/"/>
   <updated>2018-07-21T00:00:00+09:00</updated>
   <id>http://localhost:4000/regex-usage-02-basic</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/20/regex-usage-01-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 01. Basic&lt;/a&gt;&lt;br /&gt;
&lt;strong&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/21/regex-usage-02-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 02. 문자, 경계, flags&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/22/regex-usage-03-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 03. OR, 반복&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/28/regex-usage-04-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 04. 그룹, 캡처&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/04/regex-usage-05-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 05. 주석, 치환, 분리&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/05/regex-usage-06-advanced/&quot;&gt;파이썬 정규표현식(re) 사용법 - 06. 치환 함수, 양방탐색, 조건문&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-07-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 07. 예제(숫자)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-08-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 08. 예제(단어, 행)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/24/regex-usage-09-other-functions/&quot;&gt;파이썬 정규표현식(re) 사용법 - 09. 기타 기능&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이 글에서는 정규표현식 기초와 python library인 &lt;code class=&quot;highlighter-rouge&quot;&gt;re&lt;/code&gt; 패키지 사용법에 대해서 설명한다.&lt;/p&gt;

&lt;p&gt;본 글에서 정규표현식은 &lt;code class=&quot;highlighter-rouge&quot;&gt;regex&lt;/code&gt;와 같이, 일반 문자열은 ‘regex’와 같이 표시하도록 한다.&lt;/p&gt;

&lt;p&gt;파이썬 버전은 3.6을 기준으로 하나, 3.x 버전이면 (아마) 동일하게 쓸 수 있다.&lt;br /&gt;
2.7 버전은 한글을 포함한 비 알파벳 문자 처리가 다르다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;특수문자&quot;&gt;특수문자&lt;/h2&gt;

&lt;h3 id=&quot;메타문자&quot;&gt;메타문자&lt;/h3&gt;

&lt;p&gt;메타문자에 대해서는 &lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/20/regex-usage-01-basic/#%EB%A9%94%ED%83%80%EB%AC%B8%EC%9E%90&quot;&gt;이전 글&lt;/a&gt;에서 설명했다.&lt;/p&gt;

&lt;h3 id=&quot;비인쇄-문자&quot;&gt;비인쇄 문자&lt;/h3&gt;

&lt;p&gt;벨&lt;code class=&quot;highlighter-rouge&quot;&gt;\a&lt;/code&gt;, 이스케이프&lt;code class=&quot;highlighter-rouge&quot;&gt;\e&lt;/code&gt;, 폼 피드&lt;code class=&quot;highlighter-rouge&quot;&gt;\f&lt;/code&gt;, 라인 피드(개행문자)&lt;code class=&quot;highlighter-rouge&quot;&gt;\n&lt;/code&gt;, 캐리지 리턴&lt;code class=&quot;highlighter-rouge&quot;&gt;\r&lt;/code&gt;, 가로 탭&lt;code class=&quot;highlighter-rouge&quot;&gt;\t&lt;/code&gt;, 세로 탭&lt;code class=&quot;highlighter-rouge&quot;&gt;\v&lt;/code&gt;는 다음 두 가지 방식으로 쓸 수 있다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;\a \e \f \n \r \t \v&lt;br /&gt;
\x07 \x1B \f \n \r \t \v&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;정규표현식을 쓰면서 다른 것들은 거의 볼 일이 없을 것이지만, &lt;code class=&quot;highlighter-rouge&quot;&gt;\t&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;\n&lt;/code&gt;은 알아두는 것이 좋다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; d'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['\t ', '\t ']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;탭 문자와 공백 문자가 붙어 있는 것은 2개임을 확인할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;이스케이프-&quot;&gt;이스케이프 &lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;이스케이프 문자 &lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt;는 메타문자를 일반 리터럴 문자로 취급하게끔 해 준다.&lt;br /&gt;
예를 들어 여는 괄호 &lt;code class=&quot;highlighter-rouge&quot;&gt;[&lt;/code&gt;는 메타 문자지만, &lt;code class=&quot;highlighter-rouge&quot;&gt;\[&lt;/code&gt;와 같이 처리하면 리터럴 문자인 일반 대괄호 문자 ‘[‘와 매칭될 수 있게 된다.&lt;/p&gt;

&lt;p&gt;하지만, 일반 영수 문자(알파벳 또는 숫자)를 이스케이프 처리하면 에러가 나거나 혹은 전혀 다른 의미의 정규식 토큰이 생성된다.&lt;br /&gt;
예를 들어 파이썬에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;\1&lt;/code&gt;의 경우에는 캡처한 문자열 중 첫번째를 재사용한다는 의미(나중에 자세히 설명할 것이다)가 되어 버린다. 따라서 &lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt;를 남용하면 안 된다.&lt;/p&gt;

&lt;hr /&gt;

&lt;script data-ad-client=&quot;ca-pub-9951774327887666&quot; async=&quot;&quot; src=&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;--대괄호여러-문자-중-하나와-일치&quot;&gt;[ ] 대괄호:여러 문자 중 하나와 일치&lt;/h2&gt;

&lt;p&gt;대괄호 &lt;code class=&quot;highlighter-rouge&quot;&gt;[&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;]&lt;/code&gt; 사이에 원하는 문자를 여러 개 넣으면, 문자열이 넣은 문자 중 하나와 일치하면 매칭이 이루어진다. 즉 OR 개념이라고 할 수 있다.&lt;br /&gt;
여기서 중요한 것은 &lt;code class=&quot;highlighter-rouge&quot;&gt;[ ]&lt;/code&gt; 안에 얼마나 많은 문자 종류가 있는지에 상관없이 딱 한 문자와 일치된다는 것이다.&lt;/p&gt;

&lt;p&gt;예를 들어 정규식 표현이 &lt;code class=&quot;highlighter-rouge&quot;&gt;[abc]&lt;/code&gt;이고 문자열이 ‘a’이면 &lt;strong&gt;re.match&lt;/strong&gt;는 매칭되었다고 할 것이다.&lt;br /&gt;
문자열이 ‘b’이거나 ‘c’이어도 매칭이 된다. 다만 문자열이 ‘d’이거나 ‘가나다’ 같은 것이면 매칭이 되지 않는다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fullmatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;You[;']re studying re module[.,]&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; \
                        &lt;span class=&quot;s&quot;&gt;'You;re studying re module,'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;_sre.SRE_Match object; span=(0, 26), match='You;re studying re module,'&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;사용자의 오타를 잡기에 괜찮은 기능이다.&lt;/p&gt;

&lt;p&gt;대괄호 &lt;code class=&quot;highlighter-rouge&quot;&gt;[ ]&lt;/code&gt;에는 다른 기능이 더 있다. 이전 글에서 &lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/20/regex-usage-01-basic/#semi-%EB%A9%94%ED%83%80%EB%AC%B8%EC%9E%90&quot;&gt;semi-메타문자&lt;/a&gt;를 설명했었는데, 문자 &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;는 대괄호 안에서는 메타문자 역할을 한다.&lt;/p&gt;

&lt;p&gt;하이픈 &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;는 범위를 형성한다. 예를 들어 &lt;code class=&quot;highlighter-rouge&quot;&gt;[a-z]&lt;/code&gt;는 알파벳 소문자 중 하나이기만 하면 매칭이 된다. 또 &lt;code class=&quot;highlighter-rouge&quot;&gt;[A-Z]&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;[0-9]&lt;/code&gt;는 각각 알파벳 대문자와 숫자 하나에 매칭된다.&lt;br /&gt;
물론 위의 경우뿐만 아니라 넓은 범위도 가능하다. &lt;code class=&quot;highlighter-rouge&quot;&gt;[가-힣]&lt;/code&gt;의 경우는 한글 한 글자에 일치된다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;[A-z]&lt;/code&gt;는 영문 대소문자와 몇 개의 특수문자를 포함한다. 하지만 여러분이 잘 모르는 문자까지 포함될 수 있으므로 영문자는 &lt;code class=&quot;highlighter-rouge&quot;&gt;[A-Za-z]&lt;/code&gt;와 같이 쓰기를 권한다.&lt;/p&gt;

&lt;p&gt;참고로, 대괄호 안에서는 메타문자 역할을 하는 것은 오직 &lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;]&lt;/code&gt; 4개뿐이다. 즉, 이전에 메타문자라고 설명했었던 &lt;code class=&quot;highlighter-rouge&quot;&gt;.&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt; 등은 대괄호 안에서는 그냥 문자 ‘.’, ‘*’, ‘+’ 하나에 매칭된다.&lt;br /&gt;
그러나 헷갈릴 소지가 다분하기 때문에 원래 메타문자인 문자들은 그냥 대괄호 안에서도 &lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt; 이스케이프 처리하는 것이 편할 것이다.&lt;br /&gt;
물론 IDE가 좋다면 redundant escape character라는 경고를 띄워 줄지도 모른다.&lt;/p&gt;

&lt;p&gt;캐릿(caret)&lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt; 문자가 여는 대괄호 바로 뒤에 있으면 문자가 반전된다. 바로 예시를 보도록 하자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Why [a-z]o serious\?'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Why so serious?'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Why [^0-9]o serious\?'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Why so serious?'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;_sre.SRE_Match object; span=(0, 15), match='Why so serious?'&amp;gt;
&amp;lt;_sre.SRE_Match object; span=(0, 15), match='Why so serious?'&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;[a-z]&lt;/code&gt;는 영문 소문자 하나(‘s’)와 일치되므로 매칭 결과가 반환되었다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;[^0-9]&lt;/code&gt;는 숫자를 제외한 문자 하나에 일치되므로, ‘s’는 숫자가 아니기에 매칭이 되었다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;[z-a]&lt;/code&gt;와 같이 거꾸로 쓰는 것은 불가능하다.&lt;/p&gt;

&lt;p&gt;대괄호 안의 &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;는 또 다른 기능이 있다. 바로 진짜 빼기(마이너스), 즉 차집합 연산이다.&lt;br /&gt;
대괄호 한 쌍을 집합으로 보면 차집합이란 말이 이해가 될 것이다. &lt;code class=&quot;highlighter-rouge&quot;&gt;[a-z-[g-z]]&lt;/code&gt;의 경우 a-f와 같은 의미이다.&lt;br /&gt;
또 &amp;amp;&amp;amp;를 안에 쓰면 C언어 문법의 and 기능처럼 교집합을 의미한다고 한다.&lt;br /&gt;
하지만 필자가 글을 쓰는 시점에서 이 문법이 유효한지는 확인되지 않았다. 파이썬 버전에 따라 다를 수도 있고, 지원하지 않는 기능일 수도 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-마침표-모든-문자와-일치&quot;&gt;. 마침표: 모든 문자와 일치&lt;/h2&gt;

&lt;p&gt;개행문자를 제외한 모든 문자와 일치하는 정규표현식은 마침표 &lt;code class=&quot;highlighter-rouge&quot;&gt;.&lt;/code&gt; 이다. 정말로 모든 문자와 일치되기 때문에 별다른 설명은 필요 없을 것 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'r..n[.]'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'ryan. ruin rain round. reign'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['ryan.']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;대괄호 &lt;code class=&quot;highlighter-rouge&quot;&gt;[ ]&lt;/code&gt; 안에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;.&lt;/code&gt;가 메타문자로 동작하지 않는다고 하였다. 따라서 일치되는 문자열은 ‘ryan’ 하나뿐이다.&lt;/p&gt;

&lt;h3 id=&quot;마침표는-개행-문자와-일치-옵션&quot;&gt;마침표는 개행 문자와 일치 옵션&lt;/h3&gt;

&lt;p&gt;파이썬 re 패키지의 많은 함수들은 다음과 같은 인자들을 받는다고 &lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/20/regex-usage-01-basic/#rematchpattern-string-flags&quot;&gt;이전 글&lt;/a&gt;에서 설명했었다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;re.match(pattern, string, flags)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여기서 flags는 다음과 같은 종류들이 있다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;syntax&lt;/th&gt;
      &lt;th&gt;long syntax&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;inline flag&lt;/th&gt;
      &lt;th&gt;meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;re.I&lt;/td&gt;
      &lt;td&gt;re.IGNORECASE&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;(?i)&lt;/td&gt;
      &lt;td&gt;대소문자 구분 없이 일치&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;re.M&lt;/td&gt;
      &lt;td&gt;re.MULTILINE&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;(?m)&lt;/td&gt;
      &lt;td&gt;^와 $는 개행문자 위치에서 일치&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;re.S&lt;/td&gt;
      &lt;td&gt;re.DOTALL&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;(?s)&lt;/td&gt;
      &lt;td&gt;마침표는 개행문자와 일치&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;re.A&lt;/td&gt;
      &lt;td&gt;re.ASCII&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;(?a)&lt;/td&gt;
      &lt;td&gt;{\w, \W, \b, \B}는 ascii에만 일치&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;re.U&lt;/td&gt;
      &lt;td&gt;re.UNICODE&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;(?u)&lt;/td&gt;
      &lt;td&gt;{\w, \W, \b, \B}는 Unicode에 일치&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;re.L&lt;/td&gt;
      &lt;td&gt;re.LOCALE&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;(?L)&lt;/td&gt;
      &lt;td&gt;{\w, \W, \b, \B}는 locale dependent&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;re.X&lt;/td&gt;
      &lt;td&gt;re.VERBOSE&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;(?x)&lt;/td&gt;
      &lt;td&gt;정규표현식에 주석을 달 수 있음&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;우선 다른 것들은 나중에 살펴보고, 마침표 옵션만을 보자.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;syntax&lt;/th&gt;
      &lt;th&gt;long syntax&lt;/th&gt;
      &lt;th&gt;meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;re.S&lt;/td&gt;
      &lt;td&gt;re.DOTALL&lt;/td&gt;
      &lt;td&gt;마침표는 개행문자와 일치&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a..'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'abc a  a&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a..'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'abc a  a&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a..'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'abc a  a&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DOTALL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['abc', 'a  ']
['abc', 'a  ', 'a\na']
['abc', 'a  ', 'a\na']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;개행 문자도 마침표에 일치되는지를 설정할 수 있음을 확인하였다.&lt;br /&gt;
문자열을 행 단위로 처리하거나 아니면 전체 문자열을 대상으로 처리할 수 있다는 것에 이 옵션의 존재 의의가 있다.&lt;/p&gt;

&lt;h4 id=&quot;모드-변경자&quot;&gt;모드 변경자&lt;/h4&gt;

&lt;p&gt;아니면 다른 방법도 있다. 정규표현식 내에서 사용할 수도 있다.&lt;br /&gt;
문자열 앞에 &lt;code class=&quot;highlighter-rouge&quot;&gt;(?s)&lt;/code&gt; 토큰을 넣으면 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'(?s)a..'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'abc a  a&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['abc', 'a  ', 'a\na']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;모드 변경자는 여러 개를 중첩하여 사용할 수도 있다.&lt;br /&gt;
또한 일부분에만 사용하고 싶으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;(?s&amp;lt;regex&amp;gt;)&lt;/code&gt;처럼 모드 변경자의 소괄호 안에 집어넣으면 된다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'(?is)a..'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Abc'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'(?is:a..) and abc is good'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;'''
Abc and abc is good.
abc and Abc is good. 
'''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['Abc']
['Abc and abc is good']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;두 번째 &lt;strong&gt;findall&lt;/strong&gt;에서 문장을 한 개만 찾은 것을 유의하라.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;문자-집합-w-w-d-d-s-s-b-b&quot;&gt;문자 집합: \w \W, \d \D, \s \S, \b \B&lt;/h2&gt;

&lt;h3 id=&quot;w-w-단어-문자-비-단어-문자&quot;&gt;\w, \W: 단어 문자, 비 단어 문자&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;\w&lt;/code&gt;는 단어 문자 1개와 일치된다. 단어 문자는 영문 대소문자, 숫자 0-9, 언더바 ‘_’ 를 포함한다.&lt;br /&gt;
한글 등 알파벳 이외의 단어는 파이썬 버전에 따라 다른데, Unicode를 기본으로 사용하는 파이썬 3이라면 아마 &lt;code class=&quot;highlighter-rouge&quot;&gt;\w&lt;/code&gt;의 범위에 한글도 포함될 것이다. 여러분이 스스로 확인해 봐야 할 것이다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;\W&lt;/code&gt;는 단어 문자 이외의 문자 1개에 일치된다. 즉 공백 문자, 특수 문자 등에 일치된다고 보면 된다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;\w&lt;/code&gt;와 정확히 반대의 역할을 한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\w\w\w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a_가'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\w\W\w'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a (9_a a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;_sre.SRE_Match object; span=(0, 3), match='a_가'&amp;gt;
['a a']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;첫 번째 출력 결과의 경우 단어 3개를 나타내는 정규표현식에 ‘a_가’가 매칭되었다.
두 번째 출력 결과는 잘 보면&lt;br /&gt;
1) 비 단어 문자&lt;br /&gt;
2) 단어 문자&lt;br /&gt;
3) 비 단어 문자&lt;br /&gt;
순으로 되어 있는데, 그런 결과는 ‘a a’ 하나뿐이다.&lt;/p&gt;

&lt;h3 id=&quot;d-d-숫자-문자-비-숫자-문자&quot;&gt;\d, \D: 숫자 문자, 비 숫자 문자&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;\d&lt;/code&gt;는 숫자 문자 1개에 일치된다. 마찬가지로 &lt;code class=&quot;highlighter-rouge&quot;&gt;\D&lt;/code&gt;는 비 숫자 문자 1개에 일치된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\d\d'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'12abc34'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\d\d\D\D'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'11aa11c1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;_sre.SRE_Match object; span=(0, 2), match='12'&amp;gt;
['11aa']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;첫 번째 출력 결과는 매칭되는 문자열은 두 군데로 ‘12’와 ‘34’이다. 하지만 &lt;strong&gt;re.search&lt;/strong&gt;는 제일 처음 하나만 찾아내기 때문에 하나만 반환하였다.
두 번째 출력 결과는 숫자 2개에 비 숫자 문자 2개가 붙어 있는 문자열 ‘11aa’를 잘 찾아 주었다.&lt;/p&gt;

&lt;h3 id=&quot;s-s-공백-문자-비-공백-문자&quot;&gt;\s, \S: 공백 문자, 비 공백 문자&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;\s&lt;/code&gt;는 공백 문자(빈칸 ‘ ‘, 탭 ‘\t’, 개행 ‘\n’) 1개에 일치된다. 마찬가지로 &lt;code class=&quot;highlighter-rouge&quot;&gt;\S&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;\s&lt;/code&gt;의 반대 역할이다. 즉, 공백 문자 이외의 모든 문자 1개에 일치된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'Oh\smy\sgod\s\S'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;'''Oh my&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;god
!'''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;_sre.SRE_Match object; span=(0, 11), match='Oh my\tgod\n!'&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;b-b-단어-경계-비-단어-경계&quot;&gt;\b, \B: 단어 경계, 비 단어 경계&lt;/h3&gt;

&lt;p&gt;단어 경계 &lt;code class=&quot;highlighter-rouge&quot;&gt;\b&lt;/code&gt; 는, 문자 하나와 일치되는 것이 아니라 정말로 단어 경계와 일치된다. 단어 문자와 비 단어 문자 사이와 매칭된다고 보면 된다.&lt;/p&gt;

&lt;p&gt;비 단어 경계 &lt;code class=&quot;highlighter-rouge&quot;&gt;\B&lt;/code&gt; 는 마찬가지로 반대의 역할을 수행한다. 즉, 단어 문자와 단어 문자 사이 혹은 비 단어 문자와 비 단어 문자 사이와 일치된다.&lt;/p&gt;

&lt;p&gt;다른 말로는, &lt;code class=&quot;highlighter-rouge&quot;&gt;\b&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;\w&lt;/code&gt;에 일치되는 한 문자와 &lt;code class=&quot;highlighter-rouge&quot;&gt;\W&lt;/code&gt;에 일치되는 한 문자 사이에서 일치되고, &lt;code class=&quot;highlighter-rouge&quot;&gt;\B&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;\w&lt;/code&gt;에 일치되는 두 문자 사이 또는 &lt;code class=&quot;highlighter-rouge&quot;&gt;\W&lt;/code&gt;에 일치되는 두 문자 사이에서 일치된다.&lt;/p&gt;

&lt;p&gt;한 가지 주의할 점으로는 &lt;code class=&quot;highlighter-rouge&quot;&gt;\b&lt;/code&gt;나 &lt;code class=&quot;highlighter-rouge&quot;&gt;\B&lt;/code&gt;를 사용하기 위해서는 정규표현식 앞에 &lt;code class=&quot;highlighter-rouge&quot;&gt;r&lt;/code&gt; prefix를 붙여줘야 한다는 것이다.&lt;br /&gt;
예시를 보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'\w\b\W\B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'ab  c d  == = e= =f'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['b ', 'd ', 'e=']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;위의 예시는&lt;br /&gt;
1) 단어 문자&lt;br /&gt;
2) 단어 경계&lt;br /&gt;
3) 비 단어 문자&lt;br /&gt;
4) 비 단어 경계&lt;/p&gt;

&lt;p&gt;순으로 되어 있는 문자열을 찾는다. 위의 조건을 만족시키려면 단어 문자 + 비 단어 문자 + 비 단어 문자 조합을 찾아야 한다. 그리고 실제로 매칭되는 문자열은 단어 문자 + 비 단어 문자이다.&lt;br /&gt;
(주: 여기서 2) 단어 경계는 쓸모가 없다. 이유는 여러분이 알아서 생각하면 된다.)&lt;/p&gt;

&lt;h4 id=&quot;응용-문제&quot;&gt;응용 문제&lt;/h4&gt;

&lt;p&gt;문제 1: ‘line’과는 일치하지만, ‘outline’나 ‘linear’ 등과는 일치하지 않는 정규표현식을 작성하라. 즉, 정확히 ‘line’ 단어와만 일치해야 한다.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 1 정답보기&lt;/summary&gt;
    &lt;p&gt;\bline\b&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;문제 2: ‘stacatto’에는 일치하지만, ‘cat’이나 ‘catch’, ‘copycat’ 등과는 일치하지 않는 정규표현식을 작성하라.&lt;/p&gt;
&lt;details&gt;
    &lt;summary&gt;문제 2 정답보기&lt;/summary&gt;
    &lt;p&gt;\Bcat\B&lt;/p&gt;
&lt;/details&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;\b&lt;/code&gt;는 단어 경계로, 다음에 일치된다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;첫 문자가 단어 문자인 경우, 첫 문자 앞에서&lt;/li&gt;
  &lt;li&gt;인접한 두 문자 중 하나만 단어 문자인 경우, 그 사이에서&lt;/li&gt;
  &lt;li&gt;끝 문자가 단어 문자인 경우, 끝 문자 뒤에서&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;즉 문자열의 맨 앞과 맨 끝은 비 단어인 것으로 처리된다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;\B&lt;/code&gt;는 비 단어 경계로, 다음에 일치된다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;첫 문자가 비 단어 문자인 경우, 첫 문자 앞에서&lt;/li&gt;
  &lt;li&gt;두 단어 문자 사이 또는 두 비 단어 문자 사이에서&lt;/li&gt;
  &lt;li&gt;끝 문자가 비 단어 문자인 경우, 끝 문자 뒤에서&lt;/li&gt;
  &lt;li&gt;빈 문자열에서&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;(헷갈리는) 예시를 보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'\b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'\B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'\b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a aa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;r'\B'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a aa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['', '']
[]
['', '', '', '']
['']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;각각 어디에서 일치된 것인지 이해해 보기 바란다.&lt;/p&gt;

&lt;h3 id=&quot;옵션-r-prefix&quot;&gt;옵션: r prefix&lt;/h3&gt;

&lt;p&gt;원래 r prefix란 이스케이프 문자 &lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt;를 이스케이프 처리 문자가 아닌 일반 리터럴 문자로 인식하게끔 하는 역할을 한다. &lt;a href=&quot;https://stackoverflow.com/questions/2241600/python-regex-r-prefix&quot;&gt;영문 설명&lt;/a&gt;을 가져오면 아래와 같다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;When an “r” or “R” prefix is present, a character following a backslash is included in the string without change, and all backslashes are left in the string. For example, the string literal r”\n” consists of two characters: a backslash and a lowercase “n”. String quotes can be escaped with a backslash, but the backslash remains in the string; for example, r”&quot;” is a valid string literal consisting of two characters: a backslash and a double quote; r”&quot; is not a valid string literal (even a raw string cannot end in an odd number of backslashes). Specifically, a raw string cannot end in a single backslash (since the backslash would escape the following quote character). Note also that a single backslash followed by a newline is interpreted as those two characters as part of the string, not as a line continuation.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;해석하면,&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“r”이나 “R” 접두사가 있으면, \ 뒤에 있는 문자는 문자열에 변화 없이 그대로 남아 있게 되고, 모든 \ 또한 문자열에 남아 있게 된다. 예를 들어, 리터럴 문자열 r”\n”은 \와 소문자 n 2개의 문자로 구성된다. 따옴표 문자열 역시 \가 있으면 이스케이프 처리될 수 있지만, \는 여전히 문자열에 남아 있게 된다. 예를 들어 r”\&quot;”의 경우 \와 “ 두 개로 구성된 유효한 문자열이다. r”\“는 유효하지 않다(raw string은 홀수 개의 \로 끝날 수 없다). 특별히, raw string은 한 개의 \로 끝날 수 없다(\는 다음에 오는, 즉 문자열의 끝을 알리는 따옴표를 이스케이프 처리하므로). newline이 다음에 오는 한 개의 \는 문자열의 일부로서 두 개의 문자로 취급되지, 개행으로 처리되지 않는다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;예시를 보자.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; r'\'
SyntaxError: EOL while scanning string literal
&amp;gt;&amp;gt;&amp;gt; r'\''
&quot;\\'&quot;
&amp;gt;&amp;gt;&amp;gt; '\'
SyntaxError: EOL while scanning string literal
&amp;gt;&amp;gt;&amp;gt; '\''
&quot;'&quot;
&amp;gt;&amp;gt;&amp;gt; 
&amp;gt;&amp;gt;&amp;gt; r'\\'
'\\\\'
&amp;gt;&amp;gt;&amp;gt; '\\'
'\\'
&amp;gt;&amp;gt;&amp;gt; print r'\\'
\\
&amp;gt;&amp;gt;&amp;gt; print r'\'
SyntaxError: EOL while scanning string literal
&amp;gt;&amp;gt;&amp;gt; print '\\'
\
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;unicodelocale-dependent-옵션&quot;&gt;Unicode/Locale dependent 옵션&lt;/h3&gt;

&lt;p&gt;파이썬3은 기본적으로 한글도 “단어 문자”에 포함되기 때문에 쓸 일이 있을지는 모르지만, 이 옵션들도 소개해 본다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;syntax&lt;/th&gt;
      &lt;th&gt;long syntax&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;inline flag&lt;/th&gt;
      &lt;th&gt;meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;re.A&lt;/td&gt;
      &lt;td&gt;re.ASCII&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;(?a)&lt;/td&gt;
      &lt;td&gt;{\w, \W, \b, \B}는 ascii에만 일치&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;re.U&lt;/td&gt;
      &lt;td&gt;re.UNICODE&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;(?u)&lt;/td&gt;
      &lt;td&gt;{\w, \W, \b, \B}는 Unicode에 일치&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;re.L&lt;/td&gt;
      &lt;td&gt;re.LOCALE&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;(?L)&lt;/td&gt;
      &lt;td&gt;{\w, \W, \b, \B}는 locale dependent&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;파이썬3은 기본적으로 Unicode를 기준으로 처리되기 때문에 &lt;code class=&quot;highlighter-rouge&quot;&gt;re.U&lt;/code&gt;는 쓸모가 없다. 그러나 호환성을 위해 아직까지는 살아 있는 옵션이다.&lt;br /&gt;
아스키에만 일치하는 옵션을 쓰고 싶으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;re.ASCII&lt;/code&gt; 옵션을 사용하면 된다.&lt;/p&gt;

&lt;p&gt;조금 더 자세한 설명은 &lt;a href=&quot;https://docs.python.org/3/library/re.html#module-contents&quot;&gt;여기&lt;/a&gt;를 참조하라.&lt;/p&gt;

&lt;p&gt;다른 flags 사용법과 똑같으므로 생략하도록 하겠다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;--a-z-문자열-전체-또는-행의-시작이나-끝의-대상을-대조&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt;, $, \A, \Z: 문자열 전체 또는 행의 시작이나 끝의 대상을 대조&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;\A&lt;/code&gt;는 문자열 시작을, &lt;code class=&quot;highlighter-rouge&quot;&gt;\Z&lt;/code&gt;는 문자열 끝과 일치된다.&lt;/p&gt;

&lt;p&gt;이들은 일명 앵커라고 부르는데, 문자와 일치되는 것이 아니라 정규식 패턴을 특정 위치에 고정시켜서 그 위치에 일치시키는 역할을 한다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;$&lt;/code&gt;는 기본적으로 행 시작과 행 끝에 일치된다.&lt;/p&gt;

&lt;p&gt;여기서 행은 문자열의 시작과 개행문자 사이, 개행문자와 개행문자 사이, 개행문자와 문자열의 끝 사이 부분이다. 문자열에 개행문자가 없으면 전체 문자열이 한 개의 행이 된다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;$&lt;/code&gt;는 일반적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;\A&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;\Z&lt;/code&gt; 앵커와 효과가 같다. 다른 경우는 옵션을 설정하는 경우인데, re.MULTILINE 옵션을 설정하면 &lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;$&lt;/code&gt;는 문자열 전체의 시작/끝이 아닌 행의 시작/끝에서 일치된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\Aryan\d\Z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'ryan1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'^ryan\d$'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'ryan1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\A ryan\d\s\Z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;' ryan1 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; ryan2 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; rain1 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; ryan3 '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'^ ryan\d\s$'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;' ryan1 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; ryan2 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; rain1 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; ryan3 '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'^ ryan\d\s$'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;' ryan1 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; ryan2 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; rain1 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; ryan3 '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'^ ryan\d\s$'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;' ryan1 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; ryan2 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; rain1 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; ryan3 '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MULTILINE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['ryan1']
['ryan1']
[]
[]
[' ryan1 ', ' ryan2 ', ' ryan3 ']
[' ryan1 ', ' ryan2 ', ' ryan3 ']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Java, .NET 등에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;\z&lt;/code&gt; 옵션이 있지만, 파이썬에는 bad escape 에러를 보게 되므로 사용하지 말자.&lt;/p&gt;

&lt;p&gt;응용으로, 빈 문자열 혹은 빈 행을 검사할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fullmatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\A\Z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fullmatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'\A\Z'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fullmatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'^$'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fullmatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'^$'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'^$'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;_sre.SRE_Match object; span=(0, 0), match=''&amp;gt;
None
&amp;lt;_sre.SRE_Match object; span=(0, 0), match=''&amp;gt;
None
['', '']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;^&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;$&lt;/code&gt;도 마침표 &lt;code class=&quot;highlighter-rouge&quot;&gt;.&lt;/code&gt;처럼 옵션을 인라인으로 설정할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'(?m)^$'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['', '']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고로, 옵션을 여러 개 쓰려면 &lt;code class=&quot;highlighter-rouge&quot;&gt;|&lt;/code&gt;로 OR 연산을 시켜주면 된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'^ ryan\d\s$'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;' ryan1 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; Ryan2 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; rain1 &lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; RYAN3 '&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IGNORECASE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[' ryan1 ', ' Ryan2 ', ' RYAN3 ']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위의 예시처럼 full-name과 약자를 같이 써도 되지만, 가독성을 생각한다면 굳이 그렇게 할 이유는 없다.&lt;/p&gt;

&lt;h2 id=&quot;유니코드-번호&quot;&gt;유니코드 번호&lt;/h2&gt;

&lt;p&gt;한 글자 일치와 사용법은 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\u18ff&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;\d'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'0᣿1頶᣿2䅄ሲ᣿3456'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['\u18ff1', '\u18ff2', '\u18ff3']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;참고로 ‘\u18ff’는 ‘᣿’이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/22/regex-usage-03-basic/&quot;&gt;다음 글&lt;/a&gt;에서는 다자택일(OR), 반복 등을 다루도록 하겠다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>YOLO</title>
   <link href="http://localhost:4000/YOLO/"/>
   <updated>2018-07-21T00:00:00+09:00</updated>
   <id>http://localhost:4000/YOLO</id>
   <content type="html">&lt;h2 id=&quot;yolo-you-only-look-once&quot;&gt;YOLO: You Only Look Once&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;본 포스트는 아래의 논문, 코드와
Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi - You Only Look Once: Unified, Real-Time Object Detection (2015)
Joseph Redmon, Ali Farhadi - YOLO9000: Better, Faster, Stronger (2016)
Allan Zelener - YAD2K: Yet Another Darknet 2 Keras
Andrew Ng의 Convolutional Neural Networks 강의의 내용을 토대로 정리한 것임을 밝힌다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;YOLO&lt;/strong&gt; 알고리즘은 Sliding Window를 사용하여 이미지의 픽셀을 Stride 단위로 하나하나&lt;br /&gt;
살펴보는 것이 아니라 이미지를 Grid로 나누어 각각의 Grid Cell에 대해&lt;br /&gt;
Label(그 셀의 정보)를 부여함으로써 한 번에 이미지를 스캔한다.&lt;br /&gt;
이 때문에 YOLO 알고리즘은 빠른 속도라는 강점을 갖고 있다.&lt;/p&gt;

&lt;p&gt;알고리즘에 대해 세세하게 설명하기 전에 코딩을 위한 Setting부터 진행하도록 하겠다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backend&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;yad2k.utils.yolo_utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_anchors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generate_colors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preprocess_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;draw_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale_boxes&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;yad2k.models.keras_yolo&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yolo_head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yolo_boxes_to_corners&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preprocess_true_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yolo_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yolo_body&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여기서 제일 아래 두 줄에 있는 yad2k 모듈은 터미널에서 바로 다운로드를 받을 수 없다.&lt;br /&gt;
아래 깃헙들을 통해서 다운을 받도록 하자.
&lt;a href=&quot;https://github.com/allanzelener/YAD2K/blob/master/yad2k/models/keras_yolo.py&quot;&gt;yad2k-첫 번째&lt;/a&gt;,
&lt;a href=&quot;https://github.com/tejaslodaya/car-detection-yolo&quot;&gt;yad2k-두 번째&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;첫 번째 깃헙에서는 아래에 보이는 것처럼 font와 yad2k폴더를 저장하면 된다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018_07_21_YOLO/yolo01.PNG&quot; width=&quot;90%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;두 번째 깃헙에서는 아래에 보이는 것처럼 yolo_uilts.py파일만 저장하여&lt;br /&gt;
위 코드에서 알 수 있듯이 yad2k.utils안에 넣어두어 편리하게 사용할 수 있다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018_07_21_YOLO/yolo02.PNG&quot; width=&quot;90%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;하지만 이 사용자 패키지를 그대로 Lib/site-packages에 집어넣는다고 모든 게 해결되지는 않는다.&lt;br /&gt;
폰트 설정 작업을 다시 해주어야 한다.&lt;/p&gt;

&lt;p&gt;첫 번째 깃헙에서 다운로드를 받은 font폴더를 열어보면 아래의 파일을 확인할 수 있다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018_07_21_YOLO/yolo03.PNG&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;물론 다른 otf폰트를 사용해서 문제가 없을 것이다만, 나는 이 패키지를 만드신 분의 폰트를 그대로 따랐다.&lt;/p&gt;

&lt;p&gt;여기서 FiraMono-Medium.otf파일을 글꼴 설치해주자. 그러고 나서는 모듈 내 함수에서 2가지만  수정해주면 된다. 모듈 내에 있는 draw_boxes.py와 yolo_utils.py를 열어보자&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018_07_21_YOLO/yolo04.PNG&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018_07_21_YOLO/yolo05.PNG&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;모두 draw_boxes란 함수를 포함하고 있는데, 여기서 &lt;strong&gt;font=” “&lt;/strong&gt; 부분에 본인이 폰트를 저장한 경로로&lt;br /&gt;
수정을 해주어야만 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;자 그럼 모듈 준비는 끝났다. 본격적으로 YOLO에 대해 탐구해볼까?&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;bounding-boxes-and-endocing-vector&quot;&gt;Bounding Boxes and Endocing Vector&lt;/h3&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018_07_21_YOLO/yolo06.PNG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;YOLO 알고리즘을 사용하기 전에는 본인이 detect하고 싶은 물체를 구분할 수 있는 pre-trained된 CNN기반 모델이 필요하다. 즉, 내가 이미지에서 1개 이상의 차/보행자/오토바이를 구분하고 싶다면,&lt;br /&gt;
pre-trained된 모델은 이미지가 차인지 보행자인지 오토바이인지 하나의 Class로 구분할 수 있는 모델이어야 한다는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Size가 608 X 608&lt;/strong&gt;인 이미지 셋을 이용한다고 해보자.&lt;br /&gt;
그리고 우리는 여러 object를 detect하기 위해 5개 종류의 anchor box를 사용한다고 해보자.&lt;br /&gt;
그렇다면 처음 Input은 (m, 608, 608, 3)의 shape을 가질 것이고(m개의 이미지),&lt;br /&gt;
이 Input은 Deep CNN을 거쳐 (m, 19, 19, 5, 85)의 shape으로 인코딩된다.&lt;/p&gt;

&lt;p&gt;여기서 &lt;strong&gt;19, 19&lt;/strong&gt;는 Grid의 Size를 말한다.&lt;br /&gt;
즉 아래의 그림처럼 19*19개의 각각의 Grid Cell이 어떤 object를 detect하고 있는지&lt;br /&gt;
각각의 sign을 남긴다는 뜻이다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018_07_21_YOLO/yolo07.PNG&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;마지막 85의 길이를 가진 벡터는 아래와 같이 생겼다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018_07_21_YOLO/yolo08.PNG&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;이러한 벡터가 각 anchor box별로 하나 씩 있기 때문에 shape의 마지막 부분이 5, 85)가 되는 것이다.&lt;/p&gt;

&lt;p&gt;(m, 19, 19, 5, 85)는 필요 이상으로 고차원이기 때문에 계산의 편리함을 위해&lt;br /&gt;
(m, 19, 19, 425)로 Unroll해주도록 한다.&lt;br /&gt;
다시 정리하자면, 위 matrix의 의미는, &lt;strong&gt;19X19&lt;/strong&gt;개 각각의 Cell이 자기자신이 어떤 Label인지에&lt;br /&gt;
대한 정보를 425개의 숫자로 표현하고 있다는 것이다.&lt;/p&gt;

&lt;p&gt;마지막 425의 길이를 가진 벡터를 분리하여 다음과 같이 Score를 계산해주도록 한다.
아래 코드에선 이를 &lt;strong&gt;box_scores&lt;/strong&gt;라고 명명할 것이다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018_07_21_YOLO/yolo09.PNG&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;이제 위에서 구한 box_scores를 바탕으로,&lt;br /&gt;
각 Grid Cell은 각각의 box(여기서는 5개의 anchor box가 있다.)와&lt;br /&gt;
각각의 class(여기서는 80개의 classes가 있다.)에 대해 maximum probability를 찾고&lt;br /&gt;
이를 토대로 자신의 정체성을 확립하게 된다. (나는 어떤 object이다라고 결정!)&lt;/p&gt;

&lt;p&gt;Cell의 중심에 앵커의 중심을 놓고 bbox를 그리면, 아래와 같은 그림을 얻을 수 있을 것이다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018_07_21_YOLO/yolo10.PNG&quot; width=&quot;30%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;Box가 너무 많기 때문에 일단 Score면에서 일정 수준 미달인 Box들을 제거해준다.&lt;br /&gt;
Score가 낮다는 것은 Cell이 실제로 이 object를 detect했을 확률이 낮다는 것이다.&lt;br /&gt;
그러고 나서 최고 Score를 받은 Box와 너무 많이 겹치는 Box들을 제거해준다.
(IOU가 높은 박스 제거) 이것이 바로 Non-max Suppression 과정이다.&lt;/p&gt;

&lt;p&gt;자 이제 본격적으로 코드로 구현해보자.&lt;/p&gt;

&lt;h3 id=&quot;filtering-with-a-threshold-on-class-scores&quot;&gt;Filtering with a threshold on class scores&lt;/h3&gt;
&lt;p&gt;앞서 언급한 과정 중 첫 번째 단계를 실현하는 과정이다.&lt;br /&gt;
아래 코드에 등장하는 객체에 대해 설명하자면,&lt;br /&gt;
&lt;strong&gt;box_confidence&lt;/strong&gt;: (19&lt;em&gt;19, 5, 1) - $P_c$를 담고 있다. (타겟 Object가 존재할 확률)&lt;br /&gt;
&lt;strong&gt;boxes&lt;/strong&gt;: (19&lt;/em&gt;19, 5, 4) - Bounding Box 좌표 4개를 담고 있다.&lt;br /&gt;
&lt;strong&gt;box_class_probs&lt;/strong&gt;: (19*19, 5, 80) - Class 80개에 대한 확률 값을 담고 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;yolo_filter_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;box_confidence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box_class_probs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    threshold -- real value, if [highest class probability score &amp;lt; threshold],
    then get rid of the corresponding box

    Returns:
    몇 개의 박스를 선택하는지 모르기 때문에 None을 쓴다. 
    이 개수는 설정된 threshold의 값에 달려 있다.
    scores -- tensor of shape (None,), containing the class probability score for selected boxes
    boxes -- tensor of shape (None, 4), containing (b_x, b_y, b_h, b_w)
    classes -- tensor of shape (None,), containing the index of the class
    detected by the selected boxes
    &quot;&quot;&quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Step 1: Compute box scores
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;box_scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;box_confidence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box_class_probs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Step 2: box_scores에서 제일 큰 스코어의 위치와 값을 찾는다.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;box_classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;box_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;box_class_scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;box_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Step 3: 아래 필터링 마스크는 부울렌 tensor로 threshold보다 큰 score를 가지는
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# box_class를 판별한다.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;filtering_mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;greater_equal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;box_class_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Step 4: Apply the mask to scores, boxes and classes
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boolean_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;box_class_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtering_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boolean_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtering_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boolean_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;box_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filtering_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위에서 tf.boolean_mask함수는 아래와 같은 형식을 갖는다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boolean_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'boolean_mask'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;해당 텐서에 True, False로 구성된 mask를 씌우면 True와 연결된 값만 남고 나머지는 지워진다.&lt;br /&gt;
예를 들어&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;boolean_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;의 결과는 [0, 2]이다.&lt;/p&gt;

&lt;h3 id=&quot;non-max-suppression&quot;&gt;Non-max Suppression&lt;/h3&gt;
&lt;p&gt;이제 필요 없는 Box들을 제거해보자.&lt;br /&gt;
아래 함수에서 사용할 메서드 중 tf.image.non_max_suppression에 대해 설명하자면,&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;non_max_suppression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_output_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;iou_threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;score_threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'-inf'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;아래와 같은 arguements를 가진다.&lt;br /&gt;
1) &lt;strong&gt;boxes&lt;/strong&gt;: A 2-D float Tensor of shape [num_boxes, 4].&lt;br /&gt;
2) &lt;strong&gt;scores&lt;/strong&gt;: A 1-D float Tensor of shape [num_boxes] representing a single score corresponding to each box.&lt;br /&gt;
3) &lt;strong&gt;max_output_size&lt;/strong&gt;: NMS에 의해 선택될 box의 최대 개수 = num_boxes&lt;br /&gt;
4) &lt;strong&gt;iou_threshold&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;반환하는 객체는&lt;br /&gt;
&lt;strong&gt;Selected_indices&lt;/strong&gt;: A 1-D integer Tensor of shape [M] representing the selected indices from the boxes tensor, where M &amp;lt;= max_output_size. 사실상 shape은 (M, 1)&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;yolo_non_max_suppression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_boxes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iou_threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Applies NMS to set of boxes
    scores -- tensor of shape (None,), output of yolo_filter_boxes()
    boxes -- tensor of shape (None, 4), output of yolo_filter_boxes()
    that have been scaled to the image size (see later)
    classes -- tensor of shape (None,), output of yolo_filter_boxes()
    max_boxes -- integer, maximum number of predicted boxes you'd like
    iou_threshold -- real value, &quot;intersection over union&quot; threshold used for NMS

    Returns:
    scores -- tensor of shape (, None), predicted score for each box
    boxes -- tensor of shape (4, None), predicted box coordinates
    classes -- tensor of shape (, None), predicted class for each box

    Note: 이 함수는 scores, boxes, classes의 shape을 편의를 위해 transpose 시킬 것이다.
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 내가 예측하고 싶은 박스 최대치
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;max_boxes_tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# initialize variable max_boxes_tensor
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variables_initializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_boxes_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# get the list of indices corresponding to boxes you keep
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;nms_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;non_max_suppression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_boxes_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;iou_threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iou_threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Use K.gather() to select only nms_indices from scores, boxes and classes
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gather&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nms_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gather&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nms_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gather&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nms_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;첫 줄부터 설명하면
내가 만약 최대 10개의 Box를 선택하고 싶다면, arguement에서 max_boxes=10을 설정하고, 이 숫자를 tensor로 만든 것이 max_boxes_tensor이다.&lt;br /&gt;
다음 줄에서 위 텐서를 집어넣고 세션을 실행시킨다.&lt;br /&gt;
tf.image.non_max_suppression을 통해 nms_indices를 얻게 되는데 이는 선택할 Box의 indices를 의미한다.&lt;/p&gt;

&lt;p&gt;K.gather에 대해 설명하자면,&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gather&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validate_indices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;여기서 &lt;strong&gt;params&lt;/strong&gt;는 최소 axis+1의 rank를 갖는 텐서이다.&lt;br /&gt;
&lt;strong&gt;indices&lt;/strong&gt;는 [0, params.shape[axis]) 범위 사이에 있는 텐서이다.&lt;/p&gt;

&lt;p&gt;이 함수는 아래와 같이 indices에 따라 결과 값을 직관적으로 반환한다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018_07_21_YOLO/yolo11.PNG&quot; width=&quot;30%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;이제 return되는 scores, boxes, classes에는 NMS를 거쳐 축소된 (max_boxes 이하로 줄어든)&lt;br /&gt;
값이 담겨 있다.&lt;/p&gt;

&lt;h3 id=&quot;wrapping-up-the-filtering&quot;&gt;Wrapping up the filtering&lt;/h3&gt;
&lt;p&gt;위에서 정의한 두 함수를 바탕으로 종합 함수를 만들어보자.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;yolo_eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yolo_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;720.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1280.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_boxes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;score_threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iou_threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    Converts the output of YOLO encoding (a lot of boxes) to your predicted boxes along 
    with their scores, box coordinates and classes.

    Arguments:
    yolo_outputs -- output of the encoding model (for image_shape of (608, 608, 3)),
    contains 4 tensors:
                    box_confidence: tensor of shape (None, 19, 19, 5, 1)
                    box_xy: tensor of shape (None, 19, 19, 5, 2)
                    box_wh: tensor of shape (None, 19, 19, 5, 2)
                    box_class_probs: tensor of shape (None, 19, 19, 5, 80)
    image_shape -- Input shape을 담은 (2,) 텐서: 여기선 (608., 608.)이고 float32여야 함
    max_boxes -- integer, maximum number of predicted boxes you'd like
    score_threshold -- highest class probability score &amp;lt; threshold이면, 그 Box 제거
    iou_threshold -- IOU threshold used for NMS filtering

    Returns:
    scores -- tensor of shape (None, ), predicted score for each box
    boxes -- tensor of shape (None, 4), predicted box coordinates
    classes -- tensor of shape (None,), predicted class for each box
    &quot;&quot;&quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Retrieve outputs of the YOLO model
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;box_xy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box_wh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box_confidence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box_class_probs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yolo_outputs&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Convert boxes to be ready for filtering functions
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yolo_boxes_to_corners&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;box_xy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box_wh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yolo_filter_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;box_confidence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box_class_probs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score_threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Scale boxes back to original image shape.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yolo_non_max_suppression&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;max_boxes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iou_threshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iou_threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;두 번째 줄에 등장한 yolo_boxes_to_corners는 yad2모듈의 사용자 함수로,&lt;br /&gt;
height, width, x_center, y_center로 표기했던 좌표를 편의를 위해 코너 좌표로 바꿔준다.&lt;/p&gt;

&lt;p&gt;위에서 정의한 yolo_filter_boxes함수를 통해 수준 미달인 Box들을 제거해주고,&lt;br /&gt;
다음 단계를 위해 yad2k의 scale_boxes 메서드를 통해 scaling을 해준다.&lt;br /&gt;
다음 NMS를 적용하는 yolo_non_max_suppression함수를 통해 겹치는 Box들을 제거해준다.&lt;/p&gt;

&lt;h3 id=&quot;test&quot;&gt;Test&lt;/h3&gt;
&lt;p&gt;이제 실제 이미지에 적용해보자.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;yolo_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;load_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'C:/Users/YY/Documents/Winter Data/NN/Model/yolo.h5'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;yolo_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sgd'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'categorical_crossentropy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# yolo_model.count_params()
# yolo_model.summary()
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;path/coco_classes.txt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;anchors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;read_anchors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;path/yolo_anchors.txt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;image_shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;720.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1280.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;yolo_outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yolo_head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yolo_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anchors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yolo_eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yolo_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;적용을 위해선 class_names와 anchors가 필요하다. 각 txt파일의 내용은 아래와 같다.&lt;br /&gt;
&lt;strong&gt;coco_classes&lt;/strong&gt;: person/bicycle/car/motorbike/aeroplane/bus/train … 등 80개 class&lt;br /&gt;
&lt;strong&gt;anchor&lt;/strong&gt;: 0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828 = 5개의 anchor box 길이&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Runs the graph stored in &quot;sess&quot; to predict boxes for &quot;image_file&quot;.
    Prints and plots the preditions.

    Returns:
    out_scores -- tensor of shape (None, ), scores of the predicted boxes
    out_boxes -- tensor of shape (None, 4), coordinates of the predicted boxes
    out_classes -- tensor of shape (None, ), class index of the predicted boxes
    &quot;&quot;&quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Preprocess your image
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preprocess_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_image_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;608&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;608&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Run the session
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;out_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yolo_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_phase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Print predictions info
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Found {} boxes for {}'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Generate colors for drawing bounding boxes.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;colors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generate_colors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Draw bounding boxes on the image file
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;draw_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;colors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Save the predicted bounding box on the image
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# image.save(os.path.join(&quot;out&quot;, image_file), quality=90)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'path/output01.jpg'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;quality&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;90&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_classes&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;image_file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;path/image01.jpg&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;out_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;image_file에 이미지가 있는 path를 입력하고 predict함수를 이용하면 원하는 결과물을 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;위 함수들에 보충설명을 하자면, image, image_data라는 output을 반환하는 preprocess_image메서드는 원하는 size에 맞게 이미지를 조정해준다.&lt;/p&gt;

&lt;p&gt;image는 이미지 파일 자체를 말하며, image_file은 그 이미지의 RGB 데이터를 저장한다.&lt;br /&gt;
generate_colors를 통해 다양한 색깔을 미리 생성해두면,&lt;br /&gt;
draw_boxes는 찾고자하는 object 둘레에 bounding box를 그려준다.&lt;br /&gt;
quality 설정을 통해 저장하고자 하는 이미지의 화질을 조정할 수 있다.&lt;br /&gt;
image.save를 통해 자동으로 output 이미지를 저장할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;check-the-result&quot;&gt;Check the result&lt;/h3&gt;
&lt;p&gt;Input:&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018_07_21_YOLO/yolo12.jpg&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018_07_21_YOLO/yolo13.jpg&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

</content>
 </entry>
 
 <entry>
   <title>파이썬 정규표현식(re) 사용법 - 01. Basic</title>
   <link href="http://localhost:4000/regex-usage-01-basic/"/>
   <updated>2018-07-20T00:00:00+09:00</updated>
   <id>http://localhost:4000/regex-usage-01-basic</id>
   <content type="html">&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/20/regex-usage-01-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 01. Basic&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/21/regex-usage-02-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 02. 문자, 경계, flags&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/22/regex-usage-03-basic/&quot;&gt;파이썬 정규표현식(re) 사용법 - 03. OR, 반복&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/28/regex-usage-04-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 04. 그룹, 캡처&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/04/regex-usage-05-intermediate/&quot;&gt;파이썬 정규표현식(re) 사용법 - 05. 주석, 치환, 분리&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/05/regex-usage-06-advanced/&quot;&gt;파이썬 정규표현식(re) 사용법 - 06. 치환 함수, 양방탐색, 조건문&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-07-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 07. 예제(숫자)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/06/regex-usage-08-example/&quot;&gt;파이썬 정규표현식(re) 사용법 - 08. 예제(단어, 행)&lt;/a&gt;&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/08/24/regex-usage-09-other-functions/&quot;&gt;파이썬 정규표현식(re) 사용법 - 09. 기타 기능&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;이 글에서는 정규표현식 기초와 python library인 &lt;code class=&quot;highlighter-rouge&quot;&gt;re&lt;/code&gt; 패키지 사용법에 대해서 설명한다.&lt;/p&gt;

&lt;p&gt;본 글에서 정규표현식은 &lt;code class=&quot;highlighter-rouge&quot;&gt;regex&lt;/code&gt;와 같이, 일반 문자열은 ‘regex’와 같이 표시하도록 한다.&lt;/p&gt;

&lt;p&gt;파이썬 버전은 3.6을 기준으로 하나, 3.x 버전이면 (아마) 동일하게 쓸 수 있다.&lt;br /&gt;
2.7 버전은 한글을 포함한 비 알파벳 문자 처리가 다르다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;정규표현식의-기초&quot;&gt;정규표현식의 기초&lt;/h2&gt;

&lt;h3 id=&quot;일대일-매칭되는-문자&quot;&gt;일대일 매칭되는 문자&lt;/h3&gt;

&lt;p&gt;정규표현식 안에서, 바로 다음 절에서 설명하는 메타문자를 제외한 모든 문자 하나는 일반 문자열 하나와 매칭된다. 예를 들어, &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;는 a와 매칭되고, &lt;code class=&quot;highlighter-rouge&quot;&gt;가&lt;/code&gt;는 ‘가’와 매칭되는 식이다.&lt;br /&gt;
당연히 &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;가 ‘b’ 또는 ‘가’와 매칭되지는 않는다.&lt;/p&gt;

&lt;h3 id=&quot;메타문자&quot;&gt;메타문자&lt;/h3&gt;

&lt;p&gt;어떤 프로그래밍 언어의 정규표현식이든 메타문자라는 것이 존재한다.&lt;br /&gt;
이는 특수한 기능을 하는 문자로, &lt;code class=&quot;highlighter-rouge&quot;&gt;import&lt;/code&gt; 등 파이썬의 예약어와 비슷한 역할을 맡는 문자라고 생각하면 된다.&lt;/p&gt;

&lt;p&gt;파이썬 re 모듈의 메타문자는 총 12개로 다음과 같은 것들이 있다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt; $()*+.?[\^{| &lt;/code&gt;&lt;/p&gt;

&lt;p&gt;이들 메타문자는 각각의 문자 하나에 매칭되지 않는다.&lt;br /&gt;
예를 들어 일반 문자인 &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;는 문자 ‘a’에 매칭하지만, 여는 소괄호 &lt;code class=&quot;highlighter-rouge&quot;&gt;(&lt;/code&gt;는 문자 ‘(‘와 매칭하지 않는다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;그럼 찾고자 하는 문자열에 소괄호가 있으면 어떻게 하나?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;위의 문자들의 앞에 백슬래시 &lt;code class=&quot;highlighter-rouge&quot;&gt;\&lt;/code&gt;를 붙여 주면 일반 문자처럼 한 글자에 매칭된다. 
예를 들어 &lt;code class=&quot;highlighter-rouge&quot;&gt;\(&lt;/code&gt;는 문자 ‘(‘와 매칭된다.&lt;/p&gt;

&lt;p&gt;이들의 사용법은 차차 알아보도록 하자.&lt;/p&gt;

&lt;h3 id=&quot;semi-메타문자&quot;&gt;semi-메타문자&lt;/h3&gt;

&lt;p&gt;사실 이건 필자가 붙인 이름이지만… 이들 문자는 평소에는 메타문자가 아니지만, 특수한 상황에서는 메타문자 역할을 하는 문자들이다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;]&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;)&lt;/code&gt; 가 있다.&lt;/p&gt;

&lt;p&gt;닫는 괄호야 당연히 여는 괄호에 대응된다는 것은 알 수 있을 것이다. &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;는 이후에 설명한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;re-패키지-기본-method&quot;&gt;re 패키지 기본 method&lt;/h2&gt;

&lt;h3 id=&quot;import&quot;&gt;import&lt;/h3&gt;

&lt;p&gt;물론 &lt;code class=&quot;highlighter-rouge&quot;&gt;py&lt;/code&gt; 파일에서는 &lt;code class=&quot;highlighter-rouge&quot;&gt;import re&lt;/code&gt;를 해주어야 쓸 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;rematchpattern-string-flags&quot;&gt;re.match(pattern, string, flags)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/정규표현식(re)/2018-07-20-regex-usage-01-basic/01_match.PNG&quot; alt=&quot;01_match&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;re.match&lt;/strong&gt; 함수는 “문자열의 처음”부터 시작하여 패턴이 일치되는 것이 있는지를 확인한다.&lt;br /&gt;
다음과 같이 사용한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aba'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'bbb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;match&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'baa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 사실 match의 결과를 바로 print하지는 않는다. 결과를 활용하는 방법은 나중에 설명할 matchObj.group 함수를 쓰는 것이다.
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;_sre.SRE_Match object; span=(0, 1), match='a'&amp;gt;
&amp;lt;_sre.SRE_Match object; span=(0, 1), match='a'&amp;gt;
None
None
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;re.match&lt;/strong&gt; 함수는 문자열의 처음부터 시작하여 패턴이 일치되는 것이 있는지를 확인한다.&lt;br /&gt;
위의 예시에서 첫번째는 패턴과 문자열이 동일하므로 매치되는 것을 확인할 수 있다.&lt;br /&gt;
두번째 예시는 문자열이 ‘a’로 시작하기 때문에 매치가 된다.&lt;br /&gt;
나머지 두 개는 ‘a’로 시작하지 않아 패턴 &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;와 매치되지 않는다. 매치되지 않을 때 &lt;strong&gt;re.match&lt;/strong&gt; 함수는 None을 반환한다.&lt;/p&gt;

&lt;p&gt;매치가 되었을 때는 match Object를 반환한다. 위의 결과에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;_sre.SRE_Match object&lt;/code&gt;를 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;re.match&lt;/strong&gt; 함수는 인자로 1)pattern 2)string 3)flags를 받는다. 3번은 필수 인자는 아닌데, 어떤 옵션이 있는지는 뒤에서 설명한다.&lt;br /&gt;
각 인자는 각각 1)패턴 2)패턴을 찾을 문자열 3)옵션을 의미한다.&lt;/p&gt;

&lt;h3 id=&quot;researchpattern-string-flags&quot;&gt;re.search(pattern, string, flags)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/정규표현식(re)/2018-07-20-regex-usage-01-basic/02_search.PNG&quot; alt=&quot;02_search&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;re.search&lt;/strong&gt; 함수는 &lt;strong&gt;re.match&lt;/strong&gt;와 비슷하지만, 반드시 문자열의 처음부터 일치해야 하는 것은 아니다.&lt;/p&gt;

&lt;p&gt;다음 예시를 보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aba'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'bbb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'baa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;_sre.SRE_Match object; span=(0, 1), match='a'&amp;gt;
&amp;lt;_sre.SRE_Match object; span=(0, 1), match='a'&amp;gt;
None
&amp;lt;_sre.SRE_Match object; span=(1, 2), match='a'&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;네 번째 결과가 달라졌음을 볼 수 있다. &lt;strong&gt;re.search&lt;/strong&gt; 함수는 문자열의 처음뿐 아니라 중간부터라도 패턴과 일치되는 부분이 있는지를 찾는다.&lt;br /&gt;
따라서 네 번째 문자열 ‘baa’의 경우 1번째 index(두 번째 문자) ‘a’와 매치된다.&lt;/p&gt;

&lt;p&gt;위의 결과에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;span=(0, 1)&lt;/code&gt; 를 확인할 수 있다. 위의 두 결과는 &lt;code class=&quot;highlighter-rouge&quot;&gt;span=(0, 1)&lt;/code&gt;인데,&lt;br /&gt;
이는 0번째 문자부터 1번째 문자 전까지(즉, 0번째 문자 하나인 ‘a’)가 패턴과 매치되었음을 뜻한다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;span=(1, 2)&lt;/code&gt;의 경우 1번째 문자(‘baa’ 의 첫 번째 ‘a’이다)가 패턴과 매치되었음을 볼 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;refindallpattern-string-flags&quot;&gt;re.findall(pattern, string, flags)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/정규표현식(re)/2018-07-20-regex-usage-01-basic/03_findall.PNG&quot; alt=&quot;03_findall&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이름에서 알 수 있듯이 &lt;strong&gt;re.findall&lt;/strong&gt; 함수는 문자열 중 패턴과 일치되는 모든 부분을 찾는다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aba'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'bbb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'baa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;findall&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'aaa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aaaa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['a']
['a', 'a']
[]
['a', 'a']
['aaa']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;각 예시에서, 문자열의 a의 개수를 세어 보면 잘 맞는다는 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;함수 설명을 잘 보면, “non-overlapping” 이라고 되어 있다. 즉 반환된 리스트는 서로 겹치지 않는다는 뜻이다.  마지막 예시가 이를 말해주고 있다. 겹치는 것을 포함한다면 두 개가 반환되어야 했다.&lt;/p&gt;

&lt;h3 id=&quot;refinditerpattern-string-flags&quot;&gt;re.finditer(pattern, string, flags)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/정규표현식(re)/2018-07-20-regex-usage-01-basic/04_finditer.PNG&quot; alt=&quot;04_finditer&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;re.findall&lt;/strong&gt;과 비슷하지만, 일치된 문자열의 리스트 대신 matchObj 리스트를 반환한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;finditer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'baa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matchObj_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;callable_iterator object at 0x000002795899C550&amp;gt;
&amp;lt;_sre.SRE_Match object; span=(1, 2), match='a'&amp;gt;
&amp;lt;_sre.SRE_Match object; span=(2, 3), match='a'&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;iterator 객체 안에 matchObj가 여러 개 들어 있음을 확인할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;refullmatchpattern-string-flags&quot;&gt;re.fullmatch(pattern, string, flags)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/정규표현식(re)/2018-07-20-regex-usage-01-basic/05_fullmatch.PNG&quot; alt=&quot;05_fullmatch&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;re.fullmatch&lt;/strong&gt;는 패턴과 문자열이 남는 부분 없이 완벽하게 일치하는지를 검사한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fullmatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fullmatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aba'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fullmatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'bbb'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fullmatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'baa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fullmatch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'aaa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'aaaa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;_sre.SRE_Match object; span=(0, 1), match='a'&amp;gt;
None
None
None
None
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;맨 위의 예시만 문자열이 남는 부분 없이 정확하게 일치하므로 매칭 결과를 반환했다. 나머지 예시는 문자열이 뒤에 남기 때문에 매치되는 결과 없이 None을 반환했다.&lt;/p&gt;

&lt;h3 id=&quot;match-object의-메서드들&quot;&gt;match Object의 메서드들&lt;/h3&gt;

&lt;p&gt;match Object를 그대로 출력해서 쓰고 싶은 사람은 별로 없을 것이다. &lt;strong&gt;re.match&lt;/strong&gt; 등의 결과로 얻은 matchObj를 활용하는 방법을 정리하면 다음과 같다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Method&lt;/th&gt;
      &lt;th&gt;Descrption&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;group()&lt;/td&gt;
      &lt;td&gt;일치된 문자열을 반환한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;start()&lt;/td&gt;
      &lt;td&gt;일치된 문자열의 시작 위치를 반환한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;end()&lt;/td&gt;
      &lt;td&gt;일치된 문자열의 끝 위치를 반환한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;span()&lt;/td&gt;
      &lt;td&gt;일치된 문자열의 (시작 위치, 끝 위치) 튜플을 반환한다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'match'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;'matchObj' is a good name, but 'm' is convenient.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matchObj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;span&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;결과&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;_sre.SRE_Match object; span=(1, 6), match='match'&amp;gt;
match
1
6
(1, 6)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;잘 세어보면 ‘match’가 1번째 문자부터 6번째 문자 직전까지임을 알 수 있다. 인덱스는 0부터이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)/2018/07/21/regex-usage-02-basic/&quot;&gt;다음 글&lt;/a&gt;에서는 정규표현식의 기초를 더 살펴보도록 한다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>It will update soon...</title>
   <link href="http://localhost:4000/it-will-update-soon/"/>
   <updated>2018-07-13T00:00:00+09:00</updated>
   <id>http://localhost:4000/it-will-update-soon</id>
   <content type="html">&lt;p&gt;곧 업데이트됩니다…&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>BOJ 06086(최대 유량) 문제 풀이</title>
   <link href="http://localhost:4000/PS-06086/"/>
   <updated>2018-07-12T00:00:00+09:00</updated>
   <id>http://localhost:4000/PS-06086</id>
   <content type="html">&lt;h2 id=&quot;참조&quot;&gt;참조&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;분류&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/6086&quot;&gt;최대 유량&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://greeksharifa.github.io/algorithm%20&amp;amp;%20data%20structure/2018/07/07/algorithm-library/&quot;&gt;참조 라이브러리&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/dinic.h&quot;&gt;dinic.h&lt;/a&gt;, &lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/sharifa_header.h&quot;&gt;sharifa_header.h&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이 글에서 설명하는 코드&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/BOJ/06086_%EC%B5%9C%EB%8C%80%20%EC%9C%A0%EB%9F%89.cpp&quot;&gt;06086_최대 유량&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;

&lt;h3 id=&quot;시간복잡도--ov2-cdot-e-&quot;&gt;시간복잡도: $ O(V^2 \cdot E) $&lt;/h3&gt;
&lt;h3 id=&quot;공간복잡도--ov--e-&quot;&gt;공간복잡도: $ O(V + E) $&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;V는 정점의 수, E는 간선의 수이다. 복잡도는 &lt;a href=&quot;https://greeksharifa.github.io/algorithm%20&amp;amp;%20data%20structure/2018/07/11/algorithm-dinic/&quot;&gt;디닉 알고리즘&lt;/a&gt;과 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;문제-풀이&quot;&gt;문제 풀이&lt;/h2&gt;

&lt;p&gt;이 문제는 생긴 것부터가 네트워크 플로우 문제이다. Maximum Flow를 찾는 많은 알고리즘이 있지만,
&lt;a href=&quot;https://greeksharifa.github.io/algorithm%20&amp;amp;%20data%20structure/2018/07/11/algorithm-dinic/&quot;&gt;디닉 알고리즘&lt;/a&gt;이 가장 빠르기 때문에
필자는 이 알고리즘을 사용하도록 하겠다.&lt;/p&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;

&lt;p&gt;네트워크 플로우 문제는 모델링이 굉장히 중요한데, 이 문제는 모델링이 어렵지는 않다.&lt;/p&gt;

&lt;p&gt;주의할 점으로는 간선을 입력받아 그래프를 생성할 때, 각 파이프가 양방향 수송이 가능하다고 하였으므로 최대 유량을 똑같이 (0이 아닌) cap으로 설정해주어야 한다는 것이다.
또 문자를 정점 번호로 변환할 때 번호가 겹치지 않도록 주의한다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &quot;../library/dinic.h&quot;
&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#define MAX_V 52
#define S 0     // source
#define T 25    // sink
#define INF 1000000009
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Dinic&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;network&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MAX_V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main_06086&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ios&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sync_with_stdio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'A'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'Z'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'A'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'a'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;26&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'A'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'Z'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'A'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'a'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;26&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;network&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addEdge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;network&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;network&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_next_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;network&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 코드를 그대로 복붙하여 채점 사이트에 제출하면 당연히 틀린다. 저런 헤더 파일이 채점 사이트에 있을까?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>디닉 알고리즘(Dinic's Algorithm)</title>
   <link href="http://localhost:4000/algorithm-dinic/"/>
   <updated>2018-07-11T00:00:00+09:00</updated>
   <id>http://localhost:4000/algorithm-dinic</id>
   <content type="html">&lt;h2 id=&quot;참조&quot;&gt;참조&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;분류&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/6086&quot;&gt;최대 유량&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;응용 문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/11495&quot;&gt;스포일러 1&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://greeksharifa.github.io/algorithm%20&amp;amp;%20data%20structure/2018/07/07/algorithm-library/&quot;&gt;참조 라이브러리&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/sharifa_header.h&quot;&gt;sharifa_header.h&lt;/a&gt;, &lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/bit_library.h&quot;&gt;bit_library.h&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이 글에서 설명하는 라이브러리&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/dinic.h&quot;&gt;dinic.h&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;그림 출처: wikipedia&lt;/code&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;

&lt;h3 id=&quot;시간복잡도--ov2-cdot-e-&quot;&gt;시간복잡도: $ O(V^2 \cdot E) $&lt;/h3&gt;
&lt;h3 id=&quot;공간복잡도--ov2--또는--ove-&quot;&gt;공간복잡도: $ O(V^2) $ 또는 $ O(V+E) $&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;V는 정점(vectex)의 수, E는 간선(edge)의 수이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 글에서는 네트워크 플로우(Network Flow) 분야에서 Maximum Flow를 구하는 알고리즘인
&lt;a href=&quot;https://en.wikipedia.org/wiki/Dinic%27s_algorithm&quot;&gt;디닉 알고리즘&lt;/a&gt;에 대해서 설명한다.&lt;/p&gt;

&lt;p&gt;Maximum Flow를 구하는 다른 대표적인 알고리즘으로
&lt;a href=&quot;https://en.wikipedia.org/wiki/Edmonds%E2%80%93Karp_algorithm&quot;&gt;에드몬드-카프 알고리즘(Edmonds–Karp algorithm)&lt;/a&gt;,
&lt;a href=&quot;https://en.wikipedia.org/wiki/Ford%E2%80%93Fulkerson_algorithm&quot;&gt;포드-풀커슨 알고리즘(Ford–Fulkerson algorithm)&lt;/a&gt;이 있지만,
현재 PS에서 구현할 만한 알고리즘 중 가장 빠른 알고리즘은 디닉 알고리즘이다.
그래서 여러 개 외울 필요 없이 알고리즘 하나만 알아두는 것이 좋을 듯 하다.&lt;/p&gt;

&lt;h2 id=&quot;network-flow네트워크-플로우&quot;&gt;Network Flow(네트워크 플로우)&lt;/h2&gt;

&lt;p&gt;네트워크 플로우에 대한 기본적인 설명을 조금 적어 두려고 한다.
예를 하나 들면, Network Flow는 파이프가 복잡하게 연결되어 있고, 각 파이프는 물이 흐를 수 있는 최대 양이 정해져 있고,
source에서 sink방향으로 물이 흐를 때, 물이 흐를 수 있는 최대 양을 구하는 것이라고 보면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Algorithm_and_Data_Structure/2018-07-11-algorithm-dinic/01_network_flow.png&quot; alt=&quot;01_network_flow&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;s는 source를 의미한다. 물이 나오는 원천이라고 생각하면 된다.&lt;/li&gt;
  &lt;li&gt;t는 sink를 의미한다. 물이 최종적으로 들어가는 곳이라 생각하면 된다. 모든 물(유량)은 source에서 sink로 흐른다.&lt;/li&gt;
  &lt;li&gt;두 정점을 잇는 간선은 해당 정점 사이에 흐를 수 있는 최대 물(유량)을 의미한다. s에서 1번 정점으로 0/10이라고 적혀 있는데, 여기서 10이 최대 유량이다.&lt;/li&gt;
  &lt;li&gt;잔여유량은 최대유량에서 현재 유량을 뺀 값이다. s에서 1번 정점으로 0/10인 것은 현재 유량이 0이고 따라서 잔여유량은 10이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;네트워크 플로우의 Maximum Flow는 Minimum Cut과 깊은 연관이 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;알고리즘&quot;&gt;알고리즘&lt;/h2&gt;

&lt;p&gt;디닉 알고리즘은 크게 두 단계로 이루어진다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://greeksharifa.github.io/references/2018/07/13/it-will-update-soon/&quot;&gt;BFS&lt;/a&gt;를 써서 레벨 그래프(Level Graph)를 생성하는 것&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://greeksharifa.github.io/references/2018/07/13/it-will-update-soon/&quot;&gt;DFS&lt;/a&gt;를 써서, 레벨 그래프에 기초한 차단 유량(Blocking Flow)의 규칙을 지키면서, 최대 유량을 흘려주는 것&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;레벨-그래프level-graph&quot;&gt;레벨 그래프(Level Graph)&lt;/h3&gt;

&lt;p&gt;레벨 그래프는 각 정점들에 source로부터의 최단 거리를 레벨 값을 할당한 그래프이다.
아래 그림에서 source의 레벨은 0이되고 source와 인접한 1번과 2번 정점의 레벨은 1, 이후는 2… 등이 된다.
빨간색 숫자로 적혀 있는 것이 레벨이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Algorithm_and_Data_Structure/2018-07-11-algorithm-dinic/02_residual_capacity.png&quot; alt=&quot;02_residual_capacity&quot; /&gt;&lt;/p&gt;

&lt;p&gt;레벨 그래프는 BFS로 구현한다.&lt;/p&gt;

&lt;h3 id=&quot;차단-유량blocking-flow&quot;&gt;차단 유량(Blocking Flow)&lt;/h3&gt;

&lt;p&gt;디닉 알고리즘에서는, 유량을 흘려보낼 때 레벨 차이가 딱 1이 나는 정점으로만 유량을 보낼 수 있다.
즉 바로 위의 그림에서의 간선과 같은 곳으로만 보낼 수 있다. 레벨이 같아도 안 된다.&lt;/p&gt;

&lt;p&gt;유량을 흘려보내는 것은 DFS로 구현한다. source에서 시작하여, 차단 유량 규칙을 만족하는 정점으로만 따라가면서 최종적으로
sink에 도달할 때까지 탐색하는 과정을 반복한다.&lt;/p&gt;

&lt;p&gt;위의 레벨 그래프에서는 다음 세 경로를 DFS로 찾을 수 있다.&lt;/p&gt;

&lt;p&gt;(s, 1, 3, 4): 유량 4&lt;br /&gt;
(s, 1, 4, t): 유량 6&lt;br /&gt;
(s, 2, 4, t): 유량 4&lt;/p&gt;

&lt;h3 id=&quot;반복&quot;&gt;반복&lt;/h3&gt;

&lt;p&gt;BFS 1번 그리고 DFS를 한번씩 해서는 최대 유량이 찾아지지 않는다. 다만 복잡한 것은 아니고, 위의 과정을 반복해주면 된다.&lt;/p&gt;

&lt;p&gt;다시 BFS를 돌려 레벨 그래프를 새로 생성한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Algorithm_and_Data_Structure/2018-07-11-algorithm-dinic/03_residual_capacity.png&quot; alt=&quot;03_residual_capacity&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 레벨 그래프에서는 다음 경로를 DFS로 찾을 수 있다.&lt;/p&gt;

&lt;p&gt;(s, 2, 4, 3, t): 유량 5&lt;/p&gt;

&lt;p&gt;다시 레벨 그래프를 그리면, 더 이상 sink로 가는 경로가 없음(sink의 레벨이 $\inf$)을 알 수 있다. 알고리즘을 종료한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Algorithm_and_Data_Structure/2018-07-11-algorithm-dinic/04_residual_capacity.png&quot; alt=&quot;04_residual_capacity&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;

&lt;p&gt;BFS는 어려운 부분이 아니기 때문에 설명은 생략하도록 하겠다.&lt;/p&gt;

&lt;p&gt;DFS의 구현은 조금 까다롭다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;우선 sink(T)에 도달하면 종료한다.&lt;/li&gt;
  &lt;li&gt;종료할 때 &lt;code class=&quot;highlighter-rouge&quot;&gt;max_flow&lt;/code&gt;라는 것을 리턴한다. 이는 Network Flow에서 수송량은 경로에 포함된 파이프 최대 유량의 최솟값이기 때문이다. &lt;code class=&quot;highlighter-rouge&quot;&gt;flow&lt;/code&gt;의 계산식을 잘 보면 최대 유량과 min 연산을 취하는 것을 볼 수 있다.&lt;/li&gt;
  &lt;li&gt;레벨 차이가 1 나는지를 먼저 검사한다. 그리고 그 정점의 잔여 용량이 0보다 큰지 또한 검사한다.&lt;/li&gt;
  &lt;li&gt;만약 그런 정점을 찾았으면, 재귀적으로 DFS를 수행한다.&lt;/li&gt;
  &lt;li&gt;DFS가 리턴되어 반환한 flow 값이 0보다 크면, 아직 DFS로 탐색할 수 있는 경로가 남아 있다는 뜻이다.&lt;/li&gt;
  &lt;li&gt;경로를 찾았으므로, 해당 경로를 따라서(스택에 재귀 호출로 쌓인 함수에 의해 자동으로 역추적됨) 잔여 용량을 줄여준다.&lt;/li&gt;
  &lt;li&gt;만약 어떤 flow도 0이라면, 경로를 찾지 못한 것이므로 종료한다.&lt;/li&gt;
  &lt;li&gt;next_v라는 배열(벡터)이 있다. 이는 DFS에서 다음 경로를 효율적으로 찾기 위해 존재하는 배열이다.
    &lt;ol&gt;
      &lt;li&gt;DFS로 경로를 탐색할 떄 정점 번호가 낮은 정점부터 탐색한다.&lt;/li&gt;
      &lt;li&gt;만약 처음에 1번 정점으로 가는 경로를 모두 찾았다면, 더 이상 1번 정점으로는 갈 필요가 없다. 이때 next_v[u]를 1 증가시켜, 다음부터는 2번 정점부터 탐색을 시작하도록 한다.&lt;/li&gt;
      &lt;li&gt;2번도 끝났으면 또 next_v[u]를 증가시킨다. 이를 반복한다.&lt;/li&gt;
      &lt;li&gt;코드 상으로는 &lt;code class=&quot;highlighter-rouge&quot;&gt;int &amp;amp;i&lt;/code&gt;로 되어 있다. i가 레퍼런스로 선언되어 있기 때문에 for loop의 &lt;code class=&quot;highlighter-rouge&quot;&gt;i++&lt;/code&gt; 구문에 따라 같이 증가한다(i는 next_v[u]와 값을 공유한다)&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;

                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;addEdge 함수의 inv는 각 간선이 양방향 수송이 가능하면 &lt;code class=&quot;highlighter-rouge&quot;&gt;true&lt;/code&gt;로 지정하면 된다.
sparse graph일 경우를 대비해 edges를 2차원 배열로 표현하지 않고 대신 역방향 간선에 대한 참조를 저장하고 있다.
이러면 정점이 많을 경우에도 메모리 사용량을 줄일 수 있다.&lt;/p&gt;

&lt;p&gt;구현은 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#pragma once
&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#include &quot;sharifa_header.h&quot;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Edge&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;// u -&amp;gt; v&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Dinic&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Edge&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;// graph&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// level: 레벨 그래프, next_v: DFS에서 flow 계산 시 역추적에 사용&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;nl&quot;&gt;public:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Dinic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MAX_V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MAX_V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MAX_V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;next_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MAX_V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;addEdge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emplace_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emplace_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fill&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;queue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;front&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reset_next_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fill&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dfs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;

                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;문제-풀이&quot;&gt;문제 풀이&lt;/h2&gt;

&lt;h3 id=&quot;boj-06086최대-유량&quot;&gt;BOJ 06086(최대 유량)&lt;/h3&gt;

&lt;p&gt;문제: &lt;a href=&quot;https://www.acmicpc.net/problem/6086&quot;&gt;최대 유량&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;풀이: &lt;a href=&quot;https://greeksharifa.github.io/ps/2018/07/12/PS-06086/&quot;&gt;BOJ 06086(최대 유량) 문제 풀이&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;스포일러-문제&quot;&gt;스포일러 문제&lt;/h3&gt;

&lt;p&gt;문제: &lt;a href=&quot;https://www.acmicpc.net/problem/11495&quot;&gt;스포일러 문제&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;풀이: &lt;a href=&quot;&quot;&gt;스포일러 풀이&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>BOJ 11658(구간 합 구하기 3) 문제 풀이</title>
   <link href="http://localhost:4000/PS-11658/"/>
   <updated>2018-07-11T00:00:00+09:00</updated>
   <id>http://localhost:4000/PS-11658</id>
   <content type="html">&lt;h2 id=&quot;참조&quot;&gt;참조&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;분류&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/11658&quot;&gt;구간 합 구하기 3&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://greeksharifa.github.io/algorithm%20&amp;amp;%20data%20structure/2018/07/07/algorithm-library/&quot;&gt;참조 라이브러리&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/fenwick_tree_2D_BIT.h&quot;&gt;fenwick_tree_2D_BIT.h&lt;/a&gt;, &lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/sharifa_header.h&quot;&gt;sharifa_header.h&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이 글에서 설명하는 코드&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/BOJ/11658_%EA%B5%AC%EA%B0%84%20%ED%95%A9%20%EA%B5%AC%ED%95%98%EA%B8%B0%203.cpp&quot;&gt;11658_구간 합 구하기 3&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;

&lt;h3 id=&quot;시간복잡도--on2--m-log2-n-&quot;&gt;시간복잡도: $ O(N^2 + M \log^2 N) $&lt;/h3&gt;
&lt;h3 id=&quot;공간복잡도--on2-&quot;&gt;공간복잡도: $ O(N^2) $&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;N은 원소의 수, M은 연산의 수이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;문제-풀이&quot;&gt;문제 풀이&lt;/h2&gt;

&lt;p&gt;이 문제도 역시 &lt;a href=&quot;https://greeksharifa.github.io/references/2018/07/13/it-will-update-soon/&quot;&gt;인덱스 트리&lt;/a&gt;라고 부르는 자료구조를 써도 풀리긴 하지만, 펜윅 트리가 굉장히 간단하기 때문에 이것으로 문제를 풀었다.&lt;/p&gt;

&lt;p&gt;원소가 하나씩 업데이트될 때, 구간의 합을 구하라는 문제는 그냥 펜윅 트리를 쓰라는 문제이다. 
왜냐하면 BIT가 그에 최적화되어 있기 때문이다.&lt;/p&gt;

&lt;p&gt;이 문제는 &lt;a href=&quot;https://www.acmicpc.net/problem/2042&quot;&gt;구간 합 구하기&lt;/a&gt;와는 달리 2차원이기 때문에, data 배열도 2차원으로 잡아야 한다. 즉, data[][] 형식이 될 것이다.&lt;/p&gt;

&lt;p&gt;구간 합을 구하는 것은 1차원을 2차원으로 확장한 것에 불과하다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;1차원은 sum(a,b) = sum(b) - sum(a-1)이었다.&lt;/li&gt;
  &lt;li&gt;2차원은 sum(x1~x2, y1~y2) = sum(x2, y2) - sum(x1-1, y2)  -sum(x2, y1-1) + sum(x1-1, y1-1)이다.
    &lt;ul&gt;
      &lt;li&gt;손으로 그림을 딱 한번만 그려보면 위 식이 단번에 이해될 것이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;업데이트 연산 역시 2차원으로 확장한 것에 불과하다.&lt;/p&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;

&lt;p&gt;이 문제는 2차원이기 때문에 sum과 update에서 중첩 while문을 볼 수 있을 것이다.&lt;br /&gt;
그리고 &lt;a href=&quot;https://greeksharifa.github.io/ps/2018/07/10/PS-02042/&quot;&gt;BOJ 02042(구간 합 구하기) 문제 풀이&lt;/a&gt;와는 달리 arr 배열을 만들지 않고 풀이를 적었다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &quot;../library/sharifa_header.h&quot;
#include &quot;../library/fenwick_tree_2D_BIT.h&quot;
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main_11658&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;ios&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sync_with_stdio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;FenwickTree2D&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;BIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;BIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 코드를 그대로 복붙하여 채점 사이트에 제출하면 당연히 틀린다. 저런 헤더 파일이 채점 사이트에 있을까?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>BOJ 01280(나무 심기) 문제 풀이</title>
   <link href="http://localhost:4000/PS-01280/"/>
   <updated>2018-07-11T00:00:00+09:00</updated>
   <id>http://localhost:4000/PS-01280</id>
   <content type="html">&lt;h2 id=&quot;참조&quot;&gt;참조&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;분류&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/1280&quot;&gt;나무 심기&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이 글에서 설명하는 코드&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/BOJ/01280_%EB%82%98%EB%AC%B4%20%EC%8B%AC%EA%B8%B0.cpp&quot;&gt;01280_나무 심기&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;

&lt;h3 id=&quot;시간복잡도--on-log-m-&quot;&gt;시간복잡도: $ O(N \log M) $&lt;/h3&gt;
&lt;h3 id=&quot;공간복잡도--om-&quot;&gt;공간복잡도: $ O(M) $&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;N은 원소의 수, M은 좌표의 범위이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;순서대로 하나씩 주어지고, $i$번째에 대한 비용이나 시간이 1부터 $(i-1)$번째까지에만 의존하는 형식이라면 
&lt;a href=&quot;https://greeksharifa.github.io/algorithm%20&amp;amp;%20data%20structure/2018/07/09/algorithm-fenwick-tree/&quot;&gt;BIT&lt;/a&gt;, 
&lt;a href=&quot;https://greeksharifa.github.io/references/2018/07/13/it-will-update-soon/&quot;&gt;IT&lt;/a&gt;, 
&lt;a href=&quot;https://greeksharifa.github.io/references/2018/07/13/it-will-update-soon/&quot;&gt;삽입 정렬&lt;/a&gt;, 
&lt;a href=&quot;https://greeksharifa.github.io/references/2018/07/13/it-will-update-soon/&quot;&gt;우선순위 큐&lt;/a&gt;를
 한번쯤 떠올려 보는 것이 중요하다.&lt;/p&gt;

&lt;h2 id=&quot;문제-풀이&quot;&gt;문제 풀이&lt;/h2&gt;

&lt;p&gt;우선 문제의 정의에 따라, &lt;strong&gt;문제의 정답&lt;/strong&gt;(=2번 나무부터 N번 나무까지 심는 비용의 곱)을 수식으로 정리하면 다음과 같다.&lt;/p&gt;

&lt;p&gt;$ A := $ &lt;strong&gt;문제의 정답&lt;/strong&gt;&lt;br /&gt;
$ p_i := i$번 나무가 심어진 위치&lt;br /&gt;
$ c_i := i$번 나무를 심는 비용&lt;/p&gt;

&lt;p&gt;$ c_i = \displaystyle\sum_{j=1}^{i-1}{\vert(p_i - p_j)\vert} $&lt;/p&gt;

&lt;p&gt;$ A = \displaystyle\prod_{i=2}^n{c_i} $&lt;/p&gt;

&lt;p&gt;이제 약간의 수식 변형을 시키자.&lt;/p&gt;

&lt;p&gt;$ c_i&lt;br /&gt;
= \displaystyle\sum_{j=1}^{i-1}{|(p_i - p_j)|} $&lt;/p&gt;

&lt;p&gt;$ = \displaystyle\sum_{j: p_j \le p_i, \ 1 \le j \le i-1}{(p_i - p_j)} +&lt;br /&gt;
\displaystyle\sum_{j: p_j \gt p_i, \ 1 \le j \le i-1}{(p_j - p_i)} $&lt;/p&gt;

&lt;p&gt;여기서 $ n_i := p_j &amp;lt; p_i $인 $j$의 개수라고 하자. 그러면,&lt;/p&gt;

&lt;p&gt;$ c_i
= ( n_i \cdot p_i - \displaystyle\sum_{j: p_j \le p_i, \ 1 \le j \le i-1}{p_j} ) +
( \displaystyle\sum_{j: p_j \gt p_i, \ 1 \le j \le i-1}{p_j} - (i-1-n_i) \cdot p_i )$&lt;/p&gt;

&lt;p&gt;$ = (2n_i+1-i)\cdot p_i +
\displaystyle\sum_{j: p_j \gt p_i, \ 1 \le j \le i-1}{p_j} -
\displaystyle\sum_{j: p_j \le p_i, \ 1 \le j \le i-1}{p_j} $&lt;/p&gt;

&lt;p&gt;그러면 이제 문제는&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;$i$번째 나무보다 왼쪽에 심어져 있던 나무의 수와&lt;/li&gt;
  &lt;li&gt;$i$번째 나무보다 왼쪽에 심어져 있던 나무들의 좌표(위치)의 합&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;을 알아야 하는 문제로 바뀐다($p_i$와 같은 나무는 어느 쪽에 넣어도 상관없다).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$i$번째 나무와 위치가 같은 경우는 어차피 0이 되니 처리를 해주든 말든 상관이 없다.&lt;/li&gt;
  &lt;li&gt;그리고 오른쪽에 있는 나무들은 전체 나무에서 왼쪽 부분을 빼면 얻을 수 있다(사실 그냥 오른쪽을 구해버려도 된다).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제 펜윅 트리를 쓸 차례다.
펜윅 트리를 두 개 만든다. 하나는 위치에 따른 나무 수의 합을 세는 것이고, 하나는 위치에 따른 나무 좌표의 합을 세는 것이다. 맨 아래의 구현에서 각각 count[]와 summ[]으로 구현되어 있다.&lt;/p&gt;

&lt;p&gt;그리고 $i$번째 나무의 위치로 $p_i$가 들어오면, 왼쪽에 있는 나무의 수는 sum($p_i$, count=true)으로, 왼쪽에 있는 나무의 좌표의 합은 sum($p_i$, count=false)로 바로 구할 수 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;구현한 코드를 보면 이해할 수 있다. update의 코드 중복을 방지하기 위해 bool 형인 count 파라미터를 받는다.&lt;/li&gt;
  &lt;li&gt;구간 합(개수 혹은 좌표의 합)을 구하는 연산은 일반 펜윅 트리와 똑같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그리고 업데이트를 할 때는 위치는 $p_i$로 하고 count[]는 +1, summ[]에는 $p_i$만큼 더해 준다(두 배열의 정의에 의해).&lt;/p&gt;

&lt;p&gt;오른쪽 나무에 대해 구할 때는 전체에서 왼쪽 나무들의 값을 빼면 어렵지 않게 구할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;

&lt;p&gt;이번에는 펜윅 트리의 형태가 조금 다르기 때문에 따로 필자의 라이브러리를 사용하지 않았다.&lt;/p&gt;

&lt;p&gt;주의 사항이 조금 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;좌표가 0부터 시작하는데, 펜윅 트리는 인덱스 0을 쓰지 않는다. 따라서 $p_i$를 1씩 증가시켜서 구현해야 한다. MAX_X가 200000 + 1인 이유가 이것이다.&lt;/li&gt;
  &lt;li&gt;펜윅 트리의 크기는 원소의 수가 아닌 좌표의 범위이다.&lt;/li&gt;
  &lt;li&gt;MOD 연산은 그때그때 해주어야 한다. 그렇다고 남용해서 마이너스를 할 때 음수가 되어버리면 연산이 제대로 된다는 보장이 없다.&lt;/li&gt;
  &lt;li&gt;count[]는 int[]로 선언해도 되지만, int와 long long 사이에서 실수가 많다면 그냥 편하게 모든 것을 long long으로 해도 된다. 메모리가 아주 타이트한 것이 아니라면.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;cp&quot;&gt;#define ll long long
#define MOD 1000000007
#define MAX_X 200001
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FenwickTree&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;nl&quot;&gt;public:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;FenwickTree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MAX_X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;summ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MAX_X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MAX_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;summ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;summ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;FenwickTree&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main_01280&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;//freopen(&quot;input.txt&quot;, &quot;r&quot;, stdin);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ios&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sync_with_stdio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;    &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;BIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_i_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;smaller&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;smaller&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_i_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;smaller&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MOD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;p_i_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MOD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;BIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 코드를 그대로 복붙하여 채점 사이트에 제출하면 당연히 틀린다. 저런 헤더 파일이 채점 사이트에 있던가?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>TensorFlow 사용법 - 01. 소개 및 설치</title>
   <link href="http://localhost:4000/tensorflow-usage-01-Introduction/"/>
   <updated>2018-07-10T00:00:00+09:00</updated>
   <id>http://localhost:4000/tensorflow-usage-01-Introduction</id>
   <content type="html">&lt;h2 id=&quot;텐서플로tensorflow란&quot;&gt;텐서플로(TensorFlow)란?&lt;/h2&gt;

&lt;p&gt;텐서플로(TensorFlow)는 원애 머신러닝(ML)과 심층 신경망(Deep Neural Network) 연구를 수행하는 구글 브레인 팀에서 개발되었다.&lt;br /&gt;
텐서플로는 Tensor(텐서, 텐서플로의 기본 자료구조. 우선 다차원 배열이라고 생각하면 편하다)를 Data Flow Graph에 따라 수치 연산을 하는 라이브러리이기 때문에 그런 이름이 붙었다.&lt;/p&gt;

&lt;h3 id=&quot;연동-라이브러리&quot;&gt;연동 라이브러리&lt;/h3&gt;

&lt;h4 id=&quot;텐서보드&quot;&gt;&lt;a href=&quot;https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard&quot;&gt;텐서보드&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;모델(알고리즘)이 어떻게 돌아가고 있는이 모니터링/디스플레이해주는 모듈이다.&lt;br /&gt;
알고리즘이 잘 돌아가는지 아닌지를 볼 수 있기에 중요한 모듈이다.&lt;/p&gt;

&lt;p&gt;실행하는 것은 명령창에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;tensorboard --logdir=&amp;lt;추적 파일 directory&amp;gt;&lt;/code&gt;를 입력하면 된다.&lt;br /&gt;
그리고 크롬 브라우저에서 &lt;a href=&quot;http://localhost:6006&quot;&gt;http://localhost:6006&lt;/a&gt;으로 접속하면 로그를 확인할 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;텐서플로-서빙&quot;&gt;&lt;a href=&quot;https://www.tensorflow.org/serving/&quot;&gt;텐서플로 서빙&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;텐서플로의 머신러닝 모델을 운영환경으로 배포하는 것을 도와준다.&lt;/p&gt;

&lt;p&gt;일반적으로 작업 파이프라인은 다음과 같다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;데이터를 입수한다.&lt;/li&gt;
  &lt;li&gt;1의 데이터를 바탕으로 학습을 시킨다. 이 결과 모델이 생성된다.&lt;/li&gt;
  &lt;li&gt;(텐서플로 서빙 등을 통해) 모델을 운영환경으로 배포한다.&lt;/li&gt;
  &lt;li&gt;배포된 모델을 gRPC(구글이 공개한 RPC 프레임워크)를 통해 클라이언트가 무언가 정보를 얻는다.&lt;/li&gt;
  &lt;li&gt;클라이언트의 피드백 등으로 데이터가 더 쌓이면, 1~2를 무한 반복한다.&lt;/li&gt;
  &lt;li&gt;모델의 성능이 향상되면 재배포한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;설치&quot;&gt;설치&lt;/h2&gt;

&lt;p&gt;파이썬(3.6 또는 2.7)과 pip은 설치되어 있다고 가정한다. conda를 쓰고 싶다면 써도 된다.&lt;br /&gt;
본인이 프로젝트를 여러 개 할 것이라면 가상환경을 만드는 것을 추천한다(virtualenv 또는 conda)&lt;/p&gt;

&lt;h3 id=&quot;cpu-버전-설치&quot;&gt;CPU 버전 설치&lt;/h3&gt;

&lt;p&gt;우선 본인이 gpu가 없거나 사용할 계획이 없다면, cpu 버전 설치는 매우 간단하다.&lt;/p&gt;

&lt;p&gt;윈도우라면 명령창(cmd)를 관리자 권한으로 실행한다. Mac/Linux라면 (sudo권한으로) 터미널을 실행한다.&lt;br /&gt;
다음 명령들을 차례대로 실행한다. ::뒤의 문구는 주석이므로 입력할 필요 없다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;virtualenv tensorflow_cpu :: tensorflow_cpu란 이름의 가상환경을 만든다.
cd tensorflow_cpu/Scripts
activate
(tensorflow_cpu) pip install tensorflow :: 가상환경 (tensorflow_cpu) 안에서 tensorflow를 설치&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;가상환경에서 나오고 싶다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;deactivate&lt;/code&gt;를 입력하면 된다.&lt;/p&gt;

&lt;p&gt;별다른 문제가 없다면 설치가 완료된다. 만약 에러 메시지가 보인다면 구글링을 하면 웬만해선 해결이 된다.&lt;/p&gt;

&lt;h3 id=&quot;gpu-버전-설치&quot;&gt;GPU 버전 설치&lt;/h3&gt;

&lt;p&gt;우선 본인의 GPU(그래픽카드)가 텐서플로 사양을 맞추는지 확인해 보자.&lt;br /&gt;
일반적으로 Compute Compatability가 3.0 혹은 3.5 이상이면 다 돌아간다고 보면 된다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://developer.nvidia.com/cuda-gpus&quot;&gt;https://developer.nvidia.com/cuda-gpus&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;그리고 그래픽 드라이버가 일정 버전 이상인지 확인하도록 한다. 390 이상이면 문제 없을 것이다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.nvidia.co.kr/Download/index.aspx?lang=kr&quot;&gt;http://www.nvidia.co.kr/Download/index.aspx?lang=kr&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;첫-예제-코드&quot;&gt;첫 예제 코드&lt;/h2&gt;

&lt;p&gt;본인이 원하는 곳에 test.py 파일을 하나 만든다. 그리고 그 안에 다음과 같이 입력해 본다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;tensorflow&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그리고 실행해 본다. 명령창이라면 &lt;code class=&quot;highlighter-rouge&quot;&gt;python test.py&lt;/code&gt;를 입력하면 된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;C:\tensorflow_cpu\Scripts\python.exe C:/tensorflow_cpu/test.py
2018-07-10 18:05:50.108245: IT:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] 
Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
9.0&lt;/p&gt;

  &lt;p&gt;Process finished with exit code 0&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;위와 같이 나오면 정상이다.&lt;br /&gt;
CPU 버전을 설치했다면 중간에 &lt;code class=&quot;highlighter-rouge&quot;&gt;Your CPU ... AVX2&lt;/code&gt; 라는 문구가 경고처럼 뜨는데, CPU 버전이라면 뜨는 문제이므로 별 신경쓰지 않아도 된다.&lt;br /&gt;
저 메시지를 끌 수는 있지만, 다른 경고 메시지까지 없어져 버리므로 추천하지 않는다.&lt;/p&gt;

&lt;p&gt;이제 위 코드의 의미를 살펴보면,&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;import는 무엇인지 알 것이다.&lt;/li&gt;
  &lt;li&gt;a와 b를 float형 placeholder로 정의했다. 이것은 a와 b가 각각 float타입의 데이터를 담을 그릇이라는 뜻이다. 하지만 아직 어떤 값이 담길지는 정해지지 않은 상태이다.&lt;/li&gt;
  &lt;li&gt;y는 짐작하다시피 a와 b의 값을 곱한 값으로 정의된다. 하지만 마찬가지로 무슨 값이 곱해져서 들어갈지 정해지지 않았다. 단지 곱셈을 수행할 것이란 사실만을 정의했다.&lt;/li&gt;
  &lt;li&gt;텐서플로는 코드를 실행할 때 세션(Session)이라는 곳에서 수행해야 한다. 세션의 종류는 여러 개가 있지만, 나중에 설명하도록 하겠다. 지금은 텐서플로의 ‘실행 코드’는 무조건 세션 안에서 해야 한다는 사실만 기억하자.&lt;/li&gt;
  &lt;li&gt;이제 세션 안에서 ‘y’를 실행을 시킨다(sess.run). 그리고 feed_dict라는 옵션이 있다.
    &lt;ol&gt;
      &lt;li&gt;sess라는 세션 안에서 y를 실행한다는 의미이다. 조금 전 y는 a와 b의 곱셈으로 정의된다고 하였다.&lt;/li&gt;
      &lt;li&gt;그런데 y를 계산하려면 a와 b를 알아야 한다고 했는데, 조금 전 a, b를 선언할 때 무슨 값이 들어갈지 정하지 않았다.&lt;/li&gt;
      &lt;li&gt;이것 때문에 feed_dict가 있는 것이다. feed_dict는 파이썬의 딕셔너리 형식인데, 잘 보면 a와 b에 각각 특정 값을 집어넣고 있음을 알 수 있다.&lt;/li&gt;
      &lt;li&gt;즉 a와 b에는 선언 시점(placeholder로 쓴 부분)이 아닌 실행 시점(sess.run)에 값이 들어가는 것이다.&lt;/li&gt;
      &lt;li&gt;그리고 feed_dict로 전달받는 a와 b의 값을 이용하여, 곱셈으로 정의된 y를 계산한다.
        &lt;ol&gt;
          &lt;li&gt;물론 이 때 y의 계산에 필요한 a, b가 모두 feed_dict 옵션에 들어가 있어야 한다. 넣지 않으면 에러를 뱉을 것이다.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;계산된 y값을 print()로 출력한다. 9.0이 출력되었다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;세션을 만들고 실행하는 것이 좀 비직관적이지만, 이것이 텐서플로의 구조이다. 이는 나름대로의 장점이 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;우선 계산 그래프를 만든다(전체 알고리즘을 기술한다).&lt;/li&gt;
  &lt;li&gt;그 다음 세션을 생성하고 연산을 실행하는 형태이다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;즉 텐서플로는 ‘선언(definition)’과 ‘실행(run)’이 따로 이루어진다. 사실 대부분의 다른 머신러닝 라이브러리는 선언과 대입, 실행이 동시에 이루어지긴 한다.&lt;/p&gt;

&lt;p&gt;위의 코드에서는 곱셈만 썼지만, 기본 연산으로 다음과 같은 것들이 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'add:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'subtract:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subtract&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'multiply:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'divide:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;divide&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'mod:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'abs:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'negative:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;negative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sign:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sign&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'square:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;square&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'round:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sqrt:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'pow:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'exp:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'log:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'log1p:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log1p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'maximum:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'minimum:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minimum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'cos:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sinh:'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sess&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sinh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;feed_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# hyperbolic 함수
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이외에도 함수는 많지만 간단한 함수들 위주로 적어 보았다.&lt;/p&gt;

&lt;p&gt;IPython 같은 대화형 환경을 사용하는 경우 코드의 일부분만 수행하면서 그래프 구조를 만들고 싶을 때가 있다. 이때는 tf.interactiveSession() 세션을 사용하지만, 이것도 나중에 설명하도록 하겠다.&lt;/p&gt;

&lt;p&gt;알아두어야 할 점은, 연산과 데이터에 대한 모든 정보는 그래프 구조(수학 계산을 표현함) 안에 저장된다는 것이다.&lt;br /&gt;
그래프의 노드는 수학 연산(앞에서 설명한 multiply 등)을, 엣지는 노드 사이의 관계를 표현하며 동시에 텐서플로의 기본 자료구조인 텐서를 전달한다.&lt;/p&gt;

&lt;p&gt;텐서플로는 그래프 구조로 표현된 정보를 이용해서 트랜잭션 간 의존성을 인식하고 노드에 입력 데이터로 들어올 텐서가 준비되면 cpu/gpu에 비동기적/병렬적으로 연산을 할당한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Andre_Derain_Fishing_Boats_Collioure.jpg&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Andre_Derain_Fishing_Boats_Collioure.jpg&quot; alt=&quot;01_new_repository&quot; /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>BOJ 02042(구간 합 구하기) 문제 풀이</title>
   <link href="http://localhost:4000/PS-02042/"/>
   <updated>2018-07-10T00:00:00+09:00</updated>
   <id>http://localhost:4000/PS-02042</id>
   <content type="html">&lt;h2 id=&quot;참조&quot;&gt;참조&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;분류&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/2042&quot;&gt;구간 합 구하기&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://greeksharifa.github.io/algorithm%20&amp;amp;%20data%20structure/2018/07/07/algorithm-library/&quot;&gt;참조 라이브러리&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/fenwick_tree_BIT.h&quot;&gt;fenwick_tree_BIT&lt;/a&gt;, &lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/sharifa_header.h&quot;&gt;sharifa_header.h&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이 글에서 설명하는 코드&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/BOJ/02042_%EA%B5%AC%EA%B0%84%20%ED%95%A9%20%EA%B5%AC%ED%95%98%EA%B8%B0.cpp&quot;&gt;02042_구간 합 구하기&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;

&lt;h3 id=&quot;시간복잡도--on--kmlog-n-&quot;&gt;시간복잡도: $ O(N + (k+m)log N) $&lt;/h3&gt;
&lt;h3 id=&quot;공간복잡도--on-&quot;&gt;공간복잡도: $ O(N) $&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;N, m, k는 문제에서 주어진 그대로이다. N은 원소의 수이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;문제-풀이&quot;&gt;문제 풀이&lt;/h2&gt;

&lt;p&gt;이 문제는 흔히 &lt;a href=&quot;https://greeksharifa.github.io/references/2018/07/13/it-will-update-soon/&quot;&gt;인덱스 트리&lt;/a&gt;라고 부르는 자료구조를 써도 풀리지만, 펜윅 트리가 굉장히 간단하기 때문에 이것으로 문제를 풀었다.&lt;/p&gt;

&lt;p&gt;원소가 하나씩 업데이트될 때, 구간의 합을 구하라는 문제는 그냥 펜윅 트리를 쓰라는 문제이다. 
왜냐하면 BIT가 그에 최적화되어 있기 때문이다.&lt;/p&gt;

&lt;p&gt;본인이 인덱스 트리를 좋아한다면 그것으로 풀어도 상관없지만, 코딩하기 조오금 더 귀찮지 않은가?&lt;/p&gt;

&lt;p&gt;별다른 풀이는 없다. 그냥 펜윅 트리를 쓴다. 그게 끝이다.&lt;/p&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;참고로 m과 k의 구분은 전혀 필요가 없다. 그냥 합쳐서 생각하면 된다.&lt;/li&gt;
  &lt;li&gt;펜윅 트리 클래스의 &lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/fenwick_tree_BIT.h&quot;&gt;구현&lt;/a&gt;을 보면 data[]에는 long long을 쓴다. 합이 int의 범위를 넘어가기 때문이다. 제출했는데 초반은 맞다가 갑자기 틀린다면, 오버플로우를 한번쯤 의심해 봐야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &quot;../library/sharifa_header.h&quot;
#include &quot;../library/Fenwick_tree_BIT.h&quot;
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main_02042&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;//freopen(&quot;input.txt&quot;, &quot;r&quot;, stdin);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ios&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sync_with_stdio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;FenwickTree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;BIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;BIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BIT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 코드를 그대로 복붙하여 채점 사이트에 제출하면 당연히 틀린다. 저런 헤더 파일이 채점 사이트에 있을까?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>펜윅 트리(Fenwick Tree, Binary Indexed Tree, BIT)</title>
   <link href="http://localhost:4000/algorithm-fenwick-tree/"/>
   <updated>2018-07-09T00:00:00+09:00</updated>
   <id>http://localhost:4000/algorithm-fenwick-tree</id>
   <content type="html">&lt;h2 id=&quot;참조&quot;&gt;참조&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;분류&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/2042&quot;&gt;구간 합 구하기&lt;/a&gt;, &lt;a href=&quot;https://www.acmicpc.net/problem/11658&quot;&gt;구간 합 구하기 3&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;응용 문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/1280&quot;&gt;나무 심기&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이 글에서 설명하는 라이브러리&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/fenwick_tree_BIT.h&quot;&gt;fenwick_tree_BIT.h&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;

&lt;h3 id=&quot;시간복잡도--om-log-n-&quot;&gt;시간복잡도: $ O(M log N) $&lt;/h3&gt;
&lt;h4 id=&quot;구간-합-구하기--olog-n-&quot;&gt;구간 합 구하기: $ O(log N) $&lt;/h4&gt;
&lt;h4 id=&quot;값-업데이트하기--olog-n-&quot;&gt;값 업데이트하기: $ O(log N) $&lt;/h4&gt;

&lt;h3 id=&quot;공간복잡도--on-&quot;&gt;공간복잡도: $ O(N) $&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;N은 원소의 수, M은 연산의 수이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 글에서는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Fenwick_tree&quot;&gt;펜윅 트리(Fenwick Tree)&lt;/a&gt;
라고 하는 자료구조와, 이를 활용한 문제들을 살펴볼 것이다.&lt;/p&gt;

&lt;p&gt;펜윅 트리라니? 라고 생각할지도 모르겠지만, 이는 여러분이 아마 들어본 적이 있을 Binary Indexed Tree(BIT)와 같은 것이다.&lt;/p&gt;

&lt;p&gt;참고로 펜윅 트리로 풀리는 문제는 전부 &lt;a href=&quot;https://greeksharifa.github.io/references/2018/07/13/it-will-update-soon/&quot;&gt;인덱스 트리&lt;/a&gt;로도 풀린다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;펜윅-트리fenwick-tree-binary-indexed-tree-bit&quot;&gt;펜윅 트리(Fenwick Tree, Binary Indexed Tree, BIT)&lt;/h2&gt;

&lt;p&gt;흔히 BIT라고 불리는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Fenwick_tree&quot;&gt;펜윅 트리(Fenwick Tree)&lt;/a&gt;는
‘수시로 바뀌는 수열의 구간 합’을 빠르게 구할 수 있도록 고안된 자료 구조이다.&lt;/p&gt;

&lt;h3 id=&quot;다음-상황을-살펴보자&quot;&gt;다음 상황을 살펴보자.&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;길이 10만짜리 수열이 있다.&lt;/li&gt;
  &lt;li&gt;12345~77777번 수들의 합을 구하라는 요청이 들어왔다. 65433개를 일일이 세어 합을 구해준다.&lt;/li&gt;
  &lt;li&gt;똑같은 요청이 여러 번 들어오자. 여러분은 &lt;a href=&quot;https://greeksharifa.github.io/references/2018/07/13/it-will-update-soon/&quot;&gt;부분 합&lt;/a&gt;이라는 스킬을 써서 꼬박꼬박 답을 해 주었다.&lt;/li&gt;
  &lt;li&gt;이번엔 20000번째 수와 55555번째 수를 업데이트하라고 했다.&lt;/li&gt;
  &lt;li&gt;부분 합을 8만 개를 업데이트해야 하는 여러분은 화가 나기 시작했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;…물론 이런 상황이 실제로 일어나지는 않겠지만, PS의 세계에서는 자주 있는 일이다.
누군가 무슨 숫자를 구해야 하고 그걸 여러분에게 자주 시키지 않는가?&lt;/p&gt;

&lt;p&gt;이런 상황에서 펜윅 트리를 쓸 수 있다. 즉 수시로 바뀌는 수열의 구간 합을 $O(log N)$만에 구할 수 있다.&lt;/p&gt;

&lt;p&gt;펜윅 트리는 다음과 같은 장점을 갖고 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;방금 말했듯이 업데이트가 하나씩 되는 수열의 구간 합을 $O(log N)$만에 구할 수 있다.&lt;/li&gt;
  &lt;li&gt;비트 연산을 이해하고 있다면 구현이 굉장히 쉬운 편이다.&lt;/li&gt;
  &lt;li&gt;속도도 빠르다(Big-O 표기법에서 생략된 상수가 작음).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;그럼 펜윅 트리의 구조를 살펴보자.&lt;/p&gt;

&lt;h2 id=&quot;펜윅-트리bit의-구조&quot;&gt;펜윅 트리(BIT)의 구조&lt;/h2&gt;

&lt;p&gt;앞의 예를 조금 축소시켜서, 길이 10짜리 수열을 하나 생각하자. arr[]이라고 부르도록 하겠다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Algorithm_and_Data_Structure/2018-07-09-algorithm-fenwick-tree/01_부분합1.jpg&quot; alt=&quot;01_부분합1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;펜윅 트리는 개념상 트리이지만, 구현할 때는 길이 N짜리 배열로 구현한다.&lt;br /&gt;
정확히는 앞에 하나를 비워 두기 때문에 배열 자체의 크기는 $N+1$이고, 사용하는 인덱스는 1이상 N 이하이다.&lt;/p&gt;

&lt;p&gt;그림에는 N=16일 때의 펜윅 트리가 그려져 있다. 배열의 경계 정하는 것이 헷갈리는 사람이라면 그림처럼 마음 편히 $2^n$ 꼴로 잡으면 된다.&lt;br /&gt;
하지만 펜윅 트리는 굳이 $2^n$ 꼴이 아니더라도 잘 작동한다. 이유는 이 글을 다 읽고 손으로 써 보면 알 수 있을 것이다.&lt;/p&gt;

&lt;p&gt;앞으로 이 배열을 data[]라고 부르도록 하겠다. 필자의 코드에서 FenwickTree 클래스의 vector&amp;lt;int&amp;gt; data로 구현되어 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Algorithm_and_Data_Structure/2018-07-09-algorithm-fenwick-tree/02_FenwickTree1.jpg&quot; alt=&quot;02_FenwickTree1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 배열로 구현된 펜윅 트리의, data의 각 원소가 갖는 값을 살펴보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Algorithm_and_Data_Structure/2018-07-09-algorithm-fenwick-tree/03_FenwickTree2.jpg&quot; alt=&quot;03_FenwickTree2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위 그림에 모든 것이 설명되어 있긴 하지만, 자세히 살펴보자. i는 0 이상인 정수이다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;인덱스가 홀수인 원소는 수열의 해당 인덱스의 값을 그대로 가진다.
    &lt;ol&gt;
      &lt;li&gt;$data[2i+1] = arr[2i+1]$&lt;/li&gt;
      &lt;li&gt;data[1] = arr[1], data[3] = arr[3], …&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;인덱스가 2의 배수이면서 4의 배수가 아닌 원소(2, 6, 10, 14, …)는 직전 두 arr 원소의 합을 보존한다.
    &lt;ol&gt;
      &lt;li&gt;$data[4i+2] = arr[4i+1] + arr[4i+2]$&lt;/li&gt;
      &lt;li&gt;data[2] = arr[1] + arr[2], data[6] = arr[5] + arr[6], …&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;인덱스가 $2^k$의 배수이면서 $2^{k+1}$의 배수가 아닌 원소는 직전 arr의 $2^k$개의 값의 합을 보존한다.
    &lt;ol&gt;
      &lt;li&gt;$data[2^{k+1} \cdot i + 2^k] = \Sigma_{j=1}^{2^k}{arr[2^{k+1} \cdot i + j]}$&lt;/li&gt;
      &lt;li&gt;data[12] = arr[9] + arr[10] + arr[11] + arr[12], …&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;수식이 조금 복잡할 수는 있지만 그림을 보면 바로 이해될 것이다.&lt;/p&gt;

&lt;h3 id=&quot;구간-합olog-n&quot;&gt;구간 합($O(log N)$)&lt;/h3&gt;

&lt;p&gt;이제 이 data[]로 구간 합을 어떻게 빠르게 구하는지 알아보자. 예를 들어서 arr[1…7]의 합을 구한다고 하자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Algorithm_and_Data_Structure/2018-07-09-algorithm-fenwick-tree/04_FenwickTree3.jpg&quot; alt=&quot;04_FenwickTree3&quot; /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\Sigma_{j=1}^7{arr[j]} = \Sigma_{j=1}^4{arr[j]} + \Sigma_{j=5}^6{arr[j]} + \Sigma_{j=7}^7{arr[j]}&lt;/script&gt;

&lt;p&gt;여기서
$\Sigma_{j=1}^4{arr[j]} = data[4]$,
$\Sigma_{j=5}^6{arr[j]} = data[6]$,
$\Sigma_{j=7}^7{arr[j]} = data[7]$
임을 알았으면 여러분은 구간 합을 구하는 방법을 이해한 것이다.&lt;/p&gt;

&lt;p&gt;N=10이라서 감이 잘 안 올 수는 있지만, 이렇게 구하는 방법이 $O(log N)$ 시간에 완료된다는 것도 알 수 있을 것이다.&lt;/p&gt;

&lt;p&gt;아직 의문점이 좀 있을 것이다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;그럼 arr[4…12]의 합은 어떻게 구하는가?
    &lt;ol&gt;
      &lt;li&gt;arr[1…12] - arr[1…3]을 구하면 된다. 즉, sum 연산을 두 번 실행하고, 작은 쪽을 빼 주면 끝.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;눈으로 보면 arr[1…7] = data[4] + data[6] + data[7]인 것을 알 수 있지만, 구현은 어떻게 쉽게 하는가?
    &lt;ol&gt;
      &lt;li&gt;비트 연산을 이해한다면 구현도 굉장히 쉽다. 구체적인 예(arr[1…43])를 보자.
        &lt;ol&gt;
          &lt;li&gt;arr[1…43] = data[32] + data[40] + data[42] + data[43]이다.&lt;/li&gt;
          &lt;li&gt;43을 이진법으로 나타내면 $101011_2$이다.&lt;/li&gt;
          &lt;li&gt;43의 LSB(1인 비트 중 끝자리)를 하나 뗀다. $101010_2 = 42$이다.&lt;/li&gt;
          &lt;li&gt;하나 더 떼 본다. $101000_2 = 40$이다.&lt;/li&gt;
          &lt;li&gt;하나 더 떼 본다. $100000_2 = 32$이다.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;그럼 LSB를 어떻게 쉽게 구하는가?
        &lt;ol&gt;
          &lt;li&gt;idx = 43으로 두고, idx &amp;amp;= idx – 1 연산을 idx가 0이 될 때까지 수행한다.&lt;/li&gt;
          &lt;li&gt;이게 왜 되는지 이해가 안 된다면 idx와 idx - 1을 이진법으로 나타내고, and 연산을 수행해보면 이해가 될 것이라 장담한다.&lt;/li&gt;
          &lt;li&gt;사실 LSB 자체를 구하는 것은 업데이트 연산에서 볼 수 있듯이 (idx &amp;amp; -idx)로 구할 수 있다. 하지만 LSB를 빼는 것은 idx &amp;amp;= idx - 1로도 가능하다.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;위와 같이 이진법으로 접근해보면, 시간복잡도가 $O(log N)$인 것을 알 수 있다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;값-업데이트olog-n&quot;&gt;값 업데이트($O(log N)$)&lt;/h3&gt;

&lt;p&gt;arr[7]을 업데이트했다고 가정해보자. 좀 전에 봤던 그림을 다시 가져왔다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Algorithm_and_Data_Structure/2018-07-09-algorithm-fenwick-tree/04_FenwickTree3.jpg&quot; alt=&quot;04_FenwickTree3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;arr[7]을 업데이트했다면, data[i]는 arr[j]들의 합으로 이루어져 있고, 그 값을 프로그램이 끝날 때까지 유지해야 한다. 그러면 arr[7]이 계산식에 포함되어 있는 모든 data[i]들을 업데이트해야 한다.&lt;/p&gt;

&lt;p&gt;그럼 문제는 다음으로 연결된다.&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;arr[7]을 계산식에 포함하는 data[i]들은 어떤 것이 있는가?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;일단 답을 보자. data[7], data[8], data[16]이 있다. (N=16)
이는 위 그림에서 7 위쪽으로 화살표를 쭉 그려보면 알 수 있다. data[7]은 당연히 업데이트해야 하고, 화살표와 만나는 data[8]과 data[16]을 업데이트해야 한다.&lt;/p&gt;

&lt;p&gt;각 숫자들을 이진법으로 나타내보자. $00111_2, 01000_2, 10000_2$이다.
규칙성이 보이는가? 조금은 어려울 것이다. 답은, LSB를 더하면 다음 수가 된다는 것이다.&lt;/p&gt;

&lt;p&gt;다른 예를 들어보겠다. arr[3]을 업데이트하면, data[3], data[4], data[8], data[16]을 업데이트한다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;$3 = 00011_2$&lt;/li&gt;
  &lt;li&gt;$4 = 00011_2 + 00001_2 = 00100_2$&lt;/li&gt;
  &lt;li&gt;$8 = 00100_2 + 00100_2 = 01000_2$&lt;/li&gt;
  &lt;li&gt;$16 = 01000_2 + 01000_2 = 10000_2$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;조금 전에 구간 합을 구할 때는 LSB를 빼 주었다. 업데이트를 할 때는 LSB를 더해 준다.
이것이 가능한 이유는 역시 손으로 몇 개 정도 그려 보면 이해할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;

&lt;p&gt;코드의 가독성을 위해 그리고 N이 작을 때 메모리를 아끼기 위해 동적으로 data를 vector&amp;lt;int&amp;gt;로 선언하여 &lt;code class=&quot;highlighter-rouge&quot;&gt;FenwickTree class&lt;/code&gt; 안에 넣었다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;하지만, 실제 PS 문제를 풀 때는 그냥 $2^n + 1$ 크기만큼 배열을 전역 변수로 설정해버리는 것이 실행 시간이 더 빠르다.&lt;/li&gt;
  &lt;li&gt;arr[i] = sum[i] - sum[i-1]임을 이용하면 arr배열을 유지할 필요가 없다.&lt;/li&gt;
  &lt;li&gt;사실 이 클래스의 경우 long long을 많이 사용하기 때문에 template을 사용하는 이유가 별로 없긴 하다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &quot;sharifa_header.h&quot;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;template&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FenwickTree&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;nl&quot;&gt;public:&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;FenwickTree&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;2차원-펜윅-트리-구현&quot;&gt;2차원 펜윅 트리 구현&lt;/h2&gt;

&lt;p&gt;이는 별다른 처리 해 줄 필요 없이 단순히 차원 확장을 한 것에 불과하다. 배열이 2차원이 되고, while문이 두 개가 되었을 뿐이다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &quot;sharifa_header.h&quot;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FenwickTree2D&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;nl&quot;&gt;public:&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;FenwickTree2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dval&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;yy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;kr&quot;&gt;inline&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;문제-풀이&quot;&gt;문제 풀이&lt;/h2&gt;

&lt;h3 id=&quot;boj-02042구간-합-구하기&quot;&gt;BOJ 02042(구간 합 구하기)&lt;/h3&gt;

&lt;p&gt;문제: &lt;a href=&quot;https://www.acmicpc.net/problem/2042&quot;&gt;구간 합 구하기&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;풀이: &lt;a href=&quot;https://greeksharifa.github.io/ps/2018/07/10/PS-02042/&quot;&gt;BOJ 02042(구간 합 구하기) 문제 풀이&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;boj-11658구간-합-구하기-3&quot;&gt;BOJ 11658(구간 합 구하기 3)&lt;/h3&gt;

&lt;p&gt;문제: &lt;a href=&quot;https://www.acmicpc.net/problem/11658&quot;&gt;구간 합 구하기 3&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;풀이: &lt;a href=&quot;https://greeksharifa.github.io/ps/2018/07/11/PS-11658/&quot;&gt;BOJ 11658(구간 합 구하기 3) 문제 풀이&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;boj-01280나무-심기&quot;&gt;BOJ 01280(나무 심기)&lt;/h3&gt;

&lt;p&gt;문제: &lt;a href=&quot;https://www.acmicpc.net/problem/1280&quot;&gt;나무 심기&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;풀이: &lt;a href=&quot;https://greeksharifa.github.io/ps/2018/07/11/PS-01280/&quot;&gt;BOJ 01280(나무 심기) 문제 풀이&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>GitHub 사용법 - 03. 프로젝트 clone, status check, .gitignore</title>
   <link href="http://localhost:4000/github-usage-03-clone-log-gitignore/"/>
   <updated>2018-07-08T00:00:00+09:00</updated>
   <id>http://localhost:4000/github-usage-03-clone-log-gitignore</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 글을 읽는 여러분이, 만약 git을 많이 써 봐서 익숙한 것이 아니라면, 반드시 손으로 직접 따라 칠 것을 권한다. 눈으로만 보면 100% 잊어버린다.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-02-create-project/&quot;&gt;저번 글&lt;/a&gt;에서 작업하던 것을 이어서 한다. 저번 글에서는 git_tutorial 디렉토리를 생성하는 것까지 했었다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;local-directory-생성&quot;&gt;Local Directory 생성&lt;/h2&gt;

&lt;p&gt;이제 git_tutorial 옆에 새로운 디렉토리를 생성한다. 
이름은 자유지만 필자는 &lt;code class=&quot;highlighter-rouge&quot;&gt;git_tutorial_clone&lt;/code&gt;으로 정했다.&lt;/p&gt;

&lt;p&gt;이 상황은, git으로 협력할 때 다른 사람이 프로젝트 repo를 clone하거나, 
여러분이 다른 컴퓨터로 이동하여 작업을 하고 싶을 때를 가정한 것이다.&lt;br /&gt;
그러나 다른 사람을 데려오거나 컴퓨터를 하나 더 사는 것은 부담이 될 테니, 다른 디렉토리에 새로 repo를 만든다.&lt;br /&gt;
한 가지 주의사항으로, 같은 디렉토리 내에서는 할 수 없다. 그래서 새 디렉토리를 만드는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_07_08_github_usage_03_clone_log_gitignore/01_git_tutorial_clone.PNG&quot; alt=&quot;01_git_tutorial_clone&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;git-clone-하기&quot;&gt;git clone 하기&lt;/h2&gt;

&lt;p&gt;이제 명령창을 켜서, 방금 생성한 디렉토리로 이동한다. 명령어를 잊어버렸을까봐 해서 다시 적어 둔다. 물론 이것은 예시일 뿐이다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;cd C:\Users\Sharifa-D\WebstormProjects\git_tutorial_clone&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그리고 이제 clone을 할 것이다. clone 명령은 간단하다. &lt;code class=&quot;highlighter-rouge&quot;&gt;git clone \&amp;lt;remote repo 주소\&amp;gt;&lt;/code&gt; 형식이다.&lt;br /&gt;
저번에 생성했던 &lt;code class=&quot;highlighter-rouge&quot;&gt;git_tutorial&lt;/code&gt; git 주소를 사용하면 된다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git clone https://github.com/greeksharifa/git_tutorial.git&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_07_08_github_usage_03_clone_log_gitignore/02_git_clone.PNG&quot; alt=&quot;02_git_clone&quot; /&gt;&lt;/p&gt;

&lt;p&gt;클론은 이게 끝이다. 위 명령을 실행하면 git_tutorial 폴더가 또 만들어질 것이다.&lt;/p&gt;

&lt;p&gt;이제 여러분의 디렉토리 구조는 다음과 같을 것이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;git_tutorial/
    &lt;ul&gt;
      &lt;li&gt;.git/&lt;/li&gt;
      &lt;li&gt;first.py&lt;/li&gt;
      &lt;li&gt;second.py&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;git_tutorial_clone/
    &lt;ul&gt;
      &lt;li&gt;git_tutorial/
        &lt;ul&gt;
          &lt;li&gt;.git/&lt;/li&gt;
          &lt;li&gt;first.py&lt;/li&gt;
          &lt;li&gt;second.py&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;왜 .git/이 있지? 라고 생각할 수 있다.&lt;br /&gt;
.git/ 디렉토리는 윈도우라면 숨김 처리되어 있는 폴더인데, 이 .git/ 디렉토리가 있는 디렉토리만이 local repo로 인정받는다.&lt;br /&gt;
즉, 이 .git/이 있어야만 git repo로서의 역할을 할 수 있는 것이다.&lt;br /&gt;
그리고 git init으로 생성하거나 git clone으로 remote repo를 local repo로 가져온 경우에도 자동으로 .git/ 디렉토리가 존재하게 된다.&lt;/p&gt;

&lt;p&gt;그리고 위의 두 개의 first.py와 second.py 각각은 완전히 동일한 파일일 것이다.&lt;/p&gt;

&lt;p&gt;이제 두 개의 local repo와 remote repo 사이에 상호작용을 좀 시켜보자.&lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-02-create-project/&quot;&gt;저번 글&lt;/a&gt;에서 했던
&lt;code class=&quot;highlighter-rouge&quot;&gt;git status&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;git commit&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;git push&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;git pull&lt;/code&gt; 등을 사용해 볼 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;프로젝트-파일-수정하고-3종-세트-입력하기&quot;&gt;프로젝트 파일 수정하고 3종 세트 입력하기&lt;/h2&gt;

&lt;p&gt;아무거나 수정해보자. &lt;code class=&quot;highlighter-rouge&quot;&gt;git_tutorial_clone/git_tutorial/first.py&lt;/code&gt;를 수정한다. 다음과 같은 내용으로 하자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;print(“Hello, git!”) # instead of “Hello, World!”&lt;br /&gt;
print(“Hi, git!!”)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그리고 명령창에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;git status&lt;/code&gt;를 실행한다. 무슨 일을 하는지 잊어버리지는 않았을 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_07_08_github_usage_03_clone_log_gitignore/03_git_status.PNG&quot; alt=&quot;03_git_status&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add .&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;git commit -m &quot;Edit first.py&quot;&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;git push origin master&lt;/code&gt; 3종 세트를 입력하자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_07_08_github_usage_03_clone_log_gitignore/04_3set.PNG&quot; alt=&quot;04_3set&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;옵션-3종-세트-간편-입력윈도우-기준&quot;&gt;옵션: 3종 세트 간편 입력(윈도우 기준)&lt;/h2&gt;

&lt;p&gt;우선 수정사항을 만들기 위해 &lt;code class=&quot;highlighter-rouge&quot;&gt;git_tutorial_clone/git_tutorial/first.py&lt;/code&gt; 끝에 빈 줄을 하나 추가하자.&lt;/p&gt;

&lt;p&gt;3종 세트를 한 번에 입력하는 것은 배치 파일을 만들면 쉽게 할 수 있다. 
여러분의 git local repo 안에 &lt;code class=&quot;highlighter-rouge&quot;&gt;push.bat&lt;/code&gt;이란 이름의 파일을 하나 만들자.&lt;br /&gt;
명령창에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;copy con push.bat&lt;/code&gt;이라 입력한 후 입력을 시작해도 된다.&lt;br /&gt;
파일 내용은 다음과 같이 한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git add .
git status

set str=
set /p str=enter commit message :

git commit -m &quot;%str%&quot;
git push
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그리고 명령창에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;push.bat&lt;/code&gt;이라고 입력하여 방금 만든 배치 파일을 실행시켜보자.&lt;br /&gt;
그러면 enter commit message: 앞에서 멈춰 있을 것이다. 원하는 커밋 메시지를(enter를 입력하지 않고) 짧게 입력해보자.&lt;br /&gt;
그러면 3종 세트가 하는 모든 것이 완료된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_07_08_github_usage_03_clone_log_gitignore/05_push_bat.PNG&quot; alt=&quot;05_push_bat&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;local-repo-상태-확인하고-git-pull로-local-repo-업데이트하기&quot;&gt;local repo 상태 확인하고 git pull로 local repo 업데이트하기&lt;/h2&gt;

&lt;p&gt;이제 명령창에서 다음 명령을 입력한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;git_tutorial&lt;/code&gt; 디렉토리로 이동하기 위함이다(&lt;code class=&quot;highlighter-rouge&quot;&gt;git_tutorial_clone&lt;/code&gt; 내부의 것이 아니다).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;cd ../../git_tutorial/&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여기서 &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;를 확인해 보면, &lt;code class=&quot;highlighter-rouge&quot;&gt;print(&quot;Hi, git!!&quot;)&lt;/code&gt; 문장이 없는 것을 확인할 수 있다.&lt;br /&gt;
즉, local repo는 자동으로 업데이트되지 않는다.&lt;/p&gt;

&lt;p&gt;이제 새로운 명령어를 몇 개 배워 볼 것이다. 명령창에 다음을 입력한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git log&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 명령은 현재 local repo의 commit history를 보여준다. 아마 다음과 같을 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_07_08_github_usage_03_clone_log_gitignore/06_git_log.PNG&quot; alt=&quot;06_git_log&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 local 말고 remote repo가 궁금할 것이다(&lt;code class=&quot;highlighter-rouge&quot;&gt;git_tutorial_clone&lt;/code&gt;에서 커밋을 한두 개 날렸으니까).&lt;br /&gt;
그럴 때는 다음 명령을 사용한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git log HEAD..origin/master&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_07_08_github_usage_03_clone_log_gitignore/07_git_log.PNG&quot; alt=&quot;07_git_log&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;우선 &lt;code class=&quot;highlighter-rouge&quot;&gt;git log&lt;/code&gt; 명령은 commit log를 보여준다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;..&lt;/code&gt;은 Double Dot으로, 한쪽에는 있고 다른 쪽에는 없는 커밋이 무엇인지 Git에게 물어보는 것이다.&lt;/li&gt;
  &lt;li&gt;한쪽은 &lt;code class=&quot;highlighter-rouge&quot;&gt;HEAD&lt;/code&gt;이다. 다른 한쪽은 &lt;code class=&quot;highlighter-rouge&quot;&gt;origin/master&lt;/code&gt;이다.&lt;/li&gt;
  &lt;li&gt;HEAD는, 현 local repo의 현재 상태를 의미한다. HEAD에 대한 자세한 설명은 나중에 다룰 것이다.&lt;/li&gt;
  &lt;li&gt;이 명령은 &lt;code class=&quot;highlighter-rouge&quot;&gt;HEAD&lt;/code&gt;에는 없고 &lt;code class=&quot;highlighter-rouge&quot;&gt;origin/master&lt;/code&gt;에는 있는 커밋이 무엇인지 보여준다.
    &lt;ul&gt;
      &lt;li&gt;즉 local repo에는 없고 remote repo에는 있는 커밋을 볼 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;HEAD는 생략할 수 있다. 즉, &lt;code class=&quot;highlighter-rouge&quot;&gt;git log ..origin/master&lt;/code&gt;로도 같은 효과를 얻는다.&lt;/li&gt;
  &lt;li&gt;순서를 바꾸면 remote repo에는 없고 HEAD에는 있는 커밋을 보여주게 된다. 현 시점에서는 아무것도 표시되지 않을 것이다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git log&lt;/code&gt; 명령을 쓸 때 간략하게 보고 싶으면 &lt;code class=&quot;highlighter-rouge&quot;&gt;--oneline&lt;/code&gt; 옵션을 추가한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;git log ..origin/master –oneline&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이렇게 확인하고 나면 local repo와 remote repo가 어떤 status를 갖고 있는지 확인할 수 있다. 즉,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;local repo status
    &lt;ul&gt;
      &lt;li&gt;97f92d3 (HEAD -&amp;gt; master) Initial commit for git_tutorial&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;remote repo status
    &lt;ul&gt;
      &lt;li&gt;9401817 (origin/master) 3set simple commit&lt;/li&gt;
      &lt;li&gt;f569352 Edit first.py&lt;/li&gt;
      &lt;li&gt;Initial commit for git_tutorial&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 부분까지 자세히 알 필요는 없지만, 그래도 있으니 간략한 설명을 적어둔다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;앞의 16진수 숫자는 커밋의 고유 번호이다(해시값). 유일한 값이므로, 혹시 커밋 메시지를 너무 간결히 작성해서 커밋이 비슷해 경우 이 해시값으로 구분할 수 있다.&lt;/li&gt;
  &lt;li&gt;(HEAD -&amp;gt; master)은 HEAD(현재 local repo 상태)에서 master(remote repo의 master 브랜치)로 push했다는 것을 의미한다.&lt;/li&gt;
  &lt;li&gt;(origin/master)는 remote repo의 현재 상태를 의미한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그러고 &lt;code class=&quot;highlighter-rouge&quot;&gt;git status&lt;/code&gt;로 상태를 한번 확인해 본다. 깨끗하다는 메시지를 볼 수 있을 것이다.&lt;/p&gt;

&lt;p&gt;이제 &lt;code class=&quot;highlighter-rouge&quot;&gt;git pull origin master&lt;/code&gt;(혹은 &lt;code class=&quot;highlighter-rouge&quot;&gt;git pull&lt;/code&gt;)을 입력할 차례다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_07_08_github_usage_03_clone_log_gitignore/08_git_pull.PNG&quot; alt=&quot;08_git_pull&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 local repo가 최신으로 업데이트되었다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;gitignore-추가&quot;&gt;.gitignore 추가&lt;/h2&gt;

&lt;p&gt;이제 &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일을 추가해 보자.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일은 remote repo에 올리지 않을 파일이나 디렉토리를 지정하는 파일이다.&lt;br /&gt;
즉, 여러분이 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add *&lt;/code&gt;를 아무리 시도해도, &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt;파일에 명시된 파일 혹은 디렉토리는 절대 staging area에 올라가지 않는다.&lt;/p&gt;

&lt;p&gt;올라가지 않겠지만 파일을 하나 추가하자. &lt;code class=&quot;highlighter-rouge&quot;&gt;third.py&lt;/code&gt;로 하면 좋을 것 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# third.py
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'This file is useless!'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음으로는 &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일은 만들 차례다.&lt;br /&gt;
윈도우에선 &lt;code class=&quot;highlighter-rouge&quot;&gt;.&lt;/code&gt;으로 시작하는 파일을 그냥은 만들어 주지 않기 때문에, 명령창에서 조금 전처럼 &lt;code class=&quot;highlighter-rouge&quot;&gt;copy con .gitignore&lt;/code&gt;이라고 입력한다.&lt;br /&gt;
그러면 빈 줄에서 커서가 깜빡거리는데, 이때 다음을 입력한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;third.py&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;엔터 한번 쳐 준 다음에, &lt;code class=&quot;highlighter-rouge&quot;&gt;Ctrl + C&lt;/code&gt;를 누른다. 그럼 파일 입력을 종료하고 다시 터미널로 빠져나온다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_07_08_github_usage_03_clone_log_gitignore/09_create_gitignore.PNG&quot; alt=&quot;09_create_gitignore&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 &lt;code class=&quot;highlighter-rouge&quot;&gt;git status&lt;/code&gt;를 입력해보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_07_08_github_usage_03_clone_log_gitignore/10_git_status.PNG&quot; alt=&quot;10_git_status&quot; /&gt;&lt;/p&gt;

&lt;p&gt;상태창에 &lt;code class=&quot;highlighter-rouge&quot;&gt;third.py&lt;/code&gt;는 없고 &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일만 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일이야 방금 추가했으니 목록에 뜨는 것이 맞다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;third.py&lt;/code&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일에 지정되어 staging area에 올라갈 수 없다. 즉, &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt; 명령을 써도 staging area에 올라가지 않는다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제 3종 세트를 입력하거나, 옵션에서 했던 &lt;code class=&quot;highlighter-rouge&quot;&gt;push.bat&lt;/code&gt; 파일을 실행시킨다. 여기서는 3종 세트를 입력하겠다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_07_08_github_usage_03_clone_log_gitignore/11_3set.PNG&quot; alt=&quot;11_3set&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 브라우저에서 remote repo의 상태를 확인해 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_07_08_github_usage_03_clone_log_gitignore/12_remote_repo.PNG&quot; alt=&quot;12_remote_repo&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;third.py&lt;/code&gt;는 존재하지 않는다. &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 파일이 &lt;code class=&quot;highlighter-rouge&quot;&gt;third.py&lt;/code&gt;를 훌륭하게 무시해 주었다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt;파일은 이럴 때 많이 쓴다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(용량이 큰) 데이터 파일. git repo는 기본적으로는 아주 큰 파일은 repo에 올려주지 않는다. 총 git repo 용량 제한도 있다(기업의 경우는 잘 모르겠다). 따라서 데이터 파일은 제외하는 경우가 많다.&lt;/li&gt;
  &lt;li&gt;프로젝트 설정 파일. 열려 있는 파일이라 오류가 날 수도 있고, IDE가 수시로 바꾸는 경우가 많으므로 제외할 때가 많다.&lt;/li&gt;
  &lt;li&gt;dependency 파일. 누구나 웹에서 다운받아 설치할 수 있는 용량 큰 파일을 굳이 git repo에 넣지 않는다.
    &lt;ul&gt;
      &lt;li&gt;대신 따로 dependency 목록을 만들어 관리한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제 git의 프로젝트에 대한 설명은 대략 다 끝났다. &lt;a href=&quot;https://greeksharifa.github.io/github/2018/08/07/github-usage-04-branch-basic/&quot;&gt;다음 글&lt;/a&gt;에서는 branch에 대해서 알아본다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;git-명령어&quot;&gt;Git 명령어&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-00-command-list/&quot;&gt;GitHub 사용법 - 00. Command List&lt;/a&gt;에서 원하는 명령어를 찾아 볼 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>BOJ 13277(큰 수 곱셈) 문제 풀이</title>
   <link href="http://localhost:4000/PS-13277/"/>
   <updated>2018-07-08T00:00:00+09:00</updated>
   <id>http://localhost:4000/PS-13277</id>
   <content type="html">&lt;h2 id=&quot;참조&quot;&gt;참조&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;분류&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/13277&quot;&gt;BOJ 13277: 큰 수 곱셈&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://greeksharifa.github.io/algorithm%20&amp;amp;%20data%20structure/2018/07/07/algorithm-library/&quot;&gt;참조 라이브러리&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/fft.h&quot;&gt;fft.h&lt;/a&gt;, &lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/conversion_library.h&quot;&gt;conversion_library.h&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이 글에서 설명하는 코드&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/BOJ/13277_%ED%81%B0%20%EC%88%98%20%EA%B3%B1%EC%85%88.cpp&quot;&gt;13277_큰 수 곱셈&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;

&lt;h3 id=&quot;시간복잡도--on-&quot;&gt;시간복잡도: $ O(N) $&lt;/h3&gt;
&lt;h3 id=&quot;공간복잡도--on-&quot;&gt;공간복잡도: $ O(N) $&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;N은 두 수의 길이 중 max값이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;문제-풀이&quot;&gt;문제 풀이&lt;/h2&gt;

&lt;p&gt;풀이 자체는 어렵지 않다. 빠른 곱셈을 위해, &lt;a href=&quot;https://greeksharifa.github.io/algorithm%20&amp;amp;%20data%20structure/2018/07/07/algorithm-FFT/&quot;&gt;FFT&lt;/a&gt;
를 쓰면 된다. 그게 이 문제의 풀이의 전부이다.&lt;/p&gt;

&lt;p&gt;문제 자체가 데이터에 대한 전처리는 다음과 같은 것을 해주면 된다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;reverse를 시켜준다. 큰 수 처리는 가장 낮은 자리수를 맨 앞에 두므로, reverse를 해야 한다.&lt;/li&gt;
  &lt;li&gt;곱셈을 할 경우 자리수가 최대 두 배 정도까지 늘어나므로 자리수를 두 배만큼 늘려 준다.&lt;/li&gt;
  &lt;li&gt;다시 reverse를 한다. 이 때 앞쪽의 0들은 출력하지 않도록 한다.&lt;/li&gt;
  &lt;li&gt;곱셈 결과가 0인 경우 따로 0을 출력하도록 예외처리를 해 준다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;위의 사항만 주의하면, 입력받고, FFT를 적용하고, 출력하는 것이 끝이다.&lt;/p&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;

&lt;p&gt;입출력이 조금 많으므로, string과 cin을 사용할 것이라면&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;ios::sync_with_stdio(false);&lt;br /&gt;
cin.tie(NULL);&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;를 해주자.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &quot;../library/conversion_library.h&quot;
#include &quot;../library/fft.h&quot;
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main_13277&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ios&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sync_with_stdio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string_to_vi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string_to_vi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;reverse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;reverse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;reverse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'0'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 코드를 그대로 복붙하여 채점 사이트에 제출하면 당연히 틀린다. 못 믿겠다면, 저런 헤더 파일이 채점 사이트에 있을 것이라 생각하는가?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>BOJ 10828(스택) 문제 풀이</title>
   <link href="http://localhost:4000/PS-10828/"/>
   <updated>2018-07-08T00:00:00+09:00</updated>
   <id>http://localhost:4000/PS-10828</id>
   <content type="html">&lt;h2 id=&quot;참조&quot;&gt;참조&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;분류&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/10828&quot;&gt;스택&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이 글에서 설명하는 코드&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/BOJ/10828_%EC%8A%A4%ED%83%9D.cpp&quot;&gt;10828_스택&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;

&lt;h3 id=&quot;시간복잡도--on-&quot;&gt;시간복잡도: $ O(N) $&lt;/h3&gt;
&lt;h3 id=&quot;공간복잡도--on-&quot;&gt;공간복잡도: $ O(N) $&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;N은 명령의 수이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;문제-풀이&quot;&gt;문제 풀이&lt;/h2&gt;

&lt;p&gt;이 문제는 말 그대로 스택 그 자체이다. &lt;a href=&quot;https://greeksharifa.github.io/algorithm%20&amp;amp;%20data%20structure/2018/06/29/algorithm-stack/&quot;&gt;여기&lt;/a&gt;
에서 설명한 5가지 연산만 수행하면 끝이다.&lt;/p&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;

&lt;p&gt;특히나 이 문제는 코딩의 순서를 문제에서 주어진 5가지 명령에 쓰인 그대로 코딩하면 되는 문제이니, 자세한 설명은 생략하겠다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;stack&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;iostream&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main_10828&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;freopen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;input.txt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;r&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stdin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 문제의 입력을 일일이 치기 귀찮을 때 쓰는 방법이다.&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ios&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sync_with_stdio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;order&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;push&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;// push 명령 처리&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;pop&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;// pop 명령 처리&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;size&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;// size 명령 처리&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;empty&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;// empty 명령 처리&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;                            &lt;span class=&quot;c1&quot;&gt;// top 명령 처리&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 코드를 그대로 복붙하여 채점 사이트에 제출하면 틀린다. 그대로 제출하지 말라는 뜻이다. 무언가를 바꿔 주어야 한다.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>BOJ 09012(괄호) 문제 풀이</title>
   <link href="http://localhost:4000/PS-09012/"/>
   <updated>2018-07-08T00:00:00+09:00</updated>
   <id>http://localhost:4000/PS-09012</id>
   <content type="html">&lt;h2 id=&quot;참조&quot;&gt;참조&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;분류&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/9012&quot;&gt;괄호&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이 글에서 설명하는 코드&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/BOJ/09012_%EA%B4%84%ED%98%B8.cpp&quot;&gt;09012_괄호&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;

&lt;h3 id=&quot;시간복잡도--otc-cdot-l-&quot;&gt;시간복잡도: $ O(TC \cdot L) $&lt;/h3&gt;
&lt;h3 id=&quot;공간복잡도--ol-&quot;&gt;공간복잡도: $ O(L) $&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;TC는 테스트 케이스의 수, L은 문자열의 길이이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;문제-풀이&quot;&gt;문제 풀이&lt;/h2&gt;

&lt;p&gt;괄호 짝 맞추기는 스택 문제의 단골손님이다.&lt;br /&gt;
이 문제의 핵심 아이디어는 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;문자열을 하나씩 읽는다.
    &lt;ul&gt;
      &lt;li&gt;여는 괄호 ( 가 나오면 스택에 집어넣는다.&lt;/li&gt;
      &lt;li&gt;닫는 괄호 ) 가 나오면 괄호 하나를 빼낸다.
        &lt;ul&gt;
          &lt;li&gt;이때 스택이 비어 있으면 잘못된 것이다. NO를 출력한다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;문자열을 다 읽고 나서 스택이 비어 있어야만 제대로 된 Parenthesis String이다. YES를 출력한다.
    &lt;ul&gt;
      &lt;li&gt;스택에 뭔가 들어 있으면 NO를 출력한다. 이 부분이 실수가 가장 많이 나오는 부분이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;각 테스트 케이스마다 스택을 clear시켜줘야 한다. 안 그러면 wrong answer를 받을 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;

&lt;p&gt;이 문제에는 적용 가능한 트릭이 몇 가지 있다. 코딩을 간단하게 만들 수 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;이 문제는 스택에 집어넣는 것이 오직 여는 괄호 ( 하나 뿐이다. 그럼 굳이 스택을 쓸 것도 없이, 쌓인 여는 괄호의 수를 세어 줄 변수 n 하나만 있으면 된다.&lt;/li&gt;
  &lt;li&gt;각 문자마다 검사할 때, 닫는 괄호 ) 가 나오면 일단 n을 감소시킨다. 그리고 n이 0보다 작아지면, 바로 중단한다.
    &lt;ul&gt;
      &lt;li&gt;그러면 마지막에서 n이 0인지만 보면 YES / NO 를 판별할 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;string&amp;gt;
#include &amp;lt;iostream&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main_09012&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;//freopen(&quot;input.txt&quot;, &quot;r&quot;, stdin);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ios&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sync_with_stdio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tie&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TC&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'('&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; 
                &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;NO&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;YES&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 코드를 그대로 복붙하여 채점 사이트에 제출하면 틀린다. 그대로 제출하지 말라는 뜻이다. 무언가를 바꿔 주어야 한다.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>greeksharifa's Library</title>
   <link href="http://localhost:4000/algorithm-library/"/>
   <updated>2018-07-07T00:00:00+09:00</updated>
   <id>http://localhost:4000/algorithm-library</id>
   <content type="html">&lt;h2 id=&quot;sharifa_headerh&quot;&gt;sharifa_header.h&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/sharifa_header.h&quot;&gt;코드&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;필자가 만든 라이브러리…라고 하기는 좀 그렇고, 그냥 헤더 파일이랑 #define 약간을 모아 놓은 헤더 파일이다.&lt;br /&gt;
필자의 코드에서 처음 보는 토큰들이 좀 있을 텐데, 잘 모르겠다면 위의 링크를 참조하면 된다.&lt;/p&gt;

&lt;p&gt;예를 들면, &lt;code class=&quot;highlighter-rouge&quot;&gt;ll&lt;/code&gt;은 &lt;code class=&quot;highlighter-rouge&quot;&gt;long long&lt;/code&gt;이다.&lt;/p&gt;

&lt;h2 id=&quot;bit_libraryh&quot;&gt;bit_library.h&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/bit_library.h&quot;&gt;코드&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;비트 관련 사용자 정의 함수를 모아 놓은 헤더 파일이다.&lt;br /&gt;
bit 연산을 안다면 코드를 보고 이해할 수 있으므로 따로 설명하지는 않겠다.&lt;/p&gt;

&lt;h2 id=&quot;conversion_libraryh&quot;&gt;conversion_library.h&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/conversion_library.h&quot;&gt;코드&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;어떤 데이터 타입 변수를 다른 데이터 타입 변수로 바꾸는 함수들을 모아 놓았다.&lt;br /&gt;
예를 들어 string_to_vi 함수는 “1236”과 같은 string을 vector&amp;lt;int&amp;gt;로 변환한다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>고속 푸리에 변환(Fast Fourier Theorem, FFT). 큰 수의 곱셈</title>
   <link href="http://localhost:4000/algorithm-FFT/"/>
   <updated>2018-07-07T00:00:00+09:00</updated>
   <id>http://localhost:4000/algorithm-FFT</id>
   <content type="html">&lt;h2 id=&quot;참조&quot;&gt;참조&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;분류&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/13277&quot;&gt;큰 수 곱셈&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;응용 문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/workbook/view/824&quot;&gt;koosaga BOJ FFT 문제집&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://greeksharifa.github.io/algorithm%20&amp;amp;%20data%20structure/2018/07/07/algorithm-library/&quot;&gt;참조 라이브러리&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/sharifa_header.h&quot;&gt;sharifa_header.h&lt;/a&gt;, &lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/bit_library.h&quot;&gt;bit_library.h&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이 글에서 설명하는 라이브러리&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/fft.h&quot;&gt;fft.h&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;

&lt;h3 id=&quot;시간복잡도--on-log-n-&quot;&gt;시간복잡도: $ O(N log N) $&lt;/h3&gt;
&lt;h3 id=&quot;공간복잡도--on-&quot;&gt;공간복잡도: $ O(N) $&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;N은 두 수열의 길이의 max값이다.&lt;/li&gt;
  &lt;li&gt;FFT는 convolution을 빠르게 해 주는 것이지만, PS에서는 거의 대부분 곱셈을 빠르게 하기 위해 쓰인다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 글에서는 FFT(고속 푸리에 변환)을 설명한다.&lt;br /&gt;
이론적인 부분에 대한 자세한 설명은 &lt;a href=&quot;http://topology-blog.tistory.com/6&quot;&gt;topology-blog&lt;/a&gt;에 잘 되어 있으므로 생략한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;알고리즘&quot;&gt;알고리즘&lt;/h2&gt;

&lt;p&gt;큰 수의 곱셈을 수행할 때 FFT의 개략적인 설명은 다음과 같이 적어 두었다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;각 수열을 먼저 reverse시킨다. $ O(N) $&lt;/li&gt;
  &lt;li&gt;각 수열에 푸리에 변환을 적용한다. $ O(N log N) $&lt;/li&gt;
  &lt;li&gt;푸리에 변환을 적용하면 convolution을 단순 곱셈으로 변환시킬 수 있으므로, 2의 결과물을 element-wise 곱셈을 시킨다. $ O(N) $&lt;/li&gt;
  &lt;li&gt;3의 결과물을 푸리에 역변환을 시킨다. $ O(N log N) $&lt;/li&gt;
  &lt;li&gt;1에서 reverse를 시켰으므로, 다시 reverse를 시켜준다. $ O(N) $&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;FFT의 핵심 부분은 2~4번 부분이다. 1번과 5번은 우리가 수를 쓸 때 앞부분에 큰 자리 수를 적기 때문에 필요하다.&lt;/p&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;

&lt;p&gt;다음과 같다. FFT 구현과 출력 함수만 정의되어 있으므로, 따로 설명하진 않겠다.&lt;/p&gt;

&lt;p&gt;다만 주의할 점이 하나 있는데, 출력 함수에서 곱하는 두 수가 0인 경우 예외 처리를 해주어야 한다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/*
fft 함수는 http://topology-blog.tistory.com/6 블로그를 참조한 것입니다.
*/&lt;/span&gt;

&lt;span class=&quot;cp&quot;&gt;#pragma once
&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#include &quot;sharifa_header.h&quot;
#include &quot;bit_library.h&quot;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;typedef&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;complex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;^=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kt&quot;&gt;double&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;M_PI&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;th&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;multiply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;power_of_2_ge_than&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;	&lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;boj-13277큰-수-곱셈-문제-풀이&quot;&gt;BOJ 13277(큰 수 곱셈) 문제 풀이&lt;/h2&gt;

&lt;p&gt;문제: &lt;a href=&quot;https://www.acmicpc.net/problem/13277&quot;&gt;BOJ 13277(큰 수 곱셈)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;풀이: &lt;a href=&quot;https://greeksharifa.github.io/ps/2018/07/08/PS-13277/&quot;&gt;BOJ 13277(큰 수 곱셈) 문제 풀이&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>BOJ 06549(히스토그램에서 가장 큰 직사각형) 문제 풀이</title>
   <link href="http://localhost:4000/PS-06549/"/>
   <updated>2018-07-07T00:00:00+09:00</updated>
   <id>http://localhost:4000/PS-06549</id>
   <content type="html">&lt;h2 id=&quot;참조&quot;&gt;참조&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;분류&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/6549&quot;&gt;히스토그램에서 가장 큰 직사각형&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이 글에서 설명하는 코드&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/BOJ/06549_%ED%9E%88%EC%8A%A4%ED%86%A0%EA%B7%B8%EB%9E%A8%EC%97%90%EC%84%9C%20%EA%B0%80%EC%9E%A5%20%ED%81%B0%20%EC%A7%81%EC%82%AC%EA%B0%81%ED%98%95.cpp&quot;&gt;06549_히스토그램에서 가장 큰 직사각형&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;

&lt;h3 id=&quot;시간복잡도--otc-cdot-n-&quot;&gt;시간복잡도: $ O(TC \cdot N) $&lt;/h3&gt;
&lt;h3 id=&quot;공간복잡도--on-&quot;&gt;공간복잡도: $ O(N) $&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;N은 직사각형의 수, TC는 테스트 케이스의 수이다. 즉 사실상 $ O(N) $이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 글에서는 &lt;a href=&quot;https://www.acmicpc.net/problem/6549&quot;&gt;히스토그램에서 가장 큰 직사각형&lt;/a&gt;의 가장 빠른 풀이인 스택을 활용한 풀이를 설명한다.&lt;br /&gt;
이 문제는 BOJ 사이트 맨 아래에 적혀 있는 대로 세그먼트 트리($O(N log N)$), 분할 정복($O(N log N)$) 등으로도 풀 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;문제-풀이&quot;&gt;문제 풀이&lt;/h2&gt;

&lt;p&gt;&lt;del&gt;개인적으로 스택 활용 문제 중 가장 멋있는 문제라고 생각…&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;이 문제는 처음 봤을 때는 스택이라는 것을 떠올리기가 굉장히 까다롭다. 하지만 가장 멋있는 풀이 방법이니 꼭 익혀두도록 하자.&lt;/p&gt;

&lt;p&gt;우선 $O(N^2)$ 풀이부터 생각해 보자.&lt;/p&gt;

&lt;h3 id=&quot;on2-풀이-그냥-풀기&quot;&gt;$O(N^2)$ 풀이: 그냥 풀기&lt;/h3&gt;

&lt;p&gt;사실 이 풀이는 별 것 없다. N개의 직사각형이 있으니, [0, N) 구간이라고 생각하고, 모든 구간의 넓이를 다 구해보는 것이다. 그리고 최댓값을 찾는다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;[0, 1) 부터 [0, 2), [0, 3), …, [0, N) 구간을 검사한다. 각 구간 최댓값을 유지하면서 차례로 검사한다.&lt;/li&gt;
  &lt;li&gt;[1, 2) 부터 [1, 3), [1, 4), …, [1, N) 구간을 검사한다. 각 구간 최댓값을 유지하면서 차례로 검사한다.&lt;/li&gt;
  &lt;li&gt;…&lt;/li&gt;
  &lt;li&gt;[N-1, N) 구간을 검사한다. 각 구간 최댓값을 유지하면서 차례로 검사한다(하나뿐이지만).&lt;/li&gt;
  &lt;li&gt;이 중 최댓값을 찾는다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;당연히 $O(N^2)$ 풀이는 시간 초과를 얻는다. 이를 $O(N)$으로 줄이기 위해서는, 한 칸씩 검사할 때마다 $O(N)$에 해당하는 구간을 검사해야 한다.&lt;br /&gt;
그리고 이를 가능하게 해 주는 것이 스택이다.&lt;/p&gt;

&lt;h3 id=&quot;on-풀이-스택&quot;&gt;$O(N)$ 풀이: 스택&lt;/h3&gt;

&lt;p&gt;이 풀이를 어떻게 생각해냈을까라는 생각은 잠시 접어두고, 우선 풀이를 보자.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;스택을 하나 생성하고, 답(ans)은 0으로 초기화해 둔다.&lt;/li&gt;
  &lt;li&gt;0번째 직사각형을 처리한다. (첫 번째 직사각형이지만, 0으로 시작하는 것이 편하다)
    &lt;ol&gt;
      &lt;li&gt;0번째는 우선 스택에 집어넣어 둔다. 이 때 pair&amp;lt;int, int&amp;gt;를 사용하여, (위치, 직사각형의 높이)를 같이 저장한다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;i번째 직사각형을 처리한다.
    &lt;ol&gt;
      &lt;li&gt;이때 스택에는 몇 개인지는 모르지만 (위치, 직사각형의 높이) 쌍이 몇 개 들어 있을 것이다.&lt;/li&gt;
      &lt;li&gt;스택의 top element의 높이와 i번째 직사각형의 높이를 비교한다. top element를 (top_index, top_height), i번째 직사각형을 (i_index, i_height)라고 하자.&lt;/li&gt;
      &lt;li&gt;top_height &amp;lt;= i_height이면(혹은 3.iv.b에서 다 제거해버려서 스택이 비었으면) (&lt;strong&gt;최소 위치&lt;/strong&gt;, 직사각형의 높이) 쌍을 스택에 집어넣고 (i+1)번째 직사각형으로 넘어간다.
        &lt;ol&gt;
          &lt;li&gt;top_height == i_height이면 집어넣지 않아도 상관없지만, 코드가 복잡해지므로 그냥 한 번에 처리한다.&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;최소 높이&lt;/strong&gt;란, min(i_height, 마지막으로 제거한 top_height)를 의미한다. 제거한 적이 없으면 그냥 i_height이다.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;top_height &amp;gt; i_height이면, 다음을 수행한다.
        &lt;ol&gt;
          &lt;li&gt;(i_index - top_index) * top_height와 ans의 max값을 ans에 넣는다.&lt;/li&gt;
          &lt;li&gt;top element를 제거한다. 이때 top_height는 임시저장한다.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;모든 직사각형을 처리했으면, 남은 스택의 top element에 대해서 iv의 동작을 반복한다.
        &lt;ol&gt;
          &lt;li&gt;이때 i_index 대신 n을 사용한다.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이것이 알고리즘의 전부이다.&lt;br /&gt;
BOJ의 예시(2 1 4 5 1 3 3)를 적용해 보자. 아래 그림은 BOJ에서 가져온 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/PS/2018-07-07-PS-06549/01_histogram.png&quot; alt=&quot;Histogram&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;스택을 하나 생성하고, ans 변수는 0으로 초기화해 둔다.&lt;/li&gt;
  &lt;li&gt;0번째 직사각형을 처리한다.
    &lt;ol&gt;
      &lt;li&gt;(0,2)를 저장한다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;1번째 직사각형을 처리한다.
    &lt;ol&gt;
      &lt;li&gt;(0,2)가 스택에 있다.&lt;/li&gt;
      &lt;li&gt;(0,2)와 (1,1)을 비교한다. 1번째 직사각형이 top element보다 더 작다.
        &lt;ol&gt;
          &lt;li&gt;(i_index - top_index) * top_height = (1-0)*2 = 2를 ans에 저장한다.
            &lt;ul&gt;
              &lt;li&gt;이것은 0번째 직사각형만을 사용하여 잘라낸 직사각형을 의미한다. 너비 1, 높이 2짜리 직사각형이다.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;(0,2)를 스택에서 제거한다. 이때 &lt;strong&gt;최소 위치&lt;/strong&gt;는 0이 된다.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;스택이 비었으므로 (0,1)을 집어넣고(&lt;strong&gt;(1,1)이 아니다!&lt;/strong&gt;) 다음으로 넘어간다.
        &lt;ul&gt;
          &lt;li&gt;이것의 의미는 다음과 같다. 위치는 0, 높이는 1을 집어넣었다. 이는 1번째 직사각형을 포함하는(높이 1 이상) 잘라낸 직사각형의 왼쪽 끝은 0이 된다는 뜻이다.&lt;/li&gt;
          &lt;li&gt;그림을 보면 이해가 될 것이다. 0,1번째 직사각형 모두에서 잘라낼 때 최대 높이는 1이다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;2번째 직사각형을 처리한다.
    &lt;ol&gt;
      &lt;li&gt;(0,1)이 스택이 있다.&lt;/li&gt;
      &lt;li&gt;(0,1)과 (2,4)를 비교한다. 2번째 직사각형이 top element보다 더 크다.&lt;/li&gt;
      &lt;li&gt;(2,4)를 스택에 넣고 다음으로 넘어간다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;3번째 직사각형을 처리한다.
    &lt;ol&gt;
      &lt;li&gt;(0,1)과 (2,4)가 스택에 있다.&lt;/li&gt;
      &lt;li&gt;(2,4)와 (3,5)를 비교한다. (3,5)를 스택에 넣고 다음으로 넘어간다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;4번째 직사각형을 처리한다.
    &lt;ol&gt;
      &lt;li&gt;(0,1), (2,4), (3,5)가 스택에 있다.&lt;/li&gt;
      &lt;li&gt;(3,5)와 (4,1)을 비교한다. 4번째 직사각형이 더 작다.
        &lt;ol&gt;
          &lt;li&gt;(4-3)*5 = 5를 ans에 저장한다.
            &lt;ul&gt;
              &lt;li&gt;3번째 직사각형만을 사용하여 잘라낸 것을 의미한다.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;(3,5)를 스택에서 제거한다. &lt;strong&gt;최소 위치&lt;/strong&gt;를 3으로 업데이트한다.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;(2,4)와 (4,1)을 비교한다. 이번에도 4번째 직사각형이 더 작다.
        &lt;ol&gt;
          &lt;li&gt;(4-2)&lt;em&gt;4 = 8을 ans에 저장한다(&lt;/em&gt;이것이 이 예시의 정답이다*).
            &lt;ul&gt;
              &lt;li&gt;2,3번째 직사각형을 사용하여 잘라낸 것을 의미한다.&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;(2,4)를 스택에서 제거한다. &lt;strong&gt;최소 위치&lt;/strong&gt;를 2로 업데이트한다.&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;(0,1)과 (4,1)을 비교한다. 높이가 같으므로 (2,1)(&lt;strong&gt;(4,1)이 아니다!&lt;/strong&gt;)을 스택에 집어넣고(넣지 않아도 된다) 다음으로 넘어간다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;5번째 직사각형을 처리한다.
    &lt;ol&gt;
      &lt;li&gt;(0,1), (2,1)이 스택에 있다.&lt;/li&gt;
      &lt;li&gt;(5,3)은 (2,1)보다 높이가 높기 때문에 스택에 그대로 집어넣고 다음으로 넘어간다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;6번째 직사각형을 처리한다.
    &lt;ol&gt;
      &lt;li&gt;(0,1), (2,1), (5,3)이 스택에 있다.&lt;/li&gt;
      &lt;li&gt;(6,3)은 (5,3)과 높이가 같기 때문에 스택에 그대로 집어넣고 다음으로 넘어간다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;이제 모든 직사각형을 처리했으니, 스택을 비워가면서 처리를 하면 된다.
    &lt;ol&gt;
      &lt;li&gt;(0,1), (2,1), (5,3), (6,3)이 스택에 있다.&lt;/li&gt;
      &lt;li&gt;(6,3): (7-6)*3 = 3은 ans보다 작다. 6번째 직사각형만을 사용하여 잘라낸 것(너비 1, 높이 3)이다.&lt;/li&gt;
      &lt;li&gt;(5,3): (7-5)*3 = 6은 ans보다 작다. 5,6번째 직사각형을 사용하여 잘라낸 것(너비 2, 높이 3)이다.&lt;/li&gt;
      &lt;li&gt;(2,1): (7-2)*1 = 5은 ans보다 작다. 4,5,6번째 직사각형을 사용하여 잘라낸 것(너비 5, 높이 1)이다.&lt;/li&gt;
      &lt;li&gt;(0,1): (7-0)*1 = 7은 ans보다 작다. 0~6번째 직사각형을 모두 사용하여 잘라낸 것(너비 7, 높이 1)이다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;같은 방법으로&lt;br /&gt;
1,2,3,2,1(정답은 1~3번째 직사각형을 사용한 6)과&lt;br /&gt;
3,2,1,2,3(정답은 0~4번째 직사각형을 모두 사용한 5)&lt;br /&gt;
에 대해서도 생각해 보라.&lt;/p&gt;

&lt;p&gt;이 알고리즘에 왜 동작하는지를 살펴보면 다음과 같다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;스택에는 항상 위치와 직사각형의 높이 모두 오름차순으로 정렬되어 쌓여 있다. top element가 더 높으면 항상 제거하기 때문에 이렇게 된다.&lt;/li&gt;
  &lt;li&gt;i번째 직사각형을 처리할 때, 1에 의해 놓치는 &lt;code class=&quot;highlighter-rouge&quot;&gt;잘라낸 직사각형&lt;/code&gt;이 없게 된다.
    &lt;ol&gt;
      &lt;li&gt;즉, (i-1)번째 직사각형이 잘라낸 직사각형의 오른쪽 끝이 되는 모든 경우를 처리하는 것이다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;최소 높이&lt;/strong&gt;를 사용하는 이유는, 3,2,1,2,3과 같은 경우를 처리하기 위함이다.
    &lt;ol&gt;
      &lt;li&gt;만약에 3번째 직사각형을 처리할 때 (2,1)로 그대로 집어넣어 버리면, 0~4번째 직사각형을 모두 포함한 넓이 5짜리 직사각형을 놓치게 된다.&lt;/li&gt;
      &lt;li&gt;1에 의해 i번째 직사각형보다 낮은 top element를 처음 만나기 전까지는 모두 top element가 i번째 직사각형보다 높으므로, 높이 걱정을 할 필요가 없어진다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이해가 안 된다면, 예시를 몇 개 더 생각해 보면서 해야 한다. 추천하는 예시는 1,2,5,2,2,1,6이다.&lt;/p&gt;

&lt;p&gt;다음은 자주 하는 실수를 정리한 것이다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;마지막에 스택을 비우는 작업을 안 하는 경우. 이것은 마지막 직사각형이 잘라낸 직사각형의 오른쪽 끝이 되는 경우를 놓친 것이다.&lt;/li&gt;
  &lt;li&gt;높이 10억 * 너비 10만은 int의 범위를 한참 넘는다. ans는 long long으로 선언할 것.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;

&lt;p&gt;이 문제에 적용 가능한 트릭이 몇 가지 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;높이가 같은 경우 스택에 넣어도 되고 안 넣어도 된다. 직관을 위해서라면 넣지 말고, 코딩의 편의성을 위해서라면 따로 처리할 필요 없다.&lt;/li&gt;
  &lt;li&gt;스택을 비우는 작업을 따로 처리하는 대신, 높이 -1짜리 가상의 n번째 직사각형을 생각하자. 그러면 모든 직사각형은 이 n번째 직사각형보다 높기 때문에 스택에서 모두 제거되게 된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;최소 위치&lt;/strong&gt;는 &lt;code class=&quot;highlighter-rouge&quot;&gt;left&lt;/code&gt;이다.
설명이 복잡한 것 치고는 간결한 코드이지 않은가?&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &quot;../library/sharifa_header.h&quot;
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main_06549&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;scanf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%d&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i_index&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;scanf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%d&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;i_height&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;// top_index: st.top().first, top_height: st.top().second&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i_index&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;make_pair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i_height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%lld&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 코드를 그대로 복붙하여 채점 사이트에 제출하면 당연히 틀린다. 못 믿겠다면, 저런 헤더 파일이 채점 사이트에 있을 것이라 생각하는가?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>행렬의 N 거듭제곱 빠르게 구하기</title>
   <link href="http://localhost:4000/algorithm-matrix-power/"/>
   <updated>2018-07-04T00:00:00+09:00</updated>
   <id>http://localhost:4000/algorithm-matrix-power</id>
   <content type="html">&lt;h2 id=&quot;참조&quot;&gt;참조&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;분류&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/10830&quot;&gt;행렬 제곱&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;응용 문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/2749&quot;&gt;스포일러 1&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;a href=&quot;https://greeksharifa.github.io/algorithm%20&amp;amp;%20data%20structure/2018/07/07/algorithm-library/&quot;&gt;참조 라이브러리&lt;/a&gt;&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/sharifa_header.h&quot;&gt;sharifa_header.h&lt;/a&gt;, &lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/bit_library.h&quot;&gt;bit_library.h&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이 글에서 설명하는 라이브러리&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/matrix.h&quot;&gt;matrix.h&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;

&lt;h3 id=&quot;시간복잡도--om3-log-n-&quot;&gt;시간복잡도: $ O(M^3 log N) $&lt;/h3&gt;
&lt;h3 id=&quot;공간복잡도--om2-&quot;&gt;공간복잡도: $ O(M^2) $&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;M은 행렬의 크기, N은 거듭제곱할 수를 나타낸다. 물론 행렬은 정사각행렬이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 글에서는 행렬의 N 거듭제곱을 빠르게 구하는 방법을 설명한다. 
사실 행렬의 N승은 &lt;a href=&quot;https://greeksharifa.github.io/references/2018/07/13/it-will-update-soon/&quot;&gt;정수의 N 거듭제곱 빠르게 구하기&lt;/a&gt;을 구하는 것과 근본적으로 동일하다.&lt;br /&gt;
다만 단순 정수의 곱이 아닌 행렬곱을 사용할 뿐이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;알고리즘&quot;&gt;알고리즘&lt;/h2&gt;

&lt;p&gt;먼저 예를 하나 들어보자. 행렬 $A$의 11승을 구하고 싶다고 하자. 어떻게 계산하는 것이 빠르겠는가?&lt;/p&gt;

&lt;p&gt;단순무식한 방법을 적자면, $A^2$부터 구하면 된다. 그리고 $A^3$을 구한다. … 마지막으로 $A^{11}$을 구한다.&lt;br /&gt;
그러면 계산량은? 행렬곱 10번이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;나쁘지 않은데?&lt;/em&gt; 라고 생각한다면, N이 크면 당연히 &lt;strong&gt;시간 초과&lt;/strong&gt;임을 생각하라. N이 10억쯤 한다면? 10억 번을 1초 안에 계산할 수 있겠는가?&lt;br /&gt;
&lt;a href=&quot;https://www.acmicpc.net/problem/10830&quot;&gt;문제&lt;/a&gt;처럼 N(문제에서는 B이다.)이 $10^{11}$이나 한다면?&lt;/p&gt;

&lt;p&gt;당연히 이 방법으로는 어림도 없다. 그럼 조금 더 좋은 방법을 생각해야 한다.&lt;/p&gt;

&lt;p&gt;이제 $A^{11} = A \cdot A \cdot A \cdot A \cdot A \cdot A \cdot A \cdot A \cdot A \cdot A \cdot A$를 조금 다르게 써 보자.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A^{11} = (A^5)^2 \cdot A&lt;/script&gt;

&lt;p&gt;만약에 여러분이, $A^5$를 알고 있다고 하자. 그러면 계산을 몇 번이나 해야 할까?&lt;br /&gt;
행렬곱은 딱 두 번 뿐이다.&lt;/p&gt;

&lt;p&gt;조금 전 단순무식하게 구할 때를 떠올려보자. $A^5$로부터 $A^{11}$을 구하는 것은 행렬곱 연산이 6번이나 필요했다.&lt;br /&gt;
그러나 지금은 단 두 번만에 해결이 된다.&lt;/p&gt;

&lt;p&gt;이제 $A^5$를 구하는 방법을 생각해보자. 다음을 생각할 수 있을 것이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A^5 = (A^2)^2 \cdot A&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A^2 = (A)^2&lt;/script&gt;

&lt;p&gt;그러면 이것을 어떻게 코드로 옮길 것인가?&lt;br /&gt;
고려할 것이 몇 가지 있다. 하나씩 살펴보자.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A의 N승을 위의 방법으로 구할 때 반드시 고려해야 하는 부분은, 현재 구하고자 하는 N이 짝수인지 홀수인지이다.
    &lt;ul&gt;
      &lt;li&gt;만약 홀수라면, 다음과 같다. $ A^{2k+1} = (A^k)^2 \cdot A$이다.&lt;/li&gt;
      &lt;li&gt;만약 짝수라면, 조금 더 간단하다. $ A^{2k} = (A^k)^2 $이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;$A^N$을 구하기 전에, 먼저 2진수로 나타내 본다. N=11인 경우, N=$1011_2$이다.&lt;/li&gt;
  &lt;li&gt;$A^{11}$을 종이에 쓰고 천천히 생각해보라. 다음 두 가지 중 맞는 것은 무엇인가? N=$1011_2$이다.
    &lt;ul&gt;
      &lt;li&gt;가장 끝자리 비트(LSB)부터 고려하여 위의 거듭제곱 알고리즘을 따른다.&lt;/li&gt;
      &lt;li&gt;가장 앞자리 비트(MSB)부터 고려하여 위의 거듭제곱 알고리즘을 따른다.&lt;/li&gt;
      &lt;li&gt;답은 MSB부터 고려하는 것이다. N=11로 놓고 종이에 써보면, MSB를 고려하는 것은 $A^{11}$을 구하지만, LSB를 고려하는 것은 $A^{13}$을 구하게 될 것이다.&lt;/li&gt;
      &lt;li&gt;이것이 바로 &lt;a href=&quot;https://github.com/greeksharifa/ps_code/blob/master/library/matrix.h&quot;&gt;matrix.h&lt;/a&gt;에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;bit_reverse&lt;/code&gt; 함수를 사용하는 이유이다.&lt;/li&gt;
      &lt;li&gt;한 가지 더 주의할 점은, 비트 반전만 해서는 안된다. 100이 001로 바뀌어 그냥 1이 되기 때문이다. 따라서 자리수를 기억해 두어야 한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이제 $A^{11}$는 다음과 같은 순서로 구하면 된다는 것을 알 수 있을 것이다. 11=$1011_2$임을 기억하라.&lt;br /&gt;
물론 $A^0 = 1$이다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;이진수&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;식&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$ (A^0)^2 \cdot A = A^1 $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$ (A^1)^2 = A^2 $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$ (A^2)^2 \cdot A = A^5 $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$ (A^5)^2 \cdot A = A^{11} $&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;조금 더 복잡한 예를 들어보겠다. 46=$101110_2$이다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;이진수&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;식&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$ (A^0)^2 \cdot A = A^1 $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$ (A^1)^2 = A^2 $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$ (A^2)^2 \cdot A = A^5 $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$ (A^5)^2 \cdot A = A^{11} $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$ (A^{11})^2 \cdot A = A^{23} $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;$ (A^{23})^2 = A^{46} $&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;이진수로 나타냈을 때 해당 자리가 1이면 제곱한 후 A를 추가로 곱하고, 0이면 그냥 제곱만 하면 된다.&lt;/p&gt;

&lt;p&gt;행렬의 거듭제곱은 아주 복잡하지는 않다. 헷갈린다면 &lt;a href=&quot;https://greeksharifa.github.io/references/2018/07/13/it-will-update-soon/&quot;&gt;정수의 N 거듭제곱 빠르게 구하기&lt;/a&gt;을 참조하라.&lt;/p&gt;

&lt;h2 id=&quot;구현&quot;&gt;구현&lt;/h2&gt;

&lt;p&gt;거듭제곱이 구현된 행렬 클래스는 다음과 같다. 필자의 편의를 위해, &lt;code class=&quot;highlighter-rouge&quot;&gt;re_define.h&lt;/code&gt;에 &lt;code class=&quot;highlighter-rouge&quot;&gt;#define&lt;/code&gt;을 활용한 많은 단축 선언들을 사용했다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &quot;sharifa_header.h&quot;
#include &quot;bit_library.h&quot;
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mat_mul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matrix_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matrix_B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matrix_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matrix_A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matrix_B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matrix_power_N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;binary_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;original&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    
	&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bit_reverse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mat_mul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mat_mul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;original&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%d &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;puts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ret&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;문제-풀이&quot;&gt;문제 풀이&lt;/h2&gt;

&lt;p&gt;사용법은 어렵지 않다. 행렬을 2차원 벡터로 만든다.&lt;br /&gt;
그리고 행렬을 N승을 취한 후, &lt;code class=&quot;highlighter-rouge&quot;&gt;print&lt;/code&gt; 인자를 &lt;code class=&quot;highlighter-rouge&quot;&gt;true&lt;/code&gt;로 주어 &lt;code class=&quot;highlighter-rouge&quot;&gt;matrix_power_N&lt;/code&gt; 함수를 호출하면 문제는 풀린다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &quot;../library/matrix.h&quot;
&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#define mod 1000
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main_10830&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;scanf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%d%d&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;original&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;scanf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%d&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;original&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;matrix_power_N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;original&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 코드를 그대로 복붙하여 채점 사이트에 제출하면 당연히 틀린다. 못 믿겠다면, 저런 헤더 파일이 채점 사이트에 있을 것이라 생각하는가?&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Residual Neural Network with CNN</title>
   <link href="http://localhost:4000/Residual-Neural-Network/"/>
   <updated>2018-07-01T00:00:00+09:00</updated>
   <id>http://localhost:4000/Residual Neural Network</id>
   <content type="html">&lt;h2 id=&quot;resnet&quot;&gt;Resnet&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;이 글에서는 Vanishing Gradients를 해결하는 하나의 방안인 &lt;strong&gt;Residual Block&lt;/strong&gt;을 사용한
Residual Neural Network를 구성하는 방법에 대해 설명하겠다.
본 글은 아래 참조문헌과
Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun - Deep Residual Learning for Image Recognition (2015)
Andrew Ng의 Deep Learning Specialization 강좌의 Programmin Assignment 코드를 대부분 이용한 것임을 밝힌다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;1-원리-설명&quot;&gt;[1] 원리 설명&lt;/h4&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018-07-01-Residual Neural Network/Res01.jpg&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;본 Resnet은 Identity Block과 Convolutional Block을 사용하는데 그 구조는 아래와 같다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018-07-01-Residual Neural Network/Res02.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018-07-01-Residual Neural Network/Res03.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018-07-01-Residual Neural Network/Res04.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018-07-01-Residual Neural Network/Res05.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018-07-01-Residual Neural Network/Res06.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018-07-01-Residual Neural Network/Res07.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

&lt;h4 id=&quot;2-데이터셋-로딩&quot;&gt;[2] 데이터셋 로딩&lt;/h4&gt;
&lt;p&gt;사용하는 패키지, 모듈은 다음과 같다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Setting
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BatchNormalization&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AveragePooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.models&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.initializers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;h5py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy.misc&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.preprocessing&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.applications.imagenet_utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preprocess_input&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plot_model&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.backend&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_image_data_format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'channels_last'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_learning_phase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;본 글에서 사용하는 데이터셋은 .h5 파일 형식으로 되어있는데 이 hdf파일은 다음과 같이 로드하면 된다.
위에서처럼 h5py 패키지를 설치 후 import 해주어야 한다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h5py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;File&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'path1/file.h5'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'r+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h5py&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;File&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'path2/file.h5'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'r+'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_train_orig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train_set_x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test_orig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'test_set_x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y_train_orig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train_set_y'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test_orig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'test_set_y'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_test_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;X_train shape: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_train_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;X_test shape: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_test_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Y_train shape: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Y_train shape: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h4 id=&quot;3-코드&quot;&gt;[3] 코드&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Normalize image vectors
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test_orig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Identity Block
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;identity_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)
    f -- integer, specifying the shape of the middle CONV's window for the main path: filter shape
    filters -- python list of integers, the number of filters in the CONV layers
    stage -- integer, name the layers, depending on their position in the network
    block -- string/character, name the layers, depending on their position in the network

    Returns: X -- output of the identity block, tensor of shape (n_H, n_W, n_C)
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# defining name basis
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;conv_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'res'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'_branch'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bn_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'bn'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'_branch'&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Retrieve Filters
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;F1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Save the input value.
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X_shortcut&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# glorot_uniform = Xavier uniform, BatchNormalization axis=3 means normalizing channels
&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# First component of main path
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'valid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'2a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BatchNormalization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bn_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'2a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Second component
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'same'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'2b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BatchNormalization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bn_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'2b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Third component
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'valid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'2c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BatchNormalization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bn_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'2c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Final step: Add shortcut value to main path, and pass it through a RELU
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_shortcut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;convolutional_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)
    f -- integer, specifying the shape of the middle CONV's window for the main path
    filters -- python list of integers, defining the number of filters in the CONV layers of the main path
    stage -- integer, used to name the layers, depending on their position in the network
    block -- string/character, used to name the layers, depending on their position in the network
    s -- Integer, specifying the stride to be used

    Returns: X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Setting
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;conv_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'res'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'_branch'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bn_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'bn'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'_branch'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;F1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X_shortcut&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;##### MAIN PATH #####
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# First component of main path
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'2a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BatchNormalization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bn_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'2a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Second component of main path
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'2b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'same'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BatchNormalization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bn_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'2b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Third component of main path
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'2c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BatchNormalization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bn_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'2c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;##### SHORTCUT PATH ####
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X_shortcut&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                        &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_shortcut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X_shortcut&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BatchNormalization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bn_name_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_shortcut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Final step: Add shortcut value to main path, and pass it through a RELU
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_shortcut&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ResNet50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    CONV2D -&amp;gt; BATCHNORM -&amp;gt; RELU -&amp;gt; MAXPOOL
    -&amp;gt; (CONVBLOCK, IDBLOCK*2) -&amp;gt; (CONVBLOCK, IDBLOCK*3) -&amp;gt; (CONVBLOCK, IDBLOCK*5)
    -&amp;gt; (CONVBLOCK, IDBLOCK*2) -&amp;gt; AVGPOOL -&amp;gt; TOPLAYER

    Arguments:
    input_shape -- shape of the images of the dataset
    classes -- integer, 라벨 수

    Returns: model -- a Model() instance in Keras
    &quot;&quot;&quot;&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Define the input as a tensor with shape input_shape
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Zero-Padding
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Stage 1
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'conv1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BatchNormalization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bn_conv1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Stage 2
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convolutional_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;identity_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;identity_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Stage 3
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convolutional_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;identity_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;identity_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;identity_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'d'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Stage 4
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convolutional_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;identity_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;identity_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;identity_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'d'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;identity_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'e'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;identity_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'f'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Stage 5
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convolutional_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2048&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;identity_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2048&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'b'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;identity_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2048&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# AVGPOOL: don't use padding in pooling layer
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AveragePooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'valid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'avg_pool'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# output layer
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'fc'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Create model
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ResNet50'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 학습
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ResNet50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'adam'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'categorical_crossentropy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Test the result
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Loss = &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Test Accuracy = &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;현재 이 모델의 경우 &lt;em&gt;epochs=20&lt;/em&gt; 정도로 하면 90%를 넘는 정확도를 보이는 것으로 확인되었다.&lt;/p&gt;

&lt;p&gt;다른 이미지로 확인을 해보고 싶다면 아래 함수를 이용하면 된다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 다른 이미지로 테스트
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;img_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'i01.jpg'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;img_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'C:/Users/YY/Documents/Winter Data/NN/Resnet_color_hand_sign/real test/'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_to_array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preprocess_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;255&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;my_image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scipy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;misc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Use imageio.imread
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_image&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my_image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'i05.jpg'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;4-모델-시각화&quot;&gt;[4] 모델 시각화&lt;/h2&gt;
&lt;p&gt;모델을 시각화 하고 싶다면 아래와 같은 코드를 이용하면 된다.
현재 py파일이 있는 디렉토리에 png 파일이 저장될 것이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 모델 시각화
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plot_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'resnet.png'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;show_shapes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;show_layer_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;다음은 본 모델 구조의 최하단부를 나타낸다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Deep_Learning/2018-07-01-Residual Neural Network/Res08.JPG&quot; width=&quot;100%&quot; /&gt;&lt;/center&gt;

</content>
 </entry>
 
 <entry>
   <title>Markdown 사용법</title>
   <link href="http://localhost:4000/markdown-usage/"/>
   <updated>2018-06-29T00:00:00+09:00</updated>
   <id>http://localhost:4000/markdown-usage</id>
   <content type="html">&lt;p&gt;마크다운을 쓸 때는 메모장으로도 되지만 JetBrains의 Webstorm에 Markdown support plugins을 설치하는 것이 도움이 된다.&lt;/p&gt;

&lt;p&gt;참조: &lt;a href=&quot;https://simhyejin.github.io/2016/06/30/Markdown-syntax/&quot;&gt;simhyejin.github.io&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;위의 글에 잘 설명되어 있지만,
복사해 놓고 쓰기 편하도록 본 글에 정리해 두었다.&lt;/p&gt;

&lt;p&gt;참고로 넓은 개행을 하려면 한 줄을 띄우고 작성해야 한다.&lt;/p&gt;

&lt;p&gt;좁은 개행은 문장 끝에 공백을 두 개 붙이면 된다.&lt;/p&gt;

&lt;p&gt;그러나 여러 줄을 띄워도 효과는 똑같다.
공백 문자                   (스페이스바)            도 마찬가지이다.&lt;/p&gt;

&lt;p&gt;들여쓰기는 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;amp;nbsp;&lt;/code&gt;을 사용한다. 하나당 하나의 공백이다.&lt;/p&gt;

&lt;h1 id=&quot;가장-큰-제목&quot;&gt;가장 큰 제목&lt;/h1&gt;

&lt;h3 id=&quot;적당한-제목&quot;&gt;적당한 제목&lt;/h3&gt;

&lt;p&gt;이 글은 보고 쓰기 위해 작성되었다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;[링크](https://google.com/)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://google.com/&quot;&gt;링크&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[참조 링크][1]

[1]:  https://greeksharifa.github.io/references/2018/06/29/markdown-usage/ &quot;YW &amp;amp; YY's blog: markdown-usage&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/references/2018/06/29/markdown-usage/&quot; title=&quot;YW &amp;amp; YY's blog: markdown-usage&quot;&gt;참조 링크&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;빈 줄을 넣는 것을 추천한다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;url 링크: &amp;lt;https://google.com/&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;url 링크: &lt;a href=&quot;https://google.com/&quot;&gt;https://google.com/&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;어쩐지 처음으로 돌아가고 싶은가? 내부 링크는 이렇게 사용한다. [가장 큰 제목](#가장-큰-제목)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;어쩐지 처음으로 돌아가고 싶은가? 내부 링크는 이렇게 사용한다. &lt;a href=&quot;#가장-큰-제목&quot;&gt;가장 큰 제목&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;내부 링크의 #id 규칙은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;가능하면 괄호는 쓰지 않는다. 제대로 작동하지 않는다.&lt;/li&gt;
  &lt;li&gt;영문자는 lowercase로, 한글은 그대로 둔다.&lt;/li&gt;
  &lt;li&gt;문자/숫자/space/하이픈 외의 문자는 모두 제거한다.&lt;/li&gt;
  &lt;li&gt;space는 하이픈으로 대체한다.&lt;/li&gt;
  &lt;li&gt;만약 제목이 유일한 이름이 아니라면, &lt;code class=&quot;highlighter-rouge&quot;&gt;-1&lt;/code&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;-2&lt;/code&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;-3&lt;/code&gt; 등을 붙인다.&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&amp;gt; 인용하려면 이와 같이 한다.
&amp;gt;&amp;gt; 인용을 안에 또 하고 싶으면 이렇게 한다.
&amp;gt;&amp;gt;&amp;gt; 더 할 수 있다.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;인용하려면 이와 같이 한다.&lt;/p&gt;
  &lt;blockquote&gt;
    &lt;p&gt;인용을 안에 또 하고 싶으면 이렇게 한다.&lt;/p&gt;
    &lt;blockquote&gt;
      &lt;p&gt;더 할 수 있다.&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;코드 블럭이다. ```을 써도 되고 ~~~을 써도 된다.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;greetings = input()
print('Hello, Markdown!') # greetings는 안썼음
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;조그맣게 쓰고 싶다면 이렇게&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;*기울여 쓰기*     _기울여 쓰기_

**Bold로 쓰기**     __Bold로 쓰기__

***기울이고 Bold로 쓰기*** ___기울이고 Bold로 쓰기___

~~취소하기~~
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;기울여 쓰기&lt;/em&gt;     &lt;em&gt;기울여 쓰기&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bold로 쓰기&lt;/strong&gt;     &lt;strong&gt;Bold로 쓰기&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;기울이고 Bold로 쓰기&lt;/em&gt;&lt;/strong&gt; &lt;strong&gt;&lt;em&gt;기울이고 Bold로 쓰기&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;취소하기&lt;/del&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
---

수평선. 앞뒤로 빈 줄을 하나씩 넣는 것이 좋다.

***

다시 수평선

___

-------------

* * *

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;수평선. 앞뒤로 빈 줄을 하나씩 넣는 것이 좋다.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;다시 수평선&lt;/p&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;hr /&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
- [ ] 체크리스트
- [x] 완료 리스트

1. 순서 있는 리스트
2. 순서 있는 리스트
0. 사실 숫자는 순서가 없어도 된다.
-1232. 물론 음수는 안 된다.
11111111. 뭐 그래도 숫자는 맞춰 주는 것이 좋긴 하다.

* 순서를 없애고 싶으면 이렇게
  * 탭을 누르고 치면 이렇게 보인다.
  - 사실 *, -, + 를 섞어서 써도 잘 보인다.
  + 하지만 굳이 그렇게 할 필요는 없다.
       * 탭은 적당히 쳐야 잘 보인다.
                          * 너무 많이 하면 효과가 없다.
                          - 이미 효과가 없다.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;ul class=&quot;task-list&quot;&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; /&gt;체크리스트&lt;/li&gt;
  &lt;li class=&quot;task-list-item&quot;&gt;&lt;input type=&quot;checkbox&quot; class=&quot;task-list-item-checkbox&quot; disabled=&quot;disabled&quot; checked=&quot;checked&quot; /&gt;완료 리스트&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
  &lt;li&gt;순서 있는 리스트&lt;/li&gt;
  &lt;li&gt;순서 있는 리스트&lt;/li&gt;
  &lt;li&gt;사실 숫자는 순서가 없어도 된다.
-1232. 물론 음수는 안 된다.&lt;/li&gt;
  &lt;li&gt;뭐 그래도 숫자는 맞춰 주는 것이 좋긴 하다.&lt;/li&gt;
&lt;/ol&gt;

&lt;ul&gt;
  &lt;li&gt;순서를 없애고 싶으면 이렇게
    &lt;ul&gt;
      &lt;li&gt;탭을 누르고 치면 이렇게 보인다.&lt;/li&gt;
      &lt;li&gt;사실 *, -, + 를 섞어서 써도 잘 보인다.&lt;/li&gt;
      &lt;li&gt;하지만 굳이 그렇게 할 필요는 없다.
        &lt;ul&gt;
          &lt;li&gt;탭은 적당히 쳐야 잘 보인다.
                 * 너무 많이 하면 효과가 없다.
                 - 이미 효과가 없다.
```&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Header 1&lt;/th&gt;
      &lt;th&gt;Header 2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Content 1&lt;/td&gt;
      &lt;td&gt;—의 개수는 상관없음.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Content 2&lt;/td&gt;
      &lt;td&gt;Content 4&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;| Header 1 | Header 2 | Header 3 |
| :——– | :———-: | ——–: |
| Left | Center | —의 개수가 달라도 됨. |&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
Header 1 | Header 2
------------------ | --------------------
Content 1 | ---의 개수는 상관없음.
Content 2 | Content 4

| Header 1 | Header 2 | Header 3 |
| :-------- | :----------: | --------: |
| Left | Center | ---의 개수가 달라도 됨. |

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이미지는 이렇게(링크랑 비슷)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/test1.png&quot; alt=&quot;alt text&quot; /&gt;
&lt;img src=&quot;image_URL&quot; alt=&quot;alt text&quot; /&gt;
&lt;img src=&quot;https://greeksharifa.github.io/references/2018/06/29/markdown-usage/&quot; alt=&quot;alt text&quot; title=&quot;YW &amp;amp; YY's blog: markdown-usage&quot; /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/references/2018/06/29/markdown-usage/&quot; title=&quot;YW &amp;amp; YY's blog: markdown-usage&quot;&gt;1&lt;/a&gt;: /test3.png&lt;/p&gt;

&lt;p&gt;예시:&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Andre_Derain_Fishing_Boats_Collioure.jpg&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Andre_Derain_Fishing_Boats_Collioure.jpg&quot; alt=&quot;01_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;```
이미지는 이렇게(링크랑 비슷)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/test1.png&quot; alt=&quot;alt text&quot; /&gt;
&lt;img src=&quot;image_URL&quot; alt=&quot;alt text&quot; /&gt;
&lt;img src=&quot;https://greeksharifa.github.io/references/2018/06/29/markdown-usage/&quot; alt=&quot;alt text&quot; title=&quot;YW &amp;amp; YY's blog: markdown-usage&quot; /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/references/2018/06/29/markdown-usage/&quot; title=&quot;YW &amp;amp; YY's blog: markdown-usage&quot;&gt;1&lt;/a&gt;: /test3.png&lt;/p&gt;

&lt;p&gt;예시:&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/public/img/Andre_Derain_Fishing_Boats_Collioure.jpg&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/Andre_Derain_Fishing_Boats_Collioure.jpg&quot; alt=&quot;01_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;편하게 하려면,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;/public/img directory 안에 /categories_name/post_file_name directory를 만든다.&lt;/li&gt;
  &lt;li&gt;만든 directory 안에 이미지를 붙여 넣는다.&lt;/li&gt;
  &lt;li&gt;WebStorm에 보이는 이미지에서 Ctrl + Shift + Alt + C 를 눌러 상대 경로를 복사한다.&lt;/li&gt;
  &lt;li&gt;그리고 위의 예시의 src 항목에다 붙여넣기 하면 된다. 이때 반드시 &lt;code class=&quot;highlighter-rouge&quot;&gt;/public/img/&lt;/code&gt;으로 시작해야 한다.&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>GitHub 사용법 - 02. 프로젝트와 repository 생성</title>
   <link href="http://localhost:4000/github-usage-02-create-project/"/>
   <updated>2018-06-29T00:00:00+09:00</updated>
   <id>http://localhost:4000/github-usage-02-create-project</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;&lt;em&gt;주의: 이 글을 읽는 여러분이, 만약 git을 많이 써 봐서 익숙한 것이 아니라면, 반드시 손으로 직접 따라 칠 것을 권한다. 눈으로만 보면 100% 잊어버린다.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;remote-repository-생성&quot;&gt;Remote Repository 생성&lt;/h2&gt;

&lt;p&gt;우선 &lt;a href=&quot;https://github.com/&quot;&gt;https://github.com/&lt;/a&gt;에 접속하여 로그인한다(회원가입은 되어 있어야 한다). 그러면 다음과 비슷한 화면이 보인다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/01_new_repository.PNG&quot; alt=&quot;01_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;New repository&lt;/strong&gt;를 클릭한 후, 프로젝트 이름을 &lt;strong&gt;git_tutorial&lt;/strong&gt;으로 입력한다. 원하는 이름으로 해도 상관없다.&lt;br /&gt;
또 &lt;strong&gt;Description&lt;/strong&gt;을 성심성의껏 잘 작성한다.&lt;/p&gt;

&lt;p&gt;그리고 &lt;strong&gt;Initialize this repository with a README&lt;/strong&gt; 체크박스에 체크한다.&lt;br /&gt;
체크하지 않고 만든다면 git repository를 처음 만든 이후 local repository와 연결하는 방법을 알려주는 안내 글이 뜬다. 이를 읽어 봐도 괜찮다.&lt;/p&gt;

&lt;p&gt;지금은 체크하지 않는 것이 간단하므로 체크하지 않겠다. 그림에 체크되어 있는 것은 무시하자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/02_create_a_new_repository.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;마지막으로 &lt;strong&gt;Create repository&lt;/strong&gt;를 누른다.&lt;/p&gt;

&lt;p&gt;그러면 이제 여러분의 GitHub 계정에 &lt;strong&gt;git_tutorial&lt;/strong&gt;이란 이름의 remote repository가 생성될 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/03_created_remote_repository.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;local-repository-생성&quot;&gt;Local Repository 생성&lt;/h2&gt;

&lt;p&gt;그리고 이제 local에서 directory를 하나 생성한다. Directory 이름은 프로젝트와 같은 이름으로 하고, 생성하는 위치는 본인 마음대로 하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/04_local_directory.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;다음으로 명령창(터미널 또는 cmd 창)을 하나 띄운다. &lt;code class=&quot;highlighter-rouge&quot;&gt;cd '경로명'/git_tutorial&lt;/code&gt;으로 하면 된다. 예시는 절대 경로이지만, 상대 경로로 해도 무방하다.&lt;br /&gt;
필자는 윈도우 환경(cmd)에서 진행하였다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;cd C:\Users\Sharifa-D\WebstormProjects\git_tutorial&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그리고 다음 명령들을 수행해 본다. 만약에 git이 유효한 명령이 아니라는 error가 뜬다면, 본인의 운영체제이 맞는 git을 설치해야 한다.&lt;br /&gt;
윈도우의 경우 &lt;a href=&quot;https://git-scm.com/download/win&quot;&gt;여기&lt;/a&gt;에서 다운받아 설치하면 된다(64bit 기준).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git init&lt;br /&gt;
git status&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;똑같은 과정을 거쳤다면, 다음 그림과 같은 화면이 나올 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/05_cmd.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기까지 했다면, local repository를 성공적으로 생성한 것이다.
오류가 뜬다면, 복잡해 보이는 에러 메시지를 그대로 복붙하여 &lt;a href=&quot;https://google.com/&quot;&gt;구글링&lt;/a&gt;하면 된다.&lt;br /&gt;
여러분이 겪는 문제는 다른 사람들도 겪어 본 문제라는 것을 해결법과 함께 알 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;프로젝트-수정&quot;&gt;프로젝트 수정&lt;/h2&gt;

&lt;h3 id=&quot;파일-생성하고-수정하기&quot;&gt;파일 생성하고 수정하기&lt;/h3&gt;

&lt;p&gt;이제 여러분은 1) remote repository와 2) local repository를 모두 생성했다. 그러면 이제 두 repo(repository)를 연결하는 부분이 필요할 것이다.&lt;/p&gt;

&lt;p&gt;연결은 어렵지 않다. 하지만 그 전에 파일을 조금 작성해보자. 빈 프로젝트 갖고 뭘 하기엔 심심하지 않은가?&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;란 파일을 하나 생성한다. 그리고 다음과 같은 내용을 작성해보자.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Hello, git!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# instead of &quot;Hello, World!&quot;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;심심하다면 &lt;code class=&quot;highlighter-rouge&quot;&gt;python first.py&lt;/code&gt;를 명령창에 입력해 보자.&lt;/p&gt;

&lt;p&gt;그리고 &lt;code class=&quot;highlighter-rouge&quot;&gt;git status&lt;/code&gt;를 다시 입력한다. 조금 전과는 다른 화면을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/06_python_first.py.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여기서 중요한 정보를 몇 개 찾을 수 있다. 앞으로 git을 사용할 때에는 무슨 메시지가 뜨는지 (전부) 살펴보는 것이 굉장히 중요하다.
뭔가 잘못되었는지 아닌지를 볼 수 있기 때문이다.&lt;/p&gt;

&lt;p&gt;위에서부터 하나씩 살펴보면 아래와 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;On branch master
    &lt;ul&gt;
      &lt;li&gt;지금 작업하는 &lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-01-introduction/#branch-%EB%B8%8C%EB%9E%9C%EC%B9%98&quot;&gt;branch&lt;/a&gt;가 master라는 의미이다. 본인이 어떤 branch에서 작업 중인지 확인하는 습관을 반드시 가지도록 한다. branch를 잘못 옮긴 줄 모르고 작업을 이어갔다가는 큰일 날 수 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;No commits yet
    &lt;ul&gt;
      &lt;li&gt;아직 생성한 &lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-01-introduction/#add-commit-push&quot;&gt;commit&lt;/a&gt;이 없다는 뜻이다. 이후에 commit을 추가하면, 이 부분이 다르게 보일 것이다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Untracked files:  (use “git add &lt;file&gt;...&quot; to include in what will be committed)
&lt;/file&gt;    &lt;ul&gt;
      &lt;li&gt;여러분이 수정하긴 했지만 staging area에 올라가지 않은 파일의 목록이다. staging area에 올라갔다는 말은 track한다는 말과 같다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;first.py
    &lt;ul&gt;
      &lt;li&gt;여러분은 아직 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt; 명령을 사용하지 않았기 때문에 수정/생성/삭제한 유일한 파일인 &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;가 tracking되지 않고 있다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;nothing added to commit but untracked files present (use “git add” to track)
    &lt;ul&gt;
      &lt;li&gt;tracking하려면 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt;를 쓰라고 한다. 메시지에는 도움이 되는 내용이 많다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;조금 더 자세히 설명하기 위해, &lt;code class=&quot;highlighter-rouge&quot;&gt;second.py&lt;/code&gt; 파일을 생성한다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Why don't you answer me, git?&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;git-add&quot;&gt;git add&lt;/h3&gt;

&lt;p&gt;그리고 조금 전 메시지가 친절히 알려줬던 &lt;strong&gt;git add&lt;/strong&gt; 명령을 사용하려고 한다. 명령창에 다음과 같이 입력한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git add first.py&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이제 다시 한번 &lt;code class=&quot;highlighter-rouge&quot;&gt;git status&lt;/code&gt;를 입력하면, 아까보다 메시지가 더 많은 것을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/07_git_status.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그림을 보면 tracking되고 있는 파일은 초록색, untracked file은 빨간색으로 되어 있음을 알 수 있다.
여러분은 &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt; 는 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt;로 추가했기 때문에 초록색으로, &lt;code class=&quot;highlighter-rouge&quot;&gt;second.py&lt;/code&gt;는 그러지 않았기 때문에 빨간색으로 남아 있음을 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;이번에는 다른 명령을 연습해보자. &lt;code class=&quot;highlighter-rouge&quot;&gt;git add .&lt;/code&gt;을 입력한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;git status&lt;/code&gt;로 확인해보면?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/11_git_add_all.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;.&lt;/code&gt;의 의미는 &lt;strong&gt;모든 파일과 디렉토리&lt;/strong&gt;이다.
즉, 여러분은 프로젝트에 존재하는 모든 파일(&lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;second.py&lt;/code&gt;)를 staging area에 추가한 것이다.&lt;/p&gt;

&lt;p&gt;옵션으로, &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt;의 다양한 버전을 표로 정리해 두었다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;명령어&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;git add first.py&lt;/td&gt;
      &lt;td&gt;first.py 파일 하나를 staging area에 추가한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git add my_directory/                               &lt;/td&gt;
      &lt;td&gt;my_directory라는 이름의 디렉토리와 그 디렉토리 안의 모든 파일과 디렉토리를 staging area에 추가한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git add .&lt;/td&gt;
      &lt;td&gt;현재 폴더의 모든 파일과 디렉토리, 하위 디렉토리에 든 전부를 staging area에 추가한다. 규모가 큰 프로젝트라면 써서는 안 된다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git add -p [&amp;lt;파일&amp;gt;]&lt;/td&gt;
      &lt;td&gt;파일의 일부를 staging하기&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git add -i&lt;/td&gt;
      &lt;td&gt;Git 대화 모드를 사용하여 파일 추가하기&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git add -u [&amp;lt;경로&amp;gt;]&lt;/td&gt;
      &lt;td&gt;수정되고 추적되는 파일의 변경 사항 staging하기&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;옵션-같은-파일이-changes-to-be-committed와-untracked-files-모두에-있는-경우&quot;&gt;옵션: 같은 파일이 &lt;em&gt;changes to be committed&lt;/em&gt;와 &lt;em&gt;Untracked files&lt;/em&gt; 모두에 있는 경우&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;이 부분은 옵션이다. git이 아직 잘 이해가 되지 않는다면, 반드시 할 필요는 없다. 
&lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-02-create-project/#git-commit&quot;&gt;여기&lt;/a&gt;로 바로 넘어가면 된다.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt; 파일을 다음과 같이 수정한다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Hello, git!&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# instead of &quot;Hello, World!&quot;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Don't you hear me, git?&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그리고 &lt;em&gt;다른 명령을 하지 않은 채로&lt;/em&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;git status&lt;/code&gt;를 명령창에 입력한다. 그럼 다음과 같을 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/08_both_exists.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여러분이 한 것을 되짚어 보면 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;를 생성 및 수정하였다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;를 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt; 명령으로 staging area에 추가하였다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;를 또 수정하였다.&lt;/li&gt;
  &lt;li&gt;다른 명령(&lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt;나 &lt;code class=&quot;highlighter-rouge&quot;&gt;git commit&lt;/code&gt; 등)을 하지 않는 채로 &lt;code class=&quot;highlighter-rouge&quot;&gt;git status&lt;/code&gt;로 상태를 확인하였다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이런 과정을 거쳤을 때 여러분은 동일한 파일이 &lt;em&gt;changes to be committed&lt;/em&gt;와 &lt;em&gt;Untracked files&lt;/em&gt;에 모두 있는 광경을 볼 수 있는 것이다.&lt;/p&gt;

&lt;p&gt;즉, 이는 오류가 아니라,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;이미 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add&lt;/code&gt;로 추가한 적이 있으니 &lt;em&gt;changes to be committed&lt;/em&gt;에 있는 것이고&lt;/li&gt;
  &lt;li&gt;그 이후에 수정한 사항은 staging area에 올라가지 않았으니 &lt;em&gt;Untracked files&lt;/em&gt;에도 있는 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;어렵지 않게 이해할 수 있을 것이다.&lt;/p&gt;

&lt;h3 id=&quot;옵션-git-add-취소-git-rm-cached-file&quot;&gt;옵션: git add 취소, git rm –cached &amp;lt;file&amp;gt;&lt;/h3&gt;

&lt;p&gt;여러분이 메시지를 꼼꼼히 읽어봤다면, 다음과 같은 문구를 보았을 것이다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;(use “git rm –cached &lt;file&gt;...&quot; to unstage)&lt;/file&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이는 staging area에 올라간 파일을 unstage하겠다는 뜻으로, git add를 취소하는 것과 같은 효과를 가진다.
즉 &lt;em&gt;cached&lt;/em&gt;된 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;file&amp;gt;&lt;/code&gt;을 (staging area에서) rm(remove)하겠다는 의미이다.&lt;/p&gt;

&lt;p&gt;무슨 일을 하는지 알았으니, &lt;code class=&quot;highlighter-rouge&quot;&gt;git rm --cached first.py&lt;/code&gt;를 명령창에 입력한다. 그리고 &lt;code class=&quot;highlighter-rouge&quot;&gt;git status&lt;/code&gt;를 쳐보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/09_rm_cached_error.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;에러가 뜬다. 메시지를 의역하면, &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;가 실제 파일 내용이랑 git이 인식하는 파일 내용이 달라서 staging area에서 제거할 수 없다는 뜻이다.&lt;/p&gt;

&lt;p&gt;어차피 여러분은 이 파일을 unstage하는 것이 목적이었으므로, &lt;code class=&quot;highlighter-rouge&quot;&gt;git add first.py&lt;/code&gt;이후 &lt;code class=&quot;highlighter-rouge&quot;&gt;git rm --cached first.py&lt;/code&gt;를 입력해주면 그만이다.
&lt;code class=&quot;highlighter-rouge&quot;&gt;git status&lt;/code&gt;로 상태를 확인해주자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/10_rm_cached.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 &lt;strong&gt;옵션&lt;/strong&gt;을 안 한 상태로 되돌리기 위해, &lt;code class=&quot;highlighter-rouge&quot;&gt;first.py&lt;/code&gt;에 추가한 내용을 지우고 &lt;code class=&quot;highlighter-rouge&quot;&gt;git add .&lt;/code&gt;를 입력한다.&lt;/p&gt;

&lt;h3 id=&quot;git-commit&quot;&gt;git commit&lt;/h3&gt;

&lt;p&gt;현재 다음과 같은 상태일 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/11_git_add_all.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 commit을 할 차례이다. 커밋이란 수정사항들을 하나로 묶는 것이라 보면 된다. &lt;br /&gt;
실제 프로젝트에서 하나의 커밋이란 하나의 기능이라 보면 된다. 하니의 기능이란 새 기능일 수도 있고, 버그 수정일 수도 있고, 단순 개선 사항일 수 있다.&lt;/p&gt;

&lt;p&gt;커밋은 여러 종류가 있지만, 가장 간단한 버전은 다음과 같다.&lt;br /&gt;
&lt;strong&gt;&lt;em&gt;주의: 아직 명령창에 적지 않는다.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git commit -m “commit-message”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;명령어를 입력할 때 &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;에 알파벳을 붙여 쓰는 경우가 있다. 이는 옵션을 주겠다는 의미이다.&lt;br /&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;-m&lt;/code&gt; 옵션을 주면서 &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;&lt;/code&gt;로 묶은 메시지를 전달하면, &lt;strong&gt;commit-message라는 description으로 커밋을 하나 만든다&lt;/strong&gt;라는 의미가 된다.&lt;/p&gt;

&lt;h4 id=&quot;옵션-좋은-commit-message-작성법&quot;&gt;옵션: 좋은 commit message 작성법&lt;/h4&gt;

&lt;p&gt;왜 명령창에 적지 말라고 했냐면, 이 방식으로 하는 것은 큰 프로젝트를 다룰 때 굉장히 안 좋은 습관이다. 
고작 한 문장짜리로 커밋의 모든 내용을 설명할 수 있겠는가? 만약에 커밋 내용이 다음과 같은 일을 한다고 하자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;이 커밋은 #101번과 #104번 이슈를 해결하기 위해 작성된 것이다. 이 문제에 관한 자세한 내용은 #203번과 #223번을 참조하라.&lt;br /&gt;
해당 문제를 해결하기 위해 다음과 같은 방법을 사용하였다. 블라블라&lt;br /&gt;
문제는 해결되었지만, 아직 다음과 같은 (사소한) 문제가 남아 있다. #401번을 참조하라.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;한 문장에 실수 없이 적을 수 있겠는가?&lt;br /&gt;
자신이 있다면 말리진 않겠지만, 별로 좋은 습관이 아니란 것은 명확하다.&lt;/p&gt;

&lt;p&gt;좋은 commit message 작성법에 관한 내용은 &lt;a href=&quot;https://item4.github.io/2016-11-01/How-to-Write-a-Git-Commit-Message/&quot;&gt;여기&lt;/a&gt;를 참조하라.&lt;/p&gt;

&lt;h4 id=&quot;다시-commit하기&quot;&gt;다시 commit하기&lt;/h4&gt;

&lt;p&gt;아무튼 다음과 같이 입력한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git commit&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;그럼 뭔가 화려한 편집 창이 보인다. vi 편집기라고 보면 된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/12_git_commit.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;i&lt;/strong&gt;를 누른다. insert를 한다는 뜻이다.&lt;br /&gt;
그리고 commit message를 최대한 상세히 입력한다.&lt;/p&gt;

&lt;p&gt;다 입력했으면, &lt;strong&gt;ESC&lt;/strong&gt;를 누른다. 그리고, &lt;strong&gt;:wq&lt;/strong&gt;를 입력한 후 &lt;strong&gt;Enter&lt;/strong&gt;를 누른다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/14_git_commit_complete.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;vi 편집기에서는, 입력 모드와 명령 모드가 있다.&lt;br /&gt;
입력 모드는 일반적인 텍스트 편집기와 같다.&lt;br /&gt;
명령 모드는 옵션을 주고 여러 조작을 할 수 있다. 자세한 설명은 &lt;a href=&quot;https://greeksharifa.github.io/references/2018/07/13/it-will-update-soon/&quot;&gt;Vim 사용법&lt;/a&gt;를 참조하면 된다. 
여기서는 &lt;strong&gt;w&lt;/strong&gt;는 저장이고 &lt;strong&gt;q&lt;/strong&gt;는 quit을 의미한다는 것만 알아도 된다.&lt;/p&gt;

&lt;p&gt;이제 commit에 대한 간단한 설명이 끝났다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;remote--local-repository-연결&quot;&gt;Remote &amp;amp; Local Repository 연결&lt;/h2&gt;

&lt;p&gt;이제 연결을 할 차례이다. 근데 할 것이 한 가지 더 남았다. 사용자 등록 과정이다.&lt;/p&gt;

&lt;p&gt;등록 과정은 두 가지 방법이 있다. 전역 설정을 하느냐, repo 별로 설정을 하느냐이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;전역 설정
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git config --global user.name &quot;Your name&quot;&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;여러분의 github 아이디를 적으면 된다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git config --global user.email &quot;Your email&quot;&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;여러분의 github 이메일 계정을 적으면 된다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;repo별 설정
    &lt;ul&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git config user.name &quot;Your name&quot;&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;–global 옵션이 없다. 여러분의 github 아이디를 적으면 된다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git config  user.email &quot;Your email&quot;&lt;/code&gt;
        &lt;ul&gt;
          &lt;li&gt;역시 –global 옵션이 없다. 여러분의 github 이메일 계정을 적으면 된다.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;전역 설정과 repo별 설정의 차이를 굳이 설명할 필요는 없을 것이다.&lt;/p&gt;

&lt;p&gt;일단은 global 설정부터 시작하자. Your name/email은 여러분 스스로 입력하길 바란다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git config –global user.name “Your name”
git config –global user.email “Your email”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;추가로 해야만 하는 것은 없지만, 등록된 사용자를 확인하는 방법도 알아야 하지 않겠는가?&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;명령어&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;git config –global –list&lt;/td&gt;
      &lt;td&gt;전역 설정 정보 조회&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git config –list&lt;/td&gt;
      &lt;td&gt;repo별 설정 정보 조회&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/15_git_config.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 진짜로 연결하는 과정이다. 딱 한 문장으로 끝난다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git remote add &amp;lt;remote repo 이름&amp;gt; &amp;lt;repo url&amp;gt;&lt;br /&gt;
ex) git remote add origin https://github.com/greeksharifa/git_tutorial.git&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;url은 여기서 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/17_origin.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;일반적으로 remote repo의 이름은 origin으로 둔다.&lt;/p&gt;

&lt;h2 id=&quot;옵션-git-설정하기&quot;&gt;옵션: git 설정하기&lt;/h2&gt;

&lt;p&gt;다음 명령은 Git의 출력결과 색상을 활성화하는 명령이다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git config --global color.ui “auto”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;앞으로 git push를 할 때마다 git 비밀번호를 입력해야 하는데, 이것이 매우 귀찮다면 비밀번호를 저장해 둘 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git config --global credential.helper store&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;단 보안상의 이슈가 걱정된다면, store 대신 cache 옵션을 주어 15분간 저장되게 할 수 있다. 15분 대신 다른 시간을 지정하려면 다음과 갈이 한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git config --global credential.helper cache –timeout 86400&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;git-pull-git-push&quot;&gt;git pull, git push&lt;/h2&gt;

&lt;p&gt;이제 정말로 연결한 remote repo에 local repo의 수정사항을 올릴 때가 되었다. push 명령은 어렵지 않다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git push origin master&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;한동안 origin이라는 이름만 쓰고 &lt;strong&gt;master&lt;/strong&gt; branch만 이용할 계획이라면, 위의 명령에 &lt;code class=&quot;highlighter-rouge&quot;&gt;-u&lt;/code&gt; 옵션을 붙인다. 
즉, &lt;code class=&quot;highlighter-rouge&quot;&gt;git push -u origin master&lt;/code&gt;라고 입력하면 된다. &lt;br /&gt;
그러면 앞으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;git push&lt;/code&gt;만 입력해도 origin master에 push가 이루어진다.&lt;/p&gt;

&lt;p&gt;그런데 이때 그냥 push를 하면 error가 뜰 수 있다. 이는 remote repo를 만들 때 README.md 파일을 생성했기 때문이다. &lt;br /&gt;
&lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-01-introduction/&quot;&gt;GitHub Instruction&lt;/a&gt;에서 간략히 설명한 대로, 
&lt;code class=&quot;highlighter-rouge&quot;&gt;git pull origin master&lt;/code&gt;(혹은 그냥 &lt;code class=&quot;highlighter-rouge&quot;&gt;git pull&lt;/code&gt;)으로 remote repo의 변경사항을 local repo로 받아온다.&lt;/p&gt;

&lt;p&gt;그리고 현재의 master branch와 remote repo의 branch를 연결하기 위해, 다음과 같이 입력한다.&lt;br /&gt;
여기서 upstream branch란 remote repo의 branch를 가리키는 말이라 봐도 좋다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;git push –set-upstream origin master&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/18_git_push.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이제 브라우저에서 git_tutorial repo를 확인해 본다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/GitHub/2018_06_29_github_usage_02_create_project/19_complete.PNG&quot; alt=&quot;02_create_a_new_repository&quot; /&gt;&lt;/p&gt;

&lt;p&gt;끝났다!&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/07/08/github-usage-03-clone-log-gitignore/&quot;&gt;다음 글&lt;/a&gt;에서는 프로젝트 clone, status, .gitignore에 대해서 알아본다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;git-명령어&quot;&gt;Git 명령어&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-00-command-list/&quot;&gt;GitHub 사용법 - 00. Command List&lt;/a&gt;에서 원하는 명령어를 찾아 볼 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>GitHub 사용법 - 01. 소개</title>
   <link href="http://localhost:4000/github-usage-01-introduction/"/>
   <updated>2018-06-29T00:00:00+09:00</updated>
   <id>http://localhost:4000/github-usage-01-introduction</id>
   <content type="html">&lt;h2 id=&quot;git이란&quot;&gt;Git이란?&lt;/h2&gt;

&lt;p&gt;Git은 버전 관리 시스템으로, 파일의 변경 내용을 계속 추적하도록 개발된 것이다.
즉 Git은 분산 버전 관리 시스템으로, 모든 사람이 프로젝트의 현재와 과거 모두의 전체 history를 갖고 있는 것이다.&lt;/p&gt;

&lt;h2 id=&quot;github이란&quot;&gt;GitHub이란?&lt;/h2&gt;

&lt;p&gt;GitHub은 Git repository를 업로드하는 웹사이트이다. 여러분이 알고 있는 그 &lt;a href=&quot;https://github.com&quot;&gt;깃헙&lt;/a&gt; 맞다.&lt;/p&gt;

&lt;p&gt;Git을 사용하는 이유까지 설명하지는 않도록 하겠다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;git에서-사용되는-개념&quot;&gt;Git에서 사용되는 개념&lt;/h2&gt;

&lt;h3 id=&quot;repository-저장소&quot;&gt;Repository 저장소&lt;/h3&gt;

&lt;p&gt;저장소는 당연히, 프로젝트 파일을 모아둔 곳이다. 하나의 root directory와 비슷한 개념이다.&lt;/p&gt;

&lt;p&gt;저장소에는 크게 세 가지 종류가 있다고 생각해도 무방하다. 이 중 두 개는 거의 비슷한데, 소유자가 다를 뿐이다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;나의 remote repository&lt;/li&gt;
  &lt;li&gt;다른 사람의 remote repository&lt;/li&gt;
  &lt;li&gt;나의 local repository&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;small&gt;4. 다른 사람의 local repository&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;물론 4번은 여러분이 신경쓸 부분은 아니다. 따라서 세 가지만 생각하면 된다.&lt;/p&gt;

&lt;p&gt;각 repository 사이에서 상호작용하는 과정은 다음과 같은 것들이 있다. 다른 사람이 하는 것은 생각하지 않도록 하자.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;다른 사람의 remote repository&lt;/code&gt;(2)를 &lt;code class=&quot;highlighter-rouge&quot;&gt;나의 remote repository&lt;/code&gt;(1)로 가져오는 것(fork)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;나의 remote repository&lt;/code&gt;(1)을 &lt;code class=&quot;highlighter-rouge&quot;&gt;나의 local repository&lt;/code&gt;(3)으로 가져오는 것(clone)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;나의 local repository&lt;/code&gt;(3)의 변경사항을 &lt;code class=&quot;highlighter-rouge&quot;&gt;나의 remote repository&lt;/code&gt;(1)에 반영하는 것(push)&lt;/li&gt;
  &lt;li&gt;Fork로 가져온 프로젝트인 &lt;code class=&quot;highlighter-rouge&quot;&gt;나의 local repository&lt;/code&gt;(3)의 변경사항을 &lt;code class=&quot;highlighter-rouge&quot;&gt;나의 remote repository&lt;/code&gt;(1)에 반영시킨 후(push),
다른 사람의 remote repository(2)에 반영하는 것(pull request). 이를 GitHub 프로젝트에 기여했다고 한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;init-clone&quot;&gt;Init, Clone&lt;/h3&gt;

&lt;p&gt;프로젝트를 시작하는 과정은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;먼저 local에서 directory를 하나 생성한다. 이름은 프로젝트 이름으로 한다.&lt;/li&gt;
  &lt;li&gt;생성한 directory에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;git init&lt;/code&gt; 명령을 입력한다.&lt;/li&gt;
  &lt;li&gt;브라우저에서 git repository를 하나 생성한다.&lt;/li&gt;
  &lt;li&gt;브라우저에 보이는 안내를 따르면 된다. &lt;code class=&quot;highlighter-rouge&quot;&gt;git remote add origin ...&lt;/code&gt; 명령을 입력한다.&lt;/li&gt;
  &lt;li&gt;다음 &lt;a href=&quot;###Add-Commit-Push&quot;&gt;Add, Commit, Push&lt;/a&gt;과정을 따르면 된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이미 일부 혹은 전체가 만들어져 있는 프로젝트를 local에 받아와서 하고 싶을 때가 있다. 이는 다음 과정을 따른다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;git clone ...&lt;/code&gt; 명령으로 remote repository를 &lt;code class=&quot;highlighter-rouge&quot;&gt;나의 local repository&lt;/code&gt;(3)으로 받아온다.&lt;/li&gt;
  &lt;li&gt;끝. 이제 개발을 시작하면 된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;add-commit-push&quot;&gt;Add, Commit, Push&lt;/h3&gt;

&lt;p&gt;여러분이 혼자서 간단한 프로젝트를 진행하게 된다면 가장 많이 쓰게 되는 명령들이다.&lt;/p&gt;

&lt;p&gt;앞에서 말한 &lt;code class=&quot;highlighter-rouge&quot;&gt;repository 상호작용 과정 중 3번&lt;/code&gt;을 가장 많이 하게 되는데, 이는 총 4단계로 이루어진다. 물론 경우에 따라 다른 과정이 추가될 수도 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;파일을 프로젝트 목적에 맞게 수정하고 저장한다. 즉 개발 과정이다.&lt;/li&gt;
  &lt;li&gt;Add: 이제 파일을 cache에 잠시 올려 놓는다.
이 과정이 필요한 이유는, 하나의 commit(한번에 반영할 수정사항)에 여러분이 원하는 파일만 반영할 수 있도록 하기 위함이다.
만약에 반강제적으로 모든 파일이 반영되어야만 한다면, commit이 제 역할을 하지 못하게 될 수 있다.&lt;/li&gt;
  &lt;li&gt;Commit: 이제 원하는 만큼의 수정사항을 하나의 commit으로 묶는다.&lt;/li&gt;
  &lt;li&gt;Push: 이제 commit을 진짜로 &lt;code class=&quot;highlighter-rouge&quot;&gt;나의 remote repository&lt;/code&gt;에 반영하는 과정이다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Commit에는 단지 수정사항을 정리하는 것 외에 해주어야 하는 것이 두 가지 더 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Commit message: commit할 때 같이 작성한다.
Commit message란 이 commit이 어떤 수정사항을 담고 있는지를 알려주는 것이다. 자세히 쓸수록 좋다.&lt;/li&gt;
  &lt;li&gt;Tag: 여러분이 생각하는 그 태그 맞다. 블로그의 글에 달려 있는 태그랑 같은 기능을 한다. 포스팅 대신 commit을 참조하는 것이 다를 뿐이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;branch-브랜치&quot;&gt;Branch 브랜치&lt;/h3&gt;

&lt;p&gt;새로운 기능을 개발하거나 테스트를 할 때 사용하는 독립적인 commit history이다. 나무에서 메인 줄기가 아닌 옆으로 빠져나온 나뭇가지를 생각하면 된다.&lt;/p&gt;

&lt;p&gt;Branch가 필요한 이유는 무엇인가? 혼자서 간단한 것을 할 때라면 사실 branch를 새로 만들 것도 없이 그냥 진행해도 별 문제는 없다.
하지만 프로젝트의 규모가 커지거나 여러 사람이 협업해야 한다면 branch는 필수이다. 모두가 master branch(메인 줄기)를 직접 수정하려고 들면 큰일난다.&lt;/p&gt;

&lt;p&gt;모든 Git 프로젝트는 기본적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;master&lt;/code&gt; branch를 갖는다. &lt;code class=&quot;highlighter-rouge&quot;&gt;master&lt;/code&gt; branch가 나무의 메인 줄기로서, 검증이 끝난 프로젝트의 결과물이라 할 수 있다.&lt;/p&gt;

&lt;p&gt;branch 간 상호작용은 꽤 종류가 많지만, 여기서는 몇 가지만 간략히 소개한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;branch에서 새 branch를 생성하는 것(&lt;code class=&quot;highlighter-rouge&quot;&gt;git branch ...&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;어떤 branch에서 다른 특정 branch로 옮겨가는 것(checkout)&lt;/li&gt;
  &lt;li&gt;검증이 끝난 branch를, 그 branch를 생성한 주 branch에 합치는 것(merge)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;새로운 기능을 개발하여 추가하는 과정은 대개 위의 세 과정을 따른다. 물론 2번과 3번 사이에 개발 과정이 있을 것이다.&lt;/p&gt;

&lt;p&gt;이렇게 새로운 기능을 개발하는 branch를 feature(topic) branch라 부른다.
또 구버전 소프트웨어 지원 등의 이유로 별도의 branch가 필요한 경우 이를 release branch라 부른다.&lt;/p&gt;

&lt;h3 id=&quot;issue&quot;&gt;Issue&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;기능에 대해 논의하거나&lt;/li&gt;
  &lt;li&gt;버그 수정사항을 알리거나&lt;/li&gt;
  &lt;li&gt;todoList로 활용한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;협업할 때는 당연히 필요하고, 혼자 할 때도 bugList와 todoList로 쓰면 유용하다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;git-명령어&quot;&gt;Git 명령어&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://greeksharifa.github.io/github/2018/06/29/github-usage-00-command-list/&quot;&gt;GitHub 사용법 - 00. Command List&lt;/a&gt;에서 원하는 명령어를 찾아 볼 수 있다.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>GitHub 사용법 - 00. Command List</title>
   <link href="http://localhost:4000/github-usage-00-command-list/"/>
   <updated>2018-06-29T00:00:00+09:00</updated>
   <id>http://localhost:4000/github-usage-00-command-list</id>
   <content type="html">&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;명령어&lt;/th&gt;
      &lt;th&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;git init&lt;/td&gt;
      &lt;td&gt;local repo를 생성한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git status [-s]&lt;/td&gt;
      &lt;td&gt;현재 local branch의 git 상태를 확인한다(수정 파일, cache, commit 등) &lt;code class=&quot;highlighter-rouge&quot;&gt;-s&lt;/code&gt; 옵션은 간략히 표시한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git add &amp;lt;file | directory&amp;gt;&lt;/td&gt;
      &lt;td&gt;stage에 파일이나 디렉토리 혹은 전체(*)를 올린다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git add -p|-i|-u&lt;/td&gt;
      &lt;td&gt;각각 부분/대화형/수정 사항을 stage에 추가&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git rm --cached &amp;lt;file | directory&amp;gt;&lt;/td&gt;
      &lt;td&gt;파일이나 디렉토리를 cache에서 제거한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git commit [-m “commit message”\&lt;/td&gt;
      &lt;td&gt;수정사항들을 하나의 커밋으로 묶고 커밋 메시지를 작성한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git commit -v&lt;/td&gt;
      &lt;td&gt;git diff 명령을 포함하는 커밋 메시지 편집창을 열어 커밋한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git diff [HEAD]&lt;/td&gt;
      &lt;td&gt;마지막 커밋과 현재 수정사항 사이의 차이를 보여준다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git diff [&amp;lt;branch1&amp;gt;] &amp;lt;branch2&amp;gt;&lt;/td&gt;
      &lt;td&gt;다른 브랜치와의 차이를 보여준다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git diff [&amp;lt;commit1&amp;gt;] &amp;lt;commit1&amp;gt;&lt;/td&gt;
      &lt;td&gt;다른 커밋과의 차이를 보여준다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git tag &amp;lt;tag&amp;gt; [-a [-m] ]&lt;/td&gt;
      &lt;td&gt;마지막 커밋에 태그를 붙인다. &lt;code class=&quot;highlighter-rouge&quot;&gt;-a&lt;/code&gt; 옵션은 Annotated 태그를 가리킨다. &lt;code class=&quot;highlighter-rouge&quot;&gt;-m&lt;/code&gt; 옵션은 메시지를 작성한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git tag &amp;lt;tag&amp;gt; &amp;lt;commit&amp;gt;&lt;/td&gt;
      &lt;td&gt;지정한 코드에 해당하는 커밋에 태그를 붙인다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git tag&lt;/td&gt;
      &lt;td&gt;태그 목록을 보여준다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git show &amp;lt;tag&amp;gt;&lt;/td&gt;
      &lt;td&gt;해당 태그에 대한 자세한 설명을 보여준다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git remote add origin &amp;lt;remote repo 주소&amp;gt;&lt;/td&gt;
      &lt;td&gt;local branch를 remote branch와 연결시킨다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git clone &amp;lt;remote repo 주소&amp;gt;&lt;/td&gt;
      &lt;td&gt;remote repo의 파일 복제본을 local로 가져온다. local repo가 생성된다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git log [--oneline]&lt;/td&gt;
      &lt;td&gt;현재 브랜치의 commit log를 표시한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;--oneline&lt;/code&gt; 옵션은 한줄로 간략히 표시한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git log origin/master..[HEAD]&lt;/td&gt;
      &lt;td&gt;remote repo에는 없고 HEAD에는 있는 커밋을 표시한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git log --graph&lt;/td&gt;
      &lt;td&gt;현재 브랜치의 commit log를 그래프 형태로 보여준다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git branch [--list | -r -a]&lt;/td&gt;
      &lt;td&gt;local/remote/전체 repo의 branch 목록 조회&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git checkout [-b] &amp;lt;branch&amp;gt;&lt;/td&gt;
      &lt;td&gt;선택한 branch로 이동. &lt;code class=&quot;highlighter-rouge&quot;&gt;-b&lt;/code&gt; 옵션은 브랜치를 생성하면서 이동&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git checkout -t [-b] &amp;lt;origin\/branch&amp;gt;&lt;/td&gt;
      &lt;td&gt;선택한 remote branch의 파일을 다운로드하면서 checkout&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git branch -d[-D] &amp;lt;branch&amp;gt;&lt;/td&gt;
      &lt;td&gt;선택한 local branch 삭제, &lt;code class=&quot;highlighter-rouge&quot;&gt;-D&lt;/code&gt; 옵션은 강제 삭제&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git push -d origin &amp;lt;branch&amp;gt;&lt;/td&gt;
      &lt;td&gt;remote branch 삭제&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git fetch&lt;/td&gt;
      &lt;td&gt;remote branch 목록 업데이트&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git merge &amp;lt;branch&amp;gt;&lt;/td&gt;
      &lt;td&gt;현재 브랜치에서 해당 브랜치의 수정사항을 가져온다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git merge &amp;lt;branch1&amp;gt; &amp;lt;branch2&amp;gt;&lt;/td&gt;
      &lt;td&gt;branch2의 변경사항을 branch1로 가져온다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git rebase &amp;lt;branch&amp;gt;&lt;/td&gt;
      &lt;td&gt;현재 브랜치의 base를 해당 브랜치의 tip으로 설정하여, 해당 브랜치의 변경사항을 가져온다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;기타 명령어&lt;/th&gt;
      &lt;th&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;git help [&amp;lt;command&amp;gt;] &lt;br /&gt; git [&amp;lt;command&amp;gt;] --help &lt;br /&gt; man git-[&amp;lt;commmand&amp;gt;]&lt;/td&gt;
      &lt;td&gt;명령어에 대한 도움말을 볼 수 있다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git config [--global] user.name “Your name”&lt;/td&gt;
      &lt;td&gt;local repo의 git id(name)을 Your name으로 설정한다. --global 옵션을 주면 모든 local repo에 적용한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git config [--global] user.name “Your name”&lt;/td&gt;
      &lt;td&gt;local repo의 git email을 Your email으로 설정한다. --global 옵션을 주면 모든 local repo에 적용한다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git config [--list | &amp;lt;config settings&amp;gt; \&lt;/td&gt;
      &lt;td&gt;config 세팅 상태를 볼 수 있다. --list 옵션은 config 세팅 전부를 보여준다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git config --global color.ui “auto”&lt;/td&gt;
      &lt;td&gt;Git의 출력결과 색상을 활성화&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git config --global credential.helper store&lt;/td&gt;
      &lt;td&gt;비밀번호 저장&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;git config --global credential.helper cache –timeout “seconds”&lt;/td&gt;
      &lt;td&gt;seconds 초 동안 비밀번호 저장&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

</content>
 </entry>
 
 <entry>
   <title>Github blog 수식 입력 방법</title>
   <link href="http://localhost:4000/equation-usage/"/>
   <updated>2018-06-29T00:00:00+09:00</updated>
   <id>http://localhost:4000/equation-usage</id>
   <content type="html">&lt;p&gt;이 글에서는 수식 입력방식을 설명한다.&lt;/p&gt;

&lt;p&gt;참조: &lt;a href=&quot;https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference&quot;&gt;stackexchange.com&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;수식 입력은&lt;/p&gt;

&lt;p&gt;inline style: &lt;code class=&quot;highlighter-rouge&quot;&gt;$ a^2 + b^2 = c^2 $&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;$ a^2 + b^2 = c^2 $&lt;/p&gt;

&lt;p&gt;display style: &lt;code class=&quot;highlighter-rouge&quot;&gt;$$ a^2 + b^2 = c^2 $$&lt;/code&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;a^2 + b^2 = c^2&lt;/script&gt;

&lt;p&gt;로 한다.&lt;/p&gt;

&lt;p&gt;$ x {x}  { x } $
$ x $$ $
$ {x} {x} $&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Equation&lt;/th&gt;
      &lt;th&gt;Code&lt;/th&gt;
      &lt;th&gt;Display&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;NewLine&lt;/td&gt;
      &lt;td&gt;\\&lt;/td&gt;
      &lt;td&gt;$ \ $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Greek small Letters&lt;/td&gt;
      &lt;td&gt;\epsilon, \zeta, \eta, \iota, \kappa, \mu, \nu, \rho, \tau, \chi&lt;/td&gt;
      &lt;td&gt;$ \epsilon, \zeta, \eta, \iota, \kappa, \mu, \nu, \rho, \tau, \chi $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Greek Letters&lt;/td&gt;
      &lt;td&gt;\gamma, \Gamma, \delta, \theta, \lambda, \xi, \pi, \sigma, \upsilon, \phi, \psi, \omega&lt;/td&gt;
      &lt;td&gt;$ \gamma, \Gamma, \delta, \theta, \lambda, \xi, \pi, \sigma, \upsilon, \phi, \psi, \omega $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Super/subscripts&lt;/td&gt;
      &lt;td&gt;x_i^2, x_{i^2}, \log_2 x, 10^{10}, x^{y^z}&lt;/td&gt;
      &lt;td&gt;$ x_i^2, x_{i^2}, \log_2 x, 10^{10}, x^{y^z} $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parentheses 1&lt;/td&gt;
      &lt;td&gt;(\frac{1}{2}), \left(\frac{1}{2}\right)&lt;/td&gt;
      &lt;td&gt;$ (\frac{1}{2}), \left(\frac{1}{2}\right) $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parentheses 2&lt;/td&gt;
      &lt;td&gt;(x) {x} [x] |x| \vert x \vert \Vert x \Vert&lt;/td&gt;
      &lt;td&gt;$ (x) {x} [x] |x| \vert x \vert \Vert x \Vert $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parentheses 3&lt;/td&gt;
      &lt;td&gt;\langle x \rangle \lceil x \rceil \lfloor x \rfloor&lt;/td&gt;
      &lt;td&gt;$ \langle x \rangle \lceil x \rceil \lfloor x \rfloor $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Parentheses 4&lt;/td&gt;
      &lt;td&gt;\Biggl(\biggl(\Bigl(\bigl((x)\bigr)\Bigr)\biggr)\Biggr)&lt;/td&gt;
      &lt;td&gt;$ \Biggl(\biggl(\Bigl(\bigl((x)\bigr)\Bigr)\biggr)\Biggr) $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fraction&lt;/td&gt;
      &lt;td&gt;\frac{(n^2+n)(2n+1)}{6}, {a+1\over b+1}, \cfrac{a}{b}&lt;/td&gt;
      &lt;td&gt;$ \frac{(n^2+n)(2n+1)}{6}, {a+1\over b+1}, \cfrac{a}{b} $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Sigma&lt;/td&gt;
      &lt;td&gt;\sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6}&lt;/td&gt;
      &lt;td&gt;$ \sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6} $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Signs&lt;/td&gt;
      &lt;td&gt;\infty \prod \int \bigcup \bigcap \iint \iiint \sqrt{x}&lt;/td&gt;
      &lt;td&gt;$ \infty \prod \int \bigcup \bigcap \iint \iiint \sqrt{x} $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Special functions&lt;/td&gt;
      &lt;td&gt;\lim_{x\to 0} \sin \max \ln&lt;/td&gt;
      &lt;td&gt;$ \lim_{x\to 0} \sin \max \ln $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fonts&lt;/td&gt;
      &lt;td&gt;\mathbb{Aa} \mathbf{Aa} \mathtt{Aa} \mathrm{Aa} \mathsf{Aa} \mathcal{Aa} \mathscr{Aa} \mathfrak{Aa}&lt;/td&gt;
      &lt;td&gt;$ \mathbb{Aa} \mathbf{Aa} \mathtt{Aa} \mathrm{Aa} \mathsf{Aa} \mathcal{Aa} \mathscr{Aa} \mathfrak{Aa} $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Symbols 1&lt;/td&gt;
      &lt;td&gt;\lt \gt \le \leq \leqq \leqslant \ge \geq \geqq \geqslant \neq \gg \ll \ggg \lll&lt;/td&gt;
      &lt;td&gt;$ \lt \gt \le \leq \leqq \leqslant \ge \geq \geqq \geqslant \neq \gg \ll \ggg \lll  $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Symbols 2&lt;/td&gt;
      &lt;td&gt;\times \div \pm \mp x \cdot y&lt;/td&gt;
      &lt;td&gt;$ \times \div \pm \mp x \cdot y $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Symbols 3&lt;/td&gt;
      &lt;td&gt;\cup \cap \setminus \subset \subseteq \subsetneq \supset \in \notin \emptyset \varnothing&lt;/td&gt;
      &lt;td&gt;$ \cup \cap \setminus \subset \subseteq \subsetneq \supset \in \notin \emptyset \varnothing $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Symbols 4&lt;/td&gt;
      &lt;td&gt;{n+1 \choose 2k} , \binom{n+1}{2k}&lt;/td&gt;
      &lt;td&gt;$ {n+1 \choose 2k} , \binom{n+1}{2k} $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Symbols 5&lt;/td&gt;
      &lt;td&gt;\to \rightarrow \leftarrow \Rightarrow \Leftarrow \mapsto&lt;/td&gt;
      &lt;td&gt;$ \to \rightarrow \leftarrow \Rightarrow \Leftarrow \mapsto $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Symbols 6&lt;/td&gt;
      &lt;td&gt;\land \lor \lnot \forall \exists \top \bot \vdash \vDash&lt;/td&gt;
      &lt;td&gt;$ \land \lor \lnot \forall \exists \top \bot \vdash \vDash $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Symbols 7&lt;/td&gt;
      &lt;td&gt;\star \ast \oplus \circ \bullet&lt;/td&gt;
      &lt;td&gt;$ \star \ast \oplus \circ \bullet $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Symbols 8&lt;/td&gt;
      &lt;td&gt;\approx \sim \simeq \cong \equiv \prec \lhd&lt;/td&gt;
      &lt;td&gt;$ \approx \sim \simeq \cong \equiv \prec \lhd $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Symbols 9&lt;/td&gt;
      &lt;td&gt;\infty \aleph_0 \nabla \partial \Im \Re&lt;/td&gt;
      &lt;td&gt;$ \infty \aleph_0 \nabla \partial \Im \Re $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Symbols 10&lt;/td&gt;
      &lt;td&gt;a\equiv b\pmod n&lt;/td&gt;
      &lt;td&gt;$ a\equiv b\pmod n $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Symbols 11&lt;/td&gt;
      &lt;td&gt;\ldots, \cdots&lt;/td&gt;
      &lt;td&gt;$ \ldots, \cdots $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Symbols 12&lt;/td&gt;
      &lt;td&gt;\epsilon \varepsilon \phi \varphi \ell&lt;/td&gt;
      &lt;td&gt;$ \epsilon \varepsilon \phi \varphi \ell $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Double-lined&lt;/td&gt;
      &lt;td&gt;\mathbb{E} \mathbb{R}&lt;/td&gt;
      &lt;td&gt;$ \mathbb{E} \mathbb{R} $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Style&lt;/td&gt;
      &lt;td&gt;\mathcal{L} \mathcal{R}&lt;/td&gt;
      &lt;td&gt;$ \mathcal{L} \mathcal{A} $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spaces&lt;/td&gt;
      &lt;td&gt;1 \ 2 \quad 3 \qquad 4&lt;/td&gt;
      &lt;td&gt;$ 1 \ 2 \quad 3 \qquad 4 $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Plain text&lt;/td&gt;
      &lt;td&gt;\text{text…}&lt;/td&gt;
      &lt;td&gt;$ \text{text…} $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Accents&lt;/td&gt;
      &lt;td&gt;\hat{x} \widehat{xy} \bar{x} \overline{xyz} \vec{x} \overrightarrow{xy} \overleftrightarrow{xy} \dot{x} \ddot{x}&lt;/td&gt;
      &lt;td&gt;$ \hat{x} \widehat{xy} \bar{x} \overline{xyz} \vec{x} \overrightarrow{xy} \overleftrightarrow{xy} \dot{x} \ddot{x} $&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Special Characters&lt;/td&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;\{ \_ \}&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;$ { $ $ _ $ $ } $&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

</content>
 </entry>
 
 <entry>
   <title>Stack(스택)</title>
   <link href="http://localhost:4000/algorithm-stack/"/>
   <updated>2018-06-29T00:00:00+09:00</updated>
   <id>http://localhost:4000/algorithm-stack</id>
   <content type="html">&lt;h2 id=&quot;참조&quot;&gt;참조&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;분류&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/10828&quot;&gt;스택&lt;/a&gt;, &lt;a href=&quot;https://www.acmicpc.net/problem/9012&quot;&gt;괄호&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;응용 문제&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://www.acmicpc.net/problem/6549&quot;&gt;스포일러 문제&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;이 글에서 설명하는 라이브러리&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://www.cplusplus.com/reference/stack/stack/&quot;&gt;std::stack&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;

&lt;h3 id=&quot;시간복잡도--om-&quot;&gt;시간복잡도: $ O(M) $&lt;/h3&gt;
&lt;h3 id=&quot;공간복잡도--on-&quot;&gt;공간복잡도: $ O(N) $&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;N은 원소의 수, M은 연산의 수이다.&lt;/li&gt;
  &lt;li&gt;스택 자체는 알고리즘이 아닌 자료구조이지만, 스택을 쓰는 경우 복잡도는 위와 같이 나온다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이 글에서는 스택(stack)이라고 하는 자료구조와, 이를 활용한 문제들을 살펴볼 것이다.&lt;/p&gt;

&lt;p&gt;스택은 간단하면서도 매우 유용한 자료구조이다. 여러분의 실생활에서도 자주 볼 수 있는 개념이다.&lt;br /&gt;
그리고 알고리즘으로 적용하기에도 쉽다. 그럼 스택은 무엇인가?&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;stack스택&quot;&gt;Stack(스택)&lt;/h2&gt;

&lt;p&gt;스택(&lt;a href=&quot;https://en.wikipedia.org/wiki/Stack_(abstract_data_type)&quot;&gt;stack&lt;/a&gt;)의 사전적 의미는 더미(무더기)이다.&lt;/p&gt;

&lt;p&gt;스택은 다음 그림으로 설명된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/b/b4/Lifo_stack.png&quot; alt=&quot;Stack&quot; /&gt;&lt;/p&gt;

&lt;p&gt;책상 위에 책을 몇 권 쌓는 것과 같다. 1번 책을 쌓고, 2번 책을 쌓고, … , 6번 책까지 쌓았다고 하자.&lt;br /&gt;
그리고 책을 한 권을 집는다고 치자. 그러면 여러분은 (정상적이라면) 몇 번 책을 집겠는가?&lt;br /&gt;
사서 고생하는 사람이 아니라면 굳이 아래쪽 책을 힘들게 빼진 않을 것이다. 즉, 6번 책을 뺄 것이다. 위의 그림과 갈다.&lt;br /&gt;
첫 번째 pop(책을 빼는 것) 연산은 가장 마지막에 들어온 6번부터 행해진다.&lt;/p&gt;

&lt;p&gt;이것을 Last-In-First-Out이라 부른다. 즉 가장 나중에 들어온 것이 제일 먼저 나간다는 의미이다.&lt;br /&gt;
이것이 스택의 전부이다. 그리고 C++의 STL에는 이것이 친절히 구현되어 있다. 다음에서 살펴보자.&lt;/p&gt;

&lt;h2 id=&quot;stdstack-사용법&quot;&gt;std::stack 사용법&lt;/h2&gt;

&lt;h3 id=&quot;include&quot;&gt;Include&lt;/h3&gt;

&lt;p&gt;우선 include를 해야 한다. 특별히 큰 프로젝트에서 쓰는 것이 아니라면, &lt;code class=&quot;highlighter-rouge&quot;&gt;std::&lt;/code&gt;를 매번 쓰기 귀찮으니 namespace도 써 주자.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;stack&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;선언&quot;&gt;선언&lt;/h3&gt;

&lt;p&gt;stack은 generic으로 구현된 template이다. 즉, stack에 들어갈 데이터 타입을 정해야 한다.&lt;br /&gt;
보통 int나 char 등을 사용하게 될 것이다. 물론 기본형 뿐만 아니라 사용자 정의 타입도 가능하다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 현재 비어 있다.&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// stack&amp;lt;char&amp;gt; st_c;&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// stack&amp;lt;dot_2d&amp;gt; st_person; // dot_2d는 알아서 정의하시길...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;pushe&quot;&gt;push(e)&lt;/h3&gt;

&lt;p&gt;스택에 무언가를 집어넣는(push) 연산이다. e는 집어넣을 원소이다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// 10&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// 10 20&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// 10 20 30&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;777&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 10 20 30 777&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;size&quot;&gt;size()&lt;/h3&gt;

&lt;p&gt;스택의 현재 size를 반환한다. 몇 개나 들어 있는지 알고 싶을 때 쓰면 된다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;size: %d&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// size: 4&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;size: %d&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// size: 5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;top&quot;&gt;top()&lt;/h3&gt;

&lt;p&gt;스택의 맨 위 원소를 반환한다. 스택에서는 맨 위의 것만 빼낼 수 있다. 다른 원소에는 접근이 불가능하다.&lt;br /&gt;
물론 스택을 직접 구현한다면 접근 가능하게 할 수도 있지만, 스택을 쓰는 데 그렇게 할 이유가..?&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;top: %d&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;// top: 999&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;pop&quot;&gt;pop()&lt;/h3&gt;

&lt;p&gt;스택의 맨 위 원소를 제거한다. 책을 하나 가져갔다고 생각하면 된다.&lt;br /&gt;
반환값이 &lt;code class=&quot;highlighter-rouge&quot;&gt;void&lt;/code&gt;이므로 리턴값으로 top 값을 알아낼 수는 없다.&lt;br /&gt;
또, 비어 있는데 pop을 수행하려고 하면 런타임 에러를 발생시킨다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 999가 제거됨&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; 
&lt;span class=&quot;c1&quot;&gt;// 777, 30, 20이 차례로 제거됨&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;empty&quot;&gt;empty()&lt;/h3&gt;

&lt;p&gt;스택이 비었는지를 검사한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;size() == 0&lt;/code&gt; 구문으로 체크할 수도 있지만, 이쪽이 더 직관적이다. 그리고 생각보다 자주 쓰게 된다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;stack is empty, 1&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;// 10이 제거됨&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;stack is empty, 2&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// stack is empty, 2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;emplacee&quot;&gt;emplace(e)&lt;/h3&gt;

&lt;p&gt;STL에서 emplace는 생성자를 호출하면서 &lt;code class=&quot;highlighter-rouge&quot;&gt;push&lt;/code&gt;(혹은 &lt;code class=&quot;highlighter-rouge&quot;&gt;push_back&lt;/code&gt;)하는 것과 동일하다.&lt;br /&gt;
이 기능은 stack에 기본형 말고 &lt;code class=&quot;highlighter-rouge&quot;&gt;dot_2d&lt;/code&gt;와 같은 사용자 정의 함수나 생성자 호출이 필요한 데이터 타입을 넣었을 때 필요하다.&lt;br /&gt;
int와 같은 기본형을 넣을 때는 별 차이가 없다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emplace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;top: %d&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// top: -3&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;swapanother_stack&quot;&gt;swap(another_stack)&lt;/h3&gt;

&lt;p&gt;같은 데이터 타입을 담고 있는 다른 스택과 원소 전체를 swap한다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;another_st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;another_st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;st&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;stack is empty, 3&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// stack is empty, 3&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;스택은 사실상 이게 전부이다. 그리고 생각보다 많은 문제를 풀 수 있다.&lt;br /&gt;
물론 대부분은 너무 뻔히 풀이가 스택이라는 것이 보이지만, 안 그런 것도 있다(스포일러 문제 참조)&lt;/p&gt;

&lt;h2 id=&quot;문제-풀이&quot;&gt;문제 풀이&lt;/h2&gt;

&lt;h3 id=&quot;boj-10828스택&quot;&gt;BOJ 10828(스택)&lt;/h3&gt;

&lt;p&gt;문제: &lt;a href=&quot;https://www.acmicpc.net/problem/10828&quot;&gt;스택&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;풀이: &lt;a href=&quot;https://greeksharifa.github.io/ps/2018/07/08/PS-10828/&quot;&gt;BOJ 10828(스택) 문제 풀이&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;boj-09012괄호&quot;&gt;BOJ 09012(괄호)&lt;/h3&gt;

&lt;p&gt;문제: &lt;a href=&quot;https://www.acmicpc.net/problem/9012&quot;&gt;괄호&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;풀이: &lt;a href=&quot;https://greeksharifa.github.io/ps/2018/07/08/PS-09012/&quot;&gt;BOJ 09012(괄호) 문제 풀이&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;스포일러-문제&quot;&gt;스포일러 문제&lt;/h3&gt;

&lt;p&gt;문제: &lt;a href=&quot;https://www.acmicpc.net/problem/6549&quot;&gt;스포일러 문제&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;풀이: &lt;a href=&quot;https://greeksharifa.github.io/ps/2018/07/07/PS-06549/&quot;&gt;스포일러 풀이            &lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>케라스 튜토리얼</title>
   <link href="http://localhost:4000/Keras-Tutorial/"/>
   <updated>2018-06-29T00:00:00+09:00</updated>
   <id>http://localhost:4000/Keras-Tutorial</id>
   <content type="html">&lt;h3 id=&quot;케라스-basic&quot;&gt;케라스 Basic&lt;/h3&gt;

&lt;h4 id=&quot;1-케라스의-모델-정의-방법은-크게-2가지가-있다&quot;&gt;[1] 케라스의 모델 정의 방법은 크게 2가지가 있다.&lt;/h4&gt;
&lt;p&gt;먼저 아래와 같이 정해진 형식으로 심플한 모델을 만들 수 있다.&lt;br /&gt;
이 Sequential 모델에는 리스트 형식으로 복수의 layer를 전달하면 된다.&lt;br /&gt;
(물론 하나만 전달할 때에는 리스트로 전달할 필요가 없다.)&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sigmoid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;여기서 Dense는 layer를 생성하며&lt;br /&gt;
input_shape은 입력 차원을, units는 출력 차원을 정의한다.&lt;br /&gt;
input_shape은 튜플 혹은 정수이다.&lt;br /&gt;
여기서 배치 사이즈를 정하면 모든 인풋을 (16, 2,2)로 하라고 알아 듣는다.&lt;br /&gt;
한 번에 모델을 구성하지 않고 계속해서 추가하는 방법도 있다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Customized된 모델을 만들고 싶을 때에는 Model API를 이용한다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ResNet50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BatchNormalization&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Maxpooling2D&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;여러&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;블록&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;후&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AveragePoooling&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                      &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'fc'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                      &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# 위와 같이 마지막 X는 텐서이다.
&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# create model
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'Resnet50'&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;위와 같이 먼저 Input함수를 통해 input_shape의 shape을 가진 Input 텐서를 만든다.&lt;br /&gt;
그 Input 텐서를 집어넣은 후 여러 과정으 거쳐 함수를 정의하고&lt;br /&gt;
마지막으로 return할 model을 대상으로 inputs/outputs를 정의하면 된다.&lt;br /&gt;
이렇게 하면 원하는 모델의 구조를 생성할 수 있다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;2-다음-단계에서는-loss-function-optimizer-accuracy-metrics를-정의하고-학습시킨다&quot;&gt;[2] 다음 단계에서는 Loss Function, Optimizer, Accuracy Metrics를 정의하고 학습시킨다.&lt;/h4&gt;
&lt;blockquote&gt;
  &lt;p&gt;이후에는 마찬가지로 Compiling과 Fitting을 진행하면 된다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sgd'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'mse'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;optimizer-종류는-다음과-같다&quot;&gt;Optimizer 종류는 다음과 같다.&lt;/h5&gt;
&lt;p&gt;기본 값으로 정의하려면 SGD 대신 ‘sgd’로 입력하면 된다.&lt;br /&gt;
각각의 Optimizer의 정의는 알아서 찾아보길 바란다.&lt;br /&gt;
[케라스 optimizer][https://keras.io/optimizers/]&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.optimizers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;RMSprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Adagrad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Adadelta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Adamax&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;SGD&lt;/strong&gt;(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)&lt;br /&gt;
&lt;strong&gt;RMSprop&lt;/strong&gt;(lr=0.001, rho=0.9, epsilon=None, decay=0.0)&lt;br /&gt;
&lt;strong&gt;Adagrad&lt;/strong&gt;(lr=0.01, epsilon=None, decay=0.0)&lt;br /&gt;
&lt;strong&gt;Adadelta&lt;/strong&gt;(lr=1.0, rho=0.95, epsilon=None, decay=0.0)&lt;br /&gt;
&lt;strong&gt;Adam&lt;/strong&gt;(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)&lt;br /&gt;
&lt;strong&gt;Adamax&lt;/strong&gt;(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)&lt;/p&gt;

&lt;h5 id=&quot;만약-optimizer에-옵션을-주고-싶다면-이를-미리-생성하여야-한다&quot;&gt;만약 optimizer에 옵션을 주고 싶다면 이를 미리 생성하여야 한다.&lt;/h5&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sgd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nesterov&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'binary_crossentropy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sgd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;loss-종류는-다음과-같다&quot;&gt;Loss 종류는 다음과 같다.&lt;/h5&gt;
&lt;p&gt;mean_squared_error&lt;br /&gt;
mean_absolute_error&lt;br /&gt;
mean_absolute_percentage_erro&lt;br /&gt;
mean_squared_logarithmic_error&lt;br /&gt;
categorical_crossentropy&lt;br /&gt;
sparse_categorical_crossentrop&lt;br /&gt;
binary_crossentropy&lt;br /&gt;
kullback_leibler_divergence&lt;br /&gt;
poisson&lt;br /&gt;
cosine_proximity&lt;/p&gt;

&lt;h5 id=&quot;정확도를-나타내는-metrics의-종류는-다음과-같다&quot;&gt;정확도를 나타내는 metrics의 종류는 다음과 같다.&lt;/h5&gt;
&lt;p&gt;binary_accuracy
categorical_accuracy
sparse_categorical_accuracy
top_k_categorical_accuracy&lt;/p&gt;

&lt;h5 id=&quot;custom-accuracy는-다음과-같이-이용한다&quot;&gt;Custom Accuracy는 다음과 같이 이용한다.&lt;/h5&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.backend&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mean_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'rmsprop'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'binary_crossentropy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;3-evaluation은-아래와-같이-진행한다&quot;&gt;[3] Evaluation은 아래와 같이 진행한다.&lt;/h4&gt;
&lt;blockquote&gt;
  &lt;p&gt;첫 번째가 Loss Function 값, 두 번째가 예측 정확도이다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;preds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;4-케라스-layer-기본-규칙&quot;&gt;[4] 케라스 Layer 기본 규칙&lt;/h4&gt;
&lt;blockquote&gt;
  &lt;p&gt;케라스의 Layer 종류에 대해 자세히 설명하기 전에 기본 규칙을 설명할 것이다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;layer.get_weights()&lt;/strong&gt;: np.array들을 담은 리스트로 layer의 weight을 반환한다.&lt;br /&gt;
&lt;strong&gt;layer.set_weights(weights)&lt;/strong&gt;: 이번엔 반대로 그 weight을 설정한다.&lt;br /&gt;
&lt;strong&gt;layer.get_config()&lt;/strong&gt;: layer의 configuration을 담은 딕셔너리를 반환한다. 아래와 같이 표현 가능하다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;reconstructed_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from_config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;layer가 single node를 가지고 있으면 (shared layer가 아니면) 다음을 물어볼 수 있다.&lt;br /&gt;
layer.input&lt;br /&gt;
layer.output&lt;br /&gt;
layer.input_shape&lt;br /&gt;
layer.output_shape&lt;/p&gt;

&lt;p&gt;layer가 여러 개의 node를 갖고 있으면 아래의 메서드를 쓸 수 있다.
layer.get_input_at(node_index)&lt;br /&gt;
layer.get_output_at(node_index)&lt;br /&gt;
layer.get_input_shape_at(node_index)&lt;br /&gt;
layer.get_output_shape_at(node_index)&lt;/p&gt;

&lt;h4 id=&quot;5-간단한-convolutional-model-만들기&quot;&gt;[5] 간단한 Convolutional Model 만들기&lt;/h4&gt;
&lt;p&gt;아래와 같은 데이터셋이 있다고 해보자.&lt;br /&gt;
여기서 input_shape은 (32,32,3)이 될 것이다. 이는 32X32의 Color Image shape과 일치한다. (# channel = 3)&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3072000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;307200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;간단한 합성곱 신경망 모델을 다음과 같이 만들 수 있다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;convmodel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;X_input_tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ZeroPadding2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_input_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'valid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'conv1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BatchNormalization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bn_conv1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
 
     &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'valid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'conv2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BatchNormalization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'bn_conv2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
 
     &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'softmax'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'fc'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glorot_uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
 
     &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_input_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'convmodel'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;함수 옵션으로 정의한 input_shape을 이용하여 첫 줄에서 X_input_tensor를 만들고&lt;br /&gt;
계속해서 이를 이용하여 마지막 output X까지 정의하는 방식으로 구성된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convmodel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'sgd'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'categorical_crossentropy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'accuracy'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;6-케라스-layer&quot;&gt;[6] 케라스 Layer&lt;/h4&gt;
&lt;h5 id=&quot;1-core-layer&quot;&gt;(1) Core Layer&lt;/h5&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Reshape&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'glorot_uniform'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;여기서 rate은 drop시킬 비율을 나타냄. 텐서플로의 keep_prob과 반대&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# example
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 현재 model.output_shape = (None, 32,32,16)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# model.output_shape = (None, 32*32*16)
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;2-convolutional-layer&quot;&gt;(2) Convolutional Layer&lt;/h5&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'valid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
       &lt;span class=&quot;n&quot;&gt;use_bias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'glorot_uniform'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bias_initializer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'zeros'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Cropping2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cropping&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;3-pooling-layer&quot;&gt;(3) Pooling Layer&lt;/h5&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;MaxPooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'valid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;AveragePooling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'valid'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;7-channel-설정&quot;&gt;[7] Channel 설정&lt;/h4&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backend&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_image_data_format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'channels_first'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;8-케라스-backend-조작하기&quot;&gt;[8] 케라스 Backend 조작하기&lt;/h4&gt;
&lt;blockquote&gt;
  &lt;p&gt;케라스 백엔드는 저수준의 AI 엔진을 사용할 때 활용한다.&lt;br /&gt;
현재 tensorflow, theano, CNTK 엔진을 지원하지만,&lt;br /&gt;
여기서는 tensorflow를 기준으로 설명한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;텐서, variable을 만드는 기본적인 방법이다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;backend&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;keras.layers&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Placeholder
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ndim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Variable: name에 공백이 있으면 안된다.
# 안의 값을 보고 싶으면 K.eval
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;var1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;var2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;var3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
                  &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'example_var'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;constraint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;var4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;constant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'ex_constant'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;var5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# 따라하기
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;var6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;var7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'int32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;var8&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;identity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'identity'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;# 텐서 조작: 랜덤 초기화 = Initializing Tensors with Random Numbers
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_uniform_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Uniform distribution
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_normal_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Gaussian distribution
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Tensor Arithmetic
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concatenate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concatenate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;저수준의 주요 백엔드 함수들이다.&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# 백엔드 함수
# backend check
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#1 엡실론 설정
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-05&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#2 기본 float 타입 설정
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floatx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_floatx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float16'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;floatx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#3 채널 순서 정하기
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_data_format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_image_data_format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'channels_last'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image_data_format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#4 Clear session
# 현재의 TF graph를 버리고 새로 만든다. 예전 모델, 레이어와의 충돌을 피한다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clear_session&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#5 learning_phase
# train time과 test time에 있어 다른 behavior를 적용하는 keras function에 대해
# 0 = test, 1 = train을 가리키는 bool tensor를 인풋으로 제공한다.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_phase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Sets the learning phase to a fixed value.
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_learning_phase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#6 is_tensor, is_placeholder
# 타겟이 케라스 layer 혹은 Input에서 반환된 텐서가 맞는지 True, False 반환
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras_placeholder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_keras_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras_placeholder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# A placeholder is not a Keras tensor.
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;keras_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_keras_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# An Input is a Keras tensor.
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;keras_layer_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;units&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_keras_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keras_layer_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Any Keras layer output is a Keras tensor.
&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#7 ndim, dtype: Returns the number of axes, dtype in a tensor
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_normal_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'x'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#8 파라미터 수 세기
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var9&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_normal_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#9 다른 dtype으로 바꾸기
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cast&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float64'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#10 update, update_add, update_sub, moving_average_update
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;old&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_normal_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_uniform_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;old&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#11 dot, transpose
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;old&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;old&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#12 gather: Retrieves the elements of indices in the reference tensor
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var11&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;what&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gather&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reference&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;what&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#13 max, min, sum, prod, mean, var, std -- 모두 같은 argument
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#14 cumsum, cumprod, argmax, argmin -- 같은 argument
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cumprod&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#15 수학 계산: square, sqrt, log, exp round, sign equal, not_equal,
# greater, greater_equal, less, less_equal, maximum, minimum
&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#16 Batch Normalization
# output = (x - mean) / sqrt(var + epsilon) * gamma + beta
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_normed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_normalization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Computes mean and std for batch then apply batch_normalization on batch.
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_normed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normalize_batch_in_training&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduction_axes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#17 concatenate, reshape, permute_dimensions
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;concatenate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;var12&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;permute_dimensions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#18 resize image: 중간 argument는 양의 정수
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_normal_variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resize_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'channels_last'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#19 flatten, expand_dims, squeeze
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var13&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;var14&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;var14&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;var14&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#20 spatial_2d_padding
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spatial_2d_padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#21 기타
# stack: Stacks a list of rank R tensors into a rank R+1 tensor
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# one_hot: Computes the one-hot representation of an integer tensor
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# slice
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;slice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# get_value, batch_get_value(returns: a list of np arr)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#22 gradients
# loss=scalar tensor to minimize
# variables=list of varialbes or placholder
# 아래는 style transfer 예시
# 여기서 loss는 스칼라 값이었고, combination_image는 placeholder 였음
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variables&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;combination_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#23 함수
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'tensor or variable'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;categorical_crossentropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'output과 같은 shape의 텐서'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'결과'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from_logits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'tensor'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;level&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'fraction of the entries in the tensor that will be set to 0'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;noise_shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l2_normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'tensor'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_top_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'a tensor of (batch_size, classes)'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'1D tensor of length batch size'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'# of top elements to consider'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#24 CNN
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'tensor'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'kernel_tensor'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'valid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'channels_last'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pool_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'valid'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'channels_last'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pool_mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'max'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;


&lt;span class=&quot;c1&quot;&gt;#25 returns a tensor with ~ distributions
# random_normal, random_uniform, truncated_normal
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var15&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stddev&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'float32'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</content>
 </entry>
 

</feed>
