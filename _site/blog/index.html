<!DOCTYPE html>
<html lang="en-us">
<head>
  <head>
  <!-- Description of Blog -->
  <meta name="description" content="Python, Machine & Deep Learning">
  <link rel="canonical" href="https://greeksharifa.github.io/">
  <meta property="og:type" content="website">
  <meta property="og:title" content="Python, Machine & Deep Learning">
  <meta property="og:description" content="Python, Machine Learning & Deep Learning 설명서">
  <meta property="og:image" content="https://greeksharifa.github.io/public/img/icon-144x144.png">
  <meta property="og:url" content="https://greeksharifa.github.io/">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Python, Machine & Deep Learning">
  <meta name="twitter:description" content="Python, Machine Learning & Deep Learning 설명서">
  <meta name="twitter:image" content="https://greeksharifa.github.io/public/img/icon-144x144.png">
  <meta name="twitter:domain" content="https://greeksharifa.github.io/">

  <!-- link -->
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  
  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Blog
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/main.css">
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <!-- Icons -->
  <link rel="icon-144x144" sizes="144x144" href="/public/img/icon-144x144.png">
  <link rel="shortcut icon" href="/public/img/icon_32x32.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  
  <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_SVG"> </script>
  <script type="text/x-mathjax-config">
MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } });
  </script>
  

  <!-- Ads -->
  <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
  </script>
</head>

  <!-- for Google AdSense-->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-9951774327887666",
    enable_page_level_ads: true
  });
</script>

  <style>blockquote {
    font-size: 1em;
    line-height: 1.4
  }</style>
  <link href='http://fonts.googleapis.com/css?family=Gill+Sans' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Consolas' rel='stylesheet' type='text/css'>
</head>
<body>

<!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <div class="sidebar-personal-info">
      <div class="sidebar-personal-info-section">
        <a href="http://gravatar.com/3c2986ad7ac1f2230ea3596f44563328">
          <img src="/public/img/maple_tree.jpg" title="Cover Photo" alt="Maple tree" />
        </a>
      </div>
      <div class="sidebar-personal-info-section">
        <p><strong>Developer and Analyst</strong>, YW & YY.</p>
      </div>
      
      
      
      <div class="sidebar-personal-info-section">
        <p> Follow me:
        
        
        
        <a href="https://github.com/greeksharifa">
          <i class="fa fa-github" aria-hidden="true"></i>
        </a>
        
        |
        
        
        
        <a href="mailto:greeksharifa@gmail.com">
          <i class="fa fa-envelope" aria-hidden="true"></i>
        </a>
        
        
        
        </p>
      </div>
      
    </div>
  </div>

  <nav class="sidebar-nav">
    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/">
          Home
        </a>

        
      </span>

    
      
      
      

      

      <span class="foldable">
        <a class="sidebar-nav-item active" href="/blog/">
          Blog
        </a>

        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/categories/">
                Categories
              </a>
          
        
          
            
            
            
              <a class="sidebar-nav-item sidebar-nav-item-sub " href="/blog/tags/">
                Tags
              </a>
          
        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="/about/">
          About
        </a>

        
      </span>

    
      
      
      

      

      <span class="">
        <a class="sidebar-nav-item " href="http://greeksharifa.github.io/">
          Github Project
        </a>

        
      </span>

    

  </nav>

  <div class="sidebar-item">
    <p>
    &copy; 2020 YW & YY. This work is liscensed under <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a>.
    </p>
  </div>

  <div class="sidebar-item">
    <p>
    Powered by <a href="http://jekyllrb.com">jekyll</a> and <a href="http://greeksharifa.github.io">YW & YY</a>
    </p>
  </div>
</div>


<!-- Wrap is the content to shift when toggling the sidebar. We wrap the
     content to avoid any CSS collisions with our real content. -->
<div class="wrap">
  <div class="masthead">
    <div class="container">
      <h3 class="masthead-title" align="center">
        <a href="/" title="Home" title="YW & YY">
          <img class="masthead-logo" src="/public/img/logo.png"/>
        </a>
        <small>YW & YY's Python, Machine & Deep Learning</small>
        <!-- HTML elements for search -->
        <a href="/search/" id="search_icon">
          <img src="/public/img/search.png" width="25" height="25"
               align="right" style="margin-top:5px; margin-bottom:0;"
               onmouseover="this.style.opacity=0.7" onmouseout="this.style.opacity=0.5"
               alt="search">
        </a>
      </h3>
    </div>
  </div>

  <div class="container content">
    <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/github/2020/05/27/github-usage-09-overall/">
        GitHub 사용법 - 09. Overall
      </a>
    </h1>

    <span class="post-date">27 May 2020</span>
     |
    
    <a href="/blog/tags/#github" class="post-tag">GitHub</a>
    
    <a href="/blog/tags/#usage" class="post-tag">usage</a>
    
    

    <article>
      <p><a href="https://greeksharifa.github.io/github/2018/08/19/github-usage-08-conflict/">저번 글</a>에서는 Conflict에 대해서 알아보았다.<br />
이번 글에서는, 전체 Git 명령어들의 사용법을 살펴본다.</p>

<hr />

<p>명령어에 일반적으로 적용되는 규칙:</p>

<ul>
  <li>이 글에서 <code class="highlighter-rouge">&lt;blabla&gt;</code>와 같은 token은 여러분이 알아서 적절한 텍스트로 대체하면 된다.</li>
  <li>각 명령에는 여러 종류의 옵션이 있다. ex) <code class="highlighter-rouge">git log</code>의 경우 <code class="highlighter-rouge">--oneline</code>, <code class="highlighter-rouge">-&lt;number&gt;</code>, <code class="highlighter-rouge">-p</code> 등의 옵션이 있다.</li>
  <li>각 옵션은 많은 경우 축약형이 존재한다. 일반형은 <code class="highlighter-rouge">-</code>가 2개 있으며, 축약형은 <code class="highlighter-rouge">-</code>가 1개이며 보통 첫 일반형의 첫 글자만 따온다. ex) <code class="highlighter-rouge">--patch</code> = <code class="highlighter-rouge">-p</code>. 축약형과 일반형은 효과가 같다.</li>
  <li>각 옵션의 순서는 상관없다. 명령의 필수 인자와 옵션의 순서를 바꾸어도 상관없다.</li>
  <li>각 명령에 대한 자세한 설명은 <code class="highlighter-rouge">git help &lt;command-name&gt;</code>으로 확인할 수 있다.</li>
  <li>ticket branch는 parent branch로부터 생성되어, 어떤 특정 기능을 추가하고자 만든 실험적 branch라 생각하면 된다.</li>
</ul>

<hr />

<h2 id="working-tree작업트리-생성">Working tree(작업트리) 생성</h2>

<h3 id="git-init">git init</h3>

<p>빈 디렉토리나, 기존의 프로젝트를 <strong>git 저장소</strong>(=<strong>git repository</strong>)로 변환하고 싶다면 이 문단을 보면 된다.</p>

<p>일반적인 디렉토리(=git 저장소가 아닌 디렉토리)를 git working tree로 만드는 방법은 다음과 같다. <strong>명령창</strong>(cmd / terminal)에서 다음을 입력한다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git init

# 결과 예시
Initialized empty Git repository <span class="k">in</span> blabla<span class="sr">/sample_directory/</span><span class="p">.</span>git/
</code></pre></div></div>

<p>그러면 해당 디렉토리에는 <code class="highlighter-rouge">.git</code> 이라는 이름의 숨김처리된 디렉토리가 생성된다. 이 디렉토리 안에 든 것은 수동으로 건드리지 않도록 한다.</p>

<p>참고) <code class="highlighter-rouge">git init</code> 명령만으로는 인터넷(=<strong>원격 저장소</strong> = <strong>remote repository</strong>)에 그 어떤 연결도 되어 있지 않다. <a href="https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#git-repository-%EC%97%B0%EA%B2%B0">여기</a>를 참조한다.</p>

<h3 id="git-clone">git clone</h3>

<p>인터넷에서 이미 만들어져 있는 작업트리를 본인의 컴퓨터(=<strong>로컬</strong>)로 가져오고 싶을 때에는 해당 git repository의 <code class="highlighter-rouge">https://github.com/blabla.git</code> 주소를 복사한 뒤 다음과 같은 명령어를 입력한다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone <span class="p">&lt;</span>git<span class="p">-</span>address<span class="p">&gt;</span>

# 명령어 예시 
git clone https<span class="p">:</span><span class="sr">//</span>github<span class="p">.</span><span class="k">com</span><span class="sr">/greeksharifa/</span>git_tutorial<span class="p">.</span>git

# 결과 예시
Cloning into <span class="s1">'git_tutorial'</span><span class="p">...</span>
remote<span class="p">:</span> Enumerating objects<span class="p">:</span> <span class="m">56</span><span class="p">,</span> done<span class="p">.</span>
remote<span class="p">:</span> Total <span class="m">56</span> <span class="p">(</span>delta <span class="m">0</span><span class="p">),</span> reused <span class="m">0</span> <span class="p">(</span>delta <span class="m">0</span><span class="p">),</span> <span class="k">pack</span><span class="p">-</span>reused <span class="m">56</span>
Unpacking objects<span class="p">:</span> <span class="m">100</span>% <span class="p">(</span><span class="m">56</span>/<span class="m">56</span><span class="p">),</span> done<span class="p">.</span>
</code></pre></div></div>
<p>그러면 현재 폴더에 해당 프로젝트 이름의 하위 디렉토리가 생성된다. 이 하위 디렉토리에는 인터넷에 올라와 있는 모든 내용물을 그대로 가져온다(<code class="highlighter-rouge">.git</code> 디렉토리 포함).<br />
단, 다른 branch의 내용물을 가져오지는 않는다. 다른 branch까지 가져오려면 <a href="">추가 작업</a>이 필요하다.</p>

<hr />

<h2 id="git-repository-연결">Git Repository 연결</h2>

<p>이 과정은 <code class="highlighter-rouge">git clone</code>으로 원격저장소의 로컬 사본을 생성한 경우에는 필요 없다.</p>

<p>먼저 <a href="https://github.com/">github</a> 등에서 원격 저장소(remote repository)를 생성한다.</p>

<p>로컬 저장소를 원격저장소에 연결하는 방법은 다음과 같다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git remote add <span class="p">&lt;</span>remote<span class="p">-</span>name<span class="p">&gt;</span> <span class="p">&lt;</span>git address<span class="p">&gt;</span>

# 명령어 예시
git remote add origin https<span class="p">:</span><span class="sr">//</span>github<span class="p">.</span><span class="k">com</span><span class="sr">/greeksharifa/</span>git_tutorial<span class="p">.</span>git
</code></pre></div></div>

<p><code class="highlighter-rouge">&lt;remote-name&gt;</code>은 원격 저장소에 대한 일종의 별명인데, 보통은 <code class="highlighter-rouge">origin</code>을 쓴다. 큰 프로젝트라면 여러 개를 쓸 수도 있다.</p>

<p>이것만으로는 완전히 연결되지는 않았다. <a href="https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#upstream-%EC%97%B0%EA%B2%B0">upstream 연결</a>을 지정하는 <code class="highlighter-rouge">git push -u</code> 명령을 사용해야 수정사항이 원격 저장소에 반영된다.</p>

<h3 id="연결된-원격-저장소-확인">연결된 원격 저장소 확인</h3>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git remote <span class="p">--</span><span class="k">verbose</span>
git remote <span class="p">-</span><span class="k">v</span>

# 결과 예시
origin  https<span class="p">:</span><span class="sr">//</span>github<span class="p">.</span><span class="k">com</span><span class="sr">/greeksharifa/</span>git_tutorial<span class="p">.</span>git <span class="p">(</span>fetch<span class="p">)</span>
origin  https<span class="p">:</span><span class="sr">//</span>github<span class="p">.</span><span class="k">com</span><span class="sr">/greeksharifa/</span>git_tutorial<span class="p">.</span>git <span class="p">(</span>push<span class="p">)</span>
</code></pre></div></div>
<hr />

<h2 id="git-준비-영역index에-파일-추가">Git 준비 영역(index)에 파일 추가</h2>

<p>로컬 저장소의 수정사항이 반영되는 과정은 총 3단계를 거쳐 이루어진다.</p>

<ol>
  <li><code class="highlighter-rouge">git add</code> 명령을 통해 준비 영역에 변경된 파일을 추가하는 과정(stage라 부른다)</li>
  <li><code class="highlighter-rouge">git commit</code> 명령을 통해 여러 변경점을 하나의 commit으로 묶는 과정</li>
  <li><code class="highlighter-rouge">git push</code> 명령을 통해 로컬 commit 내용을 원격 저장소에 올려 변경사항을 반영하는 과정</li>
</ol>

<p>이 중 <code class="highlighter-rouge">git add</code> 명령은 첫 단계인, <strong>준비 영역</strong>에 파일을 추가하는 것이다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git add <span class="p">&lt;</span>filename1<span class="p">&gt;</span> <span class="p">[&lt;</span>filename2<span class="p">&gt;,</span> <span class="p">...]</span>
git add <span class="p">&lt;</span>directory<span class="p">-</span>name<span class="p">&gt;</span>
git add *
git add <span class="p">--</span><span class="k">all</span>
git add <span class="p">.</span>

# 명령어 예시
git add third<span class="p">.</span><span class="k">py</span> fourth<span class="p">.</span><span class="k">py</span>
git add temp_dir/*
</code></pre></div></div>

<p><code class="highlighter-rouge">*</code>은 와일드카드로 그냥 쓰면 변경점이 있는 모든 파일을 준비 영역에 추가한다(<code class="highlighter-rouge">git add *</code>). 특정 directory 뒤에 쓰면 해당 directory의 모든 파일을, <code class="highlighter-rouge">*.py</code>와 같이 쓰면 확장자가 <code class="highlighter-rouge">.py</code>인 모든 파일이 준비 영역에 올라가게 된다.<br />
<code class="highlighter-rouge">git add .</code>을 현재 directory(<code class="highlighter-rouge">.</code>)의 모든 파일을 추가하는 명령으로 <code class="highlighter-rouge">git add --all</code>과 효과가 같다.</p>

<p><code class="highlighter-rouge">git add</code> 명령을 실행하고 이미 준비 영역에 올라간 파일을 또 수정한 뒤 <a href="https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#git-status"><code class="highlighter-rouge">git status</code></a> 명령을 실행하면 같은 파일이 <strong>Changes to be committed</strong> 분류와 <strong>Changes not staged for commit</strong> 분류에 동시에 들어가 있을 수 있다. 딱히 오류는 아니고 해당 파일을 다음 commit에 반영할 계획이면 한번 더 <code class="highlighter-rouge">git add</code>를 실행시켜주자.</p>

<h3 id="한-파일-내-수정사항의-일부만-준비-영역에-추가">한 파일 내 수정사항의 일부만 준비 영역에 추가</h3>

<p>예를 들어 <code class="highlighter-rouge">fourth.py</code>를 다음과 같이 변경한다고 하자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 변경 전
</span><span class="k">print</span><span class="p">(</span><span class="s">'hello'</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'bye'</span><span class="p">)</span>

<span class="c1">#변경 후
</span><span class="k">print</span><span class="p">(</span><span class="s">'hello'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'git'</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">'bye'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'20000'</span><span class="p">)</span>
</code></pre></div></div>
<p>이 중 <code class="highlighter-rouge">print('bye'); print('20000')</code>을 제외한 나머지 변경사항만을 준비 영역에 추가하고 싶다고 하자. 그러면 <code class="highlighter-rouge">git add &lt;filename&gt;</code> 명령에 다음과 같이 <code class="highlighter-rouge">--patch</code> 옵션을 붙인다.</p>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git add --patch fourth.py
git add fourth.py -p

# 결과 예시
<span class="gh">diff --git a/fourth.py b/fourth.py
index 13cc618..4c8cfb6 100644
</span><span class="gd">--- a/fourth.py
</span><span class="gi">+++ b/fourth.py
</span><span class="gu">@@ -1,5 +1,5 @@
</span> print('hello')
<span class="gi">+print('git')
</span>
<span class="gd">-print(1)
-
-print('bye')
</span>\ No newline at end of file
<span class="gi">+print('bye')
+print('20000')
</span>\ No newline at end of file
stage this hunk [y,n,q,a,d,s,e,?]? 
</code></pre></div></div>

<p>그러면 수정된 코드 덩이(hunk)마다 선택할지를 물어본다. 인접한 초록색(+) 덩이 또는 인접한 빨간색 덩이(-)가 하나의 코드 덩이가 된다.</p>

<p>각 옵션에 대한 설명은 다음과 같다. <code class="highlighter-rouge">?</code>를 입력해도 도움말을 볼 수 있다.</p>

<table>
  <thead>
    <tr>
      <th>Option</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>y</td>
      <td>stage this hunk</td>
    </tr>
    <tr>
      <td>n</td>
      <td>do not stage this hunk</td>
    </tr>
    <tr>
      <td>q</td>
      <td>quit; do not stage this hunk or any of the remaining ones</td>
    </tr>
    <tr>
      <td>a</td>
      <td>stage this hunk and all later hunks in the file</td>
    </tr>
    <tr>
      <td>d</td>
      <td>do not stage this hunk or any of the later hunks in the file</td>
    </tr>
    <tr>
      <td>s</td>
      <td>split the current hunk into smaller hunks</td>
    </tr>
    <tr>
      <td>e</td>
      <td>manually edit the current hunk</td>
    </tr>
    <tr>
      <td>?</td>
      <td>print help</td>
    </tr>
  </tbody>
</table>

<p>여기서는 <code class="highlighter-rouge">y</code>, <code class="highlighter-rouge">y</code>, <code class="highlighter-rouge">n</code>을 차례로 입력하면 원하는 대로 추가/추가하지 않을 수 있다. (영어 원문을 보면 알 수 있듯이 (stage) = (준비 영역에 추가하다)와 같은 의미라고 보면 된다.)</p>

<p><code class="highlighter-rouge">-p</code> 옵션으로는 인접한 추가/삭제 줄들이 전부 하나의 덩이로 묶이기 때문에, 이를 더 세부적으로 하고 싶다면 위 옵션에서 <code class="highlighter-rouge">e</code>를 선택하면 된다.</p>

<p><code class="highlighter-rouge">git add -p</code> 명령을 통해 준비 영역에 파일의 일부 변경사항만 추가하고 나면 같은 파일이 <strong>Changes to be committed</strong> 분류와 <strong>Changes not staged for commit</strong> 분류에 동시에 들어가게 된다.</p>

<hr />

<h2 id="commit하기">Commit하기</h2>

<p>준비 영역에 올라간 파일들의 변경사항을 하나로 묶는 작업이라 보면 된다. Git에서는 이 commit(커밋)이 변경사항 적용의 기본 단위가 된다.</p>

<h3 id="git-commit--m-message-amend">git commit [-m “message”] [–amend]</h3>

<p>기본적으로, commit은 다음 명령어로 수행할 수 있다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git commit

# 결과 예시<span class="p">:</span>
All text <span class="k">in</span> <span class="k">first</span> line will be showed at <span class="p">--</span>oneline

Maximum length <span class="k">is</span> <span class="m">50</span> characters<span class="p">.</span>
Below<span class="p">,</span> <span class="k">is</span> <span class="k">for</span> detailed message<span class="p">.</span>

# Please enter the commit message <span class="k">for</span> your <span class="k">changes</span><span class="p">.</span> Lines starting
# with <span class="s1">'#'</span> will be ignored<span class="p">,</span> and an empty message aborts the commit<span class="p">.</span>
#
# On branch master
# Your branch <span class="k">is</span> <span class="k">up</span> <span class="k">to</span> date with <span class="s1">'origin/master'</span><span class="p">.</span>
#
# Changes <span class="k">to</span> be committed<span class="p">:</span>
#       modified<span class="p">:</span>   <span class="p">.</span>gitignore
#       <span class="k">new</span> <span class="k">file</span><span class="p">:</span>   third<span class="p">.</span><span class="k">py</span>
#
<span class="p">~</span>
<span class="p">~</span>
</code></pre></div></div>

<p><code class="highlighter-rouge">git commit</code>을 입력하면 vim 에디터가 열리면서 commit 메시지 편집을 할 수 있다. 방법은:</p>

<ul>
  <li><code class="highlighter-rouge">i</code>를 누른다. insert의 약자이다.</li>
  <li>이후 메시지를 마음대로 수정할 수 있다. 이 때 규칙이 있는데,
    <ul>
      <li>첫 번째 줄은 log를 볼 때 <code class="highlighter-rouge">--oneline</code> 옵션에서 나타나는 대표 commit 메시지이다. 기본값으로, 50자 이상은 무시된다.</li>
      <li>그 아래 줄에 쓴 텍스트는 해당 commit의 자세한 메시지를 포함한다.</li>
      <li>맨 앞에 <code class="highlighter-rouge">#</code>이 있는 줄은 주석 처리되어 commit 메시지에 포함되지 않는다.</li>
    </ul>
  </li>
  <li>편집을 마쳤으면 다음을 순서대로 누른다. <code class="highlighter-rouge">ESC</code>, <code class="highlighter-rouge">:wq</code>, <code class="highlighter-rouge">Enter</code>.
    <ul>
      <li><code class="highlighter-rouge">ESC</code>는 vim 에디터에서 명령 모드로 들어가가, <code class="highlighter-rouge">:wq</code>는 저장 및 종료 모드 입력을 뜻한다. 잘 모르겠으면 그냥 따라하라.</li>
    </ul>
  </li>
  <li>맨 밑에 있는 물결 표시(<code class="highlighter-rouge">~</code>)는 파일의 끝이라는 뜻이다. 빈 줄도 아니다.</li>
</ul>

<p>commit의 자세한 메시지를 작성하기 귀찮다면(<em>별로 좋은 습관은 아니다.</em>), 간단한 메시지만 작성할 수 있다:</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git commit <span class="p">-</span><span class="k">m</span> <span class="s2">"&lt;message&gt;"</span>

# 명령 예시<span class="p">:</span>
git commit <span class="p">-</span><span class="k">m</span> <span class="s2">"hotfix for typr error"</span>
</code></pre></div></div>

<p>물론 이미 작성한 commit 메시지를 변경할 수 있다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git commit <span class="p">--</span>amend
</code></pre></div></div>

<p>그러면 vim 에디터에서 수정할 수 있다.</p>

<hr />

<h2 id="수정사항을-원격저장소에-반영하기-git-push">수정사항을 원격저장소에 반영하기: git push</h2>

<h3 id="upstream-연결">upstream 연결</h3>

<p><code class="highlighter-rouge">git remote add</code> 명령으로 원격저장소를 연결했으면 <code class="highlighter-rouge">git push &lt;git-address&gt;</code> 명령으로 로컬 저장소의 commit을 원격 저장소에 반영할 수 있다. 즉, 최종 반영이 되는 것이다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git push <span class="p">&lt;</span>git<span class="p">-</span>address<span class="p">&gt;</span>
git push https<span class="p">:</span><span class="sr">//</span>github<span class="p">.</span><span class="k">com</span><span class="sr">/greeksharifa/</span>gitgitgit<span class="p">.</span>git

# 결과 예시
Enumerating objects<span class="p">:</span> <span class="m">3</span><span class="p">,</span> done<span class="p">.</span>
Counting objects<span class="p">:</span> <span class="m">100</span>% <span class="p">(</span><span class="m">3</span>/<span class="m">3</span><span class="p">),</span> done<span class="p">.</span>
Writing objects<span class="p">:</span> <span class="m">100</span>% <span class="p">(</span><span class="m">3</span><span class="sr">/3), 200 bytes | 200.00 KiB/</span>s<span class="p">,</span> done<span class="p">.</span>
Total <span class="m">3</span> <span class="p">(</span>delta <span class="m">0</span><span class="p">),</span> reused <span class="m">0</span> <span class="p">(</span>delta <span class="m">0</span><span class="p">)</span>
To https<span class="p">:</span><span class="sr">//</span>github<span class="p">.</span><span class="k">com</span><span class="sr">/greeksharifa/</span>gitgitgit<span class="p">.</span>git
 * <span class="p">[</span><span class="k">new</span> branch<span class="p">]</span>      master <span class="p">-&gt;</span> master
</code></pre></div></div>

<p>그러나 매번 git address를 인자로 주어가며 변경사항을 저장하는 것은 매우 귀찮으니, 다음 명령을 통해 upstream 연결을 지정할 수 있다. 이는 <code class="highlighter-rouge">git remote add</code> 명령을 통해 원격 저장소의 이름을 이미 지정한 경우의 얘기이다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git push <span class="p">--</span><span class="k">set</span><span class="p">-</span>upstream <span class="p">&lt;</span>remote<span class="p">-</span>name<span class="p">&gt;</span> <span class="p">&lt;</span>branch<span class="p">-</span>name<span class="p">&gt;</span>
git push <span class="p">-</span><span class="k">u</span> <span class="p">&lt;</span>remote<span class="p">-</span>name<span class="p">&gt;</span> <span class="p">&lt;</span>branch<span class="p">-</span>name<span class="p">&gt;</span>

# 명령어 예시
git push <span class="p">--</span><span class="k">set</span><span class="p">-</span>upstream origin master
git push <span class="p">-</span><span class="k">u</span> origin master

# 결과 예시
Everything <span class="k">up</span><span class="p">-</span><span class="k">to</span><span class="p">-</span>date
Branch <span class="s1">'master'</span> <span class="k">set</span> <span class="k">up</span> <span class="k">to</span> track remote branch <span class="s1">'master'</span> from <span class="s1">'origin'</span><span class="p">.</span>
</code></pre></div></div>

<p><code class="highlighter-rouge">git push --set-upstream &lt;remote-name&gt; &lt;branch-name&gt;</code> 명령은 <code class="highlighter-rouge">&lt;branch-name&gt;</code> branch의 upstream을 원격 저장소 <code class="highlighter-rouge">&lt;remote-name&gt;</code>로 지정하는 것으로, 앞으로 <code class="highlighter-rouge">git push</code>나 <code class="highlighter-rouge">git pull</code> 명령 등을 수행할 때 <code class="highlighter-rouge">&lt;branch name&gt;</code>과 <code class="highlighter-rouge">&lt;remote name&gt;</code>을 지정할 필요가 없도록 지정하는 역할을 한다. 즉, 앞으로는 commit을 원격 저장소에 반영할 때 <code class="highlighter-rouge">git push</code>만 입력하면 된다.</p>

<p>위와 같은 방법으로 지정하지 않은 branch나 원격 저장소에 push하고자 하는 경우, <code class="highlighter-rouge">git push &lt;remote-name&gt; &lt;branch-name&gt;</code>을 사용한다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 명령어 예시
git push origin ticket<span class="p">-</span>branch
</code></pre></div></div>

<h3 id="upstream-삭제">upstream 삭제</h3>

<p>더 이상 필요 없는 원격 branch를 삭제할 때는 다음 명령을 사용한다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git push <span class="p">--</span>delete <span class="p">&lt;</span>remote<span class="p">-</span>name<span class="p">&gt;</span> <span class="p">&lt;</span>remote<span class="p">-</span>branch<span class="p">-</span>name<span class="p">&gt;</span>

# 명령어 예시
git push <span class="p">--</span>delete origin ticket<span class="p">-</span>branch
git push <span class="p">-</span><span class="k">d</span> origin ticket<span class="p">-</span>branch
</code></pre></div></div>

<hr />

<h2 id="git-directory-상태-확인">Git Directory 상태 확인</h2>

<h3 id="git-status">git status</h3>

<p>현재 git 저장소의 상태를 확인하고 싶다면 다음 명령어를 입력한다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git status

# 결과 예시 <span class="m">1</span><span class="p">:</span>
On branch master
Your branch <span class="k">is</span> <span class="k">up</span> <span class="k">to</span> date with <span class="s1">'origin/master'</span><span class="p">.</span>

nothing <span class="k">to</span> commit<span class="p">,</span> working tree clean

# 결과 예시 <span class="m">2</span><span class="p">:</span>

On branch master
Your branch <span class="k">is</span> <span class="k">up</span> <span class="k">to</span> date with <span class="s1">'origin/master'</span><span class="p">.</span>

Changes <span class="k">to</span> be committed<span class="p">:</span>
  <span class="p">(</span>use <span class="s2">"git reset HEAD &lt;file&gt;..."</span> <span class="k">to</span> unstage<span class="p">)</span>

        modified<span class="p">:</span>   <span class="k">first</span><span class="p">.</span><span class="k">py</span>

Changes not staged <span class="k">for</span> commit<span class="p">:</span>
  <span class="p">(</span>use <span class="s2">"git add/rm &lt;file&gt;..."</span> <span class="k">to</span> <span class="k">update</span> what will be committed<span class="p">)</span>
  <span class="p">(</span>use <span class="s2">"git checkout -- &lt;file&gt;..."</span> <span class="k">to</span> discard <span class="k">changes</span> <span class="k">in</span> working directory<span class="p">)</span>

        modified<span class="p">:</span>   <span class="p">.</span>gitignore
        deleted<span class="p">:</span>    second<span class="p">.</span><span class="k">py</span>

Untracked <span class="k">files</span><span class="p">:</span>
  <span class="p">(</span>use <span class="s2">"git add &lt;file&gt;..."</span> <span class="k">to</span> include <span class="k">in</span> what will be committed<span class="p">)</span>

        third<span class="p">.</span><span class="k">py</span>
</code></pre></div></div>

<p><code class="highlighter-rouge">git status</code>로는 로컬 git 저장소에 변경점이 생긴 파일을 크게 세 종류로 나누어 보여준다.</p>

<ol>
  <li><strong>Changes to be committed</strong>
    <ul>
      <li>Tracking되는 파일이며, 준비 영역(stage)에 이름이 올라가 있는 파일들. 이 단계에 있는 파일들만이 commit 명령을 내릴 시 다음 commit에 포함된다. (그래서 to be commited이다)</li>
      <li>마지막 commit 이후 <code class="highlighter-rouge">git add</code> 명령으로 준비 영역에 추가가 된 파일들.</li>
    </ul>
  </li>
  <li><strong>Changes not staged for commit:</strong>
    <ul>
      <li>Tracking되는 파일이지만, 다음 commit을 위한 준비 영역에 이름이 올라가 있지 않은 파일들.</li>
      <li>마지막 commit 이후 <code class="highlighter-rouge">git add</code> 명령의 대상이 된 적 없는 파일들.</li>
    </ul>
  </li>
  <li><strong>Untracked files:</strong>
    <ul>
      <li>Tracking이 안 되는 파일들.</li>
      <li>생성 이후 한 번도 <code class="highlighter-rouge">git add</code> 명령의 대상이 된 적 없는 파일들.</li>
    </ul>
  </li>
</ol>

<p>위와 같이 준비 영역 또는 tracked 목록에 올라왔는지가 1차 분류이고, 2차 분류는 해당 파일이 처음 생성되었는지(ex. <code class="highlighter-rouge">third.py</code>), 변경되었는지(modified), 삭제되었는지(deleted)로 나눈다.</p>

<hr />

<h2 id="특정-파일디렉토리-무시하기-gitignore">특정 파일/디렉토리 무시하기: .gitignore</h2>

<p>프로젝트의 최상위 디렉토리에 <code class="highlighter-rouge">.gitignore</code>라는 이름을 갖는 파일을 생성한다. 윈도우에서는 <code class="highlighter-rouge">copy con .gitignore</code>라 입력한 뒤, 내용을 다 입력하고, <code class="highlighter-rouge">Ctrl + C</code>를 누르면 파일이 저장되면서 생성된다.</p>

<p><code class="highlighter-rouge">.gitignore</code> 파일을 열었으면 안에 원하는 대로 파일명이나 디렉토리 이름 등을 입력한다. 그러면 앞으로 해당 프로젝트에서는 <code class="highlighter-rouge">git add</code> 명령으로 준비 영역에 해당 종류의 파일 등이 추가되지 않는다.</p>

<p>예시는 다음과 같다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dum_file<span class="p">.</span><span class="k">py</span>             # `dum_file<span class="p">.</span><span class="k">py</span>`라는 이름의 파일을 무시한다<span class="p">.</span>
*<span class="p">.</span>zip                   # 확장자가 `<span class="p">.</span>zip`인 모든 파일을 무시한다<span class="p">.</span>
data<span class="sr">/                   # data/</span> 디렉토리 전체를 무시한다<span class="p">.</span>
<span class="p">!</span>data<span class="sr">/regression.csv    # data/</span> 디렉토리는 무시되지만<span class="p">,</span> data/regression<span class="p">.</span>csv 파일은 무시되지 않는다<span class="p">.</span> 
                        # 이 경우는 data/ 이전 라인에 작성하면 적용되지 않는다<span class="p">.</span>
**/*<span class="p">.</span>json               # 모든 디렉토리의 *<span class="p">.</span>json 파일을 무시한다<span class="p">.</span>
</code></pre></div></div>

<p><code class="highlighter-rouge">.gitignore</code> 파일을 저장하고 나면 앞으로는 해당 파일들은 tracking되지 않는다. 즉, 준비 영역에 추가될 수 없다.<br />
그러나 이미 tracking되고 있는 파일들은 영향을 받지 않는다. 따라서 <a href=""><code class="highlighter-rouge">git rm --cached</code></a> 명령을 통해 tracking 목록에서 제거해야 한다.</p>

<h3 id="전체-프로젝트에-gitignore-적용하기">전체 프로젝트에 .gitignore 적용하기</h3>

<p>특정 프로젝트가 아닌 모든 프로젝트 전체에 적용하고 싶으면 다음 명령을 입력한다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git config <span class="p">--</span>global core<span class="p">.</span>excludesfile <span class="p">&lt;.</span>gitignore<span class="p">-</span><span class="k">file</span><span class="p">-</span>path<span class="p">&gt;</span>

# 명령 예시
git config <span class="p">--</span>global core<span class="p">.</span>excludesfile <span class="p">~</span>/<span class="p">.</span>gitignore
git config <span class="p">--</span>global core<span class="p">.</span>excludesfile C<span class="p">:</span>\<span class="p">.</span>gitignore
</code></pre></div></div>

<p>그러면 해당 위치에 <code class="highlighter-rouge">.gitignore</code> 파일이 생성되고, 이는 모든 프로젝트에 적용된다. 일반적으로 <code class="highlighter-rouge">git config --global</code> 명령을 통해 설정하는 것은 특정 프로젝트가 아닌 해당 로컬에서 작업하는 모든 프로젝트에 영향을 준다. <a href="">여기</a>를 참고하라.</p>

<hr />

<h2 id="history-검토">History 검토</h2>

<h3 id="git-log-현재-존재하는-commit-검토">git log: 현재 존재하는 commit 검토</h3>

<p>저장소 commit 메시지의 모든 history를 역순으로 보여준다. 즉, 가장 마지막에 한 commit이 가장 먼저 보여진다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git log

# 결과 예시
commit da446019230a010bf333db9d60529e30bfa3d4e3 <span class="p">(</span>HEAD <span class="p">-&gt;</span> master<span class="p">,</span> origin<span class="sr">/master, origin/</span>HEAD<span class="p">)</span>
Merge<span class="p">:</span> <span class="m">4</span>a521c5 <span class="m">2</span>eae048
Author<span class="p">:</span> greeksharifa <span class="p">&lt;</span>greeksharifa@gmail<span class="p">.</span><span class="k">com</span><span class="p">&gt;</span>
Date<span class="p">:</span>   Sun Aug <span class="m">19</span> <span class="m">20</span><span class="p">:</span><span class="m">59</span><span class="p">:</span><span class="m">24</span> <span class="m">2018</span> <span class="p">+</span><span class="m">0900</span>

    Merge branch <span class="s1">'3rd-branch'</span>

commit <span class="m">2</span>eae048f725c1d843cad359d655c193d9fd632b4
Author<span class="p">:</span> greeksharifa <span class="p">&lt;</span>greeksharifa@gmail<span class="p">.</span><span class="k">com</span><span class="p">&gt;</span>
Date<span class="p">:</span>   Sun Aug <span class="m">19</span> <span class="m">20</span><span class="p">:</span><span class="m">29</span><span class="p">:</span><span class="m">48</span> <span class="m">2018</span> <span class="p">+</span><span class="m">0900</span>

    Unwanted commit from <span class="m">2</span>nd<span class="p">-</span>branch

<span class="p">...</span>
<span class="p">:</span>
</code></pre></div></div>

<p>이때 commit의 수가 많으면 다음 명령을 기다리는 커서가 깜빡인다. 여기서 space bar를 누르면 다음 commit들을 계속해서 보여주고, 끝에 다다르면(저장소의 최초 commit에 도달하면) <code class="highlighter-rouge">(END)</code>가 표시된다.<br />
끝에 도달했거나 이전 commit들을 더 볼 필요가 없다면, <code class="highlighter-rouge">q</code>를 누르면 log 보기를 중단한다(quit).</p>

<h4 id="git-log-옵션-patch-p-max-count-number-onelineprettyoneline">git log 옵션: –patch(-p), –max-count(-&lt;number&gt;), –oneline(–pretty=oneline)</h4>

<p>각 commit의 diff 결과(commit의 세부 변경사항, 변경된 파일의 변경된 부분들을 보여줌)를 보고 싶으면 다음을 입력한다.</p>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git log --patch

# 결과 예시
commit 2eae048f725c1d843cad359d655c193d9fd632b4
Author: greeksharifa &lt;greeksharifa@gmail.com&gt;
Date:   Sun Aug 19 20:29:48 2018 +0900

    Unwanted commit from 2nd-branch

<span class="gh">diff --git a/first.py b/first.py
index 2d61b9f..c73f054 100644
</span><span class="gd">--- a/first.py
</span><span class="gi">+++ b/first.py
</span><span class="gu">@@ -9,3 +9,5 @@ print("This is the 1st sentence written in 3rd-branch.")
</span> print('2nd')

 print('test git add .')
<span class="gi">+
+print("Unwanted sentence in 2nd-branch")
</span></code></pre></div></div>

<p>가장 최근의 commit들 3개만 보고 싶다면 다음과 같이 입력한다.</p>
<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git log <span class="m">-3</span>
</code></pre></div></div>

<p>commit의 대표 메시지와 같은 핵심 내용만 보고자 한다면 다음과 같이 입력한다.</p>
<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git log <span class="p">--</span>oneline

# 결과 예시
da44601 <span class="p">(</span>HEAD <span class="p">-&gt;</span> master<span class="p">,</span> origin<span class="sr">/master, origin/</span>HEAD<span class="p">)</span> Merge branch <span class="s1">'3rd-branch'</span>
<span class="m">2</span>eae048 Unwanted commit from <span class="m">2</span>nd<span class="p">-</span>branch
<span class="m">4</span>a521c5 Desired commit from <span class="m">2</span>nd<span class="p">-</span>branch
</code></pre></div></div>

<p>참고로, 다음과 같이 입력하면 commit의 고유 id의 전체가 출력된다.</p>
<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git log <span class="p">--</span>pretty<span class="p">=</span>oneline

# 결과 예시
da446019230a010bf333db9d60529e30bfa3d4e3 <span class="p">(</span>HEAD <span class="p">-&gt;</span> master<span class="p">,</span> origin<span class="sr">/master, origin/</span>HEAD<span class="p">)</span> Merge branch <span class="s1">'3rd-branch'</span>
<span class="m">2</span>eae048f725c1d843cad359d655c193d9fd632b4 Unwanted commit from <span class="m">2</span>nd<span class="p">-</span>branch
<span class="m">4</span>a521c56a6c2e50ffa379a7f2737b5e90e9e6df3 Desired commit from <span class="m">2</span>nd<span class="p">-</span>branch
</code></pre></div></div>

<p>옵션들은 중복이 가능하다.</p>
<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git log <span class="p">--</span>oneline <span class="m">-5</span>
</code></pre></div></div>

<h3 id="git-reflog-commit과-commit의-변화-과정-전체를-검토">git reflog: commit과 commit의 변화 과정 전체를 검토</h3>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git reflog

# 결과 예시<span class="p">:</span>
<span class="m">87</span>ab51e <span class="p">(</span>HEAD <span class="p">-&gt;</span> master<span class="p">,</span> tag<span class="p">:</span> specific_tag<span class="p">)</span> HEAD@<span class="p">{</span><span class="m">0</span><span class="p">}:</span> commit<span class="p">:</span> All text <span class="k">in</span> <span class="k">first</span> line will be showed at <span class="p">--</span>onel
ine
da44601 <span class="p">(</span>origin<span class="sr">/master, origin/</span>HEAD<span class="p">)</span> HEAD@<span class="p">{</span><span class="m">1</span><span class="p">}:</span> clone<span class="p">:</span> from https<span class="p">:</span><span class="sr">//</span>github<span class="p">.</span><span class="k">com</span><span class="sr">/greeksharifa/</span>git_tutorial<span class="p">.</span>git
</code></pre></div></div>

<p>위와 같이 <code class="highlighter-rouge">HEAD@{0}</code>: commit과 <code class="highlighter-rouge">HEAD@{1}</code>: clone 이라는 변화를 볼 수 있다. <code class="highlighter-rouge">git reflog</code>는 commit 뿐 아니라 commit이 삭제되었는지, 재배치했는지, clone이나 rebase 같은 변화가 있었는지 등등 git에서 일어난 모든 변화를 기록한다.</p>

<hr />

<h2 id="head-branch의-tip">HEAD: branch의 tip</h2>

<p>HEAD는 현 branch history의 가장 끝을 의미한다. 여기서 끝은 가장 최신 commit 쪽의 끝이다(시작점을 가리키지 않는다).<br />
다른 의미로는 checkout된 commit, 또는 현재 작업중인 commit이다.</p>

<p>예를 들어, <code class="highlighter-rouge">HEAD@{0}</code>은 1번째 최신 commit(즉, 가장 최신 commit)을 의미한다. index는 많은 프로그래밍 언어가 그렇듯 0부터 시작한다. 비슷하게, <code class="highlighter-rouge">HEAD@{1}</code>은 2번째 최신 commit을 의미한다.</p>

<p><code class="highlighter-rouge">HEAD^</code>는 HEAD의 직전, 즉 가장 최신 commit을 가리킨다.</p>

<p>범위를 나타낼 땐 <code class="highlighter-rouge">~</code>를 사용한다. 예를 들어, <code class="highlighter-rouge">HEAD~3</code>은 가장 최신 commit(1번째)부터 3번째 commit까지를 가리킨다.</p>

<p><code class="highlighter-rouge">HEAD~2^</code>는 <code class="highlighter-rouge">HEAD^</code>(가장 최신, 즉 1번째 commit)보다 2번 더 이전 commit까지 간 것이고, 범위(<code class="highlighter-rouge">~</code>)를 나타내므로 1~3번째 commit을 가리킨다. 헷갈리니까 3개의 commit을 다루고 싶으면 그냥 <code class="highlighter-rouge">HEAD~3</code>을 쓰자.</p>

<hr />

<h2 id="tag-붙이기">Tag 붙이기</h2>

<p>태그는 특정한 commit을 찾아내기 위해 사용된다. 즐겨찾기와 같은 개념이기 때문에, 여러 commit에 동일한 태그를 붙이지 않도록 한다.</p>

<p>우선 태그를 붙이고 싶은 commit을 찾자.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 명령어 예시 <span class="m">1</span>
git log <span class="p">--</span>oneline <span class="m">-3</span>

# 결과 예시 <span class="m">1</span>
<span class="m">87</span>ab51e <span class="p">(</span>HEAD <span class="p">-&gt;</span> master<span class="p">)</span> All text <span class="k">in</span> <span class="k">first</span> line will be showed at <span class="p">--</span>oneline
da44601 <span class="p">(</span>origin<span class="sr">/master, origin/</span>HEAD<span class="p">)</span> Merge branch <span class="s1">'3rd-branch'</span>
<span class="m">2</span>eae048 Unwanted commit from <span class="m">2</span>nd<span class="p">-</span>branch

# 명령어 예시 <span class="m">2</span>
git log <span class="m">87</span>ab51e <span class="p">--</span>max<span class="p">-</span>count<span class="p">=</span><span class="m">1</span>
git show <span class="m">87</span>ab51e

# 결과 예시 <span class="m">2</span>
commit <span class="m">87</span>ab51eecef1a526cb504846ddcaed0459f685c8 <span class="p">(</span>HEAD <span class="p">-&gt;</span> master<span class="p">)</span>
Author<span class="p">:</span> greeksharifa <span class="p">&lt;</span>greeksharifa@gmail<span class="p">.</span><span class="k">com</span><span class="p">&gt;</span>
Date<span class="p">:</span>   Thu May <span class="m">28</span> <span class="m">14</span><span class="p">:</span><span class="m">49</span><span class="p">:</span><span class="m">13</span> <span class="m">2020</span> <span class="p">+</span><span class="m">0900</span>

    All text <span class="k">in</span> <span class="k">first</span> line will be showed at <span class="p">--</span>oneline

    Maximum length <span class="k">is</span> <span class="m">50</span> characters<span class="p">.</span>
    Below<span class="p">,</span> <span class="k">is</span> <span class="k">for</span> detailed message<span class="p">.</span>
</code></pre></div></div>

<h3 id="git-tag">git tag</h3>

<p>이제 태그를 commit에 붙여보자.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git tag <span class="p">&lt;</span>tag<span class="p">-</span>name<span class="p">&gt;</span> <span class="m">87</span>ab51e

# 명령어 예시
git tag specific_tag <span class="m">87</span>ab51e
</code></pre></div></div>

<p>지금까지 붙인 태그 목록을 보려면 다음 명령을 입력한다.</p>
<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git tag

# 결과 예시
specific_tag
</code></pre></div></div>

<p>해당 태그가 추가된 commit을 보려면 <a href="https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#git-show-tag-name">여기</a>를 참조한다.</p>

<hr />

<h2 id="특정-commit-보기">특정 commit 보기</h2>

<h3 id="git-show">git show</h3>

<p>commit id를 사용해서 특정 commit을 보고자 하면 다음과 같이 쓴다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git log <span class="m">87</span>ab51e <span class="p">--</span>max<span class="p">-</span>count<span class="p">=</span><span class="m">1</span>
git show <span class="m">87</span>ab51e

# 결과 예시
Author<span class="p">:</span> greeksharifa <span class="p">&lt;</span>greeksharifa@gmail<span class="p">.</span><span class="k">com</span><span class="p">&gt;</span>
Date<span class="p">:</span>   Thu May <span class="m">28</span> <span class="m">14</span><span class="p">:</span><span class="m">49</span><span class="p">:</span><span class="m">13</span> <span class="m">2020</span> <span class="p">+</span><span class="m">0900</span>

    All text <span class="k">in</span> <span class="k">first</span> line will be showed at <span class="p">--</span>oneline

    Maximum length <span class="k">is</span> <span class="m">50</span> characters<span class="p">.</span>
    Below<span class="p">,</span> <span class="k">is</span> <span class="k">for</span> detailed message<span class="p">.</span>
</code></pre></div></div>

<h4 id="git-show-tag-name">git show &lt;tag-name&gt;</h4>

<div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git show &lt;tag-name&gt;

# 명령어 예시
git show specific_tag

# 결과 예시
commit 87ab51eecef1a526cb504846ddcaed0459f685c8 (HEAD -&gt; master, tag: specific_tag)
Author: greeksharifa &lt;greeksharifa@gmail.com&gt;
Date:   Thu May 28 14:49:13 2020 +0900

    All text in first line will be showed at --oneline

    Maximum length is 50 characters.
    Below, is for detailed message.

<span class="gh">diff --git a/.gitignore b/.gitignore
index 8d16a4b..6ec8ec8 100644
</span><span class="gd">--- a/.gitignore
</span><span class="gi">+++ b/.gitignore
</span><span class="gu">@@ -1,3 +1,2 @@
</span><span class="gd">-third.py
</span> .idea/
 *dummy*
<span class="gh">diff --git a/third.py b/third.py
</span>new file mode 100644
<span class="gh">index 0000000..0360dad
</span><span class="gd">--- /dev/null
</span><span class="gi">+++ b/third.py
</span><span class="gu">@@ -0,0 +1 @@
</span><span class="gi">+print('hello 3!')
</span></code></pre></div></div>
<hr />

<h2 id="git-branch">Git Branch</h2>

<h3 id="branch-목록-보기">branch 목록 보기</h3>

<p>로컬 branch 목록을 보려면 다음을 입력한다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git branch
git branch <span class="p">--</span>list
git branch <span class="p">-</span><span class="k">l</span>

# 결과 예시
* master
</code></pre></div></div>

<p>branch 목록을 보여주는 모든 명령에서, 현재 branch(작업 중인 branch)는 맨 앞에 asterisk(<code class="highlighter-rouge">*</code>)가 붙는다.</p>

<p>모든 branch 목록 보기:</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git branch <span class="p">--</span><span class="k">all</span>
git branch <span class="p">-</span><span class="k">a</span>

# 결과 예시
* master
  remotes<span class="sr">/origin/</span><span class="m">2</span>nd<span class="p">-</span>branch
  remotes<span class="sr">/origin/</span><span class="m">3</span>rd<span class="p">-</span>branch
  remotes<span class="sr">/origin/</span>HEAD <span class="p">-&gt;</span> origin/master
  remotes<span class="sr">/origin/</span>master
</code></pre></div></div>

<p><code class="highlighter-rouge">remotes/</code>가 붙은 것은 원격 branch라는 뜻이며, branch의 이름에는 <code class="highlighter-rouge">remotes/</code>가 포함되지 않는다.</p>

<p>원격 branch 목록 보기:</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git branch <span class="p">--</span>remotes
git branch <span class="p">-</span><span class="k">r</span>

# 결과 예시
  origin/<span class="m">2</span>nd<span class="p">-</span>branch
  origin/<span class="m">3</span>rd<span class="p">-</span>branch
  origin<span class="sr">/HEAD -&gt; origin/</span>master
  origin/master
</code></pre></div></div>

<h3 id="원격-branch-목록-업데이트">원격 branch 목록 업데이트</h3>

<p>로컬 저장소와 원격 저장소는 실시간 동기화가 이루어지는 것이 아니기 때문에(일부 git 명령을 내릴 때에만 통신이 이루어짐), 원격 branch 목록은 자동으로 최신으로 유지되지 않는다. 목록을 새로 확인하려면 다음을 입력한다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git fetch
</code></pre></div></div>

<p>별다른 변경점이 없으면 아무 것도 표시되지 않는다.</p>

<hr />

<h3 id="branch-전환">branch 전환</h3>

<p>단순히 branch 간 전환을 하고 싶으면 다음 명령어를 입력한다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git checkout <span class="p">&lt;</span>branch<span class="p">-</span>name<span class="p">&gt;</span>

# 명령어 예시
git checkout master

# 결과 예시
Switched <span class="k">to</span> branch <span class="s1">'master'</span>
M       <span class="p">.</span>gitignore
D       second<span class="p">.</span><span class="k">py</span>
Your branch <span class="k">is</span> ahead of <span class="s1">'origin/master'</span> by <span class="m">1</span> commit<span class="p">.</span>
  <span class="p">(</span>use <span class="s2">"git push"</span> <span class="k">to</span> publish your local commits<span class="p">)</span>
</code></pre></div></div>

<p>전환을 수행하면,</p>
<ul>
  <li>변경된 파일의 목록과</li>
  <li>현재 로컬 브랜치가 연결되어 있는 원격 브랜치 사이에 얼마만큼의 commit 차이가 있는지</li>
</ul>

<p>도 알려준다.</p>

<p>로컬에 새 branch를 생성하되, 그 내용을 원격 저장소에 있는 어떤 branch의 내용으로 하고자 하면 다음 명령을 사용한다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git checkout <span class="p">--</span>track <span class="p">-</span><span class="k">b</span> <span class="p">&lt;</span>local<span class="p">-</span>branch<span class="p">-</span>name<span class="p">&gt;</span> <span class="p">&lt;</span>remote<span class="p">-</span>branch<span class="p">-</span>name<span class="p">&gt;</span>

# 명령어 예시
git checkout <span class="p">--</span>track <span class="p">-</span><span class="k">b</span> <span class="m">2</span>nd<span class="p">-</span>branch origin/<span class="m">2</span>nd<span class="p">-</span>branch

# 결과 예시
Switched <span class="k">to</span> <span class="k">a</span> <span class="k">new</span> branch <span class="s1">'2nd-branch'</span>
M       <span class="p">.</span>gitignore
D       second<span class="p">.</span><span class="k">py</span>
Branch <span class="s1">'2nd-branch'</span> <span class="k">set</span> <span class="k">up</span> <span class="k">to</span> track remote branch <span class="s1">'2nd-branch'</span> from <span class="s1">'origin'</span><span class="p">.</span>
</code></pre></div></div>

<p>출력에서는 <code class="highlighter-rouge">2nd-branch</code>라는 이름의 새 branch로 전환하였고, 파일의 현재 수정 사항을 간략히 보여주며, 로컬 branch <code class="highlighter-rouge">2nd-branch</code>가 <code class="highlighter-rouge">origin</code>의 원격 branch <code class="highlighter-rouge">2nd-branch</code>를 추적하게 되었음을 알려준다.<br />
즉 원격 branch의 로컬 사본이 생성되었음을 알 수 있다.</p>

<h3 id="새-branch-생성">새 branch 생성</h3>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git branch <span class="p">&lt;</span><span class="k">new</span><span class="p">-</span>branch<span class="p">-</span>name<span class="p">&gt;</span>

# 명령어 예시
git branch fourth<span class="p">-</span>branch
</code></pre></div></div>

<p>위 명령은 branch를 생성만 한다. 생성한 브랜치에서 작업을 시작하려면 checkout 과정을 거쳐야 한다.</p>

<h3 id="branch-생성과-같이-checkout하기">branch 생성과 같이 checkout하기</h3>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git checkout <span class="p">-</span><span class="k">b</span> <span class="p">&lt;</span><span class="k">new</span><span class="p">-</span>branch<span class="p">-</span>name<span class="p">&gt;</span> <span class="p">&lt;</span>parent<span class="p">-</span>branch<span class="p">-</span>name<span class="p">&gt;</span>

# 명령어 예시
git checkout <span class="p">-</span><span class="k">b</span> fourth<span class="p">-</span>branch master

# 결과 예시
Switched <span class="k">to</span> <span class="k">a</span> <span class="k">new</span> branch <span class="s1">'fourth-branch'</span>
</code></pre></div></div>

<p>새로운 branch는 생성 시점에서 parent branch와 같은 history(commit 기록들)을 갖는다.</p>

<h3 id="branch-병합">branch 병합</h3>

<p><code class="highlighter-rouge">git merge &lt;branch-name&gt;</code>를 사용한다. <code class="highlighter-rouge">&lt;branch-name&gt;</code> branch의 수정 사항들(commit)을 <strong>현재 branch</strong>로 가져와 병합한다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git merge <span class="p">&lt;</span>branch<span class="p">-</span>name<span class="p">&gt;</span>

# 명령어 예시
git merge ticket<span class="p">-</span>branch

# 결과 예시
Updating <span class="m">96</span>c99dc<span class="p">..</span><span class="m">94</span>d511c
Fast<span class="p">-</span>forward
 <span class="p">.</span>gitignore <span class="p">|</span> <span class="m">2</span> <span class="p">+-</span>
 fourth<span class="p">.</span><span class="k">py</span>  <span class="p">|</span> <span class="m">5</span> <span class="p">+++++</span>
 second<span class="p">.</span><span class="k">py</span>  <span class="p">|</span> <span class="m">9</span> <span class="p">---------</span>
 third<span class="p">.</span><span class="k">py</span>   <span class="p">|</span> <span class="m">0</span>
 <span class="m">4</span> <span class="k">files</span> changed<span class="p">,</span> <span class="m">6</span> insertions<span class="p">(+),</span> <span class="m">10</span> deletions<span class="p">(-)</span>
 create <span class="k">mode</span> <span class="m">100644</span> fourth<span class="p">.</span><span class="k">py</span>
 delete <span class="k">mode</span> <span class="m">100644</span> second<span class="p">.</span><span class="k">py</span>
 create <span class="k">mode</span> <span class="m">100644</span> third<span class="p">.</span><span class="k">py</span>
</code></pre></div></div>

<p>이와 같은 방법을 history fast-forward라 한다(히스토리 빨리 감기).</p>

<p>병합할 때 ticket branch의 모든 commit들을 하나의 commit으로 합쳐서 parent branch에 병합하고자 할 때는 <code class="highlighter-rouge">--squash</code> 옵션을 사용한다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 현재 branch가 parent branch일 때
git merge ticket<span class="p">-</span>branch <span class="p">--</span>squash
</code></pre></div></div>

<p><code class="highlighter-rouge">--squash</code> 옵션은 애초에 branch를 분리하지 말았어야 할 상황에서 쓰면 된다. 즉, 병합 후 parent branch 입장에서는 그냥 하나의 commit이 반영된 것과 같은 효과를 갖는다.</p>

<p>위와 같이 처리했을 때는 ticket branch가 더 이상 필요 없으니 삭제하도록 하자.</p>

<h3 id="branch-삭제">branch 삭제</h3>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git branch <span class="p">--</span>delete <span class="p">&lt;</span>branch<span class="p">-</span>name<span class="p">&gt;</span>
git branch <span class="p">-</span><span class="k">d</span> <span class="p">&lt;</span>branch<span class="p">-</span>name<span class="p">&gt;</span>

# 명령어 예시
git branch <span class="p">--</span>delete ticket<span class="p">-</span>branch

# 결과 예시
Deleted branch fourth<span class="p">-</span>branch <span class="p">(</span>was <span class="m">94</span>d511c<span class="p">).</span>
</code></pre></div></div>

<p>branch 삭제는 해당 branch의 수정사항들이 다른 branch에 병합되어서, 더 이상 필요없음이 확실할 때에만 문제없이 실행된다.<br />
아직 수정사항이 남아 있음에도 그냥 해당 branch 자체를 폐기처분하고 싶으면 <code class="highlighter-rouge">--delete</code> 대신 <code class="highlighter-rouge">-D</code> 옵션을 사용한다.</p>

<p>이미 원격 저장소에 올라간 branch를 삭제하려면 <a href="https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#upstream-%EC%82%AD%EC%A0%9C">여기</a>를 참조한다.</p>

<hr />

<h2 id="작업-취소하기">작업 취소하기</h2>

<p>먼저 가능한 작업 취소 명령들을 살펴보자.</p>

<table>
  <thead>
    <tr>
      <th>원하는 것</th>
      <th>명령어</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>특정 파일의 수정사항 되돌리기</td>
      <td><code class="highlighter-rouge">git checkout -- &lt;filename&gt;</code></td>
    </tr>
    <tr>
      <td>모든 수정사항을 되돌리기</td>
      <td><code class="highlighter-rouge">git reset --hard</code></td>
    </tr>
    <tr>
      <td>준비 영역의 모든 수정사항을 삭제</td>
      <td><code class="highlighter-rouge">git reset --hard &lt;commit&gt;</code></td>
    </tr>
    <tr>
      <td>여러 commit 통합</td>
      <td><code class="highlighter-rouge">git reset &lt;commit&gt;</code></td>
    </tr>
    <tr>
      <td>이전 commit들을 수정 또는 통합, 혹은 분리</td>
      <td><code class="highlighter-rouge">git rebase --interactive &lt;commit&gt;</code></td>
    </tr>
    <tr>
      <td>untracked 파일을 포함해 모든 수정사항을 되돌리기</td>
      <td><code class="highlighter-rouge">git clean -fd</code></td>
    </tr>
    <tr>
      <td>이전 commit을 삭제하되 history는 그대로 두기</td>
      <td><code class="highlighter-rouge">git revert &lt;commit&gt;</code></td>
    </tr>
  </tbody>
</table>

<p>아래는 <a href="https://www.amazon.com/Git-Teams-User-Centered-Efficient-Workflows/dp/1491911182">Git for Teams</a>라는 책에서 가져온 flowchart이다. 뭔가 잘못되었을 때 사용해보도록 하자.</p>

<center><img src="/public/img/2020-05-27-github-usage-09-overall/01.png" width="100%" /></center>

<p>여러 명이 협업하는 프로젝트에서 이미 원격 저장소에 잘못된 수정사항이 올라갔을 때, 이를 강제로 되돌리는 것은 금물이다. ‘잘못된 수정사항을 삭제하는’ 새로운 commit을 만들어 반영시키는 쪽이 훨씬 낫다.</p>

<p>물론 branch를 잘 만들고, pull request 시스템을 적극 활용해서 그러한 일이 일어나지 않도록 하는 것이 최선이다.</p>

<hr />

<h3 id="특정-파일의-수정사항-되돌리기-checkout-reset">특정 파일의 수정사항 되돌리기: checkout, reset</h3>

<p>특정 파일을 지워 버렸거나 수정을 잘못했다고 하자. 이 때에는 다음 전제조건이 있다.</p>

<blockquote>
  <p>수정사항을 commit하지 않았을 때</p>
</blockquote>

<p>commit하지 않았다면, 다음 두 가지 경우가 있다. <code class="highlighter-rouge">git status</code>를 입력하면 친절히 알려준다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git status

#결과 예시
On branch master

Changes not staged <span class="k">for</span> commit<span class="p">:</span>
  <span class="p">(</span>use <span class="s2">"git add &lt;file&gt;..."</span> <span class="k">to</span> <span class="k">update</span> what will be committed<span class="p">)</span>
  <span class="p">(</span>use <span class="s2">"git checkout -- &lt;file&gt;..."</span> <span class="k">to</span> discard <span class="k">changes</span> <span class="k">in</span> working directory<span class="p">)</span>

        modified<span class="p">:</span>   third<span class="p">.</span><span class="k">py</span>

no <span class="k">changes</span> added <span class="k">to</span> commit <span class="p">(</span>use <span class="s2">"git add"</span> and/or <span class="s2">"git commit -a"</span><span class="p">)</span>
</code></pre></div></div>

<p>마지막 줄에서 아직 commit된 것이 없다는 것을 확인해야 한다.</p>

<ol>
  <li>수정사항을 준비 영역에 올리지 않았을 때(<code class="highlighter-rouge">git add</code>를 안 수행했을 때)
    <ul>
      <li><code class="highlighter-rouge">git checkout -- &lt;filename&gt;</code></li>
      <li>그러면 파일이 원래대로 복구된다.</li>
    </ul>
  </li>
  <li>수정사항을 stage했을 때(<code class="highlighter-rouge">git add</code>를 수행했을 때)
    <ul>
      <li>그러면 위 결과 예시처럼 <code class="highlighter-rouge">no changes added to commit ...</code>이라는 메시지가 없다. 다음 두 명령을 입력한다.</li>
      <li><code class="highlighter-rouge">git reset HEAD &lt;filename&gt;</code></li>
      <li><code class="highlighter-rouge">git checkout -- &lt;filename&gt;</code>
 을 입력한다.</li>
      <li>그러면 가장 최신(HEAD) commit에 저장되어 있는 파일의 원래 상태가 복구된다. commit하지 않았을 때 사용할 수 있는 이유가 이것이다.</li>
      <li>아니면 명령어 두 개를 합친 다음 명령을 써도 된다.</li>
      <li><code class="highlighter-rouge">git reset --hard HEAD -- &lt;filename&gt;</code></li>
    </ul>
  </li>
</ol>

<p><code class="highlighter-rouge">git reset &lt;filename&gt;</code>은 <code class="highlighter-rouge">git add &lt;filename&gt;</code>의 역방향이라고 보면 된다. 물론 <code class="highlighter-rouge">git reset &lt;commit&gt; &lt;filename&gt;</code>은 파일을 여러 commit 이전으로 되돌릴 수 있기 때문에 상황에 따라서는 다른 작업일 수 있다.</p>

<p>비슷하게, <code class="highlighter-rouge">git reset -p &lt;filename&gt;</code>은 <code class="highlighter-rouge">git add -p &lt;filename&gt;</code>의 역 작업이다.</p>

<p><code class="highlighter-rouge">git reset</code>의 옵션은 여러 개가 있다.</p>

<ul>
  <li><code class="highlighter-rouge">git reset [-q | -p] [--] &lt;paths&gt;</code>: <code class="highlighter-rouge">&lt;paths&gt;</code>는 <code class="highlighter-rouge">&lt;filename&gt;</code>을 포함한다. 즉, filename 뿐만 아니라 디렉토리 등도 가능하다. 이 명령의 효과는 <code class="highlighter-rouge">git add [-p]</code>의 역 작업이다.</li>
  <li><code class="highlighter-rouge">git reset [--soft | --mixed [-N] | --hard | --merge | --keep] -[q] [&lt;commit&gt;]</code>
    <ul>
      <li><code class="highlighter-rouge">--hard</code>: <code class="highlighter-rouge">&lt;commit&gt;</code> 이후 발생한 모든 수정사항과 준비 영역의 수정사항이 폐기된다.</li>
      <li><code class="highlighter-rouge">--soft</code>는 파일의 수정사항이 남아 있으며, 수정된 파일들이 모두 <strong>Changes to be committed</strong> 상태가 된다.</li>
      <li><code class="highlighter-rouge">--mixed</code>는 파일의 수정사항은 남아 있으나 준비 영역의 수정사항은 폐기된다. mixed가 기본 옵션이다.</li>
      <li><code class="highlighter-rouge">--merge</code>는 준비 영역의 수정사항은 폐기하고 <code class="highlighter-rouge">&lt;commit&gt;</code>과 <code class="highlighter-rouge">HEAD</code> 사이 수정된 파일들을 업데이트하지만 수정된 파일들은 stage되지 않는다.</li>
      <li><code class="highlighter-rouge">--keep</code>은 <code class="highlighter-rouge">--merge</code>와 비슷하나 <code class="highlighter-rouge">&lt;commit&gt;</code>때와 <code class="highlighter-rouge">HEAD</code> 때가 다른 파일에 일부 변화가 있는 경우에는 <code class="highlighter-rouge">reset</code> 과정이 중단된다.</li>
    </ul>
  </li>
</ul>

<p>모든 파일의 수정사항 되돌리기:</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git reset <span class="p">--</span><span class="k">hard</span> HEAD
</code></pre></div></div>

<hr />

<h3 id="branch-병합-취소하기">branch 병합 취소하기</h3>

<p>먼저 다음 <a href="https://www.amazon.com/Git-Teams-User-Centered-Efficient-Workflows/dp/1491911182">flowchart</a>를 살펴보자.</p>

<center><img src="/public/img/2020-05-27-github-usage-09-overall/02.png" width="100%" /></center>

<p>바로 직전에 한 병합(merge)를 취소하려면 다음 명령어를 입력한다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git reset <span class="p">--</span>merge ORIG_HEAD
</code></pre></div></div>

<p>병합 후 추가한 commit이 있으면 해당 지점의 commit을 지정해야 한다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git reset <span class="p">&lt;</span>commit<span class="p">&gt;</span>
</code></pre></div></div>

<p>어디인지 잘 모르겠으면 <a href="https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#git-reflog-commit%EA%B3%BC-commit%EC%9D%98-%EB%B3%80%ED%99%94-%EA%B3%BC%EC%A0%95-%EC%A0%84%EC%B2%B4%EB%A5%BC-%EA%B2%80%ED%86%A0">reflog</a>를 사용해보자.</p>

<hr />

<h3 id="커밋-합치기-git-reset-commit">커밋 합치기: git reset &lt;commit&gt;</h3>

<p>기본적으로, <code class="highlighter-rouge">git reset</code>은 branch tip을 <code class="highlighter-rouge">&lt;commit&gt;</code>으로 옮기는 과정이다. 그래서, <code class="highlighter-rouge">git reset &lt;option&gt; HEAD</code>는 마지막 commit의 상태로 준비 영역 또는 파일 내용을 되돌리는(reset) 작업이다.<br />
또한, 바로 위에서 살펴봤듯이, <code class="highlighter-rouge">git reset</code>은 기본 옵션이 <code class="highlighter-rouge">--mixed</code>이며, 이는 옵션을 따로 명시하지 않으면 <code class="highlighter-rouge">git reset</code>은 파일의 수정사항은 그대로 둔 채 준비 영역에는 추가된 수정사항이 없는 상태로 만든다.</p>

<p>그래서 특정 이전 commit을 지정하여 <code class="highlighter-rouge">git reset &lt;commit&gt;</code>을 수행하면 해당 <code class="highlighter-rouge">&lt;commit&gt;</code>부터 <code class="highlighter-rouge">HEAD</code>까지의 파일의 수정사항은 작업트리(=프로젝트 디렉토리 전체)에 그대로 남아 있지만, 준비 영역에는 아무런 변화도 기록되어 있지 않다.<br />
먼저 어떤 커밋들을 합칠지 <code class="highlighter-rouge">git log --oneline</code>으로 확인해보자.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 결과 예시
c8c731b (HEAD -&gt; master, origin/master, origin/HEAD) doong commit
87ab51e (tag: specific_tag) All text in first line will be showed at --oneline
da44601 Merge branch '3rd-branch'
2eae048 Unwanted commit from 2nd-branch
4a521c5 Desired commit from 2nd-branch
</code></pre></div></div>

<p>이제 가장 최신 2개의 commit을 합치고 싶으면, 현재 branch의 HEAD를 <code class="highlighter-rouge">c8c731b</code>에서 <code class="highlighter-rouge">da44601</code>로 옮기면 된다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git reset da44601
</code></pre></div></div>
<p>그러면 직전 2개의 commit의 수정사항이 파일에는 그대로 남아 있지만, 준비 영역이나 commit 내역에선 사라진다. 이제 stage, commit, push 3단계를 수행하면 최종적으로 commit 2개가 1개로 합쳐진다.</p>

<p><code class="highlighter-rouge">&lt;commit&gt;</code> id를 지정하는 것이 헷갈린다면 <code class="highlighter-rouge">git reset HEAD~2</code>로 실행하자. 이는 <a href="https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#head-branch%EC%9D%98-tip">여기</a>에서 볼 수 있듯이 범위로 2개의 commit을 포함한다.</p>

<hr />

<h3 id="git-rebase">git rebase</h3>

<p>rebase는 일반적으로 history rearrange의 역할을 한다. 즉, 여러 commit들의 순서를 재배치하는 작업이라 할 수 있다. 혹은 parent branch의 수정사항을 가져오면서 자신의 commit은 그 이후에 추가된 것처럼 하는, 마치 분기된 시점을 뒤로 미룬 듯한 작업을 수행할 수도 있다.</p>

<p>그러나 rebase와 같은 기존 작업을 취소 또는 변경하는 명령은 일반적으로 충돌(conflict)이 일어나는 경우가 많다. 충돌이 발생하면 git은 작업을 일시 중지하고 사용자에게 충돌을 처리하라고 한다.</p>

<h4 id="master-branch의-commit을-topic-branch로-가져오기">master branch의 commit을 topic branch로 가져오기</h4>

<p>다음과 같은 상황을 가정하자. 각 알파벳은 하나의 commit이며, 각 이름은 branch의 이름을 나타낸다.<br />
아래 각 예시는 <code class="highlighter-rouge">git help</code>에 나오는 도움말을 이용하였다.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>          A---B---C topic
         /
    D---E---F---G master
</code></pre></div></div>

<p>commit F, G를 topic branch에 반영(포함)시키려 한다면,</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                  A'--B'--C' topic
                 /
    D---E---F---G master
</code></pre></div></div>

<p>commit A’와 A는 프로젝트에 동일한 수정사항을 적용시키지만, 16진수로 된 commit의 고유 id(<code class="highlighter-rouge">da44601</code> 같은)는 다르다. 즉, 엄밀히는 다른 commit이다.</p>

<p>commit을 재배열하는 명령어는 다음과 같다. 현재 branch는 topic이라 가정한다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git rebase master
git rebase master topic
</code></pre></div></div>

<p>commit A, B, C가 F, G와 코드 상으로 동일한 파일 또는 다른 일부분을 수정하지 않았다면, 이 rebase 작업은 자동으로 완료된다.</p>

<p>만약 topic branch에 이미 master branch로부터 가져온 commit이 일부 존재하면, 이 commit들은 새로 배치되지 않는다.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>          A---B---C topic
         /
    D---E---A'---F master
</code></pre></div></div>
<p>에서</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                   B'---C' topic
                  /
    D---E---A'---F master
</code></pre></div></div>
<p>로 바뀐다.</p>

<h4 id="branch의-parent-바꾸기-onto">branch의 parent 바꾸기: –onto</h4>

<p>topic을 next가 아닌 master에서 분기된 것처럼 바꾸고자 한다. 즉,</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    o---A---B---o---C  master
         \
          D---o---o---o---E  next
                           \
                            o---o---o  topic
</code></pre></div></div>

<p>이걸 아래와 같이 바꿔보자.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    o---A---B---o---C  master
        |            \
        |             o'--o'--o'  topic
         \
          D---o---o---o---E  next
</code></pre></div></div>

<p>topic branch의 history에는 이제 commit D~E 대신 commit A~B가 포함되어 있다.</p>

<p>이는 다음과 같은 명령어로 수행할 수 있다:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git rebase --onto master next topic
</code></pre></div></div>

<p>다른 예시는:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                            H---I---J topicB
                           /
                  E---F---G  topicA
                 /
    A---B---C---D  master
</code></pre></div></div>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git rebase <span class="p">--</span>onto master topicA topicB
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                 H'--I'--J'  topicB
                /
                | E---F---G  topicA
                |/
    A---B---C---D  master
</code></pre></div></div>

<h4 id="특정-범위의-commit들-제거하기">특정 범위의 commit들 제거하기</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    E---F---G---H---I---J  topic
</code></pre></div></div>

<p>topic branch의 5번째 최신 commit부터, 3번째 최신 commit <strong>직전</strong>까지 commit을 topic branch에서 폐기하고 싶다고 하자. 그러면 다음 명령어로 사용 가능하다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git rebase <span class="p">--</span>onto <span class="p">&lt;</span>branch<span class="p">-</span>name<span class="p">&gt;~&lt;</span><span class="k">start</span><span class="p">-</span><span class="k">number</span><span class="p">&gt;</span> <span class="p">&lt;</span>branch<span class="p">-</span>name<span class="p">&gt;~&lt;</span><span class="k">end</span><span class="p">-</span><span class="k">number</span><span class="p">&gt;</span> <span class="p">&lt;</span>branch<span class="p">-</span>name<span class="p">&gt;</span>

# 명령어 예시
git rebase <span class="p">--</span>onto topic<span class="p">~</span><span class="m">5</span> topic<span class="p">~</span><span class="m">3</span> topic
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    E---H'---I'---J'  topic
</code></pre></div></div>

<p>여기서 5(번째 최신 commit, F)은 삭제되고, 3(번째 최신 commit, H)은 삭제되지 않음을 주의하라. rebase가 되기 때문에 commit의 고유 id는 바뀐다(H -&gt; H’)</p>

<h4 id="충돌-시-해결법">충돌 시 해결법</h4>

<p>일반적으로 rebase에서 수정하는 2개 이상의 commit이 같은 파일을 수정하면 충돌이 발생한다.</p>

<p>보통은 다음 과정을 거치면 해결된다.</p>

<ul>
  <li>충돌이 일어난 파일에 적절한 조취를 취한다. 파일을 남기거나/삭제하거나, 또는 파일 일부분에서 남길 부분을 찾는다. 코드 중 다음과 비슷해 보이는 부분이 있을 것이다. 적절히 지워서 해결하자.</li>
</ul>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ㅤ&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD
ㅤ&lt;current-code&gt;
ㅤ========
ㅤ&lt;incoming-code&gt;
ㅤ&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; da446019230a010bf333db9d60529e30bfa3d4e3
</code></pre></div></div>

<ul>
  <li><code class="highlighter-rouge">git add &lt;conflict-resolved-filename&gt;</code></li>
  <li><code class="highlighter-rouge">git rebase --continue</code></li>
</ul>

<p>그냥 다 모르겠고(?) rebase 작업을 취소하고자 하면 다음을 입력한다.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git rebased --abort
</code></pre></div></div>

<h4 id="rebase로-commit-합치거나-수정하기">rebase로 commit 합치거나 수정하기</h4>

<p>다음과 같은 history가 있다고 하자.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>c3eace0 <span class="p">(</span>HEAD <span class="p">-&gt;</span> master<span class="p">,</span> origin<span class="sr">/master, origin/</span>HEAD<span class="p">)</span> git checkout<span class="p">,</span> reset<span class="p">,</span> rebase
f6c56ef what igt
bd80626 github hem
b7801a2 github overall
<span class="m">608</span>a518 highlighter theme change
</code></pre></div></div>

<p>여러 개의 commit들을 합치거나, commit message를 수정하거나 하는 작업은 모두 rebase로 가능하다.<br />
실행하면, vim 에디터가 열릴 것이다(ubuntu의 경우 nano일 수 있다). vim을 쓰는 방법은 <a href="https://greeksharifa.github.io/github/2020/05/27/github-usage-09-overall/#git-commit--m-message-amend">여기</a>를 참고한다.</p>

<p>rebase하는 부분에서는 다른 git command들과는 달리 수정할 commit 중 가장 오래된 commit이 가장 위에 온다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git rebase <span class="p">--</span>interactive <span class="p">&lt;</span>commit<span class="p">&gt;</span>
git rebase <span class="p">-</span><span class="k">i</span> <span class="p">&lt;</span>commit<span class="p">&gt;</span>

# 명령 예시
git rebase <span class="p">-</span>interactive <span class="m">608</span>a518
git rebase <span class="p">-</span><span class="k">i</span> HEAD<span class="p">~</span><span class="m">4</span>

# 결과 예시

pick c3eace0 <span class="p">(</span>HEAD <span class="p">-&gt;</span> master<span class="p">,</span> origin<span class="sr">/master, origin/</span>HEAD<span class="p">)</span> git checkout<span class="p">,</span> reset<span class="p">,</span> rebase
pick f6c56ef what igt
pick bd80626 github hem
pick b7801a2 github overall
# Rebase <span class="m">608</span>a518<span class="p">..</span>c3eace0 onto <span class="m">608</span>a518
#
# Commands<span class="p">:</span>
# <span class="k">p</span><span class="p">,</span> pick <span class="p">=</span> use commit
# <span class="k">r</span><span class="p">,</span> reword <span class="p">=</span> use commit<span class="p">,</span> but edit the commit message
# <span class="k">e</span><span class="p">,</span> edit <span class="p">=</span> use commit<span class="p">,</span> but stop <span class="k">for</span> amending
# s<span class="p">,</span> squash <span class="p">=</span> use commit<span class="p">,</span> but meld into <span class="k">previous</span> commit
# <span class="k">f</span><span class="p">,</span> fixup <span class="p">=</span> like <span class="s2">"squash"</span><span class="p">,</span> but discard this commit's log message
# <span class="k">x</span><span class="p">,</span> exec <span class="p">=</span> run command <span class="p">(</span>the rest of the line<span class="p">)</span> using <span class="k">shell</span>
#
# These lines can be <span class="k">re</span><span class="p">-</span>ordered; they are executed from <span class="k">top</span> <span class="k">to</span> bottom<span class="p">.</span>
#
# If you remove <span class="k">a</span> line here THAT COMMIT WILL BE LOST<span class="p">.</span>
#
# However<span class="p">,</span> <span class="k">if</span> you remove everything<span class="p">,</span> the rebase will be aborted<span class="p">.</span>
#
# Note that empty commits are commented out
</code></pre></div></div>

<p>설명을 잘 살펴보면 다음을 알 수 있다:</p>

<ul>
  <li><code class="highlighter-rouge">pick</code> = <code class="highlighter-rouge">p</code>는 수정 사항과 commit을 그대로 둔다. 각 commit의 맨 앞에는 기본적으로 <code class="highlighter-rouge">pick</code>으로 설정되어 있다. 이 상태에서 아무 것도 안 하고 나간다면 이번 <code class="highlighter-rouge">rebase</code>는 아무 효과도 없다.</li>
  <li><code class="highlighter-rouge">reword</code> = <code class="highlighter-rouge">r</code>은 <code class="highlighter-rouge">pick</code>과 거의 같지만 commit message를 수정할 수 있다. commit message를 수정하고 앞의 <code class="highlighter-rouge">pick</code>을 <code class="highlighter-rouge">reword</code>나 <code class="highlighter-rouge">r</code>로 바꾸면 commit의 메시지를 수정할 수 있다. 가장 최신의 commit에 <code class="highlighter-rouge">r</code>을 붙였다면 <code class="highlighter-rouge">git commit --amend</code>와 효과가 같다.</li>
  <li><code class="highlighter-rouge">edit</code> = <code class="highlighter-rouge">e</code>는 해당 commit을 수정할 수 있다. reset 등의 작업이 가능하다.</li>
  <li><code class="highlighter-rouge">squash</code> = <code class="highlighter-rouge">s</code>는 해당 commit이 바로 이전 commit에 흡수되며, commit message 또한 합쳐져서 하나로 된다. 합친 메시지들이 존재하는 에디터가 다시 열린다.</li>
  <li><code class="highlighter-rouge">fixup</code> = <code class="highlighter-rouge">f</code>는 <code class="highlighter-rouge">squash</code>와 비슷하지만, 해당 commit의 message는 삭제된다.</li>
  <li><code class="highlighter-rouge">exec</code> = <code class="highlighter-rouge">x</code>는 commit들 아래 줄에 명령어를 추가하여 실행하게 할 수 있다.</li>
</ul>

<p>수정한 예시는 다음과 같다. 약어를 써도 되고 안 써도 된다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pick c3eace0 <span class="p">(</span>HEAD <span class="p">-&gt;</span> master<span class="p">,</span> origin<span class="sr">/master, origin/</span>HEAD<span class="p">)</span> git checkout<span class="p">,</span> reset<span class="p">,</span> rebase
<span class="k">f</span> f6c56ef what igt
<span class="k">f</span> bd80626 github hem
fixup b7801a2 github overall
<span class="p">...(</span>아래 주석은 지워도 되고 안 지워도 된다<span class="p">.</span> 어차피 commit에서는 무시되는 도움말이다<span class="p">)</span>
</code></pre></div></div>

<h4 id="하나의-commit을-2개로-분리하기">하나의 commit을 2개로 분리하기</h4>

<p>가장 최신 commit이라면 <code class="highlighter-rouge">git reset HEAD~1</code>을 사용하여 직전 commit 상태로 되돌린 뒤 stage-commit을 2번 수행하면 되고, 그 이전 commit이라면 rebase에서 해당 commit을 <code class="highlighter-rouge">edit</code>으로 두고 같은 과정을 반복하면 된다.</p>

<div class="language-vim highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 명령어 예시
git rebase HEAD<span class="p">~</span><span class="m">4</span>
# pick <span class="p">-&gt;</span> edit
git add <span class="p">-</span><span class="k">p</span> <span class="p">&lt;</span>filename<span class="p">&gt;</span>
git commit <span class="p">-</span><span class="k">m</span> <span class="p">&lt;</span><span class="m">1</span><span class="k">st</span><span class="p">-</span>commit<span class="p">-</span>message<span class="p">&gt;</span>
git add <span class="p">-</span><span class="k">p</span> <span class="p">&lt;</span>filename1<span class="p">&gt;</span> <span class="p">&lt;</span>filename2<span class="p">&gt;</span>
git commit <span class="p">-</span><span class="k">m</span> "<span class="m">2</span>nd<span class="p">-</span>commit<span class="p">-</span>message<span class="p">&gt;</span>
git rebase <span class="p">--</span>continue
</code></pre></div></div>

<hr />

<p>git cherry-pick -x</p>

    </article>
    <div class="post-more">
      
      <a href="/github/2020/05/27/github-usage-09-overall/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/github/2020/05/27/github-usage-09-overall/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/generative/model/2020/05/25/VAE/">
        Variational AutoEncoder 설명
      </a>
    </h1>

    <span class="post-date">25 May 2020</span>
     |
    
    <a href="/blog/tags/#machine-learning" class="post-tag">Machine Learning</a>
    
    <a href="/blog/tags/#paper-review" class="post-tag">Paper_Review</a>
    
    

    <article>
      <p>본 글의 주제는  2014년에 발표된 생성 모델인 Variational AutoEncoder에 대해 설명하고 이를 코드로 구현하는 내용을 담고 있다.</p>

<h2 id="1-auto-encoding-variational-bayes-논문-리뷰">1. Auto-Encoding Variational Bayes 논문 리뷰</h2>
<h3 id="11-introduction">1.1. Introduction</h3>
<p>연속형 잠재 변수와 파라미터가 다루기 힘든 사후 분포를 갖는 방향성 확률 모델에 대해 효율적인 근사 추론 및 학습을 수행할 수 있는 방법이 없을까? <strong>Variational Bayesian</strong> 접근법은 다루기 힘든 사후 분포에 대한 근사의 최적화를 내포한다.</p>

<p>불행히도, 일반적인 평균 필드(mean-field) 접근법은 근사적 사후 분포에 대해 기댓값의 분석적 해결법을 요구하는데 이는 보통 굉장히 다루기 어려운 방법이다. 본 논문은 Variational Lower Bound의 <strong>Reparameterization</strong>이 Lower Bound의 미분 가능한 불편향 estimator를 만드는 방법에 대해 보여줄 것이다. 이 <strong>Stochastic Gradient Variational Bayes: SGVB estimator</strong>는 연속형 잠재변수나 파라미터를 갖고 있는 대부분의 모델에 대해 효율적인 근사 사후 추론을 가능하게 하며, 표준 Stochastic Gradient Ascent 스킬을 사용하여 최적화하기에 굉장히 편리하다.</p>

<p>IID 데이터셋이고, 데이터포인트 별로 연속형 잠재변수를 갖고 있는 경우에 대해 본 논문은 <code class="highlighter-rouge">Auto-Encoding VB</code> 알고리즘을 제안한다. 이 알고리즘에서는 <strong>Simple Ancestral Sampling</strong>을 이용하여 근사 사후 추론을 하는 인식 모델을 최적화하기 위해 SGVB estimator를 사용하여 추론과 학습을 효율적으로 해낸다. 이 과정은 MCMC와 같이 데이터포인트 별로 반복적인 추론을 행하여 많은 연산량을 요구하지 않는 장점을 가진다.</p>

<p>학습된 근사 사후 추론 모델은 recognition, denoising, representation, visualization의 목적으로 활용될 수 있다. 본 알고리즘이 인식(recognition) 모델에 사용될 때, 이를 <code class="highlighter-rouge">Variational Auto-Encoder</code>라고 부를 것이다.</p>

<h3 id="12-method">1.2. Method</h3>
<p>본 섹션에서는 연속형 잠재 변수를 내포하는 다양한 방향성 그래픽 모델에서 Stochastic 목적 함수인 <strong>Lower Bound Estimator</strong>를 끌어내는 과정을 설명할 것이다. 데이터포인트 별 잠재변수는 iid한 상황이라는 가정 하에 본 논문에서는 파라미터에 대해 Maximul Likelihood와 Maximum Posteriori 추론을 수행하고 잠재변수에 대해 <strong>Variational Inference</strong>를 수행할 것이다. 이러한 방법은 온라인 러닝에도 사용될 수 있지만 본 논문에서는 간단히 하기 위해 고정된 데이터셋을 사용할 것이다.</p>

<h4 id="121-problem-scenario">1.2.1. Problem Scenario</h4>
<p>N개의 Sample을 가진 $X$라는 데이터가 있다고 해보자. 본 논문은 이 데이터가 관측되지 않은 연속형 확률 변수 $z$를 내포하는 어떤 Random Process에 의해 형성되었다고 가정한다.</p>

<p>이 과정은 2가지 단계로 구성된다.<br />
1) $z^{i}$라는 값은 어떤 사전 분포 $p_{\theta ^<em>}(z)$에서 발생한다.<br />
2) $x^{i}$라는 값은 어떤 조건부 분포 $p_{\theta ^</em>}(x|z)$에서 발생한다.</p>

<p>(여기서 $z$는 원인, $x$는 결과라고 보면 이해가 쉬울 것이다.)</p>

<table>
  <tbody>
    <tr>
      <td>우리는 사전확률 $p_{\theta <em>}(z)$와 Likelihood $p_{\theta ^</em>}(x</td>
      <td>z)$가 $p_{\theta}(z)$, $p_{\theta}(x</td>
      <td>z)$의 parametric families of distributions에서 왔다고 가정하고, 이들의 확률밀도함수는 거의 모든 $\theta, z$에 대해 미분가능하다고 전제한다.</td>
    </tr>
  </tbody>
</table>

<p>불행히도, 이러한 과정의 많은 부분은 우리가 직접 확인하기 어렵다. True 파라미터인 $\theta ^*$와 잠재 변수의 값 $z^{i}$은 우리에게 알려져 있지 않다.</p>

<p>본 논문은 주변 확률이나 사후 확률에 대한 단순화를 위한 일반적인 가정을 취하지 않고 분포가 다루기 힘들고 큰 데이터셋을 마주하였을 경우를 위한 효율적인 알고리즘에 대해 이야기하고자 한다.</p>

<p><strong>1) Intractability</strong>(다루기 힘듦)<br />
(1) marginal likelihood $p_{\theta}(x)$의 적분인 $\int p_{\theta}(x) p_{\theta}(x|z) dz $가 다루기 힘든 경우</p>

<table>
  <tbody>
    <tr>
      <td>(2) true posterior density $p_{\theta}(z</td>
      <td>x) = p_{\theta}(x</td>
      <td>z)p_{\theta}(z)/p_{\theta}(x)$가 다루기 힘들어 EM 알고리즘이 사용될 수 없는 경우</td>
    </tr>
  </tbody>
</table>

<p>(3) 어떠한 합리적인 평균-필드 VB알고리즘을 위한 적분이 다루기 힘든 경우</p>

<table>
  <tbody>
    <tr>
      <td>이러한 Intractability는 굉장히 흔하며, 복잡한 우도(likelihood) 함수 $p_{\theta}(x</td>
      <td>z)$를 갖는 신경망 네트워크에서 발견할 수 있다.</td>
    </tr>
  </tbody>
</table>

<p><strong>2) A Large Dataset</strong><br />
데이터가 너무 크면 배치 최적화는 연산량이 매우 많다. MC-EM과 같은 Sampling Based Solution은 데이터 포인트별로 Sampling Loop를 돌기 때문에 너무 느리다.</p>

<p>위 시나리오에서 설명한 문제들에 대해 본 논문은 아래와 같은 해결책을 제시한다.</p>

<p>1) 파라미터 $\theta$에 대한 효율적인 근사 ML/MAP estimation. 이 파라미터들은 숨겨진 랜덤 과정을 흉내내고 실제 데이터를 닮은 인공적인 데이터를 생성할 수 있게 해준다.<br />
2) 파라미터 $\theta$의 선택에 따라 관측값 $x$이 주어졌을 때 잠재 변수 $z$에 대한 효율적인 근사 사후 추론<br />
3) 변수 $x$에 대해 효율적인 근사 주변 추론. 이는 $x$에 대한 prior이 필요한 모든 추론 task를 수행할 수 있게 해준다.</p>

<table>
  <tbody>
    <tr>
      <td>위 문제를 해결하기 위해 인식 모델 $q_{\phi}(z</td>
      <td>x)$이 필요하다. 이 모델은 다루기 힘든 True Posterior $p_{\theta}(z</td>
      <td>x)$의 근사 버전이라고 할 수 있다. 본 논문에서는 인식 모델 파라미터인 $\phi$와 생성 모델 파라미터인 $\theta$를 동시에 학습하는 방법에 대해 이야기할 것이다.</td>
    </tr>
  </tbody>
</table>

<table>
  <tbody>
    <tr>
      <td>코딩 이론의 관점에서 보면, 관측되지 않은 변수 $z$는 잠재 표현 또는 <em>code</em>라고 해석될 수 있다. 본 논문에서는 따라서 인식 모델 $q_{\phi}(z</td>
      <td>x)$를 <strong>encoder</strong>라고 부를 것인데, 왜냐하면 데이터 포인트 $x$가 주어졌을 때 이 <strong>encoder</strong>가 데이터 포인트 $x$가 발생할 수 code $z$의 가능한 값에 대한 분포를 생산하기 때문이다. 비슷한 맥락에서 우리는 $q_{\theta}(x</td>
      <td>z)$를 <strong>확률적 decoder</strong>라고 명명할 것인데, 왜냐하면 code $z$가 주어졌을 때 이 <strong>decoder</strong>가 상응하는 가능한 $x$의 값에 대해 분포를 생산하기 때문이다.</td>
    </tr>
  </tbody>
</table>

<h3 id="22-the-variational-bound">2.2. The Variational Bound</h3>

<hr />

<h2 id="2-이론에-대한-보충-설명">2. 이론에 대한 보충 설명</h2>
<h3 id="21-용어-정리">2.1. 용어 정리</h3>
<p><strong>1) Variational Inference</strong><br />
$q(x)$라는 쉬운 분포를 통해 target 분포 $p(x)$를 근사 추론하는 방법론이다.</p>

<script type="math/tex; mode=display">q^* = argmin_{q \in Q} KL(q||p)</script>

<p><strong>2) KL Divergence</strong></p>

<p><strong>3) s</strong></p>

<h3 id="22">2.2.</h3>

<hr />

<h2 id="reference">Reference</h2>
<p>1) https://ratsgo.github.io/generative%20model/2018/01/27/VAE/<br />
2) https://www.youtube.com/watch?v=SAfJz_uzaa8<br />
3) https://taeu.github.io/paper/deeplearning-paper-vae/
4)</p>

    </article>
    <div class="post-more">
      
      <a href="/generative/model/2020/05/25/VAE/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/generative/model/2020/05/25/VAE/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/machine_learning/2020/05/01/AFM/">
        추천 시스템의 기본 - 06. AFM 논문 리뷰 및 Tensorflow 구현
      </a>
    </h1>

    <span class="post-date">01 May 2020</span>
     |
    
    <a href="/blog/tags/#machine-learning" class="post-tag">Machine_Learning</a>
    
    <a href="/blog/tags/#recommendation-system" class="post-tag">Recommendation System</a>
    
    <a href="/blog/tags/#afm" class="post-tag">AFM</a>
    
    

    <article>
      <p>본 글의 전반부에서는 먼저 <strong>Attentional Factorization Machines: Learning theWeight of Feature Interactions via Attention Networks</strong> 논문을 리뷰하면서 본 모델에 대해 설명할 것이다. 후반부에서는 Tensorflow를 이용하여 직접 코딩을 하고 학습하는 과정을 소개할 것이다. 논문의 전문은 <a href="https://www.ijcai.org/Proceedings/2017/0435.pdf">이곳</a>에서 확인할 수 있다.</p>

<hr />

<h2 id="1-attentional-factorization-machines-learning-theweight-of-feature-interactions-via-attention-networks-논문-리뷰">1. Attentional Factorization Machines: Learning theWeight of Feature Interactions via Attention Networks 논문 리뷰</h2>

<h3 id="10-absbract">1.0. Absbract</h3>
<p>FM은 2차원 피쳐 상호작용을 잘 통합하여 선형 회귀를 개선한 지도학습 알고리즘이다. 이 알고리즘은 효과적이긴 하지만, 모든 피쳐에 대해 같은 weight로 학습을 진행시킨다는 점에서 비효율적이다. 왜냐하면 종종 일부 피쳐는 학습에 있어 필수적이지 않은 경우가 있기 때문이다. 오히려 이러한 피쳐들의 존재는 모델의 성능을 떨어트릴 수 있다. 따라서 우리는 여러 피쳐 상호작용 속에서 중요한 피쳐들을 구분해내는 새로운 모델, <strong>Attentional Factorization Machine (AFM)</strong>을 소개한다.</p>

<h3 id="11-introduction">1.1. Introduction</h3>
<center> (전략) </center>

<p>FM은 피쳐 상호작용의 중요성을 구분하는 능력이 부족하기 때문에(피쳐의 중요성을 파악하는 능력) suboptimal 문제에 빠질 수 있다. <strong>AFM</strong>은 이러한 문제를 해결하기 위해 도입한 모델이다.</p>

<h3 id="12-factorization-machines">1.2. Factorization Machines</h3>
<p>FM 모델에 대한 설명은 <a href="2019-12-21-FM.md">이곳</a>을 참조하길 바란다. 기호에 대해서만 설명을 추가하면, $v_i$는 피쳐 $i$에 대한 임베딩 벡터이며, $k$는 임베딩 크기를 의미한다.</p>

<h3 id="13-attentioanl-factorization-machines">1.3. Attentioanl Factorization Machines</h3>
<h4 id="131-model">1.3.1. Model</h4>
<center><img src="/public/img/Machine_Learning/2020-05-01-AFM/01.JPG" width="100%" /></center>

<p>위 그림은 <strong>AFM</strong>의 구조를 보여준다. 선명히 보여주기 위해 그림에서는 선형 회귀 부분을 생략하였다. Input Layer와 Embedding Layer의 경우 FM과 같은 구조를 지니는데, Input 피쳐들은 sparse하게 이루어져있고 이들은 dense vector로 임베딩된다. 지금부터는 본 모델의 핵심인 <code class="highlighter-rouge">pair-wise interaction layer</code>과 <code class="highlighter-rouge">attention-based pooling layer</code>를 설명할 것이다.</p>

<p><strong>Pair-wise Interaction Layer</strong><br />
상호작용을 포착하기 위해 내적을 사용하는 FM을 참고하여, 본 논문에서는 신경망 모델링에서 새로운 <code class="highlighter-rouge">Pair-wise Interaction Layer</code>를 제시한다. $m$개의 벡터를 $\frac{m(m-1)}{2}$개의 interacted 벡터로 만드는데, 이 때 각 interacted 벡터는 상호작용을 포착하기 위해 2개의 다른 벡터들의 원소곱으로 계산된다.</p>

<p>정확히 말하면, 피쳐 벡터 $x$의 0이 아닌 피쳐의 집합을 $\chi$라고 하자. 그리고 <code class="highlighter-rouge">Embedding Layer</code>의 결과물을 $\epsilon = {{v_i x_i}}_{i \in \chi} $라고 하자. 우리는 아래와 같이 <code class="highlighter-rouge">Pair-wise Interaction Layer</code>의 결과물을 아래와 같은 벡터의 집합으로 표현할 수 있다.</p>

<script type="math/tex; mode=display">f_{PI}(\epsilon) = \{ (v_i \odot v_j) x_i x_j \}_{(i, j \in R_x)}</script>

<ul>
  <li>$\odot$ 기호: 원소곱</li>
  <li>$ R_x = { (i, j) }_{i, j \in \chi, j&gt;i} $</li>
</ul>

<p>이 Layer를 정의하면서 우리는 FM을 신경망 구조로 표현할 있게 된다. 먼저 $f_{PI}(\epsilon)$를 <strong>sum pooling</strong>으로 압축한다음, <strong>Fully Connected Layer</strong>를 사용하여 prediction score에 투사(project)한다.</p>

<script type="math/tex; mode=display">\hat{y} = p^T \sum_{(i, j) \in R_x} (v_i \odot v_j) x_i x_j + b</script>

<ul>
  <li>$p \in R^k$</li>
  <li>$b \in R$</li>
</ul>

<p>위에서 등장한 <strong>p, b</strong>는 <code class="highlighter-rouge">Prediction Layer</code>의 weight과 bias이다. 물론 p=1, b=0으로 값을 고정한다면 이는 FM과 동일한 형상을 취하게 될 것이다.</p>

<p><strong>Attention-based Pooling Layer</strong><br />
Attention의 기본 아이디어는, 여러 개의 부분이 압축 과정에 있어서 각각 다르게 기여하여 하나로 표현되게 만드는 것이다. interacted 벡터들의 가중 합을 수행하여 피쳐 상호작용에 대해 Attention 메커니즘을 적용하였다.</p>

<script type="math/tex; mode=display">f_{Att}(f_{PI}(\epsilon)) = a_{i,j} \sum_{(i, j) \in R_x} (v_i \odot v_j) x_i x_j</script>

<p>여기서 $a_{i, j}$는 피쳐 상호작용 $\hat{w}_{ij}$의 <strong>Attention Score</strong>이다.</p>

<p>Prediction Loss를 최소화하여 직접적으로 학습을 진행하여 $a_{i,j}$를 추정하는 것이 기술적으로는 맞게 느껴지지만, 학습 데이터에서 한 번도 동시에 등장한 적이 없는 피쳐들의 경우, 이들의 상호작용에 대한 <strong>Attention Score</strong>는 추정될 수 없다.</p>

<p>이러한 일반화 문제를 해결하기 위해 MLP를 통해 <strong>Attention Score</strong>를 파라미터화 하는 <strong>Attention Network</strong>를 추가하였다. 이 네트워크의 Input은 2개의 피쳐의 interacted 벡터인데, 이들의 상호작용 정보는 임베딩 공간에 인코딩된다.</p>

<p><script type="math/tex">e_{ij} = h^T ReLU(W (v_i \odot v_j) x_i x_j + b)</script><br />
<script type="math/tex">a_{ij} = \frac {exp(e_{ij})} { \sum_{(i, j) \in R_x} exp(e_{ij}) }</script></p>

<ul>
  <li>$W \in R^{t*k}, b \in R^t, h \in R^t$</li>
  <li>$t$: Attention Network의 hidden layer의 크기(Attention Factor)</li>
</ul>

<p><strong>Attention Score</strong>는 softmax 함수를 통해 정규화된다. 이 <code class="highlighter-rouge">Attention-based Pooling Layer</code>의 결과물은 k 차원의 벡터로, 중요성을 구별하여 임베딩 공간에서의 모든 피쳐 상호작용을 압축한 것이다. 요약하자면, <strong>AFM</strong> 모델의 최종 공식은 아래와 같다.</p>

<script type="math/tex; mode=display">\hat{y}_{AFM}(x) = w_0 + \sum_{i=1}^n w_i x_i + p^T \sum_{i=1}^n \sum_{j=i+1}^n a_{ij} (v_i \odot v_j) x_i x_j</script>

<p>모델 파라미터들은 $ w_0, w, v, p, W, b, h $이다.</p>

<h4 id="132-learning">1.3.2. Learning</h4>
<p><strong>AFM</strong>이 데이터 모델링의 관점에서 FM을 개선함에 따라 본 모델은 예측, 회귀, 분류, 랭킹 문제 등에 다양하게 적용될 수 있다. 목적 함수를 최적화하기 위해 SGD를 사용하였다. SGD 알고리즘 적용의 핵심은, 각 파라미터를 기준으로 예측 모델 <strong>AFM</strong>의 derivative를 구하는 것이다.</p>

<p><strong>과적합 문제</strong><br />
FM보다 표현력이 뛰어난 <strong>AFM</strong>이기에 더욱 과적합 문제에 민감할 수 있다. 따라서 본 모델에서는 dropout과 L2 Regularization 테크닉이 사용되었다.</p>

<p>(후략)</p>

<hr />

<h2 id="2-tensorflow를-활용한-구현">2. Tensorflow를 활용한 구현</h2>
<h3 id="21-데이터-준비">2.1. 데이터 준비</h3>
<p>본 모델의 경우 Dataset에 대한 Domain 지식이 필요하다고 볼 수는 없지만, 학습을 진행하기에 앞서 기본적으로 직접 전처리를 해주어야 하는 부분들이 있다. One-Hot 인코딩 외에도, 본 모델은 앞서 논문 리뷰에서도 확인하였듯이 0이 아닌 값에 대해서만 Lookup을 수행하여 실제 학습 데이터를 사용하기 때문에 이에 대한 정보를 저장해야할 필요가 있다. 아래 예시를 잠시 살펴보면,</p>

<center><img src="/public/img/Machine_Learning/2020-05-01-AFM/02.JPG" width="100%" /></center>

<p>만약 연속형 변수 중에 0.0이라는 값이 존재하더라도 사실 이 값은 중요한 특성을 나타낼 수도 있다. 그러나 논문의 기본 논조대로라면, 0인 값이기 때문에 학습에서 제외되게 된다. 이렇게 0이라고 해서 중요한 값이 학습에서 제외되는 현상을 막기 위해 본 구현에서는 One-Hot 인코딩 이후의 데이터에 대하여 중요한 정보의 위치를 저장하는 masking 작업을 진행하게 된다.</p>

<p>데이터는 <a href="2020-04-07-DeepFM.md">DeepFM 구현글</a>에서 사용한 것과 동일하다. 데이터 전처리는 연속형 변수에 대해서는 MinMaxScale, 범주형 변수에 대해서는 One-Hot 인코딩만을 진행하게 된다.</p>

<h3 id="22-layer-정의">2.2. Layer 정의</h3>
<p><strong>AFM</strong> 모델에서는 크게 3개의 Layer가 필요하다. <code class="highlighter-rouge">Embedding Layer</code>, <code class="highlighter-rouge">Pairwise Interaction Layer</code>, <code class="highlighter-rouge">Attention Pooling Layer</code>가 바로 그 3가지이다. <code class="highlighter-rouge">Embedding Layer</code> 부분은 이전 글(논문)들을 읽었다면, 굉장히 익숙하게 받아들여 질 것이다. 다만 이전 <a href="2020-04-07-DeepFM.md">DeepFM 구현글</a>에서는 하나의 Field에 대해 하나의 Embedding Row가 학습되었다면, 본 글에서는 하나의 Feature에 대해 하나의 Embedding Row가 학습되도록 코드를 수정하였다.</p>

<p>앞서 언급하였듯이 One-Hot 인코딩으로 생성된 0 값을 갖는 feature를 제외한 feature들만 실제 학습에 사용되는데(예를 들어 One-Hot 인코딩 이후에 0.2, 7.4, 0, 1, … 0, 1와 같은 데이터로 변환되었다면 실제 학습에 사용되는 데이터는 0.2, 7.4, 1, … 1이라는 뜻이다.)</p>

<p>위와 같은 논리를 구현하는 방법에는 여러가지가 있을 수 있겠지만 본 구현에서는 다음과 같은 논리를 따랐다.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1) 연속형 변수들은 모두 앞쪽에 배치한 후, 이들에게는 무조건 True Mask를 씌워 학습 데이터로 활용한다.  
2) 범주형 변수들에 대해서는 0이 아닌 값들에 대해서 True Mask를 씌워 학습 데이터로 활용한다.  
</code></pre></div></div>

<p>논리 자체는 간단하며, 아래 call 메서드에서 그 논리가 구현되어 있다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">config</span>


<span class="k">class</span> <span class="nc">Embedding_layer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_field</span><span class="p">,</span> <span class="n">num_feature</span><span class="p">,</span> <span class="n">num_cont</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Embedding_layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span> <span class="o">=</span> <span class="n">embedding_size</span>    <span class="c1"># k: 임베딩 벡터의 차원(크기)
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_field</span> <span class="o">=</span> <span class="n">num_field</span>              <span class="c1"># m: 인코딩 이전 feature 수
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_feature</span> <span class="o">=</span> <span class="n">num_feature</span>          <span class="c1"># p: 인코딩 이후 feature 수, m &lt;= p
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_cont</span> <span class="o">=</span> <span class="n">num_cont</span>                <span class="c1"># 연속형 field 수
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_cat</span>  <span class="o">=</span> <span class="n">num_field</span> <span class="o">-</span> <span class="n">num_cont</span>    <span class="c1"># 범주형 field 수
</span>
        <span class="c1"># Parameters
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">V</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_feature</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">),</span>
                                              <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">'V'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="c1"># inputs: (None, p, k), embeds: (None, m, k)
</span>        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># 원핫인코딩으로 생성된 0을 제외한 값에 True를 부여한 mask(np.array): (None, m)
</span>        <span class="c1"># indices: 그 mask의 indices
</span>        <span class="n">cont_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_cont</span><span class="p">),</span> <span class="n">fill_value</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">cat_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">not_equal</span><span class="p">(</span><span class="n">inputs</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_cont</span><span class="p">:],</span> <span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">cont_mask</span><span class="p">,</span> <span class="n">cat_mask</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">flatten_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="bp">True</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">flatten_indices</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_field</span><span class="p">))</span>

        <span class="c1"># embedding_matrix: (None, m, k)
</span>        <span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">V</span><span class="p">,</span> <span class="n">ids</span><span class="o">=</span><span class="n">indices</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>

        <span class="c1"># masked_inputs: (None, m, 1)
</span>        <span class="n">masked_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="p">),</span>
                                   <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_field</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

        <span class="n">masked_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">masked_inputs</span><span class="p">,</span> <span class="n">embedding_matrix</span><span class="p">)</span>    <span class="c1"># (None, m, k)
</span>
        <span class="k">return</span> <span class="n">masked_inputs</span>
</code></pre></div></div>

<p>다음은 <code class="highlighter-rouge">Pairwise Interaction Layer</code>에 대한 설명이다. 만약 14개의 Row가 존재한다면 이에 대한 모든 조합을 구하여 91 = $14\choose2$ 개의 Row를 생성하는 Layer인데, 간단하게 생각해보면 아래와 같이 코드를 짜고 싶을 것이다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>

<span class="n">interactions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">comb_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_field</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">combinations</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">comb_list</span><span class="p">,</span> <span class="mi">2</span><span class="p">)):</span>
        <span class="n">interactions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:],</span> <span class="n">inputs</span><span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="p">:]))</span>

<span class="n">pairwise_interactions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">interactions</span><span class="p">),</span>
                                    <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">))</span>
</code></pre></div></div>

<p>하지만 위와 같이 loop를 돌리게 되면, 속도가 현저하게 느려져서 실 사용이 불가능하다. 따라서 이 때는 Trick이 필요한데, 그림으로 설명하면 아래와 같다.</p>

<center><img src="/public/img/Machine_Learning/2020-05-01-AFM/03.JPG" width="100%" /></center>

<p>위 그림에서 14는 <code class="highlighter-rouge">num_field</code>의 예시이고, 5는 <code class="highlighter-rouge">embedding_size</code>의 예시이다. 가장 왼쪽에 있는 그림은 <code class="highlighter-rouge">Embedding Layer</code>를 통과한 Input 행렬을 그대로 <code class="highlighter-rouge">num_field</code> 수 만큼 쌓은 형태이이고, 그 오른쪽 그림은 똑같은 행들을 <code class="highlighter-rouge">num_field</code> 수만큼 쌓은 형태이다. 이렇게 쌓은 두 행렬 집단을 그대로 원소곱을 하게 되면 마치 조합을 구해서 곱을 한 것과 같은 형태가 나온다. 여기서 필요한 행들만 masking을 통해 취하면, 제일 오른쪽과 같은 결과물을 얻을 수 있다.</p>

<p>이를 코드를 구현한 것이 아래이다. <strong>tf.tile</strong>, <strong>tf.expand_dims</strong> 함수를 잘 이용하면 이 Trick을 코드로 구현할 수 있다. 직접 해보길 바란다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Pairwise_Interaction_Layer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_field</span><span class="p">,</span> <span class="n">num_feature</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Pairwise_Interaction_Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span> <span class="o">=</span> <span class="n">embedding_size</span>    <span class="c1"># k: 임베딩 벡터의 차원(크기)
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_field</span> <span class="o">=</span> <span class="n">num_field</span>              <span class="c1"># m: 인코딩 이전 feature 수
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_feature</span> <span class="o">=</span> <span class="n">num_feature</span>          <span class="c1"># p: 인코딩 이후 feature 수, m &lt;= p
</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">MASKS</span><span class="p">)</span>    <span class="c1"># (num_field**2)
</span>        <span class="n">masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>             <span class="c1"># (num_field**2, 1)
</span>        <span class="n">masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">])</span>   <span class="c1"># (num_field**2, embedding_size)
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">masks</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>         <span class="c1"># (1, num_field**2, embedding_size)
</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># a, b shape: (batch_size, num_field^2, embedding_size)
</span>        <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_field</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_field</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">])</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_field</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

        <span class="c1"># ab, mask_tensor: (batch_size, num_field^2, embedding_size)
</span>        <span class="n">ab</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
        <span class="n">mask_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">masks</span><span class="p">,</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

        <span class="c1"># pairwise_interactions: (batch_size, num_field C 2, embedding_size)
</span>        <span class="n">pairwise_interactions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">boolean_mask</span><span class="p">(</span><span class="n">ab</span><span class="p">,</span> <span class="n">mask_tensor</span><span class="p">),</span>
                                           <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">pairwise_interactions</span>
</code></pre></div></div>

<p><code class="highlighter-rouge">config.MASKS</code>는 아래와 같이 구현되어 있다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MASKS</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_FIELD</span><span class="p">):</span>
    <span class="n">flag</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span>

    <span class="n">MASKS</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="bp">False</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">flag</span><span class="p">))</span>
    <span class="n">MASKS</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="bp">True</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">NUM_FIELD</span> <span class="o">-</span> <span class="n">flag</span><span class="p">))</span>
</code></pre></div></div>

<p>다음으로는 마지막 <code class="highlighter-rouge">Attention Pooling Layer</code>이다. 설명할 것이 많지 않은 간단한 구조이다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Attention_Pooling_Layer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Attention_Pooling_Layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span> <span class="o">=</span> <span class="n">embedding_size</span>    <span class="c1"># k: 임베딩 벡터의 차원(크기)
</span>
        <span class="c1"># Parameters
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">h</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">),</span>
                                              <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">'h'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">),</span>
                                              <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">'W_attention'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>


    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="c1"># 조합 수 = combinations(num_feauture, 2)
</span>        <span class="c1"># inputs: (None, 조합 수, embedding_size)
</span>        <span class="c1"># --&gt; (전치 후) (None, embedding_size, 조합 수)
</span>        <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

        <span class="c1"># e: (None, 조합 수, 1)
</span>        <span class="n">e</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">h</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="p">))</span>
        <span class="n">e</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

        <span class="c1"># Attention Score 산출
</span>        <span class="n">attention_score</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">attention_score</span>
</code></pre></div></div>

<h3 id="23-model-build">2.3. Model Build</h3>
<p>위에서 설명한 모든 Layer들을 이어 붙이면 <strong>AFM</strong> 모델이 완성된다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Model 정의
</span><span class="kn">from</span> <span class="nn">layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">set_floatx</span><span class="p">(</span><span class="s">'float32'</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">AFM</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_field</span><span class="p">,</span> <span class="n">num_feature</span><span class="p">,</span> <span class="n">num_cont</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AFM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span> <span class="o">=</span> <span class="n">embedding_size</span>    <span class="c1"># k: 임베딩 벡터의 차원(크기)
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_field</span> <span class="o">=</span> <span class="n">num_field</span>              <span class="c1"># m: 인코딩 이전 feature 수
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_feature</span> <span class="o">=</span> <span class="n">num_feature</span>          <span class="c1"># p: 인코딩 이후 feature 수, m &lt;= p
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_cont</span> <span class="o">=</span> <span class="n">num_cont</span>                <span class="c1"># 연속형 field 수
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>          <span class="c1"># Attention Pooling Layer Hidden Unit 수
</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_layer</span> <span class="o">=</span> <span class="n">Embedding_layer</span><span class="p">(</span><span class="n">num_field</span><span class="p">,</span> <span class="n">num_feature</span><span class="p">,</span>
                                               <span class="n">num_cont</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pairwise_interaction_layer</span> <span class="o">=</span> <span class="n">Pairwise_Interaction_Layer</span><span class="p">(</span>
            <span class="n">num_field</span><span class="p">,</span> <span class="n">num_feature</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attention_pooling_layer</span> <span class="o">=</span> <span class="n">Attention_Pooling_Layer</span><span class="p">(</span><span class="n">embedding_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>

        <span class="c1"># Parameters
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">w_0</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">num_feature</span><span class="p">]))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">embedding_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                                              <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">DROPOUT_RATE</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">"AFM Model: embedding{}, hidden{}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="c1"># 1) Linear Term: (None, )
</span>        <span class="n">linear_terms</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_0</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="n">inputs</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 2) Interaction Term
</span>        <span class="n">masked_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_layer</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">pairwise_interactions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pairwise_interaction_layer</span><span class="p">(</span><span class="n">masked_inputs</span><span class="p">)</span>

        <span class="c1"># Dropout and Attention Score
</span>        <span class="n">pairwise_interactions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pairwise_interactions</span><span class="p">)</span>
        <span class="n">attention_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_pooling_layer</span><span class="p">(</span><span class="n">pairwise_interactions</span><span class="p">)</span>

        <span class="c1"># (None, 조합 수, embedding_size)
</span>        <span class="n">attention_interactions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">pairwise_interactions</span><span class="p">,</span> <span class="n">attention_score</span><span class="p">)</span>

        <span class="c1"># (None, embedding_size)
</span>        <span class="n">final_interactions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">attention_interactions</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># 3) Final: (None, )
</span>        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">linear_terms</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">final_interactions</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">y_pred</span>
</code></pre></div></div>

<h3 id="24-코드-전문">2.4. 코드 전문</h3>
<p>코드의 전문은 <a href="https://github.com/ocasoyy/Recommendation-Algorithms">깃헙</a>에서 확인할 수 있다.</p>


    </article>
    <div class="post-more">
      
      <a href="/machine_learning/2020/05/01/AFM/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/machine_learning/2020/05/01/AFM/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/machine_learning/2020/04/07/DeepFM/">
        추천 시스템의 기본 - 05. DeepFM 논문 리뷰 및 Tensorflow 구현
      </a>
    </h1>

    <span class="post-date">07 Apr 2020</span>
     |
    
    <a href="/blog/tags/#machine-learning" class="post-tag">Machine_Learning</a>
    
    <a href="/blog/tags/#recommendation-system" class="post-tag">Recommendation System</a>
    
    <a href="/blog/tags/#deepfm" class="post-tag">DeepFM</a>
    
    

    <article>
      <p>본 글의 전반부에서는 먼저 <strong>DeepFM: A Factorization-Machine based Neural Network for CTR Prediction</strong> 논문을 리뷰하면서 본 모델에 대해 설명할 것이다. 후반부에서는 Tensorflow를 이용하여 직접 코딩을 하고 학습하는 과정을 소개할 것이다. 논문의 전문은 <a href="https://arxiv.org/pdf/1703.04247v1.pdf">이곳</a>에서 확인할 수 있다.</p>

<hr />

<h2 id="1-deepfm-a-factorization-machine-based-neural-network-for-ctr-prediction-논문-리뷰">1. DeepFM: A Factorization-Machine based Neural Network for CTR Prediction 논문 리뷰</h2>
<h3 id="10-abstract">1.0. Abstract</h3>
<p>추천 시스템에서 CTR을 최대화하는 것에 있어 사용자의 행동 속에 숨어있는 복잡한 feature interactions들을 학습하는 것은 매우 중요하다. 본 논문에서는 저차원 및 고차원 feature interactions를 모두 강조하면서 end-to-end 학습을 진행하는 모델에 대해 설명할 것이다. 이 <strong>DeepFM</strong>이라는 모델은 FM과 딥러닝을 결합한 것이다. 최근(2017년 기준) 구글에서 발표한 <strong>Wide &amp; Deep model</strong>에 비해 피쳐 엔지니어링이 필요 없고, wide하고 deep한 부분에서 공통된 Input을 가진다는 점이 특징적이다.</p>

<h3 id="11-introduction">1.1. Introduction</h3>
<p>추천 시스템에서 CTR은 매우 중요하다. 많은 경우에 추천시스템의 목표는 이 클릭 수를 증대하는 것인데, 따라서 CTR 추정값에 근거하여 아이템을 정렬한 뒤 아이템(기사, 영화 등)을 사용자에게 제시할 수 있다. 온라인 광고에서는 수익을 증가시키는 것이 가장 중요하기에, 이 상황에서는 <strong>CTR * bid</strong>라는 기준 아래 랭킹 전략을 세울 수 있을 것이다. 여기서 bid는 사용자가 아이템을 클릭할 경우 시스템이 수령하는 수입을 의미한다. 어떠한 케이스든, 이 CTR을 정확히 추정하는 것은 매우 중요할 것이다.</p>

<p>CTR 예측에 있어 중요한 포인트는, 사용자의 클릭 행동 속에 숨어 있는 implicit feature interactions(암시적 피쳐 상호작용)를 학습할 줄 알아야 한다는 것이다.</p>

<p>예를 들어 사람들이 식사 시간에 음식 배달을 위한 앱을 다운로드 받는다면, 이 때 앱 카테고리와 시간이라는 요소 사이의 2차 상호작용이 바로 <strong>클릭</strong>에 대한 신호가 될 수 있다는 것이다. 10대 남자아이가 RPG게임을 좋아한다고 하자, 이 때는 앱 카테고리-사용자의 성별-사용자의 나이라는 3개 요소의 관계가 <strong>클릭</strong>을 결정하는 요인이 될 수 있다. 즉, 사용자의 클릭 뒤에 숨어있는 이러한 상호작용들은 매우 복잡하여 저/고차원 <strong>모두</strong> 잘 잡아내는 것이 매우 중요하다.</p>

<p>(중략)</p>

<p>feature representation을 학습하는 방법으로써 Deep Neural Network가 복잡한 feature interactions를 학습하는 잠재력을 갖고 있다고 판단된다. 다만 CNN-based 모델의 경우 이웃한 feature들 사이에 발생하는 상호작용에 의해 편향된 경향을 보이고, RNN-based 모델의 경우 sequential dependency를 갖고 있는 클릭 데이터에 상대적으로 적합한 모습을 보였다. 이후에 FNN, PNN, Wide &amp; Deep 등 여러 모델들이 제안되었다. 본 논문에서는 이러한 모델들의 단점을 보완한 새로운 모델을 제시한다.</p>

<p>1) <strong>DeepFM</strong>은 피쳐 엔지니어링 없이 end-to-end 학습을 진행할 수 있다. 저차원의 interaction들은 FM 구조를 통해 모델화하고, 고차원의 interaction들은 DNN을 통해 모델화한다.<br />
2) <strong>DeepFM</strong>은 같은 Input과 Embedding 벡터를 공유하기 때문에 효과적으로 학습을 진행할 수 있다.<br />
3) 본 논문에서 <strong>DeepFM</strong>은 벤치마크 데이터와 상업용 데이터 모두에서 평가될 것이다.</p>

<hr />

<h3 id="12-our-approach">1.2. Our Approach</h3>
<p>$n$개의 instance를 가진 $(\chi, y)$ 학습 데이터셋이 있다고 하자. 이 때 $\chi$는 $m$개의 <strong>field</strong>를 지니고 있고, $y$는 0과 1의 값을 가진다. (1 = 클릭함)</p>

<p>$\chi$에는 범주형 변수가 있을 수도 있고, 연속형 변수가 있을 수도 있다. 범주형 변수의 경우 원핫인코딩된 벡터로 표현되며, 연속형 변수의 경우 그 값 자체로 표현되거나 이산화되어 원핫인코딩된 벡터로 표현될 수도 있다.</p>

<p>그렇다면 이제 데이터는 $(x, y)$로 표현할 수 있을 것이다. 여기서 $x$는 $[x_{field_1}, x_{field_2}, …, x_{field_m}]$의 구조를 갖게 되며 각각의 $x_{field_j}$는 $\chi$에서의 j번째 field의 벡터 표현을 의미하게 된다. 일반적으로 $x$는 굉장히 고차원이고 희소하다. CTR의 목적은 context가 주어졌을 때 사용자가 특정 어플을 클릭할 확률을 정확히 추정하는 것이다.</p>

<h4 id="121-deepfm">1.2.1. DeepFM</h4>
<center><img src="/public/img/Machine_Learning/2020-04-07-DeepFM/01.JPG" width="70%" /></center>

<p>위 그림에서도 확인할 수 있다시피, <strong>DeepFM</strong>은 2가지 요소로 구성되어 있다. 이 요소들은 같은 Input을 공유한다.</p>

<ul>
  <li>$i$번재 피쳐에 대해 스칼라 $w_i$: 1차원 importance를 측정함</li>
  <li>latent vector $V_i$: 다른 피쳐들과의 interaction의 영향을 측정</li>
</ul>

<p>$V_i$의 경우 FM요소에서는 2차원 interaction을 모델화하며, Deep요소에서는 고차원 피쳐 interaction을 모델화한다. 모든 파라미터들은 통합 예측모델에서 함께 학습된다. 즉 모델을 아주 간단히 표현하자면 아래와 같다.</p>

<script type="math/tex; mode=display">\hat{y} = sigmoid(y_{FM} + y_{DNN})</script>

<p><strong>FM Component</strong></p>
<center><img src="/public/img/Machine_Learning/2020-04-07-DeepFM/02.JPG" width="60%" /></center>

<p>FM요소는 Factorization Machine이다. FM모델에 대한 설명은 <a href="2019-12-21-FM.md">이글</a>에서 확인할 수 있다.</p>

<p><strong>Deep Component</strong><br />
CTR 예측에 사용되는 Raw 데이터는 일반적으로 매우 희소하고, 고차원이며, 범주형/연속형 변수가 섞여 있고, 일종의 field(성별, 위치, 나이 등)로 그룹화되어 있다는 특징을 지닌다. 따라서 <strong>Embedding Layer</strong>로 이러한 정보들을 압축하여 저차원의, dense한 실수 벡터를 만들어서 Input을 재가공할 필요가 있다.</p>

<p>아래 그림은 <strong>Input Layer</strong>에서 <strong>Embedding Layer</strong>로 이어지는 보조 네트워크를 강조한 부분이다. 여기서 확인해야 할 부분은 2가지이다. 첫 번재는, Input으로 쓰이는 Input field 벡터가 각자 다른 길이를 갖고 있을 수 있기 때문에, 이들의 임베딩은 같은 크기(<strong>k</strong>)여야 한다는 것이다. 두 번재는, FM 모델에서 latent 벡터로 기능했던 $V$는 본 요소에서는 Input field 벡터를 Embedding 벡터로 압축하기 위해 사용되고 학습되는 네트워크 weight가 된다는 것이다.</p>

<center><img src="/public/img/Machine_Learning/2020-04-07-DeepFM/06.JPG" width="60%" /></center>

<p><strong>Embedding Layer</strong>의 Output은 아래와 같다.</p>

<script type="math/tex; mode=display">a^0 = [e_1, e_2, ..., e_m]</script>

<ul>
  <li>$e_i$는 i번재 field의 Embedding</li>
  <li>$m$은 field의 수</li>
</ul>

<p>$a^{(0)}$는 DNN에 투입되며 forward process는 다음과 같다.</p>

<script type="math/tex; mode=display">a^{(l+1)} = \sigma{(W^{(l)}a^{(l)} + b^{(l)}})</script>

<ul>
  <li>$l$: layer의 깊이</li>
</ul>

<p>이렇게 Dense한 실수 피쳐 벡터가 생성되면 CTR prediction을 위해 최종적으로 sigmoid 함수에 투입되게 된다.</p>

<script type="math/tex; mode=display">y_{DNN} = \sigma{(W^{|H|+1} a^{|H|} + b^{|H| + 1}})</script>

<ul>
  <li>$ㅣHㅣ$: hidden layer의 수</li>
  <li>$ \vert H \vert $: hidden layer의 수</li>
</ul>

<center> (중략) </center>

<h4 id="15-conclusions">1.5. Conclusions</h4>
<p>DeepFM은 FM Component와 Deep Component를 함께 학습시킨다. 이러한 방식은 다음과 같은 장점을 지닌다.<br />
1) pre-training이 필요 없다.<br />
2) 저/고차원 feature를 모두 잘 학습한다.<br />
3) feature embedding을 통해 피쳐 엔지니어링이 불필요하다.</p>

<p>실험 결과를 확인하면, DeepFM이 최신 모델들을 압도하고 상당한 효율성을 지닌 것을 알 수 있다.</p>

<hr />

<h2 id="2-tensorflow-구현">2. Tensorflow 구현</h2>
<h3 id="21-데이터-설명-및-데이터-변환">2.1. 데이터 설명 및 데이터 변환</h3>
<p>구현의 핵심은 Parameter인 $w$와 $V$의 shape과 활용 방법에 대해 이해하는 것이다. 사실 구현하는 사람의 입장에서는 논문이 썩 친절하다고 느끼지는 못할 것이다. 다소 애매모호한 표현으로 읽는 사람으로 하여금 혼란을 일으키게 하는 문구나 그림 등도 존재한다. 그럼에도 침착하게 잘 생각해보면, 모델을 구축할 수 있을 것이다.</p>

<p>학습 데이터로는 연봉이 5만 달러를 상회하는지의 여부를 예측하는 데이터를 사용하였고, <a href="https://archive.ics.uci.edu/ml/datasets/Adult">여기</a>에서 다운로드 받을 수 있다.</p>

<p>데이터는 48,842개의 Instance로 구성되어 있고, 14개의 Feature를 갖고 있으며, 이 중 6개의 변수가 연속형 변수이다. 당연히 예측 과제는 <strong>Binary Classification</strong>이다. 0은 연봉 5만 달러 이하를 의미하며, 전체 데이터의 25% 정도를 차지한다. 1은 연봉 5만 달러 초과를 의미한다.</p>

<p>앞에서 설명한 데이터를 예로 들어 설명하도록 하겠다. 이 데이터에는 총 14개의 변수가 있다. 이 14개는 곧, field의 개수가 된다. 이 중 범주형 변수를 One-Hot 인코딩을 통해 변환시키면(물론 연속형 변수도 필요에 따라 구간화하여 범주형 변수화해도 된다.) 본 데이터는 총 108개의 칼럼을 갖게 된다. 이 108개는 곧, feature의 개수가 된다. 즉, One-Hot 인코딩을 통해 변환시킨 칼럼의 개수를 feature의 개수로, 인코딩 이전의 데이터의 칼럼의 개수를 field의 개수로 이해하면 쉽다. 논문에서는 임베딩 스킬을 이용하고 있는데, 여기서 Embedding Matrix인 $V$의 칼럼의 개수는 Hyperparameter이다.</p>

<p>본 프로젝트 파일은 다음과 같이 5개의 py파일로 구성되어 있다.</p>

<center><img src="/public/img/Machine_Learning/2020-04-07-DeepFM/07.JPG" width="25%" /></center>

<p>먼저 config파일을 보자. 이 파일에는 칼럼의 목록을 연속형/범주형을 구분하여 저장한 리스트와 Hyperparameter들이 저장되어 있다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># config.py
</span><span class="n">ALL_FIELDS</span> <span class="o">=</span> <span class="p">[</span><span class="s">'age'</span><span class="p">,</span> <span class="s">'workclass'</span><span class="p">,</span> <span class="s">'fnlwgt'</span><span class="p">,</span> <span class="s">'education'</span><span class="p">,</span> <span class="s">'education-num'</span><span class="p">,</span>
             <span class="s">'marital-status'</span><span class="p">,</span> <span class="s">'occupation'</span><span class="p">,</span> <span class="s">'relationship'</span><span class="p">,</span> <span class="s">'race'</span><span class="p">,</span>
             <span class="s">'sex'</span><span class="p">,</span> <span class="s">'capital-gain'</span><span class="p">,</span> <span class="s">'capital-loss'</span><span class="p">,</span> <span class="s">'hours-per-week'</span><span class="p">,</span> <span class="s">'country'</span><span class="p">]</span>
<span class="n">CONT_FIELDS</span> <span class="o">=</span> <span class="p">[</span><span class="s">'age'</span><span class="p">,</span> <span class="s">'fnlwgt'</span><span class="p">,</span> <span class="s">'education-num'</span><span class="p">,</span>
               <span class="s">'capital-gain'</span><span class="p">,</span> <span class="s">'capital-loss'</span><span class="p">,</span> <span class="s">'hours-per-week'</span><span class="p">]</span>
<span class="n">CAT_FIELDS</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">ALL_FIELDS</span><span class="p">)</span><span class="o">.</span><span class="n">difference</span><span class="p">(</span><span class="n">CONT_FIELDS</span><span class="p">))</span>

<span class="c1"># Hyper-parameters for Experiment
</span><span class="n">NUM_BIN</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">EMBEDDING_SIZE</span> <span class="o">=</span> <span class="mi">5</span>
</code></pre></div></div>

<p>이제 데이터를 가공할 시간이다. (데이터가 매우 커서 서버에서 데이터를 받아오는 상황이라면, 아래 코드를 pyspark로 짜면 좋을 것이다.) 지금부터 할 작업은 <code class="highlighter-rouge">field_index</code>와 <code class="highlighter-rouge">field_dict</code>를 만드는 것인데, 쉽게 말해서 아래와 같은 작업을 진행하는 것이다.</p>

<center><img src="/public/img/Machine_Learning/2020-04-07-DeepFM/05.JPG" width="100%" /></center>

<p>인코딩 이후의 데이터에 대해 각 칼럼이 본래 인코딩 이전에 몇 번째 field에 속했었는지에 대한 정보를 저장한 것이 <code class="highlighter-rouge">field_index</code>와 <code class="highlighter-rouge">field_dict</code>이다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Preprocess
</span><span class="kn">import</span> <span class="nn">config</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">repeat</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="k">def</span> <span class="nf">get_modified_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">all_fields</span><span class="p">,</span> <span class="n">continuous_fields</span><span class="p">,</span> <span class="n">categorical_fields</span><span class="p">,</span> <span class="n">is_bin</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">field_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="n">field_index</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">X_modified</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">all_fields</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"{} not included: Check your column list"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">col</span><span class="p">))</span>
            <span class="k">raise</span> <span class="nb">ValueError</span>

        <span class="k">if</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">continuous_fields</span><span class="p">:</span>
            <span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>

            <span class="c1"># 연속형 변수도 구간화 할 것인가?
</span>            <span class="k">if</span> <span class="n">is_bin</span><span class="p">:</span>
                <span class="n">X_bin</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">[[</span><span class="n">col</span><span class="p">]])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">NUM_BIN</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
                <span class="n">X_bin</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">X_bin</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">'str'</span><span class="p">)</span>

                <span class="n">X_bin_col</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">X_bin</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="n">col</span><span class="p">,</span> <span class="n">prefix_sep</span><span class="o">=</span><span class="s">'-'</span><span class="p">)</span>
                <span class="n">field_dict</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">X_bin_col</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
                <span class="n">field_index</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">repeat</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">X_bin_col</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
                <span class="n">X_modified</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_modified</span><span class="p">,</span> <span class="n">X_bin_col</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">X_cont_col</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">[[</span><span class="n">col</span><span class="p">]]),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
                <span class="n">field_dict</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">col</span>
                <span class="n">field_index</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
                <span class="n">X_modified</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_modified</span><span class="p">,</span> <span class="n">X_cont_col</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">categorical_fields</span><span class="p">:</span>
            <span class="n">X_cat_col</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">],</span> <span class="n">prefix</span><span class="o">=</span><span class="n">col</span><span class="p">,</span> <span class="n">prefix_sep</span><span class="o">=</span><span class="s">'-'</span><span class="p">)</span>
            <span class="n">field_dict</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">X_cat_col</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
            <span class="n">field_index</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">repeat</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">X_cat_col</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">X_modified</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_modified</span><span class="p">,</span> <span class="n">X_cat_col</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">'Data Prepared...'</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'X shape: {}'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">X_modified</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'# of Feature: {}'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">field_index</span><span class="p">)))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'# of Field: {}'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">field_dict</span><span class="p">)))</span>

    <span class="k">return</span> <span class="n">field_dict</span><span class="p">,</span> <span class="n">field_index</span><span class="p">,</span> <span class="n">X_modified</span>
</code></pre></div></div>

<h3 id="22-모델-빌드">2.2. 모델 빌드</h3>
<p>먼저 FM Component에 대해 살펴보자. <strong>call</strong> 함수에서 y_fm을 어떤 shape으로 반환할 지는 그 task에 맞게 변환하면 된다. 아래 코드에서는 (None, 2)의 형태로 반환되어 최종적으로 Deep Component의 (None, 2)와 합쳐져 (None, 4)의 최종 Output을 반환하게 되는데, 이 수치는 성능 향상을 위해 변경이 가능하다.</p>

<p>Parameter $w$의 길이는 <code class="highlighter-rouge">num_feature(108)</code>이며, Parameter $V$의 shape은 <code class="highlighter-rouge">num_field(14), embedding_size(5)</code>이다. 그런데 아래 <strong>call</strong> 함수에서 보면 알 수 있듯이, 이 $V$행렬은 One-Hot 인코딩된 데이터에 곱해지는 구조이기 때문에 <code class="highlighter-rouge">tf.nn.embedding_lookup</code>이라는 함수를 통해 행이 복제된다. 즉, 앞서 생성한 <code class="highlighter-rouge">field_index</code>의 정보를 참조하여, 같은 field에서 나온 feature일 경우, 같은 Embedding Row($V$의 Row)를 공유하는 것이다.</p>

<p><strong>new_inputs</strong>는 Deep Component의 Input으로 쓰일 개체이다. 코드를 살펴보면, $V$라는 행렬이 FM Component에도 쓰이지만, <strong>new_inputs</strong>를 만들어내면서 Deep Component에도 영향을 미치는 것을 알 수 있다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">FM_layer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_feature</span><span class="p">,</span> <span class="n">num_field</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">field_index</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FM_layer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span> <span class="o">=</span> <span class="n">embedding_size</span>    <span class="c1"># k: 임베딩 벡터의 차원(크기)
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_feature</span> <span class="o">=</span> <span class="n">num_feature</span>          <span class="c1"># f: 원래 feature 개수
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_field</span> <span class="o">=</span> <span class="n">num_field</span>              <span class="c1"># m: grouped field 개수
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">field_index</span> <span class="o">=</span> <span class="n">field_index</span>          <span class="c1"># 인코딩된 X의 칼럼들이 본래 어디 소속이었는지
</span>
        <span class="c1"># Parameters of FM Layer
</span>        <span class="c1"># w: capture 1st order interactions
</span>        <span class="c1"># V: capture 2nd order interactions
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="n">num_feature</span><span class="p">],</span>
                                              <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">'w'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">V</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">num_field</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">),</span>
                                              <span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s">'V'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="n">x_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_feature</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="c1"># Parameter V를 field_index에 맞게 복사하여 num_feature에 맞게 늘림
</span>        <span class="n">embeds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">V</span><span class="p">,</span> <span class="n">ids</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">field_index</span><span class="p">)</span>

        <span class="c1"># Deep Component에서 쓸 Input
</span>        <span class="c1"># (batch_size, num_feature, embedding_size)
</span>        <span class="n">new_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">x_batch</span><span class="p">,</span> <span class="n">embeds</span><span class="p">)</span>

        <span class="c1"># (batch_size, )
</span>        <span class="n">linear_terms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">multiply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w</span><span class="p">,</span> <span class="n">inputs</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

        <span class="c1"># (batch_size, )
</span>        <span class="n">interactions</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">subtract</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">new_inputs</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])),</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">new_inputs</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
        <span class="p">)</span>

        <span class="n">linear_terms</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">linear_terms</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">interactions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">interactions</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

        <span class="n">y_fm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">linear_terms</span><span class="p">,</span> <span class="n">interactions</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">y_fm</span><span class="p">,</span> <span class="n">new_inputs</span>
</code></pre></div></div>

<p>아래는 메인 모델에 대한 코드이다. 성능 향상을 위해 Deep Component를 수정하는 것은 연구자의 자유이다. Task에 따라 가볍게 설계할 수도, 복잡하게 설계할 수도 있을 것이다. 본 코드에서는 Dropout만을 추가하여 다소 가볍게 설계하였다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">layers</span> <span class="kn">import</span> <span class="n">FM_layer</span>

<span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">set_floatx</span><span class="p">(</span><span class="s">'float32'</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">DeepFM</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_feature</span><span class="p">,</span> <span class="n">num_field</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">field_index</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DeepFM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span> <span class="o">=</span> <span class="n">embedding_size</span>    <span class="c1"># k: 임베딩 벡터의 차원(크기)
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_feature</span> <span class="o">=</span> <span class="n">num_feature</span>          <span class="c1"># f: 원래 feature 개수
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">num_field</span> <span class="o">=</span> <span class="n">num_field</span>              <span class="c1"># m: grouped field 개수
</span>        <span class="bp">self</span><span class="o">.</span><span class="n">field_index</span> <span class="o">=</span> <span class="n">field_index</span>          <span class="c1"># 인코딩된 X의 칼럼들이 본래 어디 소속이었는지
</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fm_layer</span> <span class="o">=</span> <span class="n">FM_layer</span><span class="p">(</span><span class="n">num_feature</span><span class="p">,</span> <span class="n">num_field</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">field_index</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">final</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="s">"DeepFM Model: #Field: {}, #Feature: {}, ES: {}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_field</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_feature</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="c1"># 1) FM Component: (num_batch, 2)
</span>        <span class="n">y_fm</span><span class="p">,</span> <span class="n">new_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fm_layer</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="c1"># retrieve Dense Vectors: (num_batch, num_feature*embedding_size)
</span>        <span class="n">new_inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_inputs</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_feature</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_size</span><span class="p">])</span>

        <span class="c1"># 2) Deep Component
</span>        <span class="n">y_deep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers1</span><span class="p">(</span><span class="n">new_inputs</span><span class="p">)</span>
        <span class="n">y_deep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">y_deep</span><span class="p">)</span>
        <span class="n">y_deep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers2</span><span class="p">(</span><span class="n">y_deep</span><span class="p">)</span>
        <span class="n">y_deep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">y_deep</span><span class="p">)</span>
        <span class="n">y_deep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers3</span><span class="p">(</span><span class="n">y_deep</span><span class="p">)</span>

        <span class="c1"># Concatenation
</span>        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">y_fm</span><span class="p">,</span> <span class="n">y_deep</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">final</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">])</span>

        <span class="k">return</span> <span class="n">y_pred</span>
</code></pre></div></div>

<h3 id="23-학습">2.3. 학습</h3>
<p>학습 코드는 아래와 같다. 그리 무거운 모델은 아니므로 Autograph는 사용하지 않았다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">config</span>
<span class="kn">from</span> <span class="nn">preprocess</span> <span class="kn">import</span> <span class="n">get_modified_data</span>
<span class="kn">from</span> <span class="nn">DeepFM</span> <span class="kn">import</span> <span class="n">DeepFM</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">perf_counter</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.metrics</span> <span class="kn">import</span> <span class="n">BinaryAccuracy</span><span class="p">,</span> <span class="n">AUC</span>


<span class="k">def</span> <span class="nf">get_data</span><span class="p">():</span>
    <span class="nb">file</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'data/adult.data'</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="nb">file</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">13</span><span class="p">]</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="nb">file</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="mi">14</span><span class="p">]</span><span class="o">.</span><span class="nb">map</span><span class="p">({</span><span class="s">' &lt;=50K'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">' &gt;50K'</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span>

    <span class="n">X</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">ALL_FIELDS</span>
    <span class="n">field_dict</span><span class="p">,</span> <span class="n">field_index</span><span class="p">,</span> <span class="n">X_modified</span> <span class="o">=</span> \
        <span class="n">get_modified_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">ALL_FIELDS</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">CONT_FIELDS</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">CAT_FIELDS</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_modified</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">Y</span><span class="p">)</span>

    <span class="n">train_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span>
        <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span> \
        <span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">30000</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">BATCH_SIZE</span><span class="p">)</span>

    <span class="n">test_ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span>
        <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)))</span> \
        <span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">BATCH_SIZE</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">train_ds</span><span class="p">,</span> <span class="n">test_ds</span><span class="p">,</span> <span class="n">field_dict</span><span class="p">,</span> <span class="n">field_index</span>


<span class="c1"># Batch 단위 학습
</span><span class="k">def</span> <span class="nf">train_on_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">auc</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">binary_crossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">y_true</span><span class="o">=</span><span class="n">targets</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">)</span>

    <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">sources</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>

    <span class="c1"># apply_gradients()를 통해 processed gradients를 적용함
</span>    <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>

    <span class="c1"># accuracy &amp; auc
</span>    <span class="n">acc</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">auc</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">targets</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span>


<span class="c1"># 반복 학습 함수
</span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="n">train_ds</span><span class="p">,</span> <span class="n">test_ds</span><span class="p">,</span> <span class="n">field_dict</span><span class="p">,</span> <span class="n">field_index</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">()</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">DeepFM</span><span class="p">(</span><span class="n">embedding_size</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">EMBEDDING_SIZE</span><span class="p">,</span> <span class="n">num_feature</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">field_index</span><span class="p">),</span>
                   <span class="n">num_field</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">field_dict</span><span class="p">),</span> <span class="n">field_index</span><span class="o">=</span><span class="n">field_index</span><span class="p">)</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"Start Training: Batch Size: {}, Embedding Size: {}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">EMBEDDING_SIZE</span><span class="p">))</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">perf_counter</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="n">BinaryAccuracy</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">auc</span> <span class="o">=</span> <span class="n">AUC</span><span class="p">()</span>
        <span class="n">loss_history</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_ds</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">train_on_batch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">auc</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">loss_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">print</span><span class="p">(</span><span class="s">"Epoch {:03d}: 누적 Loss: {:.4f}, Acc: {:.4f}, AUC: {:.4f}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span>
            <span class="n">i</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_history</span><span class="p">),</span> <span class="n">acc</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">auc</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>

    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">BinaryAccuracy</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">test_auc</span> <span class="o">=</span> <span class="n">AUC</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">test_ds</span><span class="p">:</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">test_acc</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
        <span class="n">test_auc</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s">"테스트 ACC: {:.4f}, AUC: {:.4f}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">test_acc</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">test_auc</span><span class="o">.</span><span class="n">result</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Batch Size: {}, Embedding Size: {}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">EMBEDDING_SIZE</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"걸린 시간: {:.3f}"</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="s">'weights/weights-epoch({})-batch({})-embedding({}).h5'</span><span class="o">.</span><span class="nb">format</span><span class="p">(</span>
        <span class="n">epochs</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">EMBEDDING_SIZE</span><span class="p">))</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
    <span class="n">train</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</code></pre></div></div>

<p>Embedding Size를 변환하면서 진행한 테스트 결과는 아래와 같다. (Epoch: 100)</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Embedding Size</th>
      <th style="text-align: center">누적 Loss</th>
      <th style="text-align: center">Train ACC</th>
      <th style="text-align: center">Train AUC</th>
      <th style="text-align: center">Test ACC</th>
      <th style="text-align: center">Test AUC</th>
      <th style="text-align: center">시간</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">10</td>
      <td style="text-align: center">0.3243</td>
      <td style="text-align: center"><strong>0.8485</strong></td>
      <td style="text-align: center"><strong>0.9038</strong></td>
      <td style="text-align: center"><strong>0.8464</strong></td>
      <td style="text-align: center">0.8991</td>
      <td style="text-align: center">4분 0.78초</td>
    </tr>
    <tr>
      <td style="text-align: center">9</td>
      <td style="text-align: center">0.3386</td>
      <td style="text-align: center">0.8382</td>
      <td style="text-align: center">0.8954</td>
      <td style="text-align: center">0.8402</td>
      <td style="text-align: center">0.8975</td>
      <td style="text-align: center">4분 3.64초</td>
    </tr>
    <tr>
      <td style="text-align: center">8</td>
      <td style="text-align: center">0.3704</td>
      <td style="text-align: center">0.8240</td>
      <td style="text-align: center">0.8729</td>
      <td style="text-align: center">0.8260</td>
      <td style="text-align: center">0.8745</td>
      <td style="text-align: center">4분 2.79초</td>
    </tr>
    <tr>
      <td style="text-align: center">7</td>
      <td style="text-align: center">0.3248</td>
      <td style="text-align: center">0.8471</td>
      <td style="text-align: center">0.9033</td>
      <td style="text-align: center">0.8424</td>
      <td style="text-align: center">0.9013</td>
      <td style="text-align: center">4분 0.84초</td>
    </tr>
    <tr>
      <td style="text-align: center">6</td>
      <td style="text-align: center">0.3305</td>
      <td style="text-align: center">0.8433</td>
      <td style="text-align: center">0.9001</td>
      <td style="text-align: center">0.8416</td>
      <td style="text-align: center"><strong>0.9041</strong></td>
      <td style="text-align: center">4분 1.28초</td>
    </tr>
    <tr>
      <td style="text-align: center">5</td>
      <td style="text-align: center">0.3945</td>
      <td style="text-align: center">0.8169</td>
      <td style="text-align: center">0.8512</td>
      <td style="text-align: center">0.8190</td>
      <td style="text-align: center">0.8576</td>
      <td style="text-align: center">4분 8.10초</td>
    </tr>
  </tbody>
</table>

<hr />

<h2 id="reference">Reference</h2>
<p>https://github.com/ChenglongChen/tensorflow-DeepFM</p>

    </article>
    <div class="post-more">
      
      <a href="/machine_learning/2020/04/07/DeepFM/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/machine_learning/2020/04/07/DeepFM/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/machine_learning/2020/04/05/FFM/">
        추천 시스템의 기본 - 04. Field-aware Factorization Machines 설명 및 xlearn 실습
      </a>
    </h1>

    <span class="post-date">05 Apr 2020</span>
     |
    
    <a href="/blog/tags/#machine-learning" class="post-tag">Machine_Learning</a>
    
    <a href="/blog/tags/#recommendation-system" class="post-tag">Recommendation System</a>
    
    <a href="/blog/tags/#field-aware-factorization-machines" class="post-tag">Field-aware Factorization Machines</a>
    
    

    <article>
      <p>본 글의 전반부에서는 먼저 <strong>Field-aware Factorization Machines for CTR prediction</strong> 논문을 리뷰하면서 본 모델에 대해 설명할 것이다. 후반부에서는 간단한 xlearn코드 역시 소개할 예정이다. 논문의 전문은 <a href="https://www.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf">이곳</a>에서 확인할 수 있다.</p>

<hr />

<h2 id="1-field-aware-factorization-machines-for-ctr-prediction-논문-리뷰">1. Field-aware Factorization Machines for CTR prediction 논문 리뷰</h2>
<h3 id="10abstract">1.0.Abstract</h3>
<p>CTR 예측과 같은 크고 희소한 데이터셋에 대해 <strong>FFM</strong>은 효과적인 방법이다. 본 논문에서는 우리는 <strong>FFM</strong>을 학습시키는 효과적인 구현 방법을 제시할 것이다. 그리고 우리는 이 모델을 전체적으로 분석한 뒤 다른 경쟁 모델과 비교를 진행할 것이다. 실험에 따르면 <strong>FFM</strong>이 특정 분류 모델에 있어서 굉장히 뛰어난 접근 방법이라는 것을 알려준다. 마지막으로, 우리는 <strong>FFM</strong> 패키지를 공개한다.</p>

<h3 id="11-introduction">1.1. Introduction</h3>
<p>CTR 예측에 있어서 굉장히 중요한 것은, feature 간의 conjunction(결합, 연결)을 이해하는 것이다. Simple Logistic Regression과 같은 간단한 모델은 이러한 <code class="highlighter-rouge">결합</code>을 잘 이해하지 못한다. FM 모델은 2개의 Latent Vector의 곱으로 factorize하여 feature conjunction을 이해하게 된다.</p>

<p>개인화된 태그 추천을 위해 pairwise interaction tensor factorization (PITF)라는 FM의 변형 모델이 제안되었다. 이후 KDD Cup 2020에서, Team Opera Solutions라는 팀이 이 모델의 일반화된 버전을 제안하였다. 그러나 이 용어는 다소 일반적이고 혼동을 줄 수 있는 이름이므로, 본 논문에서는 이를 <strong>FFM</strong>이라고 부르도록 하겠다.</p>

<p><strong>FFM</strong>의 중요 특징은 아래와 같다.</p>
<ol>
  <li>최적화 문제를 해결하기 위해 Stochastic Gradient를 사용한다. 과적합을 막기 위해 오직 1 epoch만 학습한다.</li>
  <li>FFM은 위 팀에서 비교한 모델 6개 중 가장 뛰어난 성적을 보여주었다.</li>
</ol>

<hr />

<h3 id="12-poly2-and-fm">1.2. POLY2 and FM</h3>
<p>(중략)</p>

<hr />

<h3 id="13-ffm">1.3. FFM</h3>
<p><strong>FFM</strong>의 중요한 아이디어는 PITF로 부터 파생되었는데, 이는 바로 개인화된 태그에 관한 것이다. PIFT에서 그들은 <code class="highlighter-rouge">User, Item, Tag</code>를 포함한 3개의 가용 필드를 가정했고, 이를 분리된 latent space에서 (User, Item), (User, Tag), (Item,Tag)로 factorize하였다. 이러한 정의는 추천 시스템에 적합한 정의이고 CTR 예측에 있어서는 자세한 설명이 부족한 편이므로, 좀 더 포괄적인 논의를 진행해보도록 하겠다.</p>

<p>아래와 같은 데이터 테이블이 있을 때, <code class="highlighter-rouge">features</code>는 <code class="highlighter-rouge">fields</code>로 그룹화할 수 있다.</p>

<center><img src="/public/img/Machine_Learning/2020-04-05-FFM/01.JPG" width="70%" /></center>

<p>예를 들어, Espn, Vogue, NBC는 Publisher라는 field에 속할 수 있겠다. <strong>FFM</strong>은 이러한 정보를 활용하는 FM의 변형된 버전이다. <strong>FFM</strong>의 원리를 설명하기 위해, 다음 새로운 예시에 대해 생각해보자.</p>

<center><img src="/public/img/Machine_Learning/2020-04-05-FFM/02.JPG" width="60%" /></center>

<p>FM의 상호작용 항인 $\phi_{FM}(w, x)$는 아래와 같이 표현될 수 있다.</p>

<center><img src="/public/img/Machine_Learning/2020-04-05-FFM/03.JPG" width="60%" /></center>

<p>FM에서는 다른 feature들과의 latent effect를 학습하기 위해 모든 feature는 오직 하나의 latent vector를 가진다. Espn을 예로 들어보면, $w_{Espn}$은 Nike와 Male과의 latent effect를 학습하기 위해 이용되었다. 그러나 Nike와 Male은 다른 Field에 속하기 때문에 사실 (Espn, Nike)의 관계와 (Espn, Male)의 관계에서 사용되었던 $w_{Espn}$의 값은 다를 가능성이 높다. 즉, 하나의 벡터로 2개의 관계를 모두 표현하기에는 무리가 있다는 점이다.</p>

<p><strong>FFM</strong>에서는 각각의 feature는 여러 latent vector를 갖게 된다. <strong>FFM</strong>의 상호작용 항인 $\phi_{FFM}(w, x)$은 아래와 같이 표현된다.</p>

<center><img src="/public/img/Machine_Learning/2020-04-05-FFM/04.JPG" width="70%" /></center>

<p>수학적으로 재표현하면 아래와 같이 표현할 수 있겠다.</p>

<center><img src="/public/img/Machine_Learning/2020-04-05-FFM/05.JPG" width="60%" /></center>

<p>여기서 $f_1$과 $f_2$는 $j_1$과 $j_2$의 field를 의미한다. $j$들은 Espn, Nike 등을 의미한다. $f$를 field의 개수라고 할 때, FFM의 변수의 개수는 $nfk$이며, FFM의 계산 복잡성은 $O(\overline{n}^2 k)$이다.</p>

<p>여기서 <strong>n, f, k</strong>는 각각 feature의 개수(often called p), field의 개수, latent 변수의 개수를 의미한다.</p>

<p><strong>FFM</strong>의 경우 각각의 latent vector아 오직 특정 field와 관련한 효과에 대해서는 학습을 진행하기 때문에 잠재 변수의 수은 $k$는 FM의 경우보다 작은 경우가 많다.</p>

<script type="math/tex; mode=display">% <![CDATA[
k_{FFM} < k_{FM} %]]></script>

<hr />

<h4 id="131-solving-the-optimization-problem">1.3.1. Solving the Optimization Problem</h4>
<p>사실 FFM의 최적화 문제를 푸는 것은 Simple Logistic Regression의 최적화 문제를 푸는 식에서 $\phi_{LM}(w, x)$를 $\phi_{FFM}(w, x)$로 바꾸는 것을 제외하면 동일하다.</p>

<center><img src="/public/img/Machine_Learning/2020-04-05-FFM/06.JPG" width="60%" /></center>

<p>실험 결과에 그 이유가 나오지만, Stochastic Gradient 알고리즘으로 행렬 분해에 있어 효과적인 <code class="highlighter-rouge">AdaGrad</code>를 적용하였다. 각 SG 스텝마다 data point $(y, x)$는 $\phi_{FFM}(w, x)$ 식에서 $w_{j1, f2}, w_{j2f1}$를 업데이트하기 위해 추출된다. CTR prediction과 같은 문제를 푸는 데에 있어 $x$는 굉장히 희소한 벡터임을 기억하자. 따라서 실제로는 0이 아닌 값들에 대해서만 업데이트가 진행될 것이다.</p>

<p>sub-gradient는 아래와 같다.</p>

<center><img src="/public/img/Machine_Learning/2020-04-05-FFM/07.JPG" width="70%" /></center>

<p>d=1…k에 대해 gradient의 제곱합은 아래와 같이 합산된다.</p>

<center><img src="/public/img/Machine_Learning/2020-04-05-FFM/08.JPG" width="50%" /></center>

<p>최종적으로 $(w_{j1, f2})<em>d$과 $(w</em>{j2, f1})_d$ 는 아래와 같이 업데이트 된다.</p>

<center><img src="/public/img/Machine_Learning/2020-04-05-FFM/09.JPG" width="50%" /></center>

<p>여기서 $\eta$는 직접 정한 learning rate를 의미한다. $w$의 초깃값은 $[0, 1/\sqrt{k}]$ 사이의 Uniform Distribution 에서의 랜덤한 값으로 초기화된다. $G$는 $(G_{j1, f2})_d^{-\frac{1}{2}}$의 값이 매우 커지는 것을 막기 위해 모두 1로 세팅된다. 전체적인 과정은 아래와 같으며, 각 instance를 normalize해주는 것이 성능 향상에 도움이 되었다는 말을 남긴다.</p>

<center><img src="/public/img/Machine_Learning/2020-04-05-FFM/10.JPG" width="60%" /></center>

<hr />

<h4 id="132-parallelization-on-shared-memory-systems">1.3.2. Parallelization on Shared-memory Systems</h4>
<p>본 논문에서는 Hog-WILD!라는 병렬처리 기법을 사용하였다.</p>

<hr />

<h4 id="133-adding-field-information">1.3.3. Adding Field Information</h4>
<p>널리 사용되는 LIBSVM의 데이터 포맷은 다음과 같다.</p>

<p>label feat1:val1 feat2:val2 …</p>

<p>여기서 각 (feat, val) 쌍은 feature index와 value를 의미한다. <strong>FFM</strong>을 위해 우리는 위 포맷을 아래와 같이 확장할 수 있다.</p>

<p>label field1:feat1:val1 field2:feat2:val2 …</p>

<p>이는 적합한 field를 각 feature 마다 지정해주어야 함을 의미한다. 특정 feature에 대해서는 이 지정 작업이 쉽지만, 나머지들에 대해서는 그렇지 않을 수도 있다. 이 부분에 대해서는 feature의 3가지 종류의 관점에서 논의해보도록 하자.</p>

<p><strong>Categorical Features</strong><br />
선형 모델에서 categorical feature는 여러 개의 binary feature로 변환하는 것이 일반적이다. 우리는 다음과 같이 데이터 instance를 변형할 수 있다.</p>

<center><img src="/public/img/Machine_Learning/2020-04-05-FFM/11.JPG" width="55%" /></center>

<p>LIBSVM 포맷에서는 0의 값은 저장되지 않기 때문에 이렇게 모든 categorical feature들을 binary feature로 변형할 수 있는 것이다. 이제 위 데이터는 최종적으로 아래와 같은 형상을 갖게 된다.</p>

<center><img src="/public/img/Machine_Learning/2020-04-05-FFM/12.JPG" width="45%" /></center>

<p><strong>Numerical Features</strong><br />
conference에서 논문이 통과될지에 대한 데이터가 있다고 하자. 칼럼의 의미는 아래와 같다.</p>
<ul>
  <li>AR: accept rate of the conference</li>
  <li>Hidx: h-index of the author</li>
  <li>Cite: # citations of the author</li>
</ul>

<p>각 feature를 dummy field로 취급하여 아래와 같은 데이터 형상을 만들 수도 있지만, 이는 딱히 도움이 되지 않는 방법 같다.</p>

<p>Yes AR:AR:45.73 Hidx:Hidx:2 Cite:Cite:3</p>

<p>또 하나의 방법은, feature는 field에 넣고, 기존의 실수 값을 이산화하여 feature로 만든 후, binary하게 1과 0의 값을 넣어주는 방식이다.</p>

<p>Yes AR:45:1 Hidx:2:1 Cite:3:1</p>

<p>이산화 방법에 대해서는 여러가지 방식이 존재할 수 있다. 어떠한 방법이든 일정 수준의 정보 손실은 감수해야 한다.</p>

<p><strong>Single-field Features</strong><br />
일부 데이터 셋에 대해서 모든 feature가 단일 field에 속하여 각 feature에 대해 field를 지정해주는 것이 무의미한 경우도 있다. 특히 NLP와 같은 분야에서는 이러한 현상이 두드러진다.</p>

<center><img src="/public/img/Machine_Learning/2020-04-05-FFM/13.JPG" width="55%" /></center>

<p>위 경우에서 유일한 field는 “sentence”가 될 것이다. 일부 사람들은 numerical features의 경우처럼 dummy field를 만들면 어떨까 하고 의문을 가지지만, 사실 그렇게 되면 n(feature의 수)이 너무 커지기 때문에 굉장히 비효율적이다.</p>

<p>(<strong>FFM</strong>의 모델 크기가 $O(nfk)$임을 기억해보자. 이 경우에는 $f=n$이 될 것이다. (field의 수 = feature의 수))</p>

<hr />

<h4 id="14-experiments">1.4. Experiments</h4>
<p>(후략)</p>

<hr />

<h3 id="2-xlearn">2. xlearn</h3>
<h4 id="21-설치">2.1. 설치</h4>
<p>여러 가지 방법으로 설치를 진행할 수 있지만, <a href="https://github.com/aksnzhy/xlearn/releases">여기</a>에서 whl파일을 통해 설치하는 것이 가장 간단하다.</p>

<h4 id="22-코드">2.2. 코드</h4>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_convert_to_ffm</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="nb">type</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">numerics</span><span class="p">,</span> <span class="n">categories</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">encoder</span><span class="p">):</span>
    <span class="c1"># Flagging categorical and numerical fields
</span>    <span class="k">print</span><span class="p">(</span><span class="s">'convert_to_ffm - START'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">numerics</span><span class="p">:</span>
        <span class="k">if</span><span class="p">(</span><span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">encoder</span><span class="p">[</span><span class="s">'catdict'</span><span class="p">]):</span>
            <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'UPDATING CATDICT: numeric field - {x}'</span><span class="p">)</span>
            <span class="n">encoder</span><span class="p">[</span><span class="s">'catdict'</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">categories</span><span class="p">:</span>
        <span class="k">if</span><span class="p">(</span><span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">encoder</span><span class="p">[</span><span class="s">'catdict'</span><span class="p">]):</span>
            <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'UPDATING CATDICT: categorical field - {x}'</span><span class="p">)</span>
            <span class="n">encoder</span><span class="p">[</span><span class="s">'catdict'</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">nrows</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">)</span> <span class="o">+</span> <span class="s">"_ffm.txt"</span><span class="p">,</span> <span class="s">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">text_file</span><span class="p">:</span>

        <span class="c1"># Looping over rows to convert each row to libffm format
</span>        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">nrows</span><span class="p">)):</span>
            <span class="n">datastring</span> <span class="o">=</span> <span class="s">""</span>
            <span class="n">datarow</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">r</span><span class="p">]</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
            <span class="n">datastring</span> <span class="o">+=</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">datarow</span><span class="p">[</span><span class="n">target</span><span class="p">]))</span>  <span class="c1"># Set Target Variable here
</span>
            <span class="c1"># For numerical fields, we are creating a dummy field here
</span>            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">encoder</span><span class="p">[</span><span class="s">'catdict'</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
                <span class="k">if</span><span class="p">(</span><span class="n">encoder</span><span class="p">[</span><span class="s">'catdict'</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                    <span class="c1"># Not adding numerical values that are nan
</span>                    <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">datarow</span><span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">True</span><span class="p">:</span>
                        <span class="n">datastring</span> <span class="o">=</span> <span class="n">datastring</span> <span class="o">+</span> <span class="s">" "</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="s">":"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="s">":"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">datarow</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>

                    <span class="c1"># For a new field appearing in a training example
</span>                    <span class="k">if</span><span class="p">(</span><span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">encoder</span><span class="p">[</span><span class="s">'catcodes'</span><span class="p">]):</span>
                        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'UPDATING CATCODES: categorical field - {x}'</span><span class="p">)</span>
                        <span class="n">encoder</span><span class="p">[</span><span class="s">'catcodes'</span><span class="p">][</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
                        <span class="n">encoder</span><span class="p">[</span><span class="s">'currentcode'</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'UPDATING CATCODES: categorical value for field {x} - {datarow[x]}'</span><span class="p">)</span>
                        <span class="n">encoder</span><span class="p">[</span><span class="s">'catcodes'</span><span class="p">][</span><span class="n">x</span><span class="p">][</span><span class="n">datarow</span><span class="p">[</span><span class="n">x</span><span class="p">]]</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">[</span><span class="s">'currentcode'</span><span class="p">]</span>  <span class="c1"># encoding the feature
</span>
                    <span class="c1"># For already encoded fields
</span>                    <span class="k">elif</span><span class="p">(</span><span class="n">datarow</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">encoder</span><span class="p">[</span><span class="s">'catcodes'</span><span class="p">][</span><span class="n">x</span><span class="p">]):</span>
                        <span class="n">encoder</span><span class="p">[</span><span class="s">'currentcode'</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'UPDATING CATCODES: categorical value for field {x} - {datarow[x]}'</span><span class="p">)</span>
                        <span class="n">encoder</span><span class="p">[</span><span class="s">'catcodes'</span><span class="p">][</span><span class="n">x</span><span class="p">][</span><span class="n">datarow</span><span class="p">[</span><span class="n">x</span><span class="p">]]</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">[</span><span class="s">'currentcode'</span><span class="p">]</span>  <span class="c1"># encoding the feature
</span>
                    <span class="n">code</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">[</span><span class="s">'catcodes'</span><span class="p">][</span><span class="n">x</span><span class="p">][</span><span class="n">datarow</span><span class="p">[</span><span class="n">x</span><span class="p">]]</span>
                    <span class="n">datastring</span> <span class="o">=</span> <span class="n">datastring</span> <span class="o">+</span> <span class="s">" "</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="s">":"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">code</span><span class="p">))</span><span class="o">+</span><span class="s">":1"</span>

            <span class="n">datastring</span> <span class="o">+=</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span>
            <span class="n">text_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">datastring</span><span class="p">)</span>

    <span class="c1"># print('Encoder Summary:')
</span>    <span class="c1"># print(json.dumps(encoder, indent=4))
</span>    <span class="k">return</span> <span class="n">encoder</span>
</code></pre></div></div>

<p>위와 같이 LIBSVM 데이터 포맷으로 데이터를 변경한 후에,</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">xlearn</span> <span class="k">as</span> <span class="n">xl</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">xl</span><span class="o">.</span><span class="n">create_ffm</span><span class="p">()</span>

<span class="c1"># 학습/테스트 데이터 path 연결
</span><span class="n">model</span><span class="o">.</span><span class="n">setTrain</span><span class="p">(</span><span class="s">"data/train_ffm.txt"</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">setValidate</span><span class="p">(</span><span class="s">"data/test_ffm.txt"</span><span class="p">)</span>

<span class="c1"># Early Stopping 불가
</span><span class="n">model</span><span class="o">.</span><span class="n">disableEarlyStop</span><span class="p">()</span>

<span class="c1"># param 선언
</span><span class="n">param</span> <span class="o">=</span> <span class="p">{</span><span class="s">'task'</span><span class="p">:</span> <span class="s">'binary'</span><span class="p">,</span> <span class="s">'lr'</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s">'lambda'</span><span class="p">:</span> <span class="mf">0.00002</span><span class="p">,</span>
         <span class="s">'k'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s">'epoch'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span> <span class="s">'metric'</span><span class="p">:</span> <span class="s">'auc'</span><span class="p">,</span> <span class="s">'opt'</span><span class="p">:</span> <span class="s">'adagrad'</span><span class="p">,</span>
         <span class="s">'num_threads'</span><span class="p">:</span> <span class="mi">4</span><span class="p">}</span>

<span class="c1"># 학습
# model.fit(param=param, model_path="model/model.out")
</span>
<span class="c1"># Cross-Validation 학습
</span><span class="n">model</span><span class="o">.</span><span class="n">cv</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>

<span class="c1"># Predict
</span><span class="n">model</span><span class="o">.</span><span class="n">setTest</span><span class="p">(</span><span class="s">"data/test_ffm.txt"</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">setSigmoid</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="s">"model/model.out"</span><span class="p">,</span> <span class="s">"output/predictions.txt"</span><span class="p">)</span>
</code></pre></div></div>

<p>위와 같이 학습을 진행하면 된다. 간단하다.</p>

<hr />

<h2 id="reference">Reference</h2>
<p>https://wngaw.github.io/field-aware-factorization-machines-with-xlearn/</p>

    </article>
    <div class="post-more">
      
      <a href="/machine_learning/2020/04/05/FFM/#disqus_thread"> <i class="fa fa-comments" aria-hidden="true"></i>Comment</a>&nbsp;
      
      <a href="/machine_learning/2020/04/05/FFM/"><i class="fa fa-plus-circle" aria-hidden="true"></i>Read more</a>
    </div>
  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/blog/page2">Older</a>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>


  </div>
</div>

<label for="sidebar-checkbox" class="sidebar-toggle"></label>

<script>
  (function (document) {
    let toggle = document.querySelector('.sidebar-toggle');
    let sidebar = document.querySelector('#sidebar');
    let checkbox = document.querySelector('#sidebar-checkbox');

    document.addEventListener('click', function (e) {
      let target = e.target;

      if (target === toggle) {
        checkbox.checked = !checkbox.checked;
        e.preventDefault();
      } else if (checkbox.checked && !sidebar.contains(target)) {
        /* click outside the sidebar when sidebar is open */
        checkbox.checked = false;
      }
    }, false);
  })(document);
</script>

<script>
  (function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r;
    i[r] = i[r] || function () {
      (i[r].q = i[r].q || []).push(arguments)
    };
    i[r].l = 1 * new Date();
    a = s.createElement(o);
    m = s.getElementsByTagName(o)[0];
    a.async = 1;
    a.src = g;
    m.parentNode.insertBefore(a, m)
  })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

  ga('create', 'UA-00000000-1', 'auto');
  ga('send', 'pageview');
</script>


<!-- Naver Analytics -->	
<script type="text/javascript" src="//wcs.naver.net/wcslog.js"></script>
<script type="text/javascript">
  if(!wcs_add) var wcs_add = {};
    wcs_add["wa"] = "18cbce78e94161";
  wcs_do();
</script>

</body>

<script id="dsq-count-scr" src="//greeksharifa-github-io.disqus.com/count.js" async></script>

</html>
